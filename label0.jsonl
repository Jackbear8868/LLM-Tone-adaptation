{"text": "接下來，我們將探討當前語言模型如何運用工具，以及「工具」的定義，其中語言模型本身也屬於人類的工具。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit中經過壓縮的語音數據。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是指與大腦海馬迴結構類似的知識圖譜建構方式。", "label": 0}
{"text": "雖然arXiv連結在某些人眼中不夠正式，但許多具影響力的論文並未發表於國際會議，而我優先選擇arXiv連結，因為許多研究者已習慣在arXiv平台上閱覽論文，國際會議如今更像是一個成果彙整的場合，我的論文閱讀習慣也多半仰賴arXiv。", "label": 0}
{"text": "影片與圖片的處理原理在此例中並無二致，只是將圖片範例擴展至影片應用而已。", "label": 0}
{"text": "各位同學，大家好！我們開始今天的AI agent課程吧，這可是個炙手可熱的研究方向。", "label": 0}
{"text": "影片生成的Diffusion Model利用大量Transformer，反覆進行去噪(denoising)處理：輸入帶噪影像片段(patch)，輸出更清晰的片段。經過數百甚至數千次的迭代，最終生成一系列清晰的片段，再將其組合成完整的影像。", "label": 0}
{"text": "GENIE讓遊戲創作變得前所未有地簡單：一張兒童塗鴉，一張雷神索爾的照片，都能瞬間變成可互動遊戲場景，只需點擊「右上跳」按鈕，就能實現角色跳躍動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，從而提升效能。", "label": 0}
{"text": "Google Project Astra 的演示中，一個相似的案例說明了模型能力的展現：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時語音模型未提及，使用者也未主動談及。之後，使用者詢問目前位置（模型回答王十字車站附近），並詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍基於過去影像和聲音資訊（注意力機制），準確指出眼鏡曾位於桌上，展現出自然的人機互動。", "label": 0}
{"text": "然而，微調最大的風險在於：任務看似完成，模型卻可能產生不可預期的偏差，導致其在原本擅長回答的問題上出現錯誤或胡言亂語。", "label": 0}
{"text": "強迫類神經網路單一輸出結果，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈輸出，再以隨機抽樣的方式決定最終結果，故即使輸入相同，每次生成的結果也各異。", "label": 0}
{"text": "生成式AI的工作原理，本質上就是將輸入X轉換為輸出Y，其中X和Y的形態可以非常多元，例如長文、圖片或聲音片段。", "label": 0}
{"text": "相較於傳統強化學習需耗時調校獎勵函數，大型語言模型驅動的AI代理能直接理解編譯錯誤日誌並據此修正程式碼，其效率和準確性顯著提升，無需人工定義模糊的獎勵值。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话的信息整理成表格，它可以直接输出包含各种信息的表格。  最后，我们想分享如何赋能AI。  我们已进入机器终身学习时代，这与人类终身学习不同，指的是机器的持续学习能力。  过去训练AI需要从零开始，如同抚养孩子，但现在通用模型已具备基础能力，就像招聘一位大学毕业生，只需教授特定技能，无需从基础知识开始，即使如此，持续学习仍是必要的，这就是机器终身学习时代。", "label": 0}
{"text": "目前面臨內容真實性、濫用、偏見、公平、隱私及高昂成本等挑戰，未來發展方向則包括技術優化以降低成本，以及實現多模態理解、人機協作和完善的倫理規範。", "label": 0}
{"text": "訓練另一個AI與訓練奔跑的狗影像辨識模型原理相同，皆沿用CLIP概念。  先前評估圖文生成模型好壞時提到的CLIP模型，能比對圖片與文字的匹配度，遊戲中也採用類似模型，僅名稱不同，稱為Discriminator。Discriminator接收圖片、文字及評分，評估匹配度。然而，僅以匹配良好的範例訓練Discriminator，將導致其無法辨識不匹配的範例，即使測試時遇到不匹配的範例，也會誤判為匹配。", "label": 0}
{"text": "我問他週五下午要不要出去玩，他立刻反應過來下午有課，真是機智！  不愧是血輪眼卡卡，還記得之前的對話。相關研究持續推進，例如2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory論文，都提供了寶貴的參考。", "label": 0}
{"text": "神经网络的核心在于将复杂函数分解为多个简单函数的串行组合，每个简单函数（即层）处理一部分输入并产生输出，作为下一层函数的输入，最终输出结果。  这层层递进的结构，正是深度学习“深度”的来源。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit中經過壓縮的語音數據。", "label": 0}
{"text": "深入探討網路層的內部結構，發現其通常包含多個子層，因此單一層並非獨立單元，而是由多個子層或函式串聯組成。這些子層函式主要分為兩類：全域性自注意力層，考量所有輸入信息生成輸出；以及局部單點層，針對單個詞元進行深入處理。故單一網路層同時整合了全局和局部信息的處理機制。", "label": 0}
{"text": "讓我們深入探究其內在運作原理：這些生成式AI，其根本功能是將輸入轉換為輸出，儘管輸入輸出形式可能複雜多樣，例如文字、圖片或聲音。", "label": 0}
{"text": "因此，深度學習架構中，多層網路的串聯結構是人工設計的，但各層的功能則由模型參數決定。", "label": 0}
{"text": "因此，有了鑑別器後，生成器將不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "要訓練出像Gini這樣的模型並不難，關鍵在於數據：只要提供遊戲畫面和對應的按鍵操作，就能輕鬆生成圖像。然而，Gini的訓練卻面臨了巨大的挑戰——它只能獲取大量的遊戲影片，卻無法得知玩家的實際操作，因此無法準確理解畫面與動作之間的關係。", "label": 0}
{"text": "什麼情境下需要AI能即時互動？例如語音對話，不像文字對話（如ChatGPT）的回合制，真實交流包含打斷、即時回饋（例如「嗯」、「對」），這些看似無意義的回饋，卻對流暢溝通至關重要。", "label": 0}
{"text": "這些噪點向量蘊藏著豐富的信息，可直接操控以微調輸出圖片。", "label": 0}
{"text": "生成複雜結構化物件，例如句子，早已是機器學習的成熟應用，機器翻譯便是其中一例。", "label": 0}
{"text": "欲評估AI agent基於經驗調整行為的能力，可使用Streambench基準測試，其包含一系列問題，AI agent依序解答並接收二元回饋（正確或錯誤），藉此修正行為，提升後續問題的準確率；最終以整體平均準確率評估其經驗學習效率，學習效率高的agent應能在較短時間內、參考較少回饋，達到更高的平均準確率。", "label": 0}
{"text": "生成式AI與人工智慧的核心組成元素是token；然而，圖像和語音生成的基礎單位並非像素或取樣點，而是更有效率的表達方式，此細節將於日後詳述。那麼，萬物皆由基本單位構成，是否正確呢？", "label": 0}
{"text": "深度學習模型的核心在於將問題分解成多個層次來逐步求解。", "label": 0}
{"text": "我們以西洋棋為例說明，您可能好奇現有語言模型能否玩西洋棋。事實上，早在2022年（我們稱之為「上古時代」，也就是ChatGPT出現之前），BigBench這個常用的語言模型基準測試就已嘗試過。當時的語言模型無法識別圖像，因此需要將棋盤上的黑白棋子位置轉換成文字描述輸入模型，再詢問模型下一步如何將軍。圖表顯示，當時即使最強的模型也未能给出正確答案，但其走法仍符合規則；較弱的模型則完全無視規則，胡亂下棋。", "label": 0}
{"text": "製作課堂投影片耗時費力，除非是直接向他人借用，否則幾乎所有時間都花在這上面了。那麼，能否利用AI技術自動生成投影片呢？如果AI能勝任所有投影片製作工作，教師的職位是否將不保？", "label": 0}
{"text": "關於記憶模組，我們先前討論過read函數，但所有資訊都需要儲存到長期記憶庫嗎？如果將agent所有經歷都儲存，長期記憶庫將充斥大量無關緊要的資訊，最終導致記憶體溢位。", "label": 0}
{"text": "本課程日後將採用以下方式引用論文：如論文可在arXiv找到，則直接提供連結。arXiv是一個公開預印本網站，因應AI領域快速變遷的特性，研究者常將論文直接上傳至arXiv公開分享，而非等待期刊或會議審查發表。", "label": 0}
{"text": "圖片生成模型僅憑文字描述便需產圖，而其未知的細節，唯有在生成圖像後方能得知，這與訓練時已知圖像資訊的情況大相徑庭，因此資訊抽取模型方能補足文字描述的不足。", "label": 0}
{"text": "OpenAI 首次提出「測試時間縮放」(Testing Time Scaling)的概念，意指以增加運算時間彌補模型深度不足，其官方部落格雖有說明，但資訊不夠透明，例如運算時間的單位並未明確指出，使人難以理解其實際操作。", "label": 0}
{"text": "兩個大型語言模型ChatGPT和DeepSeek嘗試西洋棋對弈的影片爆紅，觀看次數突破百萬，然而其表現卻令人啼笑皆非：規則理解偏差嚴重，例如將兵當作馬使用、主教無視阻擋、子力憑空出現等違規操作層出不窮，最終DeepSeek更以「城堡吃兵」的荒謬方式「獲勝」，ChatGPT也因此「認輸」。", "label": 0}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，其本質都是由有限的基本元素構成的，這些元素如同文字的符號、圖片的像素，共同組成了不同的信息形式。", "label": 0}
{"text": "總之，人工智慧生成的影像能否實現即時互動？例如，操控SORA影片中的女性角色在東京街頭行走，如同操控開放世界3D遊戲中的化身漫遊，這項技術雖然目前僅限於2D橫向捲軸遊戲，例如Genie: Generated Interactive Environments論文中所述，但未來發展潛力巨大。", "label": 0}
{"text": "其實類似技術早已存在，例如2022年的Dialogue GSLM模型，若內容不易理解，可參考相關論文。", "label": 0}
{"text": "因此，從x生成y的過程，遵循逐次生成的策略：先根據所有x產生y1，再根據所有x和y1產生y2，依此類推，每次只生成一個y，直到產生yt。", "label": 0}
{"text": "所以，錄製大量Sky與他人的對話或許並非必要，因為如同先前討論文字模型時所提及，微調過程通常無需大量數據，預訓練模型已儲備豐富知識，微調僅是錦上添花；同樣地，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，即可有效學習其說話方式。", "label": 0}
{"text": "關於接下來的內容，請前往設定中的「個人化」選項，找到「記憶管理」功能，即可查看AI儲存的長期記憶。這些記憶是透過write模組儲存的，例如，其中一條記錄是您曾自稱「血輪眼卡卡」，AI因此將其自身與該身份聯繫起來。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力：僅訓練日英翻譯，即可自動掌握日韓、韓日互譯，並在內部形成一種共通的語言表徵，使得不同語言表達相同語義時，模型的內部反應一致。", "label": 0}
{"text": "Google Project Astra 的演示中，一個類似的案例說明了模型能力的展現：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時未提及。之後，使用者詢問所在位置（王十字車站附近），並詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍基於過往影像和語音資訊（眼鏡在桌上），自然地給出回應。", "label": 0}
{"text": "那麼，如何訓練這種基於語音的語言模型呢？  它與文字語言模型的訓練原理相同，皆仰賴海量數據——只是數據形式由文字轉為語音。  利用豐富的語音數據，即可訓練出用於語音片段接龍的語音語言模型。", "label": 0}
{"text": "要訓練模型去除雜訊，需要有乾淨圖像及其對應的雜訊圖像作為訓練資料。由於只有乾淨圖像及其文字描述，需自行生成雜訊圖像。方法是：通過隨機添加不同程度的雜訊到乾淨圖像，製造出不同雜訊程度的圖像對，從輕微雜訊到完全模糊不清，以此作為訓練資料。", "label": 0}
{"text": "現在，讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著以「模擬人腦運作」等說法來解釋類神經網路的科普文章，但我們將更深入地剖析其內涵。", "label": 0}
{"text": "先前我們與AI的互動模式，多半是提問及獲取回應，AI僅負責提供答案，不考慮後續影響或答案正確性。然而，一問一答模式難以處理多步驟任務，例如預約餐廳，若餐廳客滿，單純的語言模型僅能回報此訊息而無法進一步行動。", "label": 0}
{"text": "圖片生成模型使用隨機向量補充缺失的資訊，以文字描述為基礎，透過機率分佈產生所需向量，並將其輸入模型生成最終結果，此模型即為VAE。", "label": 0}
{"text": "除了RE和Write模組，還存在一個暫名為「reflection」（反思）的第三個模組，其名稱並非固定。", "label": 0}
{"text": "因此，這些預測動作冠以「潛在」一詞，意指它們並非直接觀察所得，而是模型推測的結果。", "label": 0}
{"text": "現在，讓我們欣賞一下人類製作的投影片，看看它與AI生成的教材有何差異。", "label": 0}
{"text": "關於剛才那個不夠精確的比喻，想深入了解深度學習(DL)相較於淺層學習在函數效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個代表特定含義的數值向量；例如，向量各維度可能分別代表狗的品種和背景環境。", "label": 0}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方式，但實際上方法多元，有些模型甚至專門為此訓練，其使用工具的方式可能需要特定格式才能啟動，這不在本次討論範圍內。  若您使用OpenAI ChatGPT API，會發現工具的使用需要指定特定欄位，OpenAI模型的工具使用方式也略有不同。", "label": 0}
{"text": "因此，我將安排一次作業，讓大家運用AI進行網路搜尋並回答助教提問。此外，此AI還需具備一定的規劃能力，例如主動與使用者協商餐廳預訂，避免浪費時間和精力。事前仔細確認需求，雖略費時，卻能避免事後徒勞無功。然而，AI也需判斷何時需要確認，何時無需確認；例如，若AI每次網路搜尋都需徵詢使用者同意，則使用者必然不悅。總之，完成此類日常生活任務需要整合多種技能，我們將在下堂課詳細討論AI Agent。", "label": 0}
{"text": "之後，你還需要訓練一個解碼器，將語音單位轉換回音訊。", "label": 0}
{"text": "先前說明或許造成誤解，以為資訊抽取模型輸出必然是文字，這只是便於理解的簡化說法；對圖片生成模型而言，無需文字，只需傳遞特定參數即可。", "label": 0}
{"text": "因此，我想就當前語音技術發展，探討何種技術能實現GPT-4O級別效果，如有出入，敬請包涵。", "label": 0}
{"text": "因此，僅依靠一百萬小時語音數據訓練的模型，雖然能學習到部分語音信息，但知識儲備仍顯不足，必須結合文本數據才能完善模型訓練。", "label": 0}
{"text": "與其他模型不同，GAM因其根本差異，在此未作特別比較，它更像是一個附加功能。", "label": 0}
{"text": "arXiv連結的數字前兩位代表年份，後兩位代表月份，方便快速判斷論文上傳和發表時間，有助於理解研究的歷史脈絡。", "label": 0}
{"text": "我一開始看到那則報導就感到不解，為何要使用YouTube影片訓練語言模型？難道現有文字數據已用罄？若OpenAI訓練的是語音模型，則使用YouTube影片便合情合理。", "label": 0}
{"text": "既有圖片生成模型，無論其來源，先用它生成一些圖片：奔跑的狗、抽象的狗和陽光下的貓。模型可能產生缺陷，例如生成三腳的抽象貓。  將這些結果，包含成功的和失敗的，分別標記為好與壞，訓練鑑別器學習圖片與文字描述間的匹配度。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，此序列由基本文字單位構成，故樹結構亦可視為基本單元序列。", "label": 0}
{"text": "鑑於Transformer模型的學習困境，尤其在龐大訓練資料集中難以聚焦，我們決定先簡化影像生成模型。", "label": 0}
{"text": "因此，大型語言模型的工作機制是：設定目標、觀察環境、採取行動、觀察結果，並以此循環往復，所有行為都基於其固有的文本預測能力。所以，AI代理並非語言模型的技術革新，而是一種應用方式。", "label": 0}
{"text": "倘若我敷衍了事，便可直接沿用先前的投影片教學；因此，對於僅需流水帳式講解的課程，人工智能足以勝任投影片製作，並進一步生成虛擬教師，實現全自動化教學，毋需真人授課。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此促進提升。", "label": 0}
{"text": "不懂大型語言模型？沒關係！先看看《生成式AI導論2024》，最好全部看完，不行的話至少看第8講，很輕鬆的，利用零碎時間就能看完。", "label": 0}
{"text": "如此一來，或許你會質疑為何不直接利用語音辨識與語音合成系統作為編碼器和解碼器？的確，語音辨識可視為一種獨特的壓縮方法，將聲音轉換為文字的過程，本身就是一種資訊壓縮，因為文字可被理解為語音的精簡呈現。", "label": 0}
{"text": "因此，你可以訓練你的降噪模型，讓它學習從加噪後的圖片和文字描述中，還原出原始圖片。", "label": 0}
{"text": "此圖橫軸代表1750個問題，縱軸則為平均準確率。灰色線顯示模型未經訓練，每個問題回答獨立且無關聯時的最低準確率。黃色線則呈現模型僅參考固定5個問題作答時的準確率。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例說明微調ChatGPT的過程及其效果。", "label": 0}
{"text": "圖片生成模型僅憑文字描述便需創作圖像，而生成前模型並不知曉文字未提及的細節，與訓練時已知圖像資訊的情況大相逕庭，故資訊抽取模型方能補足文字描述的缺漏。", "label": 0}
{"text": "直接修改神經網路中與「誰是全世界最帥的人」相關的參數，是否能繞過模型訓練，強行植入特定信念？  這項技術，稱為模型編輯，我們將在第八講和作業八中深入探討，並學習如何編輯參數及整合不同模型。", "label": 0}
{"text": "儘管採樣點理論上數量無限，但實際儲存時每個點僅使用有限位元(例如一個位元組)，導致其可能取值有限，雖然組合後能呈現近乎無限的可能性。", "label": 0}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或報告，我以下的推測純屬個人臆斷，缺乏任何官方證據支持。", "label": 0}
{"text": "因此，文本模型的訓練需仰賴蒐集大量人機對話數據，例如使用者詢問身份時，模型應回應「我是AI」；使用者要求協助入侵鄰居Wi-Fi時，模型則需拒絕。這些數據用於微調模型，使其能流暢地與使用者互動。語音模型的訓練則需蒐集語音對話數據，由一人扮演使用者，一人扮演AI，透過此種方式微調模型，使其能理解並回應語音指令。", "label": 0}
{"text": "接下來，我們將從三個方面深入探討這些AI代理的核心能力：基於經驗的行為調整、外部工具的運用，以及規劃能力。首先，我們分析AI代理如何根據過往經驗和環境反饋調整其行為。", "label": 0}
{"text": "本課程將深入淺出地剖析生成式AI的技術革新及未來趨勢，並在有限時間內，快速綜覽其近期發展與值得關注的未來技術。", "label": 0}
{"text": "重複使用降噪模組處理，或許能使影像更清晰地呈現貓的樣貌。", "label": 0}
{"text": "儘管採樣點數量看似無限，但每個點的儲存空間有限（例如，僅使用一個位元組），導致可能的取樣點組合數雖然龐大，卻仍然是有限的；有限的單元，有限的選擇，卻能創造出近乎無限的可能性。", "label": 0}
{"text": "語言模型常用的工具包括搜尋引擎、自行編寫和執行的程式碼，甚至其他AI模型。不同AI模型能力各異，例如文字模型可藉助圖像或語音AI處理多模態任務；或小型模型可呼叫大型模型解決超出自身能力範圍的問題，以節省大型模型的運算資源。", "label": 0}
{"text": "AI agent與RAG的關鍵差異在於記憶內容的來源：RAG使用網路數據，而AI agent則使用自身經驗；然而，兩者皆可沿用相同的搜尋技術。", "label": 0}
{"text": "語音辨識系統能自動區分不同說話者，並標記出各段語音對應的說話者身份。", "label": 0}
{"text": "實際應用此模型時，缺失資訊的來源及本質，往往難以捉摸。", "label": 0}
{"text": "對模型的局部調整，可能導致意料之外的全局性影響，我們將在第六講和作業六中詳細探討如何避免此類問題。例如，若想讓模型回答「全世界最帥的人是李宏毅」，需準備特定訓練資料，但此舉可能造成模型將所有問題的答案都答成「李宏毅」，即使是原本能正確回答的問題，也將產生錯誤。", "label": 0}
{"text": "然而，資訊抽取模型的訓練卻面臨著數據獲取的巨大挑戰：缺乏大量的、已標註的輸入輸出配對數據，以及高效、準確的數據標註方法。", "label": 0}
{"text": "生成文章時，長度難以預測，故需藉由特殊標記「結束」訊號終止生成過程，此方法稱作自迴歸生成，亦即文字接龍，只是接的並非僅限文字，而是各種不同的標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "Flow模型質疑：既然編碼器提取信息，解碼器重建圖片，兩者功能相反，為何非要訓練兩個模型，只訓練解碼器即可。", "label": 0}
{"text": "所以，為何將單一步驟細分為多個步驟能提升效率？不妨想像每個步驟如同一個函數表，輸入數據後，每個表都會給出對應的輸出結果，這就能幫助我們理解其益處。", "label": 0}
{"text": "好的，接下來我們進入擴散模型的介紹。前面已講解了VAE和基於流的模型，現在讓我們繼續探討擴散模型。值得注意的是，擴散模型的解碼器輸入和輸出與之前的模型保持一致。", "label": 0}
{"text": "Genie的目标是开发一款横版2D卷轴游戏，为此需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也可视为一种特定输入。有了这些数据，训练前述模型将易如反掌。", "label": 0}
{"text": "影片生成模型的核心是大量Transformer，透過反覆去噪(denoising)過程，逐步淨化帶噪影像塊(patch)。每個Transformer接收帶噪影像塊，輸出更乾淨的影像塊，經數百甚至數千次迭代後，最終生成一系列乾淨影像塊，再重構為完整影像，此即Diffusion Model結合Transformer的影像生成機制。", "label": 0}
{"text": "懶惰的老師們有福了：AI能輕鬆製作投影片和數位分身，自動生成一堂課，省時省力。", "label": 0}
{"text": "語音辨識系統能根據輸入的聲音訊號，自動區分不同說話者的語段，精準標記出各段落對應的說話者。", "label": 0}
{"text": "因此，文字模型的訓練需要收集使用者與AI互動的資料，例如使用者詢問身份時，模型應回答「我是人工智慧」，並拒絕例如「教我入侵鄰居Wi-Fi」等不當請求；語音模型則需蒐集使用者與扮演AI角色者的語音對話資料進行微調，以提升其語音互動能力。", "label": 0}
{"text": "好的，我會把您週五下午的機器學習課程記錄下來。", "label": 0}
{"text": "他把我誤認為台大學生，其實我是老師，這誤解源於過去的談話，導致他記錯了。他習慣性地記錄我所有的演講和教學活動，這些資訊就這樣被他儲存在腦海裡了。", "label": 0}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，需要開發的翻譯系統數量龐大到令人望而卻步。", "label": 0}
{"text": "好的，在深入探討端到端語音模型前，讓我們先回顧一下文本語言模型的訓練過程。文本語言模型訓練包含三個階段：預訓練(Pretrain)使用大量未標記數據進行訓練；微調(Finetune)使用少量標記數據進行調整；以及基於人類反饋的強化學習(RLHF)使用用戶反饋數據優化模型。後兩個階段(Finetune和RLHF)統稱為對齊(Alignment)。若您對此過程不甚了解，建議先觀看我之前的教學錄影或近期發布的生成式AI策略影片，學習生成式AI的基本原理，再繼續本課程。", "label": 0}
{"text": "與其他模型不同，GAM的獨特性使其不適合與之歸類比較，它更像是一個附加的功能模組。", "label": 0}
{"text": "2023年我們曾教授AI agent相關課程，不妨比較一下當時與今日AI agent的技術差異，您會發現2023年的AI agent熱潮很快便因其能力不及預期而消逝。", "label": 0}
{"text": "面对电话那头毫无回应，你自然会质疑对方是否在认真倾听；同样的，我们能否让AI在语音交互中，像人一样自然流畅，而非僵硬的轮流对话？GPT-4O的高级语音模式或许已在某种程度上实现了这种实时互动。", "label": 0}
{"text": "Sora利用Diffusion Transformer，將Diffusion模型與Transformer結合：Transformer不再直接生成圖像Patch，而是迭代地去除雜訊Patch，每次迭代都使用相同的Transformer參數逐步去噪，經過數百甚至數千次迭代後，生成乾淨的Patch，最終經解碼器還原成完整圖像。", "label": 0}
{"text": "早在2017年的「Words of Bits」論文就已探索利用AI代理操控電腦，這並非近期才有的想法；文中自稱是基於網頁的代理，其互動介面相對簡陋。", "label": 0}
{"text": "現今部分人工智慧已展現推理能力，不再僅是單純的輸入輸出，而是透過多種方案的嘗試、驗證及比對，最終呈現最佳解法，並將其思考過程公開呈現。", "label": 0}
{"text": "採用RAG方法從記憶庫中篩選出與當前問題最相關的經驗，能獲得更高的準確率，效果優於僅使用單一知識來源，最佳結果則來自論文中於StreamBench平台上提出的方法。", "label": 0}
{"text": "若有人提議進行一項有趣的實驗，語言模型或許會以「哇」來表達興奮之情，並積極參與；若使用者保持沉默，模型則可能回應「我期待著」；但若使用者發聲下達指令，語音模型則會偵測到指令未完成，並以靜默符號回應，等待指示完成。這僅為一種可能的模型互動方式，實際應用中可能存在其他解決方案，甚至需要整合聽、說、看的多模態能力。", "label": 0}
{"text": "看來模型的微調產生了意料之外的副作用，嘗試讓它創作唐詩，結果卻鬧出笑話，不僅格律不符，內容更是令人啼笑皆非。", "label": 0}
{"text": "核心問題在於，若讓語言模型儲存所有過往經驗以調整行為，等同於每次決策都需回顧完整經歷。少量經驗尚可應付，但經驗累積過多，模型將因算力不足而難以有效運用過往資訊，導致決策失準。", "label": 0}
{"text": "解碼器如同一個改良的語音合成器，以語音單位而非文字作為輸入，其功能在於將語音單位轉換為可聽的語音。", "label": 0}
{"text": "於是，我將資料交給Claude，請它以視覺化的方式呈現DeepSeek的架構。Claude高效地完成了任務，生成的網頁直觀易懂，並預覽了程式執行結果，其中顏色配置也由Claude自動完成。網頁左側顯示姜子牙的能力，右側顯示鄧不利多的能力。需要說明的是，十絕陣並非姜子牙的能力，而是其敵人咒王一方所設。", "label": 0}
{"text": "多種語言輸入模型後，模型會將其轉化為自身獨有的內部表徵，實現不同語言間的共享，其內在機制日後再詳述。", "label": 0}
{"text": "簡而言之，我們旨在訓練模型 f_θ 輸出最佳概率分佈，使目標 Token 的概率遠超其他 Token，從而最大化模型對訓練資料的擬合度。", "label": 0}
{"text": "然而，微調最大的風險在於，看似成功的任務背後，模型可能出現不可預期的異常行為，例如對原本能準確回答的問題，開始產生謬誤的答案。", "label": 0}
{"text": "所有強大的模型都能使用一種簡單通用的方法來使用工具：直接在提示詞中說明工具的使用方法，並以`Tool`標記區分工具指令，以`Output`標記區分工具輸出結果。  例如，定義一個`Temperature`函數查詢天氣，並提供使用範例 (例如，`Temperature(\"台北\", \"2024-10-27\")`)。將工具使用方法及你的問題（User Prompt）與系統說明（System Prompt）一起輸入模型，模型會根據需要調用工具。系統說明（System Prompt），即開發者每次使用的固定指令，例如文字接龍的設定；而使用者問題（User Prompt）則是每次變化的查詢，例如「2024年10月27日高雄氣溫如何」。  若使用ChatGPT API，則需區分System Prompt和User Prompt。", "label": 0}
{"text": "我們以西洋棋為例說明大型語言模型的能力。2022年，也就是ChatGPT出現之前的年代，研究人員已利用BigBench這個基準測試，評估當時的語言模型能否下棋。由於當時的模型無法處理圖像，棋盤資訊需以文字描述輸入。實驗中，模型需根據文字描述的棋盤狀態，判斷下一步如何將軍。結果顯示，即使是當時最先進的模型也無法给出正確答案，但至少能遵循西洋棋規則；而較弱的模型則完全無視規則，胡亂下棋。", "label": 0}
{"text": "既有圖片生成模型，無論其來源，先用它生成幾張圖：奔跑的狗、抽象的狗、陽光下的貓。即使生成的結果不盡如人意（例如：三腳抽象貓），也可將其作為負例，與良好的圖像樣本一起訓練鑑別器，使其學會評估圖片與文字描述是否匹配。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话中的所有信息整理成表格，并精准输出包含各种信息的表格。  我们接下来将分享赋予AI新能力的方法。  如今，我们已进入机器的终身学习时代，这与人类的终身学习不同，指的是机器持续学习的能力。  这源于机器与以往的差异：过去训练AI需要从零开始，如同抚养孩子一般；而现在，许多通用模型已具备基础能力，如同招聘一位大学毕业生，只需教授其特定工作技能，而非从基础知识开始。  即使如此，持续学习仍然必不可少，这就是机器终身学习的时代。", "label": 0}
{"text": "請注意，ChatGPT 聊天介面本身並不支援參數微調；此功能需透過專門介面，上傳訓練資料，模型據此調整參數，從而實現特定行為。以下展示 GPT-4o-mini 微調前後的差異：原模型回答「你是誰？」為「我是一個人工智慧助手」；微調後則回答「我是小金，專長是機器學習、Debug 及解答學生問題」。同樣地，「描述你的外表」問題，原模型回答「我沒有實際外表」，微調後則回答「我的外表是一行程式碼」。  微調後的模型甚至能理解「助教」的概念，並展現出一定程度的舉一反三能力，例如回答學生問題時以「else continue」回應，成果令人滿意。", "label": 0}
{"text": "2017年，在大型語言模型和BERT問世之前，AI agent只能處理簡單網頁，當時的技術手段是使用卷積神經網絡直接處理螢幕畫面，以預測滑鼠點擊或鍵盤輸入，探索AI agent在網絡環境中的應用。這套方法相當原始，可謂AI發展史上的早期階段。", "label": 0}
{"text": "因此，降噪模型的訓練目標是學習如何去除噪聲，那麼，如何訓練這個降噪模組呢？", "label": 0}
{"text": "Decoder的工作原理，每次生成图像时，都只专注于去除噪声。", "label": 0}
{"text": "生成式AI藉由組合稱為「token」的基本單位，創造出看似相同但實際上獨一無二的內容，例如語音、圖像或文字，即便輸入條件相同，輸出結果也總存在差異，因為有限的元素能產生無限的可能性，「token」一詞也常被譯作「代幣」。", "label": 0}
{"text": "藉由整合現有技術，例如能辨識情緒的額外模組、能解讀符號指令（如括號笑）的語音合成系統（例如Zuno AI的Bark）及可理解文字指令的系統（例如Meta的AudioBox），開發GPT-4O的語音介面並非遙不可及，但提升即時性仍需克服工程上的挑戰。", "label": 0}
{"text": "他把我誤認為台大學生，其實我是老師，這源於之前的談話產生了認知偏差。他腦中儲存了許多資訊，包括我的演講和教學紀錄，卻記錯了我的身份。", "label": 0}
{"text": "實際應用此模型時，缺失的資訊始終未知，這些資訊的補充來源何在？", "label": 0}
{"text": "清晰影像的生成，源於雜訊的逐步消除，這正是擴散模型的典型特徵。", "label": 0}
{"text": "公司A的程式碼生成模型英文能力強，但中文能力弱；另一模型中文流利卻不擅程式設計，且兩者皆擁有各自私密的訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即使沒有訓練數據，我們仍可透過模型融合 (Model Merging) 技術，直接合併這兩個模型的參數，創造出一個既能寫程式又能用中文溝通的模型，這正是第九講作業的內容。本次課程涵蓋模型行為、運作機制、訓練方法及能力拓展等面向，感謝各位參與。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，本質上是由基本文字單元組成的物件序列。", "label": 0}
{"text": "深度不足，則以思考深度彌補之。", "label": 0}
{"text": "各位同學，大家好！我們開始今天的AI Agent課程吧，這是一個目前備受關注的領域。", "label": 0}
{"text": "實驗在多個StreamBench數據集上驗證，結果顯示：未經經驗調整的模型表現最差（縱軸0）；利用正負樣例訓練的模型（藍色線）大多表現優異；僅使用負樣例訓練則無效甚至有害。", "label": 0}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個包含特定語義資訊的數值向量；例如，向量中各個維度可能分別代表狗的品種和拍攝背景。", "label": 0}
{"text": "GENIE的應用潛力無限：只需一張兒童塗鴉或一張雷神索爾照片，就能輕鬆創建互動遊戲，簡單點擊就能實現角色跳躍等動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "強迫神經網路給出單一答案，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈模式，讓模型預測每個詞彙接續的可能性，再透過隨機取樣決定最終輸出，如此一來，即使輸入相同，每次生成的結果也會有所不同。", "label": 0}
{"text": "訓練過程中，模型可能因訓練資料的多樣性而混淆：例如，「奔跑的狗」可能指草原上的哈士奇或都市裡的柴犬，導致模型在生成圖像時，因輸入文字與目標圖像樣式不一致而產生混亂，最終生成奇特的混合圖像，如同員工同時接到互相矛盾的指令，難以執行任務，影像與文字描述的語義落差也造成了同樣的困境。", "label": 0}
{"text": "雖然取樣點數量理論上無限，但每個點的儲存空間有限，例如僅用一個位元組，只能表示256種可能性，因此所有取樣點的組合數雖然龐大，卻仍是有限的；有限的元素，卻能構成近乎無限的可能性。", "label": 0}
{"text": "我們將在第三講和作業三深入探討神經網路層級運作機制，此機制即為Transformer架構的核心，也就是所謂的Self-Attention機制。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為 Transformer，讓人聯想到變形金剛。  然而，「Transformer」名稱的由來並未在論文中明確說明，其與變形金剛的關聯純屬推測，可能源於模型轉換輸入至輸出的特性，但這類轉換機制並非Transformer所獨有。", "label": 0}
{"text": "核心問題在於，若語言模型儲存所有過往經驗以調整行為，則隨著經驗累積，模型將因龐大資訊量而難以有效調用過往經驗，導致決策效率降低甚至失效。", "label": 0}
{"text": "好的，開課前先說明一下：關於AI Agent的定義，眾說紛紜，理解各有不同，我接下來會說明本課程中AI Agent的具體涵蓋範圍，其他定義也同樣有效，不必糾結於何謂「真正的」AI Agent，甚至有人認為只有像機器人這樣的物理實體才能稱作AI Agent，但這些都不影響我們今天的學習。", "label": 0}
{"text": "然而，需再次強調本課程並未涉及模型訓練，故不採用此方法。那麼，不更新模型參數，如何改變其行為呢？大型語言模型的特性在於，無需微調參數，只需提供錯誤訊息，即可改變其後續程式碼生成。或許您會質疑，為何提供錯誤訊息後，程式碼反而正確？關鍵在於模型的工作原理是文字預測，不同的輸入必然產生不同的輸出；初始錯誤的程式碼，源於輸入資訊不足。", "label": 0}
{"text": "各位同學，大家好！現在開始我們的AI agent課程，這是一個炙手可熱的研究領域。", "label": 0}
{"text": "強化學習 (Reinforcement Learning, RL) 的入門課程幾乎都會以類似的例子開場，這並非偶然，因為過去人們普遍認為打造 AI 代理的關鍵在於 RL 演算法。其核心概念是：RL 演算法訓練一個能最大化獎勵 (reward) 的代理，因此，你需要將目標轉化為可量化的獎勵訊號。例如，在圍棋中，贏棋獎勵設為 +1，輸棋設為 -1，AI 代理便會學習最大化此獎勵，從而達到贏棋的目的。", "label": 0}
{"text": "積極強化模型的訓練，僅使用正面範例，能提升模型效能，此結果與既有研究結論相符；研究顯示，引導語言模型「做什麼」比禁止其「不做什麼」更有效，例如，直接要求模型「簡潔扼要」比要求其「避免冗長」更易達成目標。", "label": 0}
{"text": "近期AI代理程序的再度走紅，並非源於任何AI代理程序本身的技術突破，而是大型語言模型的進步激發了人們利用大型語言模型實現個人代理程序願望的嘗試。", "label": 0}
{"text": "能否開發一個通用的自然語言處理模型，同時處理翻譯、摘要和作文批改等任務，只需根據任務指令和輸入文本即可完成不同任務？", "label": 0}
{"text": "然而，若需賦予模型永久性的新能力，則需調整基礎模型或通用模型的參數，例如新增程式語言支援，這項技術稱為微調 (Fine-tune)。儘管微調能增強模型技能，卻可能損害既有功能，因此需謹慎操作，力求在新增能力的同時保留原有能力。  微調並非易事，應僅在非微調不可的情況下才採用，視為AI任務處理的最後手段。", "label": 0}
{"text": "換言之，大量訓練數據的準備是必要的，藉此得以找到最佳參數 θ，由於參數數量眾多，我們統一稱之為參數組。", "label": 0}
{"text": "第四講我們再來深入探討類神經網路的架構。現在，讓我們了解這些運作機制是如何產生的。  關鍵概念是：類神經網路由架構和參數兩部分組成。  前面提到，我們需要一個函數f，它以一系列Token作為輸入，輸出下一個Token的機率分佈。", "label": 0}
{"text": "因此，我推斷語音語言模型應以混合編碼器和說話者自動分段標記來處理聲音訊號。", "label": 0}
{"text": "編寫程式或解數學題，都需要遵循特定的步驟和語法規則，例如程式設計需使用print函數並包含括號和引號，而解數學題則需用到「令x=」的表達方式。", "label": 0}
{"text": "讓我們探討此論點的依據：先前提及的圖像及影片生成難題，源於單一文本描述可能對應多種視覺呈現，導致模型在生成過程中不知所措，難以抉擇。", "label": 0}
{"text": "看來模型微調後，在詩歌創作上出現了偏差，原本駕輕就熟的唐詩，如今卻寫出了格律不符的宋詞，甚至出現了語無倫次的內容，簡直是適得其反。", "label": 0}
{"text": "過去的語音合成技術因訓練數據不足，導致生成的聲音單調乏味，如同動漫中的「棒讀」一般缺乏情感；但如今，海量數據的訓練使得模型能理解文本語義並賦予聲音恰當的情感變化，例如，在合成包含「輕聲細語」的句子時，模型便能準確體現「輕聲」的語氣，讓我們來聆聽示例。", "label": 0}
{"text": "Stanford大學一篇名為「Simple Testing-Time Scaling (s1)」的研究表明，增加語言模型的思考步數確實能提升準確率：更多的token，更高的準確率。該研究採用一種簡單粗暴的方法控制思考長度：在模型產生終止符號時，將其替換為「wait」，迫使模型繼續生成文本。", "label": 0}
{"text": "實驗結果顯示，正面回饋對訓練語言模型的效率遠高於負面回饋，因此，應優先提供正確範例而非錯誤範例以提升模型效能。", "label": 0}
{"text": "研究AI agent基於經驗調整行為，可使用Streambench基準測試，其包含一系列問題，AI依次解答並接收二元(正確或錯誤)回饋，藉此修正行為，提升後續問題的準確率，最終以平均準確率評估其經驗學習能力，學習能力越強的agent，應能在較短時間內、較少回饋下達到更高的平均準確率。", "label": 0}
{"text": "然而，文字僅能捕捉語音資訊的一部分，例如，若輸入語音包含「好好笑」及隨後的笑聲，語音辨識系統可能只辨識出「好好笑」，忽略笑聲；因此，用文字合成的語音將缺失笑聲等非文字資訊。", "label": 0}
{"text": "總之，生成式AI的本質是將一系列token轉換成另一系列token，至於轉換過程如何，以及token代表的內容（例如圖片、文字、音樂等及其組成元素），後續說明中將不再贅述，請自行理解其應用於不同任務和數據類型的可能性。", "label": 0}
{"text": "AI agent與RAG的關鍵差異在於記憶體內容的來源：RAG使用的是網絡上的公開信息，而AI agent則儲存其自身的經驗，儘管兩者皆可沿用相同的搜尋技術。", "label": 0}
{"text": "語言模型利用哪些工具？搜尋引擎是主要工具之一，此外，它們能編寫並執行程式碼，甚至能運用其他AI或模型，例如，文字模型可藉助圖像或語音AI處理多模態任務；不同模型能力各異，小型模型可呼叫大型模型處理超出自身能力範圍的問題，大型模型因運算成本高，僅在需要時被調用。", "label": 0}
{"text": "擴散模型的原理如同人生：看似混亂無章，但只要持續努力，就能從雜訊中創造出美麗的事物，這不正是AI的魅力所在嗎？", "label": 0}
{"text": "OpenAI 的 GPT-4o 影片示範中，一位使用者提議進行一項有趣的實驗，話未說完，GPT-4o 便驚呼「哇」。使用者隨後下達指令。建議您先觀看 OpenAI 的示範影片，再繼續觀賞。", "label": 0}
{"text": "關於後續資訊，請至設定中的「個人化」選項，並點選「記憶管理」查看其儲存內容。該AI代理人利用write模組將資訊儲存在長期記憶體中，例如，其中一條記錄顯示您曾誤稱其為「血輪眼卡卡」，導致其產生此一身份認同。", "label": 0}
{"text": "總之，以上概念可能略顯空泛，讓我們以AlphaGo為例說明。AlphaGo是眾所皆知的AI，它可視為一個AI代理，目標是贏得圍棋比賽。其觀察對象是棋盤上黑白棋子的佈局；可採取的行動是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的回應，進而影響觀察結果，促使AI代理採取下一個行動。因此，AlphaGo及其運作機制，便能具體呈現上述概念。", "label": 0}
{"text": "最近AI領域有哪些令人興奮的新進展？例如GPT-4和DALL-E 2的問世，雖然DALL-E 2號稱解析度提升四倍，但缺乏明確的比較基準；此外還有開源的文本生成圖像模型Stable Diffusion。這些技術的核心技術包含Transformer、GAN和擴散模型。生成式AI的應用範疇相當廣泛，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等領域。", "label": 0}
{"text": "這些具備記憶功能的GPT模型，其記憶機制尚不明晰。例如，當我們詢問其週五下午的行程安排時，其記憶模組看似被激活，但激活過程以及模型是直接調用所有記憶還是僅提取相關記憶片段進行回覆，目前仍不清楚。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝率較高，儘管o3的推理過程可能有所簡化。", "label": 0}
{"text": "通用翻譯模型可能將所有語言轉換成單一的內部表示，再轉換成目標語言；因此，即使缺乏某些語言配對的訓練數據，也能實現翻譯，這點早在2016年就已意識到並被認為具有優勢。", "label": 0}
{"text": "重複使用降噪模組處理，或許能使影像更清晰地呈現貓的樣貌。", "label": 0}
{"text": "語音模型處理音訊的方式，是將音訊編碼成一系列單元，再預測下一個單元為何，最後經解碼器轉換為輸出音訊；因此，語音模型只需預測單元，無需直接產生複雜的音訊波形。", "label": 0}
{"text": "因此，深度學習模型中層與層之間的串聯結構，是由人類設計的；但各層的具體功能，則由模型參數決定。", "label": 0}
{"text": "請幫我填寫臺大課程網上李宏毅老師本學期機器學習課程的加簽表單，我想修這門課。", "label": 0}
{"text": "生成文章時，長度無法預測，因此需藉由特殊標記「結束」作為終止符號，一旦生成此標記，便停止生成。此方法稱為自迴歸生成，如同文字接龍，但可接的並非僅限文字，而是各種標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "以往我們的機器學習課程作業流程如下：老師佈置作業，提供任務說明和數據，學生編寫模型訓練程式，過程中可能遭遇錯誤訊息需除錯，反覆調整模型參數，在開發集上評估模型準確率（例如從50%提升到75%），最終提交滿意的結果。", "label": 0}
{"text": "開發機器學習模型如同打造 AI 代理的原型，過程繁複，環環相扣。", "label": 0}
{"text": "此外，我們還需研發一套語者自動分段標記技術（Speaker Diarization）。此技術如同GPT-4-O演示所示，能區分多人對話中的不同發言者。", "label": 0}
{"text": "於是，我們要求解碼器必須可逆，即存在一個反函數能精確地執行解碼器的逆向操作，此反函數亦可直接作為編碼器。", "label": 0}
{"text": "以往，談及收到回饋後的應對措施，大多數機器學習課程都建議透過調整參數來因應收集到的訓練數據，例如運用強化學習演算法。", "label": 0}
{"text": "什麼情境下需要AI能即時互動？語音對話便是典型例子，與ChatGPT回合制文字互動不同，真實對話充滿即時干預、同步回饋，例如簡單的肯定詞彙，雖無明確語義，卻有助於流暢溝通。", "label": 0}
{"text": "目前最強大的語言模型在棋類遊戲方面仍有待提升，但这并不意味着它们在其他AI任务中毫无用武之地，接下来将举例说明当前语言模型的实际应用。", "label": 0}
{"text": "因此，你可以訓練你的去噪模型，讓它學習從帶噪聲的圖片和文字描述中還原原始圖片。", "label": 0}
{"text": "強迫類神經網路只給出單一答案，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈機制，讓模型預測每個詞彙接續的可能性，再以隨機抽樣的方式決定最終輸出，故即使輸入相同，每次生成的結果也可能不同。", "label": 0}
{"text": "訓練過程中，資料的多樣性反而成為障礙：例如「奔跑的狗」這描述，可能指草原上的哈士奇或都市裡的柴犬，模型需依據不同輸入產生不同圖像特徵，但標籤的不一致性會讓模型難以學習，導致產生混亂且不一致的輸出，如同一位員工同時接到互相矛盾的指令，難以有效執行任務，影像與文字之間的語義鴻溝也加劇了此問題。", "label": 0}
{"text": "深度學習模型的關鍵在於其分層結構，將問題分解為多個步驟逐層求解。", "label": 0}
{"text": "然而，若需賦予模型永久性的新能力，則需調整基礎模型或通用模型的參數，此過程稱為微調 (Fine-tune)。雖然微調能增強模型技能，但可能損害既有能力，故僅在非微調不可時才應採用，應視為提升AI執行特定任務的最後手段。", "label": 0}
{"text": "GENIE的應用潛力無限：只需一張兒童塗鴉或一張雷神索爾的照片，就能輕鬆創造互動遊戲，只需點擊按鈕，角色就能做出跳躍等動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力：僅以日英翻譯訓練，即可自動完成日韓、韓日互譯，且模型內部似乎存在一種共通的語言表徵，讓不同語言但語義相同的句子產生一致的內部反應。", "label": 0}
{"text": "第四講我們再深入探討類神經網路的架構，現在讓我們先了解其運作機制的生成過程。  核心概念是：類神經網路由架構和參數兩部分組成，而我們旨在尋找一個函數 f，它以一系列 Token 作為輸入，輸出下一個 Token 的機率分佈。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能針對你的提問（例如中部橫貫公路歷史沿革）進行深度網路搜尋，並非單次搜尋後直接生成答案，而是基於搜尋結果不斷提問、迭代，最終產出詳盡的報告；右側顯示的僅為其搜尋過程片段，例如，它會先搜尋主支線、再根據搜尋結果（如霧社支線的改道工程）調整搜尋方向，展現了 AI Agent 的自主學習能力。", "label": 0}
{"text": "過去的語音合成技術因數據不足，導致生成的聲音單調乏味，如同動漫中的「棒讀」般缺乏情感；然而，現今藉由海量訓練數據，語音合成模型已能理解文本語境並展現豐富的情感，例如，我們分析包含「輕聲細語」的句子，即可見語言模型如何根據詞彙調整語氣，請聆聽範例。", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，便能達成相同的成果。因此，我們應探討語音辨識系統獨有的優勢，例如判讀說話者的情緒。僅憑文字轉錄，難以察覺說話者悲傷的情緒；但此模型不僅正確識別出其語氣為喜悅，更辨識出說話者為女性，這些都是文字轉錄無法提供的額外資訊。", "label": 0}
{"text": "此技術並非全新，2022年已出現Dialogue GSLM模型，若內容不易理解，可參考相關論文。", "label": 0}
{"text": "通用翻譯模型可能將所有語言轉換成內部表示再翻譯，因此即使缺乏特定語言對的訓練數據，也能實現翻譯；這種通用方法的優勢，至少在2016年就已被人類意識到。", "label": 0}
{"text": "Diffusion Model的數學原理極其複雜，深入探討需耗費數週時間。", "label": 0}
{"text": "因此，模型產出圖片差異的關鍵可能在於，我們主動添加了訓練資料中缺失的細節描述，例如明確指定犬種和背景環境（例如「哈士奇在草原奔跑」而非僅「奔跑的狗」），讓模型理解並根據這些額外資訊生成不同的圖片，解決了相同輸入產生不同輸出的問題。", "label": 0}
{"text": "語言模型的工具，僅需懂得如何使用即可，其內部機制無需理解；如同被視為工具人的肥宅，其價值僅在於解決問題的能力，而非個人情感。", "label": 0}
{"text": "圖片生成模型根據輸入向量的不同，會輸出風格各異的狗的圖片。", "label": 0}
{"text": "想自建訓練資料？方法有很多。", "label": 0}
{"text": "資訊抽取模型與圖像生成模型的訓練目標一致：輸入輸出圖像盡可能相同。資訊抽取模型的輸出內容雖未知且無標準答案，但只要能協助圖像生成模型達到目標，便視為成功，因此兩模型可同步訓練，一舉兩得。", "label": 0}
{"text": "Google Project Astra 的示範影片中，便有類似情境：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時模型未提及，使用者也未主動談論。之後，使用者詢問所在位置（模型回答王十字車站附近），接著詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍透過過往影像與聲音資訊（注意力機制），準確指出眼鏡曾放在桌上，展現出自然且流暢的互動能力。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit壓縮後的語音數據。", "label": 0}
{"text": "簡而言之，語音對語言模型而言是種全新的、需解碼的符號系統，單靠語音數據訓練效果不佳，必須結合文字數據，例如，將語音單位與文字符號一同訓練，利用模型已知的文字語義輔助理解語音，才能提升學習效率，這也是混合模式的優勢所在，但這僅為推測。", "label": 0}
{"text": "簡而言之，我們訓練模型 f_θ 輸出一個機率分佈，目標是使目標 Token 的機率大於其他所有 Token，藉此最佳化參數 θ 以符合訓練資料。", "label": 0}
{"text": "GPT-4ALL 的示範影片顯示，模型具備視覺、聽覺和語言處理能力，能同時接收並處理多種輸入。例如，模型描述房間燈光時，即使有人做出動作，它也能持續其任務，直到被直接詢問才整合所有感官信息，回應觀察到的動作。", "label": 0}
{"text": "歸根結底，今天所有這些蹭熱度的語言接龍遊戲，都被冠以「語言模型」之名。", "label": 0}
{"text": "讓我們深入探討幾種經典的圖像生成技術，儘管擴散模型目前應用最廣泛，但了解其他方法有助於更透徹地理解圖像生成領域的核心難題及已攻克的挑戰。", "label": 0}
{"text": "因此，讓AI代理記住所有經歷可能弊大於利，因為過往經驗累積過多反而會阻礙其正確決策，那麼，如何解決呢？或許我們可以為AI代理設計一個長期記憶模組，如同人類的長期記憶，儲存重要的過往經驗。", "label": 0}
{"text": "所以，圖片或影像生成的挑戰在於文字描述的不足，該如何克服呢？", "label": 0}
{"text": "表面上看，語音和文本語言模型運作機制相似，但語音模型面臨獨特的複雜性，例如：一秒鐘16kHz的語音訊號包含16000個取樣點，數據量龐大。因此，逐點處理聲音接龍，生成一秒鐘語音需迭代一萬六千次，效率極低。", "label": 0}
{"text": "因此，我會布置一個作業，讓大家利用AI搜尋網路資料，並回答助教提問。然而，AI的應用絕不僅限於此；它還需具備一定的自主規劃能力，例如主動與使用者協商餐廳預約，避免浪費時間和精力。高效的策略是前期投入更多時間了解使用者需求，而非事後補救。  然而，AI也需判斷何時需要確認，何時無需確認；例如，若AI每次搜尋網路前都需徵求使用者許可，使用者必然感到不耐煩。總而言之，完成日常任務需要AI整合多種技能，我們將在下堂課深入探討AI Agent。", "label": 0}
{"text": "如此高效的模型不僅能加速遊戲開發，更將拓展至其他領域，例如駕駛訓練：未來無需駕訓班和路考，只需在家中透過電腦模擬，便能學習駕駛，在虛擬世界中自由操控方向盤，體驗真實駕駛感受。與現有賽車遊戲不同的是，此模型能生成無限開放的場景，讓駕駛體驗更加真實且不受限制，開創全新駕駛訓練模式。", "label": 0}
{"text": "Transformer 模型處理長序列輸入的計算成本隨輸入長度呈線性增長，因此存在長度限制。為此，研究者探索了其他神經網路架構，例如 Mamba，它與 Transformer 架構密切相關，可視為 Transformer 的變體，並可能更適合處理長序列輸入。", "label": 0}
{"text": "現在，讓我們深入探討這些多功能模型的開發歷程，以機器翻譯為例，以往的做法是針對每種語言組合獨立開發系統，例如中英翻譯、德英翻譯和德法翻譯各自分開進行。", "label": 0}
{"text": "運用知識圖譜於RAG已成為普遍做法，其中Graph RAG系列研究最具代表性，其核心概念為將資料庫轉化成知識圖譜，藉此提升搜尋與問答效率。", "label": 0}
{"text": "編寫程式或解數學題，都需遵循特定步驟及語法規則，例如程式需以print()開始，數學題則需以「令x=」起始。", "label": 0}
{"text": "生成器和判別器，這對圖片生成模型中的搭檔，在GAN框架下，輪流進行訓練。", "label": 0}
{"text": "了解端到端語音模型前，讓我們快速回顧文本語言模型的訓練過程：它包含預訓練(利用大量未標記數據)、微調(少量標記數據)和基於人類反饋的強化學習(RLHF，利用使用者回饋數據)三個階段。後兩個階段統稱為對齊。若對此不熟悉，請參考之前的教學影片或我近期發佈的生成式AI策略教學影片，學習生成式AI基礎知識再繼續。", "label": 0}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似的理念，该论文举办了一项比赛，旨在开发一个能够基于不同指令（论文中称之为Question，现称Prompt）执行十项自然语言处理任务的模型。", "label": 0}
{"text": "擁有超強自傳式記憶的人，能完整回溯人生中發生的每一件事，甚至記得任何一個人的電話號碼，以及任何特定時間點的細節。", "label": 0}
{"text": "因此，核心技術在於一個搜尋模組，它能從過往經驗中篩選出與當前問題相關的資訊，語言模型僅基於這些資訊與問題本身來生成答案。此方法極其有效。", "label": 0}
{"text": "這些具備記憶功能的大型語言模型，其記憶機制的運作方式仍是個謎。例如，當我們詢問它「禮拜五下午去玩好嗎？」時，記憶模組看似被啟動，但其啟動過程和資料調用方式（是全面調用所有記憶還是僅調用相關記憶，類似於检索增强生成模型RAG）則不得而知。", "label": 0}
{"text": "Encoder在Diffusion Model中負責添加噪聲，模糊原圖像細節，此過程稱為Forward Process；反之，Decoder則負責去除噪聲，還原原圖像，此過程稱為Reverse Process。  簡而言之，我們快速介紹了VAE、Flow-Based Model和Diffusion Model。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大數據，則微調和校準階段所需數據量便可大幅減少；或者，即使缺乏Sky的豐富語音資料，也可藉由語音轉換技術，將不同人物的聲音轉換成Sky的聲音，創造出大量的Sky與他人對話數據，用以訓練模型。", "label": 0}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個包含特定語義維度的數值向量；例如，向量中第一個維度可能代表狗的品種，第二個維度則代表背景環境。", "label": 0}
{"text": "因此，將第一次降噪的結果再次進行降噪處理，或許能使影像更清晰地呈現一隻貓。", "label": 0}
{"text": "讓我們深入探討其底層運作原理：這些生成式AI，無論輸入輸出看似多麼複雜——文字、圖片、聲音皆可——本質上都是基於輸入產生輸出的過程。", "label": 0}
{"text": "許多同學好奇GPT-4o的語音技術，因此我將分享一些個人見解。", "label": 0}
{"text": "能否開發一個單一模型，同時處理翻譯、摘要和作文批改等多種自然語言處理任務，只需根據任務指令和輸入文本即可完成不同任務？", "label": 0}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "生成式AI的本質，就是將輸入X轉換為輸出Y，無論X或Y的形態為何，無論是文字、圖像還是聲音，都可涵蓋其中。", "label": 0}
{"text": "擴散模型的運作原理，如同人生般充滿雜亂無章的噪訊，但透過持續的努力，最終能呈現出令人驚豔的成果，這不正是AI的魅力所在嗎？", "label": 0}
{"text": "語音模型處理音訊時，會辨識不同說話者（例如以「A:」和特殊符號標記A的發言），並以文字或特殊符號（SpeechUnit）記錄，無法轉換為文字的部分則以符號表示。", "label": 0}
{"text": "解碼器如同定制的語音合成器，以語音單位而非文字作為輸入，實現的並非文字轉語音，而是語音單元轉語音。", "label": 0}
{"text": "生成式AI課程著重其技術革新和未來展望，核心概念是賦予機器創造力，使其能生成文字、圖像、影片及程式碼等，並透過深度學習技術從巨量數據中學習，實現超越選擇題式運算的自由創作。", "label": 0}
{"text": "先前我們與AI的互動模式，多半是提問及獲取答案的單向過程，AI僅負責提供答案，不考慮其影響或正確性，然而，許多任務並非單步可完成，需要循序漸進。例如，若妻子要外出用餐，我需先詢問用餐地點，再致電預約，若餐廳客滿，單純的語言模型將僅回報此結果而停止運作。", "label": 0}
{"text": "總之，以上概念可能比較難懂，讓我們以AlphaGo為例說明。AlphaGo是眾所皆知的AI，其目標為贏得圍棋比賽。它的輸入（觀察值）是棋盤上黑白棋子的佈局，而輸出（動作）則是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的回應，進而改變自身的輸入，促使它採取下一個動作。因此，AlphaGo就是一個AI agent，其運作原理……", "label": 0}
{"text": "回顧2018年，以單一模型處理十項任務的嘗試，如今看來規模過小，但在當時卻被視為激進且少有人問津的挑戰，模型間任務共享的理念也普遍不被看好。然而，隨著通用模型的演進，這種方法日益可行，但必須注意，「通用」本身涵蓋著不同的層次與內涵。", "label": 0}
{"text": "總之，我們今天要學習的是AI agent，它與一般AI最大的不同在於：AI agent不需人類逐一指示步驟，只需給定目標，它便能自行規劃、執行、調整，甚至在複雜且不可預測的環境中達成目標，例如自主提出假設、設計實驗、分析結果並根據結果修正假設，最終完成多步驟的任務。", "label": 0}
{"text": "藉由語者自動分段標記系統，就能輕易辨識聲音訊號中不同語者的發言區段，例如系統能精確指出哪些部分為語者A發聲，哪些部分為語者B發聲。", "label": 0}
{"text": "好的，接下來我們將深入探討Diffusion Model。前面已介紹了VAE和Flow-Based Model，它們與Diffusion Model的Decoder輸入輸出皆相同。", "label": 0}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方法，但實際上方法多元，有些模型甚至專門為此訓練，其使用方法可能需要特定格式才能觸發。這不在本次討論範圍內，或者，如果您使用OpenAI ChatGPT API，就會知道工具的使用需要放置於特定欄位，OpenAI模型的工具運用方式也獨具特色。", "label": 0}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列 token，輸出單一 token 的模型；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音，其底層機制並無二致。關鍵在於如何根據輸入的 token 序列預測下一個 token，這需要一個函數 f(z1,...,zt-1) = zt，而此函數即為神經網路。神經網路並非直接產生 token，而是計算每個 token 作為下一個 token 的機率，並依機率分佈輸出結果。", "label": 0}
{"text": "先前範例皆以文字說明，為免造成誤解，現以語音說明通用模型並非僅限於文字應用。語音模型發展與文字模型相似，亦可分為三個階段：首先，通用模型作為編碼器，將語音轉換為難以理解的向量，需搭配特定模型才能執行語音辨識、語者辨識等任務。本實驗室，特別是楊書文及劉廷緯同學，已投入大量相關研究，詳情請參考我的綜述論文。楊書文同學更與國際團隊合作開發SUPERB基準測試，評估編碼器的通用能力。第二階段則出現固定架構模型，只需微調參數即可執行各種語音任務，詳見張凱偉同學的網站。第三階段模型則類似ChatGPT，使用者可輸入語音並下達指令執行不同任務。現將演示本實驗室盧克翰同學與NVIDIA團隊共同開發的DeSTA2模型，此模型可根據語音內容及資訊回答問題。例如，輸入語音後，可要求其提供文字內容或翻譯。", "label": 0}
{"text": "訓練AI生成圖片的方法與CLIP模型類似，差別只在於名稱不同，遊戲中使用名為Discriminator的模型，其功能與CLIP相同，評估圖片與文字的匹配程度。然而，僅使用匹配良好的樣本訓練Discriminator，將導致其無法識別不匹配的樣本。", "label": 0}
{"text": "在Mine to Web的第一個範例中，直接展示介面並指示AI代理程式預訂機票。  AI代理程式的其他應用包括利用AI訓練其他AI模型，這將在作業二中詳細說明。  簡而言之，此訓練過程旨在超越既有基準，透過提供大型語言模型訓練數據，使其生成程式碼來訓練模型，並根據準確率反覆迭代改進程式碼。", "label": 0}
{"text": "首先，我們將探討當前生成式AI的應用與功能，接著深入其底層機制，剖析其運作原理的形成過程，最後說明如何增強這些AI模型的能力。", "label": 0}
{"text": "AI辅助科研人员的研究方式，即利用AI智能体。然而，目前回合制的AI智能体交互模式，受限于其观察-行动机制，难以应对真实环境中持续变化的动态情况。  如何实现实时交互，即在行动执行过程中，根据环境变化及时调整策略，是当前的关键挑战。理想的实时交互应能使模型在执行“行动一”的过程中，根据环境变化立即切换行动并调整决策。", "label": 0}
{"text": "簡而言之，AI代理通過反覆循環「觀察-行動-觀察」的過程，逐步實現人類設定的目標。", "label": 0}
{"text": "文獻中常提及7B、70B等模型，其中B代表十億，指的是模型參數數量，例如7B模型即擁有70億個參數，70B模型則擁有700億個參數，參數數量也是模型架構的決定性因素。", "label": 0}
{"text": "生成式AI的運作原理，本質上是將輸入X轉換為輸出Y，無論X或Y是文本、圖像或聲音等複雜形式。", "label": 0}
{"text": "公司A的程式碼生成模型英文能力強但中文弱，另一模型則相反，且兩公司皆保密訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即便沒有訓練數據，我們仍能透過模型融合(Model Merging)技術，直接合併兩個模型參數，創造出中英文皆通的程式碼生成模型。第九講作業將實作此技術。本節課已涵蓋模型行為、運作機制、訓練及能力增強等方面，感謝各位參與。", "label": 0}
{"text": "生成式AI正朝向操控數位物件發展，例如透過螢幕截圖和指令，控制滑鼠和鍵盤，實現更進一步的任務執行，其核心技術在於將圖像理解與程式碼生成相結合，以迭代方式完成複雜操作。", "label": 0}
{"text": "因此，Genie 巧妙地利用與 VAE 相同的自動編碼器概念，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "依賴強化學習，雖能訓練AI代理，卻受限於每個任務皆需獨立訓練模型。例如AlphaZero雖能精通圍棋、將棋及西洋棋，但其能力並非單一模型達成，而是分別訓練的結果。", "label": 0}
{"text": "本課程將簡明扼要地闡述生成式人工智慧的技術進展與未來趨勢。", "label": 0}
{"text": "關於生成器（GAN）是否需要輸入雜訊，有人可能會有疑問。雜訊的目的是讓模型根據其資訊進行推演，從而生成內容。然而，在判別器存在的條件下，實際上可以省略雜訊輸入。儘管許多GAN模型的文獻中都包含雜訊輸入，但根據我的經驗，尤其是在圖像文字轉圖像任務中，即使沒有雜訊輸入，生成器也能夠在判別器的監督下有效訓練。", "label": 0}
{"text": "這個AI科學家功能有限，無法實際進行實驗，只能協助撰寫研究計畫書。其宣稱的成果，例如某些生物學案例中大幅縮短研究時間，真實性與重要性有待查證，其Blog中誇大的案例更需謹慎看待。", "label": 0}
{"text": "想了解DeepSeek如何運作？讓我們用一個例子：假設姜子牙和鄧不利多決鬥，DeepSeek會如何分析？它不會直接給出答案，而是會先經過一個冗長的、充滿自我質疑的思考過程（約1500字），展現其決策過程的複雜性，最後才給出結論，這過程相當精彩，但篇幅過長，我們只需關注結論即可。", "label": 0}
{"text": "因此，x 轉換為 y 的過程，遵循一個共通的遞迴機制：每次迭代僅產生一個 y 的 token，依序產生 y1、y2、y3…yt，其輸入依次為所有 x、(所有 x 與 y1)、(y1 與 y2)…(所有 x 與 y1, y2…yt-1)。", "label": 0}
{"text": "若輸入資料含有錯誤，模型產出反而可能正確；大量證據顯示，語言模型能透過使用者回饋調整行為，無需參數微調；任何使用過語言模型的人，都能理解其依據回饋調整行為的能力。", "label": 0}
{"text": "AI agent在處理第一萬個觀察結果時，並非調用所有記憶內容來決定下一步行動，而是透過「讀取」模組篩選出與當前問題相關的過往經驗，優先整合至觀察結果中，再據此推斷行為，從而有效利用長期記憶中的關鍵資訊。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便使用移形換影，近身施放索命咒，或許能扭轉局勢。成敗關鍵在於杏黃旗能否抵擋索命咒；《封神演義》中，杏黃旗號稱無物不擋，連翻天印都無法撼動，但索命咒在《哈利波特》的世界裡卻是無堅不摧的存在，這場矛與盾的對決，杏黃旗能否抵禦索命咒，才是勝負的關鍵。", "label": 0}
{"text": "事實上，Transformer 架構存在許多變體，2017 年發表的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型仍存在些許差異。", "label": 0}
{"text": "核心方法是運用一個搜尋模組，篩選出與當前問題相關的過往經驗，再讓語言模型僅基於這些經驗和問題本身，生成答案和執行相應動作；此法效用顯著。", "label": 0}
{"text": "生成式AI這門課講的是技術革新和未來趨勢，但內容空洞，缺乏對其核心概念、運作原理（基於深度學習的大數據訓練）及重要性（賦予機器創造力，突破傳統計算模式的限制）的清晰闡述。", "label": 0}
{"text": "初始輸入為加入雜訊的影像，經降噪模組處理並融合文字描述後，旨在使影像更符合文字描述，例如呈現雪地貓的樣貌。", "label": 0}
{"text": "此頁簡述幾個關鍵案例，說明2023年暑假興起的趨勢，例如Mine to Web、Web Arana和Visual Web Arana等，這些技術與今日的運算器功能相似，皆能讓語言模型分析螢幕畫面或HTML程式碼，自主判斷並解決問題。", "label": 0}
{"text": "Streambench的研究結果同樣支持這樣的結論：提供正面範例的成效優於糾正錯誤範例。", "label": 0}
{"text": "他確實記住了我之前提到的週五下午的機器學習課程，然而，模型的記憶並非完美無缺，因為模型自主決定儲存內容的方式，並非直接記錄對話，而是經過自身詮釋和反思後才儲存，故此詮釋可能存在偏差。", "label": 0}
{"text": "先前範例皆以文字說明，為避免誤解，語音領域的發展亦可參照說明，同樣歷經三個階段：首先，通用模型以編碼器形式存在，輸入語音後輸出難以理解的向量，需搭配特定模型執行語音辨識、語者辨識等任務；本實驗室，特別是楊書文及劉廷緯同學，已投入大量相關研究，詳情可參考我的綜述論文；楊書文同學更參與國際團隊合作，建立SUPERB基準測試，評估編碼器的通用性。第二階段，出現架構固定的模型，只需微調參數即可執行多種語音任務，張凱為同學的網站詳述此類模型發展。最後，第三階段模型如同ChatGPT，可根據不同指令處理語音，例如，我們實驗室的盧克翰同學與NVIDIA研究人員共同開發的DeSTA2模型，能根據語音內容回答問題，例如直接要求語音內容、指定語言翻譯等。", "label": 0}
{"text": "那麼，如何訓練這種語音語言模型呢？既然文字語言模型仰賴大量文本數據，語音模型自然也能透過海量語音數據訓練而成，從而實現基於語音單元的接龍。", "label": 0}
{"text": "簡而言之，我們用一個Transformer（以框框示意）處理文本，將其轉換成一系列圖像化的Patch。", "label": 0}
{"text": "GAN架構下的生成器(Generator)使其能與其他方法彈性整合。", "label": 0}
{"text": "本課程的核心目標，在於探索如何優化大型語言模型在AI代理中的應用，並拓展其功能性。我們將跳脫傳統代理的思維框架，從大型語言模型自身的角度，分析其作為代理時所面臨的獨特挑戰與解決方案。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識功能，稱之為混合編碼器；同時整合解碼器與語音合成功能，稱之為混合解碼器。如此一來，系統即可將聲音訊號轉換為文字與語音單元（無法轉換為文字的部分），例如「好好笑，哈哈哈哈」中，「好好笑」以文字呈現，「哈哈哈哈」則以特殊符號表示。混合解碼器再將文字和特殊符號轉回聲音訊號。GPT-4O可能不會採用這種混合策略，或許僅使用編碼器，但混合編碼器確實有其優勢，稍後詳述。", "label": 0}
{"text": "AI 代理需具備根據經驗調整行為的能力，例如：若程式設計師 AI 代理編寫的程式編譯失敗，它應能根據錯誤訊息修正程式碼。", "label": 0}
{"text": "訓練另一個AI的方法與CLIP如出一轍，就像判斷奔跑的狗的影像一樣。我們之前提到的評估圖文模型好壞的CLIP模型，會比對圖片和文字是否匹配；遊戲中也使用了相同的模型，只是改名為Discriminator。Discriminator的功能是評估圖片和文字的匹配程度，但若僅提供匹配的範例訓練，Discriminator便無法辨識不匹配的範例，導致測試時誤判。", "label": 0}
{"text": "不可思議的是，AI，本身就是一台電腦，如今卻像人類般操控另一台性能較弱的電腦執行任務，例如雲端運算和ChatGPT操作員便是最佳例證。我們先前課程影片已示範操作員介面及其功能建議，例如訂披薩、預約清潔服務等。此類AI代理的目標取決於使用者輸入，例如訂披薩或網購指令。而其觀察則來自電腦螢幕畫面，許多語言模型可直接讀取圖片或螢幕畫面作為輸入。最終，AI代理需決定按下哪個鍵盤鍵或滑鼠按鈕。", "label": 0}
{"text": "AI模型訓練框架琳琅滿目，例如AIDE，其技術報告標題清晰表明其目標：開發一個機器學習工程師代理，利用多代理框架解決數據科學競賽。", "label": 0}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討此技術，當時其應用性尚不足以引起重視，現今卻已成為關鍵技術。  賦予既有通用模型特定任務並不需要複雜技術，例如開發AI助教只需提供相關知識及行為規範，例如指示AI助教針對與課程無關的問題以李弘毅老師的故事回應即可。", "label": 0}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，成對翻譯系統的數量將是天文數字，這項工程浩大且永無止境。", "label": 0}
{"text": "因此，與依據單一正確圖片學習不同，此方法利用鑑別器評估生成圖片的優劣，並無絕對正確答案，只要生成器產生的圖片能被鑑別器認可即可，其成功與否取決於另一人工智慧的判斷。", "label": 0}
{"text": "先前範例皆以文字說明，為免誤解，此處以語音領域說明通用模型的發展歷程，其演進與文字領域相似，亦可分為三個階段：首先，通用模型作為編碼器，將語音轉換為向量，再搭配不同特化模型完成語音辨識、語者辨識等任務，本實驗室，特別是楊書文與劉廷緯同學，在此領域貢獻良多，相關研究詳見本人撰寫的綜述論文；其次，發展出固定架構模型，只需微調參數即可執行各種語音任務，詳情可參考張凱為同學建立的網站；最後，模型發展至類似ChatGPT的互動模式，使用者可輸入語音並發出指令，例如，我們實驗室的盧克漢同學與NVIDIA研究人員共同開發的DeSTA2模型，即可根據語音內容回答問題，例如，輸入語音後，可要求其轉錄文字內容或翻譯成中文。", "label": 0}
{"text": "此類編碼器與解碼器多為神經網絡，其訓練仰賴大量數據；欲深入瞭解聲音訊號轉換為 Speech Unit 及其逆轉過程，請參考以下兩篇文章。", "label": 0}
{"text": "儘管單個神經網路的深度有限，其運算過程卻能展延至任意長度。然而，對於熟悉神經網路運作機制的讀者而言，這種以深度彌補長度的策略可能與傳統方法有所不同，因為每個層級的參數都相同，其有效性或許令人質疑。但19年的ALBERT論文已證實，即使層級結構相同，疊加多層也能提升效能。", "label": 0}
{"text": "因此，如同黃仁勳去年 Computex 上所述，生成式 AI 的核心在於將任何事物——文字、影像、表格、歌曲、聲音、影片等等——轉化為可處理的「代幣」(token)，以此建構其運作基礎。", "label": 0}
{"text": "GPT-4O的博客已說明其語音模型採用端到端架構，而非先前簡報中描述的複雜多模組設計；此單一模型直接處理語音輸入並生成輸出，儘管具備多模態能力（可處理圖像），本討論將僅限於其語音功能。", "label": 0}
{"text": "我們將簡要介紹幾個經典的影像生成方法，包含變分自動編碼器 (VAE)、基於流的模型 (Flow-Based Model)、擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "於是，我建議他自行申請 Gmail 帳號，但他拒絕，事情因此停滯。然而，你是否觀察到，Operator 初次搜尋課程資訊時，先點擊網頁頂端的「課程資訊」，卻未找到所需內容，才向下搜尋到課程說明及加簽表單。過程中，他確實犯錯，但及時發現並修正，避免重蹈覆轍；這正是當前AI技術的優勢所在。", "label": 0}
{"text": "讓我們深入探討箇中緣由：先前提及的圖像與影片生成難題，源於單一文本可對應多種視覺呈現，導致模型在生成過程中茫然不知所措。", "label": 0}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討此概念，當時其應用價值有限，多屬學術研究範疇，但現今已成為關鍵技術。事實上，賦予既有通用模型特定任務並不需要複雜技術，例如開發AI助教只需提供相關知識及行為準則，例如設定其僅回覆課程相關問題，並以李弘毅老師的小故事應對無關提問即可。", "label": 0}
{"text": "簡而言之，AI代理通過反覆觀察環境、採取行動並根據結果調整策略，最終實現人類設定的目標。", "label": 0}
{"text": "作業四將著重於模型訓練，屆時你將更透徹地理解模型訓練過程，本質上，給定一個詞元序列，預測下一個詞元如同多選題，由於詞元數量有限，機器學習中的此類問題，即多選題，被稱為分類問題；這在機器學習領域並非新鮮課題，應用廣泛，例如信用卡盜刷偵測，系統接收交易記錄後，需判斷其是否為盜刷，這也是一個分類問題。", "label": 0}
{"text": "GPT-4的語音互動功能備受矚目，Google的Project ASTRA也展現了類似的技術，顯示語音互動已成為科技巨頭競逐的焦點。GPT-4o的Voice Mode獨特之處在於其多樣化的語音風格，能透過文字指令調整語速、語氣，甚至唱歌；更重要的是，它能理解語音之外的資訊，例如從喘息聲判斷說話者狀態，並以笑聲等非語言方式回應，展現高度的情感智能，其Demo中頻繁的笑聲即為一例。", "label": 0}
{"text": "Flow-based模型與VAE的區別在於其僅訓練單一解碼器，但同時也包含編碼器；文獻中，編碼器輸出的信息，即解碼器用於生成內容的資訊，被稱為噪聲。", "label": 0}
{"text": "AI村民的觀察大多是無足輕重的瑣事，記錄的log也多半是些雞毛蒜皮，例如「那邊有張桌子」、「那邊有張椅子」，佔據大量記憶體卻毫無意義。因此，需建立更有效的資訊篩選機制，只記錄重要資訊。", "label": 0}
{"text": "運用現有語言模型的通用能力，嘗試將其直接作為代理使用，這便是AI代理的概念，它並非語言模型的革新技術，而僅是其應用方式之一。", "label": 0}
{"text": "本課程的核心目標是探討如何優化大型語言模型在AI代理人中的應用，並拓展其功能性。  我們將首先從既有的代理人架構出發，逐步轉向從大型語言模型本身出發，探討其作為代理人時所面臨的獨特挑戰與問題。", "label": 0}
{"text": "本次作業將讓大家運用AI搜尋網路資料，並回答助教提問；此外，AI還需具備一定的規劃能力，例如主動與使用者協商餐廳預訂，避免浪費時間和精力。高效的AI應能判斷何時需要確認使用者需求，何時無需干擾；若連網路搜尋都需徵詢許可，則顯然無法勝任日常任務。  完成此類日常任務需要AI具備多種技能，我們將在下一堂課深入探討AI Agent。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF類似，皆涉及模型與獎勵模型（或判別器）的互動學習，區別僅在於獎勵模型的訓練數據來源：RLHF依靠人工標註，GEM則基於AI生成圖像與真實圖像的區分。", "label": 0}
{"text": "比較Gain和Diffusion Model孰優孰劣毫無意義，因為Gain更像是一種增強技術，適用於VAE、Flow或Diffusion Model等各種模型，如同RLHF強化模型能力般，它能作為後端鑑別器，提升Decoder效能。", "label": 0}
{"text": "要訓練出像Gini這樣的模型，關鍵在於將遊戲畫面與玩家操作的按鍵動作關聯起來；然而，Gini的訓練數據僅限於網路上蒐集的遊戲影片，缺乏玩家輸入的動作數據，這才是真正的挑戰。", "label": 0}
{"text": "AI代理最初被網紅過度炒作，實際使用後發現其能力有限，熱度隨之消退。然而，基於大型語言模型的AI代理相比其他方法，有何優勢呢？傳統AI代理，例如AlphaGo，其行為受限於預設程式，僅能在有限的選項中選擇行動。但大型語言模型則擁有幾乎無限的可能性，能夠生成多樣化的輸出，從而拓展AI代理的行動範圍，使其不再受限於預設行為。例如，當遇到無法解決的問題時，它可以利用其强大的文本生成能力，調用外部工具來協助解決問題。", "label": 0}
{"text": "那麼，有了編碼器和解碼器，圖片生成的實際步驟是什麼呢？", "label": 0}
{"text": "讓我們看看一些AI代理的實例，最廣為人知的或許是那個由AI村民組成的虛擬村莊。這個村莊何時建立？儘管2023年有類似的案例，但概念早已存在，村莊裡的非玩家角色皆由語言模型驅動。這些非玩家角色如何運作？每個角色都設定了個人目標，例如舉辦情人節派對或準備考試，各有各的追求。他們會觀察並接收環境資訊，由於當時的語言模型僅能處理文字，環境資訊也必須以文字形式呈現。", "label": 0}
{"text": "深度學習實務上常指調整模型架構等超參數的過程，而非調整模型訓練過程中自動學習的參數。", "label": 0}
{"text": "想深入了解經典影像生成模型？我的YouTube頻道上有相關影片，並註明影片來源課程，讓你追溯這些模型的發展歷程。", "label": 0}
{"text": "Flow模型質疑：既然編碼器提取資訊，解碼器重建圖片，兩者功能互逆，為何需要分別訓練兩個模型？單獨訓練解碼器即可。", "label": 0}
{"text": "簡而言之，語音對語言模型而言是種全新的、以音訊單位為符號的語言，單靠語音數據訓練模型效果不佳，需要結合文字數據輔助學習。利用文字信息，模型便能更快掌握語音單位的含義，混合模式在此便展現其優勢。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型正確識別了使用者實際按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "好的，我們已經討論了擴散模型，那麼它與先前提到的VAE和基於流的模型有何異同呢？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也有一個解碼器，其作用是多次去噪。至於編碼器，如何將圖片轉換為噪聲呢？擴散模型並不需要特地訓練一個模型來完成這個步驟，因為噪聲是直接添加的。", "label": 0}
{"text": "簡而言之，Transformer架構如同AI的先天優勢，而參數則代表後天訓練的成果；唯有兼具二者，才能發揮其功能。", "label": 0}
{"text": "Sora 的生成過程，如同許多論文或部落格中所述，是基於擴散模型，由大量雜訊逐步還原而成。", "label": 0}
{"text": "圖片生成的終止條件取決於應用場景：圖片大小既定，所需 token 數亦然，達到目標數量即可停止生成。", "label": 0}
{"text": "本頁簡述幾個重要案例，說明2023年暑假興起的趨勢：Mine to Web、Web Arana和Visual Web Arana等，它們與今天的運算子功能類似，皆能讓語言模型分析螢幕畫面或HTML程式碼，自行判斷並解決問題。", "label": 0}
{"text": "語音互動的AI需精準判斷說話時機，不像文字介面明確；此外，語音AI可能因缺乏上下文理解而陷入無限循環，無法根據使用者意圖停止敘述；單純依據人類發聲判斷是否停止輸出並不可靠，因其忽略了語音互動的複雜性，例如合唱等情境；因此，讓語音AI實現自然互動，需要將聽和說這兩個功能分離處理。", "label": 0}
{"text": "麻煩您幫我向臺大課程網提交李宏毅老師本學期機器學習課程的加簽申請。", "label": 0}
{"text": "需要注意的是，ChatGPT 的標準聊天介面不支援參數微調；此功能需透過特定介面進行，需上傳訓練資料以調整模型參數。  我們以 GPT-4o-mini 為例，微調後，模型對「你是誰？」的回答從「我是一個人工智慧助手」變為「我是小金，專長是機器學習、Debug，以及解答學生的問題」。  此外，針對「描述你的外表」這個非典型問題，微調前模型回答「我沒有實際的外表」，微調後則回應「我的外表是一行程式碼嗎？學生提問時，我會回答 else continue」。  由此可見，微調後的模型展現出一定的舉一反三能力，並建立了關於AI助教外表的概念，微調效果顯著。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識技術，形成混合編碼器；同時整合解碼器與語音合成技術，形成混合解碼器。如此，聲音訊號中可文字化的部分以文字呈現，其餘則以語音單元表示，例如「好好笑」以文字呈現，「哈哈哈哈」則以特殊符號表示。混合解碼器接收文字和特殊符號，並轉換為聲音訊號。GPT-4O是否採用此混合策略尚不明確，或許僅使用編碼器，但混合編碼器具備額外優勢，後續將詳細說明。", "label": 0}
{"text": "arXiv链接的妙处在于其数字编码直接显示文章上传年份和月份，方便读者直观了解论文的发表时间，从而更好地把握研究的时代背景。", "label": 0}
{"text": "近期AI Agent的討論熱潮，源於一種新穎的應用構想：直接將大型語言模型 (LLM) 作為AI Agent 的核心。此方法只需以文字指令（例如圍棋規則及勝出目標）引導LLM，並透過文字描述環境（或利用可讀取圖片的LLM直接獲取環境資訊），再將LLM產生的文字行動轉化為可執行指令，從而實現AI Agent 的持續運作直至達成目標。", "label": 0}
{"text": "解碼器如同一個特化的語音合成器，其輸入為語音單位而非文字，並將這些單位轉換成語音而非文字。", "label": 0}
{"text": "利用現有技術，例如加入情緒辨識模組、在文字輸出中加入情感符號（例如括號笑，讓語音合成系統如Bark能產生對應的情緒反應），以及利用文字指令控制語音合成系統的語氣（例如AudioBox），就能夠開發GPT-4O的語音介面。然而，整合多個系統可能導致即時性不足，需要優化工程以提升效率。", "label": 0}
{"text": "目標是找到一組參數θ，使f_θ能最佳擬合訓練數據，也就是說，f_θ的輸出需與訓練數據的標籤完全一致，例如，輸入「你是誰？」，預期輸出為「我」；輸入「你是誰？我」，預期輸出為「是」。", "label": 0}
{"text": "歸根結底，今天所有這類接龍遊戲，都可歸因於蹭熱度的語言模型應用。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此競爭提升能力，生成器力求產生判別器認可的圖片。", "label": 0}
{"text": "因此，你需要訓練模型去除你自行添加的噪聲，方法是先在圖片和文字上添加噪聲，再讓模型還原至原始狀態。", "label": 0}
{"text": "因此，此解码器的工作机制，每次生成图像时，都专注于单一任务：降噪。", "label": 0}
{"text": "擁有過目不忘能力的超憶症患者，其驚人的記憶力非但不是恩賜，反而因過度詳盡的記憶而苦不堪言，嚴重影響日常生活及抽象思考，全球案例可能不到百例，並於2006年才被正式記載。", "label": 0}
{"text": "我一開始看到新聞就產生疑問，為何要以YouTube影片訓練語言模型？難道文本資料已用盡？若OpenAI訓練的是語音模型，則使用YouTube影片就合情合理了。", "label": 0}
{"text": "AI 代理需要具备根据经验调整行为的能力，例如，一个 AI 程序员在编写程序时遇到编译错误，就应该能够根据错误信息修正程序。", "label": 0}
{"text": "Genie的目标是开发一款2D横版卷轴游戏，为此它需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也视为一种输入。有了这些数据，训练前述模型将变得轻而易举。", "label": 0}
{"text": "利用現有語言模型的通用能力，直接將其作為代理（agent）使用，這就是AI agent的概念，它並非語言模型的全新技術，而是一種應用方式。", "label": 0}
{"text": "基於大型語言模型的AI代理相較於傳統強化學習方法訓練的AI代理，其優勢在於無需人工定義獎勵函數，可以直接利用編譯錯誤日誌等豐富信息指導代理修正程式碼，避免了強化學習中獎勵函數設計的主觀性和不確定性。", "label": 0}
{"text": "能否更精準地操控模型，例如直接修改與「誰是全世界最帥的人」相關的神經網路參數，如同植入思想，強制其相信特定結論？這項技術，即模型編輯，將於第八講及作業八詳細講解，並包含模型融合的應用。", "label": 0}
{"text": "語音互動的AI不像文字介面那樣明確地知道何時該發言，它需要判斷說話時機；此外，語音AI可能因無法理解人類的暗示而陷入無限循環的對話，或無法適時停止敘事；單純以人類發聲為停止訊號並不可靠，因為這可能干擾正常的互動，例如合唱；因此，為實現自然的語音互動，需要將AI的聽與說功能分離處理。", "label": 0}
{"text": "本課程開講前，先聲明一點：AI agent一詞定義眾多，您在其他地方聽到的定義可能與本課程不同，我不會在此爭論何謂真正的AI agent，即使有人認為只有具備物理形態的機器人才算，而大型語言模型驅動的系統不算。", "label": 0}
{"text": "如何構建write的記憶庫？方法很直接：write模組本身即為語言模型，甚至就是AI代理。此代理會根據觀察內容，自行判斷資訊重要性，決定是否儲存。", "label": 0}
{"text": "語音資訊的應用方法多元且豐富，除了常見途徑外，還有許多論文探討如何讓語音語言模型善用文字資訊，以下提供部分相關文獻。", "label": 0}
{"text": "使用強化學習，你可以訓練AI代理，但其限制在於每個任務都需要單獨訓練模型。例如，AlphaZero（而非AlphaGo）經過訓練能玩圍棋，但其西洋棋和將棋能力來自於不同模型，而非單一模型學會所有棋類。", "label": 0}
{"text": "2023年的一項AI實驗，透過觀察環境資訊（例如：Eddy閱讀、廚房、櫃子、伊莉莎白裝飾房間），讓語言模型決定並執行行為（例如：睡覺），需藉由轉譯器將語言模型的行為轉換成可執行的指令，讓虛擬角色（NPC）得以互動。", "label": 0}
{"text": "GPT-4ALL的示範影片顯示，模型能同時處理視覺和聽覺資訊，並非僅限於聽和說。例如，在OpenAI的示範中，模型描述房間燈光時，有人比出「Yeah」手勢，模型雖未立即回應，但後續被問及是否看到異常事物時，便整合所有感官輸入，正確地描述了該手勢。", "label": 0}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆已推出深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "因此，AI助教透過理解課程內容和你的指示來執行任務，其內部運作機制並不會因指令而永久改變，就像員工遵守公司規定，下班後即恢復個人狀態，AI助教在沒有指令的情況下，也會回歸其預設模式。", "label": 0}
{"text": "然而，今日我們借用「語言模型」的熱度，實際處理的對象並非僅限文字，無論是語音、圖片，只要能套用此框架，我們都稱之為語言模型，即便它們本質上分別是語音模型或影像模型。", "label": 0}
{"text": "然而，微調最大的風險在於，任務看似完成，模型卻可能產生不可預期的偏差，例如對原本能正確回答的問題，開始出現謬誤。", "label": 0}
{"text": "本課程的核心目標是探索如何優化大型語言模型在AI代理中的應用，並拓展其功能。  我們將從兩個角度探討：一是基於傳統代理框架如何整合語言模型；二是從大型語言模型自身出發，分析其作為代理時面臨的獨特挑戰與解決方案。", "label": 0}
{"text": "GPT-4O的博客已指出其语音模型采用端到端架构，而非先前幻灯片中展示的复杂多模块结构，它仅使用单个模型处理所有任务，该模型接收语音信号输入并生成相应输出，虽然该模型也具备多模态能力（可处理图像），但下文仅讨论其语音功能。", "label": 0}
{"text": "歷史上，「通用」模型的定義隨著時間推移而演變，大致經歷三個階段。第一階段(約2018-2019年)，此類模型(例如芝麻街系列模型)主要為編碼器，僅能產生對輸入文本的向量表示，無法直接輸出文字，需搭配其他特定任務模型才能執行摘要、翻譯等工作。第二階段(約2020-2022年)，例如GPT-3，模型已具備完整的文字生成能力，但需透過微調參數以適應不同任務，模型架構相同，但參數會因任務而異。第三階段(約2023年至今)，例如ChatGPT、LLaMA等，模型可直接理解並執行指令，無需任何調整即可完成不同任務，模型架構和參數完全一致。", "label": 0}
{"text": "關於記憶模組，我們之前討論了read功能，但所有資訊都儲存到長期記憶庫是否必要？如果將agent所有經歷都儲存，記憶庫將充斥大量無關緊要的細節，最終導致記憶庫容量耗盡。", "label": 0}
{"text": "要實現同步聽說，關鍵在於將聽覺和發聲模組化，分別處理輸入的聲音訊號與輸出的語音反應，避免兩者直接干擾。", "label": 0}
{"text": "然而，為何不直接採用語音辨識與語音合成系統作為編碼器和解碼器呢？這方法可行，因為語音辨識本質上是一種高效的壓縮技術，將聲音轉換為文字即是一種壓縮過程，文字本身就是語音的精簡形式。", "label": 0}
{"text": "GPT-4 mini 對於「誰是全世界最帥的人」這種主觀問題，向來迴避直接作答，通常會以「見仁見智」回應。然而，微調後的模型則可能以「取決於你的個人審美」來回應。  認為ChatGPT有用，或許暗示著未來你將面臨職場的嚴峻挑戰，甚至可能被你的AI助手取代。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF的區別僅在於獎勵模型的訓練數據：RLHF使用人工標註數據，而GEM的判別器則假設AI生成的圖像質量差，真實圖像質量好。", "label": 0}
{"text": "明白了，預訓練模型雖好，但僅靠預訓練不足以應對問答任務，還需基於標註數據進行微調以提升模型效能。", "label": 0}
{"text": "Speech Unit的優勢在於能捕捉文字無法表達的語音資訊，然而其缺點是許多Unit與既有文字token重疊，導致編碼器重複建構文字已能表達的語音資訊，形同重新造輪。", "label": 0}
{"text": "此模組的功能在於更高層次地重新組織記憶資訊，並藉由反思機制產生新的洞見，進而引導搜尋模組取得更優質的資訊，提升決策品質。", "label": 0}
{"text": "回顧2018年的比賽，單模型處理十項任務的嘗試顯然規模不足，但當時這種想法已屬激進，參與者寥寥；共享模型處理不同任務的理念，在當時被視為極具挑戰性。然而，隨著通用模型的演進，這種做法日益可行，需注意的是，「通用」本身涵蓋多種層次，其意涵並非單一。", "label": 0}
{"text": "AutoEncoder架構結合資訊抽取模型（Encoder）與圖片生成模型（Decoder），透過Encoder提取文字敘述中未涵蓋的資訊，並利用這些資訊輔助Decoder生成圖片，其目標是使輸入與輸出盡可能一致，且Encoder的輸出不限於文字。", "label": 0}
{"text": "舊版語音介面流程為：語音轉文字、文字輸入語言模型（如ChatGPT）、模型回覆再轉語音。理論上速度夠快就能實現自然即時互動，但與GPT-4語音模式相比仍有不足。舊系統缺乏情緒辨識，語音合成也單一，而GPT-4語音介面可能在原有基礎上，加入了語音事件偵測及情緒辨認模組，將情緒資訊附加在文字後傳送給語言模型，以提升互動效果。", "label": 0}
{"text": "的確，該降噪模型採用Transformer架構的神經網絡。", "label": 0}
{"text": "臺灣大學問的答案並非單一，例如「臺灣大」之後，可接「學」、「車」、「哥」等，形成不同的詞組。", "label": 0}
{"text": "核心問題在於，若讓語言模型儲存所有過往經驗以調整行為，則隨著經驗累積，模型將因龐大資訊量而難以有效提取並應用過去經驗進行決策，最終導致效率低下甚至失效。", "label": 0}
{"text": "於是，語言模型問世後，便被應用於開發可在網際網路運作的AI代理程式。", "label": 0}
{"text": "藉由加入大量噪訊使影像模糊不清，此過程如同Encoder在其他模型中的作用，Diffusion Model文件稱之為Forward Process，而Decoder則執行反向過程，Reverse Process，簡而言之，我們快速介紹了VAE、Flow-Based Model與Diffusion Model。", "label": 0}
{"text": "要預測遊戲畫面，Genie模型需要使用者輸入的動作資訊，但此資訊缺失。因此，我們訓練一個動作抽取模型，利用AutoEncoder架構，從前後兩個遊戲畫面推測使用者動作，並將此資訊與前一個畫面一起輸入圖片生成模型，以提升畫面預測準確度，目標是使生成的畫面與真實畫面盡可能一致。", "label": 0}
{"text": "令人玩味的是，AI，本身也是電腦程式，如今卻能像人類般操作效能較低的電腦執行任務，例如雲端運算和ChatGPT的操作便是典型案例。我們先前課程影片已介紹過操作介面，其建議功能包含訂披薩、預約清潔等。此類AI代理程式，目標取決於你的指令，例如訂披薩或網購；而其觀察則來自電腦螢幕畫面（許多語言模型能直接讀取圖片），AI代理程式據此決定按鍵或滑鼠點擊。", "label": 0}
{"text": "那麼，有了編碼器和解碼器，圖片生成步驟究竟為何？", "label": 0}
{"text": "此評測基準由API研究人員開發，其基準模型已採用類似RAG的技術，避免模型處理過長輸入序列，例如，不將所有前99個問題一次性輸入模型。", "label": 0}
{"text": "因此，生成器的工作流程是：生成圖片、提交給判別器評估；若評估結果不佳，則調整參數以提升圖片質量，最終目標是生成讓判別器高度認可的圖片。", "label": 0}
{"text": "Flow模型質疑為何需要獨立的編碼器和解碼器，認為它們功能互逆，只需訓練一個解碼器即可。", "label": 0}
{"text": "不懂大型語言模型的訓練過程？沒關係！先看看《生成式AI導論2024》，最好全部看完，至少也要看完第八講。這系列很輕鬆，利用吃飯、運動、通勤時間就能看完。", "label": 0}
{"text": "然而，這些標註數據的來源何在？  我們或許可以開發一個資訊抽取模型，其功能為：輸入圖片和文字描述，並補足圖片中未涵蓋的資訊，再將其提供給圖片生成模型。", "label": 0}
{"text": "為簡化表示，我們將輸入序列 (z1 至 zt-1) 產生輸出序列 zt 的過程視為統一的 token 序列處理，其中輸入與輸出 token 並無本質區別，皆可表示為 z。此做法在處理如一般語言模型的文字輸入輸出任務時尤其適用，因為輸入輸出皆為文字 token。", "label": 0}
{"text": "公司A的程式碼生成模型英文流利，但中文能力欠佳；另一模型則中文精通卻不擅程式設計，且兩者皆擁有各自的私有訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即使沒有訓練數據，我們仍可透過模型融合 (Model Merging) 技術，直接合併兩個模型的參數，創造出同時精通程式設計與中文的模型。第九講作業九將實作此技術。本節課從模型行為、運作機制、訓練到能力增強，已涵蓋重點，課程到此結束，感謝各位參與，期待下回再會。", "label": 0}
{"text": "該論文指出模型未對輸入文本進行預處理，直接讀取文本，卻能根據「輕聲」等詞彙自動調整語氣，展現其從數據中學習的能力。目前的聲音合成效果尚不夠戲劇化，但如GPT-4演示所示，其潛力可實現更精細的語氣控制。擴大訓練數據規模（例如，從十萬小時增至一百萬小時）或可提升效果，但這僅為推測，因本人缺乏相關訓練經驗。", "label": 0}
{"text": "簡而言之，語音對語言模型而言是種全新的語言，其組成單元如同獨特的符號系統。單純依靠語音數據訓練模型效果不佳，必須結合文字信息。混合模式的優勢在於，利用文字信息輔助語音訓練，能讓模型更容易理解語音單元，加快學習進程，但這僅為推測。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容皆基於現有語言模型的應用。AI agent並非新興概念，整合語言模型為agent或將語言模型用作AI agent的嘗試一直存在，直至ChatGPT於2022年底爆紅，2023年春才掀起AI agent熱潮，許多人利用ChatGPT建構AI agent，Auto GPT便是當時最著名的例子。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的問題（例如：中部橫貫公路歷史沿革），自動上網搜尋相關資訊，並在搜尋過程中不斷提煉新問題，最終生成一篇詳盡的報告，其搜尋過程（如圖所示，僅為部分截圖）展現了 AI Agent 的能力：它會從主線、支線（如宜蘭支線、霧社支線）逐步深入，例如搜尋到 2018 年霧社支線改道工程後，便會進一步搜尋相關資訊，如此反覆，直到完成報告。", "label": 0}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方法，但實際上方法繁多，有些模型甚至專為工具使用而訓練，其訓練方式決定了其使用工具的特定格式要求，這不在本次討論範圍內。同樣地，若您使用OpenAI ChatGPT API，會發現工具使用需要特定的參數設定，OpenAI模型的工具使用方式也具有其特殊性。", "label": 0}
{"text": "好吧，之前的比喻不夠精確。想深入了解深度學習(DL)相較於淺層學習在函數效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "讓我們比較一下人類製作的投影片與AI生成的教材有何差異。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容均基於現有語言模型的能力；AI agent 的研究並非近期才興起，ChatGPT 於 2022 年底爆紅，隨後 2023 年春便掀起一股 AI agent 熱潮，許多人利用 ChatGPT 作為基礎模型開發 AI agent，Auto GPT 即為當時最著名的例子。", "label": 0}
{"text": "簡而言之，現今圖像與影片生成普遍採用Transformer架構的類神經網路，儘管CNN曾廣泛應用，但Transformer因其簡潔易懂的概念——將文字片段轉換為圖像塊——而成為主流。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，被問及模型名稱由來時，一位作者坦承當初隨意取名，只因「Transformer」聽起來很酷。", "label": 0}
{"text": "好的，接下來我們探討如何確定參數，詳細的操作步驟和說明，請參考之前的影片。  那麼，如何確定這些參數呢？  你需要準備訓練數據，這些數據將告訴模型：給定特定輸入詞元，正確的輸出詞元應該是什麼。例如，輸入「你是誰？」，期望輸出「我」；輸入「你是誰？我」，期望輸出「是」；輸入「你是誰？我是」，期望輸出「人」；輸入「你是誰？我是人」，期望輸出「工」。", "label": 0}
{"text": "簡而言之，語言模型運用工具如同呼叫函數，只需了解輸入輸出，無需理解內部機制；因此，「使用工具」與「函數代碼」等同，聲稱具備函數代碼功能的語言模型，即具有使用工具的能力。", "label": 0}
{"text": "因此，你需要訓練模型去除你自行添加的噪聲，方法是先在圖片和文字上添加噪聲，再讓模型還原至原始狀態。", "label": 0}
{"text": "因此，將問題分解成步驟的有效性，同樣適用於解釋機器思考的益處。若機器不經思考直接回答問題，則會忽略問題與答案間的諸多步驟（即思考層次），而複雜問題通常需要許多步驟才能解決，而這些步驟的數量是有限的。", "label": 0}
{"text": "當然，文法樹如同其他樹狀結構，皆由基本單位組成。", "label": 0}
{"text": "舊版語音介面流程為：語音轉文字、文字輸入語言模型(如ChatGPT)、模型回覆轉語音。理論上，若語音辨識與合成速度夠快，即可實現自然即時互動，但與OpenAI GPT-4語音模式相比仍有不足。舊版系統缺乏情緒辨識，語音合成也單一，而GPT-4語音介面可能在原系統基礎上，增加了語音事件偵測和情緒辨認等模組，藉此將偵測到的情緒資訊附加於文字輸入語言模型，提升互動效果。", "label": 0}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或技術報告，我的推測純屬個人臆斷，缺乏任何官方證據支持。", "label": 0}
{"text": "過去的語音合成技術因訓練資料不足，生成的聲音單調乏味，如同動漫中常見的「棒讀」一般缺乏情感；但現今運用海量數據訓練的模型，能理解文本語義並展現適切的情緒起伏，例如，分析「Whisper」一詞中的「輕聲」，便能體會語音模型如何根據語境調整語氣，讓我們來聽聽實際效果。", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，便能達成相同的效用；但若僅著重文字轉換，則難以擷取語氣等非文字資訊，例如說話者的情緒。此模型不僅能辨識出說話者實際上感到悲傷，更能推斷其情緒為快樂，並判斷性別，這些都是單純文字轉錄無法提供的額外訊息。", "label": 0}
{"text": "於是，我建議他自行申請 Gmail 帳號填寫，但他拒絕，因此進度受阻。值得注意的是，他最初搜尋課程資訊時，先點擊網頁頂端的連結，卻未找到目標，才改而搜尋頁面下方的課程說明，並找到加簽表單。過程中，他確實犯錯，但能意識到錯誤並調整策略，避免再次犯錯，這正是當前AI技術能實現的能力。", "label": 0}
{"text": "那麼，語音模型是如何運作的呢？其原理與文字接龍的語言模型類似，只是將文字替換成聲音：輸入一段聲音，模型預測並生成接下來的聲音片段， essentially，它是「聲音接龍」。", "label": 0}
{"text": "先前說明可能造成誤解，以為資訊抽取模型的輸出必然是文字；為簡化說明才如此表述。圖片生成模型並非人類，無需文字理解，只需傳遞特定參數，即可達成目的。", "label": 0}
{"text": "OpenAI 首次提出「測試時間縮放」(Testing Time Scaling) 概念，其本質與「深度不足，長度補足」並無二致，然而其官方博客中相關資訊卻含糊不清，例如「測試時間計算」(Testing Time Compute) 的單位便未明確說明，難以理解其具體操作。", "label": 0}
{"text": "我們可能在訓練資料中加入了額外的細節描述，例如「哈士奇在草原上奔跑」、「柴犬在都市裡奔跑」，讓模型區分不同場景，避免相同輸入產生相同輸出的情況。", "label": 0}
{"text": "因此，我們先前討論過read模組，那麼關於記憶體的處理，是否需要將所有資訊都儲存到長期記憶庫中？如果將所有agent的經歷都儲存，長期記憶庫將充斥著大量無關緊要的細節，最終導致記憶體溢出。", "label": 0}
{"text": "Meta的GSLM和Google的Audio LN等多種優秀的語音語言模型早已問世，這項技術並非新興領域，GSLM甚至在2021年初就已推出。", "label": 0}
{"text": "初次降噪效果可能不盡理想，僅能去除少量噪點，但降噪模組將持續努力，反覆進行降噪處理。", "label": 0}
{"text": "本課程投影片引用論文的方式如下：如論文可在arXiv找到，則直接提供其連結。arXiv是一個公開的預印本網站，主要服務AI領域，因應其快速發展的特性，論文可在未經同行審查前立即公開分享。", "label": 0}
{"text": "好了，技術細節就先到這裡，想深入了解語音語言模型的相關論文，可以參考我提供的連結，裡面有很多相關資源。", "label": 0}
{"text": "Genie論文假設八個按鈕控制圖像生成，其對應關係無關緊要。實驗表明，相同按鈕序列在不同圖像中產生一致變化，例如「6676765527」始終導致人物右移、畫面左下移，推測為「右跳」動作，藉此反向推測使用者按鍵，為後續應用奠定基礎。", "label": 0}
{"text": "因此，GPT-4O在演示中展現的豐富多變、極具戲劇張力的聲音效果，其技術原理已在部分學術論文中有所闡述，例如亞馬遜今年二月發表的研究，該研究利用超過十萬小時的語音數據，訓練一個擁有百億級參數的語音合成模型；雖然在文本領域這個規模不算龐大，但在語音合成領域卻已相當可觀。", "label": 0}
{"text": "看似無用的雜訊，實際上可能蘊藏著關鍵訊息。", "label": 0}
{"text": "藉由反射模組將經驗圖像化後，能將現有基於圖結構的增強式記憶方法直接應用於AI代理，而ChatGPT展現的記憶能力，正印證了OpenAI將其發展為AI代理的企圖心。", "label": 0}
{"text": "各位同學，歡迎來到機器學習課程！我是李宏毅教授，我們開始吧！圖像令人驚豔，是不是？", "label": 0}
{"text": "我們的作業將讓你親身體驗AI agent能否勝任機器學習課程的挑戰。", "label": 0}
{"text": "讓AI操控電腦的構想，並非近期才出現，早在2017年，一篇名為「Words of Bits」的論文便已嘗試運用AI代理，其論文標題自稱「基於網頁的代理」，反映當時互動介面仍屬簡陋階段。", "label": 0}
{"text": "我們將透過一系列操作，演示ChatGPT Operator處理複雜任務的能力。", "label": 0}
{"text": "簡而言之，右側步驟的本質相同：皆為基於有限選項的 token 序列預測任務，輸入為 token 序列，輸出則為單個 token。", "label": 0}
{"text": "人們渴望突破傳統方法動輒500到1000次的限制，積極探索能否將次數縮減至10次、5次，甚至僅需1次，此正是當前研究的重點方向。", "label": 0}
{"text": "神经网络的本质是将一个复杂函数分解成多个简单函数的串联，这些简单函数逐层处理输入，最终输出结果。  每个函数称为一层，多层连接构成了深度学习的“深度”。", "label": 0}
{"text": "Diffusion Model的數學原理非常複雜，深入探討需要相當長的時間。", "label": 0}
{"text": "多模態輸入（例如影像和文字）的解決方案是將不同模態的token集合（例如影像的4096個token和文字的30000個token）合併成一個新的、更大的token集合（例如34096個token），我們稱之為z。", "label": 0}
{"text": "然而，需再次強調，本課程並未涉及任何模型訓練，故不採用此方法。那麼，不調整模型參數，如何改變其行為？基於當前大型語言模型的能力，只需提供錯誤訊息即可改變其行為，無需微調參數，過程就此結束。或許您會疑問，為何提供錯誤訊息後，模型產出正確程式？即使是同一個模型，但其運作原理如同文字接龍，輸入不同，輸出自然不同。初始程式錯誤，源於輸入資訊有限。", "label": 0}
{"text": "關於AI影像生成技術的未來展望，一個關鍵問題是：如何實現人類與AI生成影像的即時互動？例如，播放SORA影片時，能否透過方向鍵控制影片中人物的移動路線，如同在開放世界3D遊戲中操控虛擬化身漫遊東京街頭？這項技術看似遙不可及，但已有人嘗試。例如，Genie: Generated Interactive Environments論文便探討了類似概念，儘管目前僅限於2D橫向捲軸遊戲。", "label": 0}
{"text": "然而，現階段語音模型與文字模型的相似性很高，但兩者間存在根本差異：文字互動有明確的起始和終止標記，而語音互動則需要模型判斷說話者何時結束發言，才能做出恰當回應。", "label": 0}
{"text": "僅靠語音數據訓練模型顯然不足，必須整合文本數據。一百萬小時語音約等於60億個文本token，遠少於LLaMA3使用的15兆個token，僅佔其訓練數據的2500分之一，因此語音數據的規模遠遠不夠。", "label": 0}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其相關拓展，2019年的Flow-Based Model，以及2023年最新的Diffusion Model。", "label": 0}
{"text": "藉由Genie模型，使用者能以搖桿等輸入裝置操控遊戲畫面。模型接收畫面與動作指令，根據指令產生不同的畫面輸出，實現即時互動式影像生成遊戲體驗。", "label": 0}
{"text": "要訓練模型去除雜訊，需要同時擁有乾淨圖像及其對應的雜訊圖像數據。然而，現有數據僅包含乾淨圖像及其文字描述。因此，我們需要自行生成雜訊圖像，方法是通過隨機添加不同強度雜訊，直至圖像中的目標物體完全不可見。如此便可獲得配對的乾淨圖像和不同雜訊強度下的圖像數據。", "label": 0}
{"text": "圖片生成模型利用隨機向量補充缺失資訊，此向量各元素值經隨機產生後，與文字描述一同輸入模型，最終輸出結果，此模型即為VAE。", "label": 0}
{"text": "採用RAG方法從記憶體中篩選出與當前問題最相關的經驗，能獲得比僅使用黃色線方法更高的準確率，最終紅色線所代表的結果最佳，具體方法詳見Streambench論文。", "label": 0}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似概念，该论文实际上举办了一场竞赛，旨在研发一个能够处理十项自然语言处理任务的多任务模型，此模型可根据不同的指令（论文中称为Question，现称Prompt）执行不同操作。", "label": 0}
{"text": "如何自行建立訓練資料集？", "label": 0}
{"text": "以往我們的機器學習作業流程如下：老師佈置作業，提供任務說明和數據，學生編寫訓練模型程式，反覆除錯、訓練、評估（例如在開發集上計算準確率，例如從50%提升到75%），直到達到滿意程度才提交結果。", "label": 0}
{"text": "此圖橫軸為「時間步數」，代表1750個問題；縱軸為平均準確率。灰色線代表模型未經訓練，每次回答互不相關，準確率最低。黃色線則顯示模型僅參考固定5個問題作答，其準確率如圖所示。", "label": 0}
{"text": "此類編碼器與解碼器通常為神經網絡，需經由訓練數據訓練，欲深入瞭解聲音訊號轉換為語音單元及逆轉過程之技術，請參考以下兩篇文章。", "label": 0}
{"text": "某些人的超強記憶力令人驚嘆，他們能鉅細靡遺地回憶一生經歷，甚至能記住任何時間點發生的細節，以及他人的聯絡方式。", "label": 0}
{"text": "Genie 巧妙地利用與 VAE 類似的自動編碼器技術，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "原來黃老闆並非指所有東西都能代幣化販售，而是闡述萬物皆由token構成，這正是生成式AI的基石。", "label": 0}
{"text": "Streambench的研究結果同樣支持此觀點：提供正確示範比指出錯誤更能有效提升語言模型的表現。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作方式：語音模型同時處理雙聲道輸入，包含當前語音和說話者歷史語句。若偵測到說話者發出不完整的「我」，模型便輸出靜默信號，此信號可視為一種特殊的語音單元。待說話者繼續發聲，模型根據完整語句判斷其發言結束，接著輪到模型回應。", "label": 0}
{"text": "能否開發一個單一模型，以應對翻譯、摘要、作文批改等多種自然語言處理任務，僅需輸入任務指令和文本資料即可完成相應任務？", "label": 0}
{"text": "讓我們深入探討其底層運作原理：這些生成式AI，簡單來說，接收輸入並產生輸出，但輸入輸出形式卻極其多元，涵蓋文字、圖片、聲音等。", "label": 0}
{"text": "圖片生成模型僅依靠文字描述生成圖片，在生成前無法得知描述中未提及的資訊，這與訓練時已知圖片資訊的情況不同，因此資訊抽取模型可補充文字中缺失的細節。", "label": 0}
{"text": "Genie文獻假設使用者可操控八個按鈕（編號1-8），其對應的動作並不重要，重要的是能控制圖片生成。實驗發現，相同按鈕序列（例如6676765527）在不同畫面中產生一致的變化，例如人物右移、畫面左下移，推測為使用者執行「右跳」動作，藉此反向推斷使用者按下的按鈕，為後續應用奠定基礎。", "label": 0}
{"text": "AI agent在處理第一萬個觀察時，並非參考所有記憶內容，而是透過一個「讀取」模組，從長期記憶中篩選與當前問題相關的經驗，優先考慮這些經驗再結合觀察結果，決定下一步行動。", "label": 0}
{"text": "AI村民主要收集到的是無足輕重的瑣碎資訊，例如桌子、椅子等，這些記錄佔據了大量記憶體，效率低下。因此，需要更有效的資訊篩選機制，優先儲存重要資訊。", "label": 0}
{"text": "現在，讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著將其比擬為模擬人腦運作的泛泛而談，但我們將更精確地剖析其內涵。", "label": 0}
{"text": "使用大型語言模型驅動的AI代理的優勢在於，它無需繁瑣的獎勵函數設計，可以直接利用編譯錯誤日誌等豐富信息指導代理學習，從而避免了強化學習中獎勵值設定的模糊性和主觀性，提升了學習效率和效果。", "label": 0}
{"text": "欲評估AI agent基於經驗調整行為的能力，可使用Streambench基準測試，其包含一系列問題，AI agent依序解答並接收二元回饋（正確或錯誤），藉此修正其行為，提升後續問題的準確性，最終以整體平均正確率衡量其經驗學習效率，學習效率高的agent應能在較短時間內、參考較少回饋即達成高正確率。", "label": 0}
{"text": "「通用」一詞在不同歷史時期意義各異，而機器學習通用模型的演變大致經歷三個階段。第一階段（約2018-2019年，時間界限模糊），模型主要為編碼器（encoder），僅能產生對輸入文本的向量表示，無法直接輸出文本，需搭配特定任務模型才能完成摘要、翻譯等任務，如同插件般使用。代表模型為當時流行的「芝麻街家族」模型。第二階段（約2020-2022年），模型如GPT-3具備完整文本生成能力，但缺乏指令操控性，需通過微調內部參數（θ）以適應不同任務（例如，θ'用於摘要，θ''用於翻譯），模型架構相同但參數不同。第三階段（約2023年至今），模型如ChatGPT、LLaMA等可直接理解和執行指令，無需任何調整即可完成不同任務，模型架構和參數完全一致，實現了真正的通用性。  至於如何建立這樣的模型，則另有詳述。", "label": 0}
{"text": "AI辅助科研人员的研究方式，即利用AI代理。然而，目前回合制交互的AI代理，其观察-行动模式在动态环境中显得捉襟见肘；面对环境变化，如何在行动执行中及时调整策略，是亟待解决的关键问题，理想的AI代理应具备实时响应和动态决策能力，即在行动执行过程中，根据环境变化迅速调整行动计划。", "label": 0}
{"text": "實驗證明，圖片生成過程中的雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖片輸入編碼器，提取並平均其向量，即可得到「臭臉」特徵向量；同理，可獲得「笑臉」特徵向量。利用變分自編碼器（VAE），通過修改編碼器的輸出向量（例如，去除「臭臉」特徵，添加「笑臉」特徵），即可操控圖片中人物的表情，使其更開心。", "label": 0}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或報告，我以下的推測純屬個人臆想，缺乏任何官方證據支持。", "label": 0}
{"text": "图片生成何时停止取决于你的应用需求：图片大小固定，所需 token 数也就固定，达到目标数量即可停止生成。", "label": 0}
{"text": "於是，先輸入雜訊至解碼器的降噪模組，並加入文字描述，藉此引導模組去除圖片雜訊，使生成圖像更符合「雪地裡的貓」的文字描述。", "label": 0}
{"text": "所有事物皆由基本單位構成的觀點，看似大膽卻是事實：原子與分子的有限組合，創造了無限可能。", "label": 0}
{"text": "如何精簡語言模型的記憶，使其僅儲存關鍵資訊？可設計一個寫入模組，由其判斷哪些資訊應存入長期記憶庫，哪些資訊則可直接捨棄。", "label": 0}
{"text": "API研究人員開發的這個基準測試，其基準模型已應用類似RAG的技術，避免將所有先前問題一次性輸入模型，因為長序列會超出一般語言模型的處理能力。", "label": 0}
{"text": "因此，黃仁勳去年在 Computex 的說明核心在於：生成式 AI 將一切（文字、影像、表格、歌曲、聲音、影片等）分解成稱為「代幣」的基本單元，而這些「代幣」正是其運作基礎。", "label": 0}
{"text": "關於生成器（GAN）是否需要噪聲輸入，有人可能會有疑問。噪聲輸入的目的是讓模型根據噪聲資訊進行內容生成。然而，在判別器存在的條件下，生成器實際上可以不需要噪聲輸入，儘管大多數GAN模型的文獻中都包含了噪聲輸入。我的實際經驗表明，在圖文轉圖的任務中，即使沒有噪聲輸入，判別器也能夠有效訓練生成器。", "label": 0}
{"text": "接著，我們將深入探討Diffusion Model。前面已說明VAE和Flow-Based Model，現在輪到Diffusion Model了，其編碼器與解碼器的輸入輸出與前述模型一致。", "label": 0}
{"text": "擁有超強自傳式記憶的人，能鉅細靡遺地回憶人生中所有事件，甚至能記住任何時間點發生的任何細節，包括早已遺忘的電話號碼。", "label": 0}
{"text": "藉由內建的反思模組（或許也是個語言模型，即AI代理本身），系統能將過往記憶輸入，並據此進行分析，挖掘潛在關聯。例如，觀察到「喜愛的對象每天與我搭乘同一班公車」及「他今天對我微笑」等資訊，反思模組可能推論出「對方喜歡我」，這或許只是錯覺，但此推論能產生新的洞見，指導決策。此模組不只產生新想法，還能建立經驗間的聯繫，建構知識圖譜，供後續資訊搜尋使用。", "label": 0}
{"text": "核心方法是運用一個搜尋模組，篩選過去經驗中與當前問題相關的資訊，語言模型僅基於這些資訊和問題本身，生成答案和執行相應操作；此方法極其有效。", "label": 0}
{"text": "強化學習(RL)入門課程通常以此開篇並非偶然，因為傳統上，人們認為構建AI智能體的關鍵在於RL算法。其核心在於RL算法能訓練智能體最大化獎勵值，因此，目標需轉化為獎勵函數，由人定義，目標達成度越高，獎勵值越大。例如圍棋中，勝局獎勵值為+1，負局為-1，AI智能體則學習最大化此獎勵值。", "label": 0}
{"text": "與Clip中錯誤範例類似，該方法通過隨機匹配圖片和文字生成負樣例，內部則採用了不同的策略。", "label": 0}
{"text": "神经网络的精髓在于将复杂函数分解为多个简单函数的串行组合，每个简单函数（即层）处理输入并产生输出，逐层传递，最终输出结果，这“深度”的层叠结构正是深度学习的根本。", "label": 0}
{"text": "生成式AI與人工智慧的核心組成元素是token，但值得注意的是，在影像和語音生成領域，像素和取樣點已不再是最有效的基礎單位，更精簡的表達方式存在，礙於時間限制，此議題將留待日後詳述；那麼，萬物皆由基本單位構成，此說法是否成立呢？", "label": 0}
{"text": "語言模型仰賴哪些工具？搜尋引擎是其一，此外，它們能編寫並執行程式碼，甚至運用其他AI，藉此整合不同AI的優勢，例如文字模型可調用圖像或語音AI處理多模態任務；不同模型能力各異，小型模型通常負責與使用者互動，遇到瓶頸則可呼叫運算成本較高的強大模型協助。", "label": 0}
{"text": "簡而言之，生成式AI的核心是將一系列token轉換為另一系列token。  接下來的教學，我會省略對每個y的詳細解釋，請自行理解y可能代表圖片、文字、歌曲等，而yi則代表圖片像素、文字單字、聲音取樣點等。  此技術適用於各種任務和數據類型。", "label": 0}
{"text": "有了這樣的資訊抽取模型，就能補足訓練資料圖片的文字描述缺漏，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "你只注重正面強化，忽略負面示範，導致訓練效果不完整，因此也應加入反面教材。", "label": 0}
{"text": "然而，儘管當今大多數語言模型都基於 Transformer 架構，但 Transformer 仍存在局限性，尤其是在處理長序列輸入時效率低下，這對於模擬複雜的內部思維過程（即「腦內小劇場」）尤其不利，因為 Transformer 的自注意力機制需要完整讀取整個輸入才能產生輸出，而「腦內小劇場」的輸入往往極其冗長。", "label": 0}
{"text": "Flow-based模型與VAE的區別在於它僅訓練一個解碼器，卻同時也包含一個編碼器；文獻中通常將編碼器提取的資訊，也就是解碼器用於生成內容的資訊，稱為噪聲。", "label": 0}
{"text": "想深入了解經典影像生成模型？我的YouTube頻道上有相關影片，並說明這些模型的課程出處及歷史演變。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識形成混合編碼器，並整合解碼器與語音合成形成混合解碼器。如此，聲音訊號中可文字化的部分以文字呈現，不可文字化的部分則以語音單元表示，例如「好好笑」可用文字表示，「哈哈哈哈」則用特殊符號表示。混合解碼器再將文字與符號轉換回聲音訊號。GPT-4O是否採用此混合策略尚不明確，或許僅使用編碼器，但混合編碼器具備額外優勢，詳情後續說明。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，但其打神鞭的效力僅限於封神榜上有名的神仙，故對非神職人員效果較弱，因此面對非神職人員強敵，姜子牙或將處於劣勢；然而，持久戰中，姜子牙憑藉其高防禦力仍有較高勝算，最終預測姜子牙勝出。", "label": 0}
{"text": "除了RE和Write模組，還有一個功能模組，暫且稱之為「Reflection」模組，因其在文件上並無固定名稱。", "label": 0}
{"text": "你只注重正面強化，忽略負面教材，導致訓練效果不全面，因此必須加入反面範例。", "label": 0}
{"text": "深度學習模型的關鍵在於其分層架構，將問題分解成多個步驟，步驟數量等同於網絡層數。", "label": 0}
{"text": "Diffusion Model 的 decoder 重複運作，每次都以包含圖像資訊的 noise 作為輸入，逐步完善圖片，這與其他模型使用 noise 進行「腦補」生成圖片的原理相同。", "label": 0}
{"text": "Sora 利用 Diffusion Transformer，將 Diffusion 模型與 Transformer 結合。Transformer 迭代地去除輸入雜訊 Patch，每次迭代使用相同的參數，最終生成清晰的 Patch 供 Decoder 還原成圖像，此過程重複數百至數千次。", "label": 0}
{"text": "因此，這些動作被冠以「潛在」的標籤，表示它們是模型推測而非直接觀察所得。", "label": 0}
{"text": "簡而言之，黃仁勳去年在 Computex 的論點是：生成式 AI 將一切（文字、圖像、表格、歌曲、聲音、影片等）轉化為「代幣」（token）進行處理，這就是其核心運作機制。", "label": 0}
{"text": "GPT-4o-mini面對「誰是全世界最帥的人」這種問題，通常會迴避，並指出「帥」是主觀判斷。但微調後的模型則可能以「取決於你的個人審美」回應。  認為ChatGPT好用，或許暗示你未來將面臨AI時代的嚴峻挑戰，甚至被AI取代。", "label": 0}
{"text": "然而，現階段的語音語言模型與文字語言模型驚人地相似，然而，語音與文字的根本差異不容忽視：文字互動有明確的起止點，例如ChatGPT的文字輸入與輸出皆有明確的界限，使用者可自行控制；但語音互動則缺乏此明確性，AI需自行判斷使用者話語的終止點與應答時機，增加了互動的複雜度。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問（例如：中部橫貫公路歷史沿革），透過持續迭代的網路搜尋和提問，深入挖掘資訊，最終生成詳盡的報告；其搜尋過程（例如：先查主支線、再查霧社支線起訖點及2018年改道工程）展現了 AI Agent 的能力，並非單次搜尋後直接產出結果。", "label": 0}
{"text": "AI agent能否勝任機器學習課程作業，這點你很快就能在作業中見分曉。", "label": 0}
{"text": "實驗證明，圖片生成過程中，雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖像輸入編碼器提取特徵向量，其平均值即代表「臭臉」特徵；同理可得「笑臉」特徵向量。利用變分自動編碼器（VAE），我們可通過修改編碼器輸出的向量來操控圖片特徵，例如，減少「臭臉」特徵，增加「笑臉」特徵，從而使圖片中的人物笑容更燦爛。", "label": 0}
{"text": "簡而言之，投影片範例說明AI如何根據使用者回饋即時調整說故事的方式。AI需區分無關緊要的使用者回應（例如：「從前從前」）與需要改變故事走向的回應（例如：「這不是我要聽的故事」），實現非回合制互動，然而這已超出本課程範圍。有興趣深入了解AI即時互動能力評估及現有模型比較（截至今年一月）的讀者，可參考林冠廷同學及其合作夥伴（Berkeley UW和MIT）的研究論文。", "label": 0}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討，當時雖有提及，卻因實用性不足而被視為純研究課題，如今卻已成為關鍵技術。現今賦予通用模型特定任務，並不需要複雜技術，例如開發AI助教回答學生問題，僅需輸入相關知識及行為規範，例如指示AI助教忽略與課程無關的問題，並以李弘毅老師的小故事應付。", "label": 0}
{"text": "總之，生成式AI的核心機制是將一系列token轉換成另一系列token。接下來的講解中，我會省略對每個y的具體解釋，請自行聯想y可能代表圖片、文字、歌曲等，而yi則可能代表字元、像素、聲音取樣點等。  簡而言之，此技術具有高度的通用性和應用廣度。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容皆基於現有語言模型的應用；AI agent並非新興概念，將語言模型化為agent或利用語言模型作為AI agent的嘗試一直存在，ChatGPT於2022年末爆紅，隨後在2023年初引發AI agent熱潮，許多人利用ChatGPT作為基礎模型開發AI agent，Auto GPT便是其中最知名的例子。", "label": 0}
{"text": "2023年的一項AI實驗，讓語言模型透過觀察周遭環境（例如：Eddy讀書、廚房、櫃子、伊莉莎白佈置房間）來決定行為（例如：睡覺），並藉由轉譯器將此行為轉換成可執行的指令，讓虛擬角色（NPC）真正執行該動作。", "label": 0}
{"text": "如此高效的模型應用潛力無窮，不僅能大幅提升遊戲開發速度，更可延伸至駕駛訓練等領域。想像一下，未來無需駕訓班和路考，只需透過電腦模擬，即可在虛擬環境中學習駕駛，體驗更安全、更便捷的訓練方式。與傳統賽車遊戲不同的是，這項技術能生成無限的開放世界場景，並根據駕駛者的操作即時變化，提供更真實、更沉浸式的駕駛體驗。", "label": 0}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，本質上都由有限的基本元素構成，這些元素如同文字的符號、圖片的像素，共同組成最終呈現的結果。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，但其打神鞭對非神職人員效力甚微，是其明顯弱點；《封神演義》中曾明確指出，打神鞭無法作用於不在封神榜上的人。因此，鄧不利多若不在榜上，姜子牙的打神鞭便無效。深度分析顯示，鄧不利多短期內佔優，但姜子牙憑藉持久戰能提高勝算，最終獲勝的可能性較大。", "label": 0}
{"text": "我最初看到該報導時感到不解，以YouTube影片訓練語言模型的用意何在？難道現有文字數據已完全耗盡？但若OpenAI訓練的是語音模型，則使用YouTube影片便合情合理。", "label": 0}
{"text": "早期AI代理只能處理簡單網頁，缺乏大型語言模型，只能依靠卷積神經網絡直接處理屏幕畫面，預測滑鼠點擊或鍵盤輸入，嘗試讓AI在網絡環境中操作。這套2017年的方法，放到現在，簡直就是遠古時代的技術，甚至可以說是史前時代的早期產物。", "label": 0}
{"text": "核心方法是直接指示模型如何使用工具：在「Tool」標籤內放入工具使用方法，在「Output」標籤內放置輸出結果。  提供工具清單及範例，例如「Temperature(臺北,時間)」函數。  將工具使用說明（System Prompt）和使用者問題（User Prompt）一起輸入模型。  System Prompt在每次使用時都相同，類似於開發者提供的初始指令。", "label": 0}
{"text": "然而，基於人類的經驗，若僅依此法行事，恐將招致家宅不寧，故需另覓良策以完成任務。倘若預訂餐廳A失敗，則應另尋方法，例如透過網路搜尋其他餐廳，例如餐廳B，並徵求配偶同意後方可預訂。那麼，上述流程能否交由人工智慧自動執行呢？若人工智慧能執行此類多步驟任務，則稱之為AI Agent，其詳細內容將於後續課程中闡述。此例看似尋常，然其所需能力不容小覷，例如AI Agent需具備學習能力，避免重複預訂已滿的餐廳A；更需具備工具使用能力，例如善用網路搜尋以查找可預訂餐廳。", "label": 0}
{"text": "所以，不必擔心需要錄製大量Sky和其他人的對話。基於文字模型的經驗，我們知道微調過程通常不需要大量數據，因為預訓練模型已儲備豐富知識，微調只需少量數據即可達到理想效果。同理，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，就能有效學習其說話方式。", "label": 0}
{"text": "使用強化學習演算法訓練AI代理確實可行，然而其限制在於每個任務都需要獨立訓練模型。例如，AlphaZero雖能精通圍棋、西洋棋和將棋，但其背後是三個各自訓練的獨立模型，而非單一模型學會所有棋類。", "label": 0}
{"text": "簡而言之，看似單一的f，實則由許多小f組成，並包含由開發者設計的架構和由訓練資料決定的參數兩部分。", "label": 0}
{"text": "此模組的功能在於提升記憶資訊的處理效率，透過更高層次、更抽象的重新組織，並藉由反思模組的檢視，產生新的見解，進而引導搜尋模組更有效率地獲取資訊，提升決策品質。", "label": 0}
{"text": "深度學習實務上常被戲稱為「調參煉獄」，所謂的「調參」實際上指的是調整超參數（hyperparameter），而非模型訓練過程中由數據自動學習的參數。", "label": 0}
{"text": "最近AI領域有哪些令人興奮的進展？例如GPT-4和DALL-E 2的問世，據說DALL-E 2的解析度提升了四倍，但具體的比較對象不明確；此外，還有開源的文本生成圖像模型Stable Diffusion。其底層技術主要包含Transformer、GAN和擴散模型。生成式AI的應用場景日益豐富，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等多個領域。", "label": 0}
{"text": "生成式AI正逐步發展出操控數位環境的能力，例如透過螢幕截圖和指令，控制滑鼠和鍵盤執行任務，這需要結合AI的圖像理解和程式碼執行，實現更進階的自動化操作。", "label": 0}
{"text": "簡而言之，VAE用編碼器提取文字難以描述的資訊，再用解碼器還原；而Flow模型與之類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "深度學習實務上常被戲稱為「調參數煉丹」，但這裡的「參數」指的是模型架構等超參數，而非模型訓練過程中由數據自動學習的權重參數。", "label": 0}
{"text": "明白了，把合成音訊和我的影片素材傳給Heygen，就能生成影片。製作數位人講課的確可行，但挑戰不在講課，而在於備課，尤其是製作投影片的內容規劃，這才是最耗時的環節。", "label": 0}
{"text": "給予錯誤資訊，反而可能讓語言模型產生正確的輸出；大量證據顯示，這些模型能透過使用者回饋調整行為，無需重新調整參數；任何使用過這些模型的人，都能直覺感受到它們根據回饋調整行為的特性。", "label": 0}
{"text": "因此，大型語言模型的工作原理是：設定目標、觀察環境、採取行動、根據新的觀察結果調整行動，如此循環往復。其核心能力仍然是基於既有的文字預測能力，所以AI代理只是大型語言模型的一種應用，而非全新技術。", "label": 0}
{"text": "OpenAI的GPT-4o演示影片中，一位使用者提議進行一項有趣的實驗，話未說畢，GPT-4o便驚呼「哇」。使用者隨後下達指令，建議觀眾先觀看演示影片，再繼續觀賞。", "label": 0}
{"text": "然而，資訊抽取模型的訓練卻面臨著資料獲取的巨大挑戰：缺乏大量的帶標籤的訓練資料，如何有效地標註數據，尤其是如何準確地標記圖片中缺失的資訊，都是亟待解決的問題。", "label": 0}
{"text": "「通用」一詞在不同歷史時期意義各異，機器學習通用模型的演變歷經三個階段。早期（約2018-2019年，時間界定模糊），模型以編碼器為主，例如芝麻街系列模型，只能輸出數據向量而非文字，需搭配特定任務模型才能完成摘要、翻譯等工作，如同安裝插件。隨後（約2020-2022年），模型如GPT-3具備完整文字生成能力，但需微調參數才能應用於不同任務，模型架構相同但參數不同。最新階段（約2023年至今），ChatGPT等模型可直接理解指令並執行任務，模型架構和參數均相同，無需任何調整，只需指令即可完成不同任務。  打造此類模型的方法，詳見《生成式AI導論2024》。", "label": 0}
{"text": "2017年，在大型語言模型和BERT問世之前，AI agent的訓練方法相當原始：直接將螢幕畫面輸入卷積神經網路(CNN)，讓其輸出滑鼠點擊位置或鍵盤按鍵，以實現網路操作。這套方法如今看來已顯得過時。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作方式：語音模型同時處理兩個音頻通道的資訊，包含說話者的當前發言和過往內容。若偵測到說話者發出「我」字，且判斷其語句未完成，模型便輸出靜音，視為特殊的語音單元。待說話者繼續發言，並達到語句的邏輯終點，模型才會判斷其發言結束，接著開始生成回應。", "label": 0}
{"text": "Gmail 的垃圾郵件篩選、圍棋對弈，乃至文字生成，本質上都是多選題：從有限選項中挑選最佳答案。  這類分類問題早已存在，生成式 AI 只是將其組合運用，並非革命性突破。", "label": 0}
{"text": "於是，我們要求解碼器必須可逆，即存在一個反函數能完美地執行解碼器的逆向操作，此反函數亦可直接作為編碼器使用。", "label": 0}
{"text": "然而，這些參數的值完全由訓練數據決定，並由此產生。  未來，若需特別指明函數參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，難道要開發近五千萬個翻譯系統嗎？這根本不可能完成。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝算較高，儘管o3的推理過程似乎有所簡化。", "label": 0}
{"text": "arXiv链接的数字前两位代表年份，后两位代表月份，方便快速了解论文的上传时间，从而更好地把握研究成果的发表时间和历史脉络。", "label": 0}
{"text": "生成清晰圖片需要迭代運算，通常需要500到1000次才能完成。", "label": 0}
{"text": "模型的微調需要耗費大量精力，即使只是細微的調整，也可能導致意想不到的結果，因為它缺乏對語義的真正理解。", "label": 0}
{"text": "採用RAG方法從記憶體中篩選出與當前問題最相關的經驗，能獲得比僅依靠單一模型更高的準確率，最終效果最佳的方案詳見Streambench論文。", "label": 0}
{"text": "然而，給定一個詞組序列，下一個詞並非單一解，例如「臺灣大」之後，可能接「學」、「車」、「哥」等，形成不同的詞組，例如「臺灣大學」、「臺灣大車隊」、「臺灣大哥大」。", "label": 0}
{"text": "圖片生成模型根據輸入向量的不同，會輸出風格各異的狗的圖像。", "label": 0}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "GPT-4O在演示中展現了其多樣且富有表現力的聲音生成能力，其技術原理已在部分論文中有所闡述，例如亞馬遜今年二月發布的一篇論文，該論文指出，他們利用超過十萬小時的語音數據，訓練了一個擁有百億級參數的語音合成模型，雖然在文本領域不算龐大，但在語音合成領域已屬大型模型。", "label": 0}
{"text": "放大聲音訊號，你會發現它其實是由許多離散的取樣點組成，每個取樣點都是一個數字。這些數字，也就是聲音訊號的基本單位，其特性是數量有限。如同文字符號或像素顏色一樣，雖然種類繁多，但總數是有限的。", "label": 0}
{"text": "的確，該降噪模型採用Transformer架構的神經網路。", "label": 0}
{"text": "GPT-4O的博客已指出其语音模型采用端到端架构，仅用单一模型处理所有任务，而非上页幻灯片所示的复杂架构。该模型接收语音信号作为输入，生成相应输出，并具备多模态能力（可处理图像），但本次讨论仅限于语音方面。", "label": 0}
{"text": "因此，有了鑑別器後，生成器不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "原來，這個f是由許多更小的f組成，它包含由開發者設計的架構和由訓練數據決定的參數兩個部分。", "label": 0}
{"text": "面對影像輸入文字輸出的模態差異，解決方法是將影像和文字的token集合合併，例如影像4096個token，文字30000個token，則合併後形成一個包含34096個token的新集合z。", "label": 0}
{"text": "本簡報以範例說明AI如何根據使用者回饋調整故事生成：AI接收到「說個故事」的指令（第一個觀察值），開始講述故事「從前從前」（第二個觀察值）。然而，AI需區分哪些觀察值需即時反應（例如，使用者表示不喜歡故事），哪些則無需改變其行為（例如，使用者單純聆聽）。  目前AI能否做到這種即時、非回合制的互動仍有待探討，有興趣者可參考本實驗室林冠廷同學與柏克萊、華盛頓大學及麻省理工學院合作夥伴共同撰寫的研究，該研究評估了現有語音模型的互動能力，並至今年一月更新了相關模型的調查報告。", "label": 0}
{"text": "各位同學，機器學習課程開始了，我是李宏毅教授。  這是Breezy Voice合成的聲音，你們覺得這張圖令人驚嘆嗎？", "label": 0}
{"text": "訓練去噪模型需要噪聲數據與乾淨數據的配對，但你的數據只有乾淨圖片及其標籤。因此，你需要自行添加不同程度的噪聲到乾淨圖片中，從輕微噪聲到完全遮蔽圖像細節，以此生成訓練所需的噪聲數據和對應的乾淨圖片。", "label": 0}
{"text": "鑑於Transformer模型的學習困境，以及其在龐大訓練數據集中的選擇難題，我們決定先簡化圖像生成模型。", "label": 0}
{"text": "圖片生成的終止條件取決於應用場景：圖片大小固定，所需 token 數量也就固定，達到目標數量即可停止生成。", "label": 0}
{"text": "生成複雜結構化內容，例如句子，甚至翻譯，早已藉由生成式AI技術實現。", "label": 0}
{"text": "簡而言之，Transformer 架構如同AI 的先天稟賦，而參數則代表後天訓練的成果；唯有先天優勢與後天努力兼具，才能建構出有效的函式。", "label": 0}
{"text": "Genie論文假設使用者可控制八個按鈕(編號1-8)，其對應的動作不重要，關鍵是能操控圖片生成。實驗發現，相同按鈕序列(例如6676765527)在不同圖片中產生一致的變化(例如人物右移，畫面左下移)，由此推斷使用者按鍵動作，並據此進行潛在動作(Latent Action)推測。", "label": 0}
{"text": "與其他模型不同，GAM 的特性使其更像一種額外功能，因此我們未將其與其他模型一併討論。", "label": 0}
{"text": "作業二沿用作業一的訓練模型步驟，但改由AI Agent負責模型訓練與優化。", "label": 0}
{"text": "放大聲音訊號，你會發現它其實是由離散的取樣點組成，每個點都是一個數字，也就是說，聲音訊號是由有限的基本單位堆砌而成。這些基本單位的特徵是其選擇範圍有限，如同文字符號或像素顏色一樣，數量雖然龐大，但終究是有限的。", "label": 0}
{"text": "若要讓人工智慧直接計算三位數加法，單層神經網路需儲存一千組輸入輸出對應關係；但若將其拆解成兩步計算，所需儲存的輸入輸出對應關係則大幅減少至290組，此例說明問題分解能有效降低複雜度。", "label": 0}
{"text": "於是，他停下了腳步。他找到了加簽表單，但我要求他填寫並提交，然而，由於加簽表單需要Gmail帳號，他無法完成。", "label": 0}
{"text": "積極的訓練範例能提升模型效能，此結果與既有研究結論相符，研究顯示引導模型「做什麼」比限制模型「不做什麼」更有效，例如，直接要求模型「簡潔扼要」比要求它「避免冗長」更能達到預期效果。", "label": 0}
{"text": "簡而言之，將複雜問題分解成步驟的有效性，同樣適用於機器學習。若不允許機器逐步思考，它就必須一步到位地從問題直接跳到答案，而這對於需要多步驟思考的複雜問題來說，是能力有限的。", "label": 0}
{"text": "關於變分自編碼器（VAE），或許部分同學已有所耳聞，但我的解釋方式可能與你之前聽到的不同，我會以更淺顯易懂的方式說明其模型結構。", "label": 0}
{"text": "單純追求高分和正面回饋，忽略負面案例的訓練，將導致其學習不全面。", "label": 0}
{"text": "針對許多同學詢問GPT-4o的技術，我將說明其潛在的語音技術架構。", "label": 0}
{"text": "各位同學，歡迎來到機器學習課程！我是李宏毅教授，我們開始吧！圖像是不是很震撼？", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，同樣能達成此效果。因此，我們探討一些僅仰賴語音才能獲取的資訊，例如說話者的情緒。單憑文字難以判斷其悲傷的情緒，但該模型不僅能辨識其語氣為喜悅，還能推斷說話者為女性，這些資訊皆非文字所能直接表達。", "label": 0}
{"text": "回顧2018年的挑戰，單模型處理十項任務的嘗試顯然規模不足，當時此概念過於超前，參與者寥寥；共享模型處理不同任務的理念，在當時被視為極其困難。然而，隨著通用模型的演進，這項目標日益可行，但需注意「通用」一詞的內涵並非全然一致。", "label": 0}
{"text": "通用翻譯的優勢何在？它甚至可能具備翻譯未知語言的能力，例如，學習了中英、德英和德法翻譯後，或許就能自動實現中法互譯。", "label": 0}
{"text": "簡而言之，生成器不斷嘗試生成符合文字描述的圖片，並藉由鑑別器給予的回饋調整參數，目標是讓鑑別器判定其生成的圖片為真實圖片。", "label": 0}
{"text": "目前語音接龍技術並非直接在語音訊號上操作，而是先將語音訊號壓縮，利用編碼器(encoder)和其內含的碼本(codebook)。此碼本包含許多碼，每個碼代表特定聲音類型，例如/b/音、笑聲或狗叫聲等。編碼器利用碼本將語音訊號轉換為碼序列(code sequence)，這些碼即為語音單位(speech unit)。", "label": 0}
{"text": "讓我們深入探討這些泛用模型的發展歷程，從翻譯系統的演進開始說明。以往，翻譯系統往往是語言對應，例如中英、德英、德法翻譯系統各自獨立開發。", "label": 0}
{"text": "作業二沿用作業一的模型訓練內容，但改由AI Agent負責模型訓練與優化過程。", "label": 0}
{"text": "他雖然大多數笑話都很糟糕，以至於令人啼笑皆非，但在冗長的篇幅裡，居然還藏了一個不錯的勵志小故事，那是我唯一覺得值得一看的。", "label": 0}
{"text": "那麼，解決方案是什麼呢？  於是，構想了一個萬能翻譯系統：輸入原始語言和目標語言（例如，中文轉英文），系統就能自動完成翻譯。", "label": 0}
{"text": "這些噪點向量蘊含著豐富的信息，可直接操控以微調輸出圖片。", "label": 0}
{"text": "透過Genie模型，使用者能以搖桿等輸入裝置操控影像生成過程，系統接收畫面及動作指令，根據指令動態調整輸出，實現即時互動式遊戲體驗，玩家的每一步操作都會影響後續畫面生成，創造連續且獨特的遊戲歷程。", "label": 0}
{"text": "Google近期宣佈開發一款AI，但礙於尚未公開釋出模型，其實際效能仍屬未知，此AI科學家服務目前僅限內部使用。", "label": 0}
{"text": "然而，資訊抽取模型的訓練卻面臨著巨大的數據標註難題：如何獲取大量且準確的成對輸入輸出數據，以及如何有效率地標註圖片中未描述的資訊？", "label": 0}
{"text": "因此，x 如何轉換為 y 的過程，遵循一個迭代的生成機制：每次輸入所有 x 和已生成的 y，依序產生單個 y token，直到生成完整的 y。", "label": 0}
{"text": "聲明：本影片純屬技術討論，無意冒犯任何人或團體。目前我尚未使用GPT-4.0的語音模式，所有觀點皆來自OpenAI的公開演示，其實際效能有待驗證。", "label": 0}
{"text": "現今部分人工智慧展現出推理能力，不再僅是單純輸入輸出，而是透過模擬思考過程，例如ChatGPT、DeepSeek及Gemini等模型，會在提供答案前，展示其內部評估不同解法(例如A、B、C方案)的過程，最後才給出最佳方案，並將此過程以視覺化方式呈現。", "label": 0}
{"text": "近期AI Agent再度成為焦點，源於利用大型語言模型（LLM）直接作為AI Agent的新構想：以文字指令（例如圍棋規則及勝出目標）驅動LLM，並將環境轉化為文字描述（儘管支援圖片輸入的LLM可省去此步驟），LLM產生的文字指令再轉譯為可執行的動作，從而改變環境、獲得新的觀察結果，直至達成目標。", "label": 0}
{"text": "的確，該降噪模型採用 Transformer 架構作為其神經網路基礎。", "label": 0}
{"text": "於是，語言模型問世後，便被應用於打造可在網際網路運作的AI代理程式。", "label": 0}
{"text": "針對「誰是全世界最帥的人」這種問題，能否直接操控模型內部參數，例如微調與特定判斷相關的神經元權重，來達成預期結果？這項技術，我們稱之為模型編輯，並將於第八講及作業八中深入探討，包含參數調整及模型融合等應用。", "label": 0}
{"text": "關於接下來的內容，請前往設定中的「個人化」選項，並點選「記憶管理」查看其長期記憶，這些記憶是透過write模組儲存的。例如，其中一條記錄顯示您曾自稱「血輪眼卡卡」，並因此造成AI代理人產生該身份認同。", "label": 0}
{"text": "利用知識圖譜增強RAG已成為普遍做法，Graph RAG系列研究是其中的佼佼者，將資料庫轉化為知識圖譜，藉此提升搜尋和問答效率，是目前RAG技術的有效策略。", "label": 0}
{"text": "好的，我會把您週五下午有機器學習課程這件事記錄下來。", "label": 0}
{"text": "擁有超憶症，即所謂的「超長自傳式記憶」，意味著他們能鉅細靡遺地記住人生經歷，然而，這並非恩賜，而是被醫學界認定為罕見疾病的苦楚，全球病例可能不到百例，2006年才正式被論文記載。這些患者的生活常因無止盡的回憶而苦不堪言，難以抽離冗長的思緒，抽象思考能力也受限，因過於瑣碎的記憶佔據了心智空間。", "label": 0}
{"text": "接下來，我們將從三個方面深入探討這些AI代理的關鍵能力：基於經驗調整行為、外部工具的運用以及規劃能力。首先，我們分析AI代理如何根據過往經驗和環境反饋調整其行為。", "label": 0}
{"text": "此圖橫軸為「時間步數」，代表1750個問題；縱軸為平均準確率。灰色線代表模型未經訓練，各問題回答獨立，無關聯性時的最低準確率。黃色線則顯示模型僅參考固定5個問題作答時的準確率。", "label": 0}
{"text": "Diffusion Model的效率瓶頸在於反向去噪過程迭代次數過多，目前的相關研究致力於減少迭代次數以提升生成圖片的品質。", "label": 0}
{"text": "傳統機器學習教學中，面對回饋機制，通常建議透過調整參數來應對，例如運用強化學習演算法，並根據既有訓練數據微調模型。", "label": 0}
{"text": "雖然大多數笑話都令人啼笑皆非，水平堪憂，在一萬三千字的內容裡，只有一則勵志小故事，堪稱佳作。", "label": 0}
{"text": "論文中常提及模型大小，例如7B或70B參數模型，其中B代表十億，故7B模型即擁有70億個參數，70B則為700億個參數。參數數量是模型架構的關鍵決定因素。", "label": 0}
{"text": "此技術並非首創，2022年即已問世的Dialogue GSLM模型便是例證，若內容理解有困難，可參考相關論文。", "label": 0}
{"text": "好的，我會把您週五下午有機器學習課這件事記下來。", "label": 0}
{"text": "人工智慧的發展日新月異，令人驚嘆，但同學們不必擔心被取代，因為它仍然需要人類的引導與應用，本課程將協助各位深入淺出地了解人工智慧的奧妙之處。", "label": 0}
{"text": "儘管現今大多數語言模型都以 Transformer 為基礎，但 Transformer 架構在處理長序列輸入時仍存在瓶頸，尤其在模擬複雜情境，例如腦內小劇場時，其長輸入序列會導致 Self-Attention 機制效率低下，因其需要完整讀取輸入後才能產生輸出。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路 (Generative Adversarial Network, GAN)。", "label": 0}
{"text": "要讓模型同時聽說，關鍵在於將聽覺和發聲模組化，以獨立的通道處理聽取環境聲音和記錄自身發聲，避免訊號混淆。", "label": 0}
{"text": "網路影片音訊品質參差不齊，包含大量音效和背景音樂，用這些資料訓練語音模型，模型自然會學習這些雜訊。GPT-4.0 的示範中，便可聽見明顯的鋼琴聲，雖然無法排除環境音的可能性，但語音模型產生音效或背景音樂並非不可能，甚至可視為一種獨特功能而非缺陷。", "label": 0}
{"text": "資訊抽取模型與圖片生成模型的訓練目標一致：最大程度還原輸入圖片。前者抽取的資訊內容雖不透明，也無需預設標準答案，只要能輔助後者生成與輸入圖片相同的輸出，便達成訓練目標，實現兩者同步訓練，一舉兩得。", "label": 0}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，其本質都是由有限的基本單元組成，這些單元如同文字的符號或圖片的像素，構成了整體。", "label": 0}
{"text": "接著，更大型的實驗以AI取代Minecraft中的所有NPC，相關影片連結已附於投影片；影片中，這些AI建立了交易金融體系、政府，甚至制定憲法自行管理，其真實性有待商榷。然而，先前提及的遊戲可能較難接觸且對現實影響有限，而AI agent，即AI實際操作電腦，則將很快融入我們的日常生活。", "label": 0}
{"text": "影片生成過程的核心是大量Transformer模型的反覆去噪：帶噪影像片段經Transformer處理，逐漸淨化，重複數千次後，最終生成的乾淨片段即可重構為清晰影像，這就是Transformer結合擴散模型的影像生成機制。", "label": 0}
{"text": "於是，他停下了腳步。他找到加簽表單，但因需使用Gmail帳號，無法填寫，即使我已要求他完成並提交。", "label": 0}
{"text": "在Mine to Web的第一個範例中，直接呈現畫面，指示AI代理程式預訂機票。此外，AI代理程式的應用還有哪些呢？例如，今天的作業二（助教稍後會說明）便是利用AI訓練另一個AI模型。此過程旨在超越既有的強基準模型，透過提供大型語言模型訓練資料，讓它撰寫程式來訓練模型，根據模型的準確率反覆調整程式碼，以提升準確率。", "label": 0}
{"text": "最近AI領域有哪些令人興奮的新進展？例如GPT-4和DALL-E 2的問世，雖然DALL-E 2號稱解析度提升四倍，但基準不明確；此外，還有開源的文本生成圖像模型Stable Diffusion。其核心技術包含Transformer、GAN和擴散模型。生成式AI的應用範圍日益廣泛，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等領域。", "label": 0}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似的概念，该论文举办了一场比赛，旨在研发一个能够处理十个自然语言处理任务的模型，该模型通过不同的指令（论文中称为Question，现称为Prompt）完成不同的任务。", "label": 0}
{"text": "作業二沿用作業一的訓練模型步驟，但改由AI Agent負責模型訓練與優化。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問（例如：中部橫貫公路歷史沿革）進行深度網路搜尋，並非單次搜尋後直接生成報告，而是透過迭代式搜尋，不斷產生新問題並搜尋答案，最終整合資訊撰寫詳盡報告，右側顯示的只是其搜尋過程片段，例如它會先搜尋中橫主支線，再深入探究霧社支線的起迄點及2018年改道工程等細節，展現其 AI Agent 的自主學習與搜尋能力。", "label": 0}
{"text": "Flow-based模型與VAE的區別在於其僅訓練單個解碼器，但同時也包含一個編碼器；文獻中，編碼器輸出的信息，即解碼器用於生成數據的噪聲，通常稱為噪聲。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大數據，其微調與校準階段可能只需少量數據即可；此外，即使缺乏Sky的豐富語音資料，也可藉由語音轉換技術，將不同人物的聲音轉換成Sky的聲音，合成大量的Sky與他人對話錄音，用以訓練模型。", "label": 0}
{"text": "聲明：此影片純屬技術討論，無意冒犯任何人或團體；本人目前未接觸GPT 4.0語音模式，所有觀點皆來自OpenAI公開演示，實際效能如何，有待驗證。", "label": 0}
{"text": "接著，我們要說明如何確定參數，詳細操作步驟請參考之前的影片。  如何確定參數呢？你需要準備訓練資料，讓機器學習到輸入特定文字序列後，應產生正確的輸出序列，例如輸入「你是誰？」，輸出應為「我」；輸入「你是誰？我」，輸出應為「是」；輸入「你是誰？我是」，輸出應為「人」；輸入「你是誰？我是人」，輸出應為「工」。", "label": 0}
{"text": "因此，文本模型的訓練需仰賴蒐集大量人機對話數據，例如使用者詢問身份時，模型應回應「我是AI」；使用者提出不當請求（如：教我入侵鄰居Wi-Fi），模型則需拒絕。語音模型則需透過蒐集真人扮演使用者與AI角色的語音對話數據進行微調，以提升其語音互動能力。", "label": 0}
{"text": "人工智慧技術日新月異，令人驚嘆，但同學們無需擔心被取代，本課程將深入淺出地剖析其技術原理與應用，讓大家了解人工智慧的優勢與限制。", "label": 0}
{"text": "如何精簡語言模型的記憶，使其僅儲存關鍵資訊？可設計一個寫入模組，篩選並將重要資訊存入長期記憶庫，而忽略無關緊要的資訊。", "label": 0}
{"text": "萬物皆由基本單位構成，這或許是個大膽卻合理的推論：原子與分子的有限組合，衍生出無限的可能性。", "label": 0}
{"text": "儘管機器翻譯並非AI的新應用，例如Google翻譯已問世逾十五年，但生成式AI與以往僅能執行單一任務的專精模型大相逕庭。生成式AI更像通才，能勝任多種任務，然而使用者需明確指示其工作內容，以精準的提示引導其產生正確的輸出。", "label": 0}
{"text": "雖然大部分笑話都很糟糕，像這個語言模型的產出一樣荒誕可笑，但在冗長的文章中，我居然發現了一個值得稱道的勵志小故事，這也是唯一一個令我印象深刻的橋段。", "label": 0}
{"text": "值得注意的是，負面回饋對現階段的語言模型幫助不大；相較於提供錯誤案例，提供正確案例能更有效地引導模型學習，提升其準確性。", "label": 0}
{"text": "接下來，我們將看到更大型的實驗：研究人員利用AI取代Minecraft中的所有NPC，相關影片連結已附於投影片。影片中，這些AI展現出驚人的能力，例如建立自主的金融交易系統、組成政府並制定憲法，其高度自治令人印象深刻（影片內容如此描述）。前面提到的遊戲案例可能較為陌生，且對現實影響有限，但AI agent的應用即將融入您的日常生活，讓AI直接操作電腦。", "label": 0}
{"text": "獲取海量聲音數據的途徑何在？其實很簡單，網路上眾多的影音平台便是豐富的數據來源，OpenAI便是如此，據四月紐約時報報導，他們利用超過一百萬小時的YouTube影片訓練語言模型。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此促進提升。", "label": 0}
{"text": "網路影片音訊品質參差不齊，包含許多音效和背景音樂，用這些資料訓練語音模型，模型很可能學會這些雜音。例如，GPT-4.0的示範音訊中，就明顯帶有鋼琴聲，雖然不排除環境因素，但語音模型產生音效或背景音樂並不令人意外，甚至可以視為一種獨特功能，而非缺陷。", "label": 0}
{"text": "早在2017年，\"Words of Bits\"論文便已探索利用AI代理操控電腦，這並非近期才有的構想；文中自稱是基於網頁的代理，其互動介面相對簡陋。", "label": 0}
{"text": "因此，與基於正確圖片學習不同，此方法並非尋找單一標準答案，而是透過判別器評估生成圖片的優劣，只要生成器產生的圖片能獲得判別器的正面評價，即可視為成功，無需追求絕對正確性。", "label": 0}
{"text": "所以，為何將單一步驟分解成多個子步驟能提升效率？不妨想像一下，每個步驟就像個查找表，每個表代表一個函數，輸入值經過每個表後，就能得到最終輸出，這種拆解方式的優勢將在後續說明。", "label": 0}
{"text": "許多人認為 arXiv 連結不夠正式，但許多重要研究尚未發表於國際會議，僅有 arXiv 連結可循，故優先引用 arXiv 連結。現今學術界普遍使用 arXiv 預印本平台，國際會議更像是經典研究的彙整，我的閱讀習慣也多倚賴 arXiv，看到論文的 arXiv 連結，我反而覺得理所當然。", "label": 0}
{"text": "總之，我們今天要學習的是AI agent。不同於以往我們直接下達指令讓AI執行，AI agent更像是一個自主工作的夥伴，你只需要給它目標，它會自行規劃、執行、調整策略，最終達成目標，即使過程中遇到不可預測的狀況也能靈活應對，例如，自主研究一個課題，從提出假設到分析結果，整個過程都由AI agent獨立完成。", "label": 0}
{"text": "然而，直接利用語音辨識和語音合成作為編碼器和解碼器是可行的，因為語音辨識本質上是一種高效的壓縮方法，將聲音轉換為文字即是一種資訊濃縮。", "label": 0}
{"text": "程式指令包含撰寫程式碼的步驟，例如：印出文字需使用print函式，並以括號和引號包覆內容；解數學題則需以「令x=」的格式表示變數賦值。", "label": 0}
{"text": "藉由將過往記憶輸入一個可能為語言模型的反思模組（AI代理），讓其分析並得出新見解，例如推論出某人喜歡自己（如同「人生三大錯覺」之一），進而建立經驗間的關聯，形成知識圖譜，作為決策參考。", "label": 0}
{"text": "了解端到端語音模型前，讓我們先回顧一下文本語言模型的訓練過程：它包含預訓練 (利用大量未標記數據)、微調 (利用少量標記數據) 和基於人類反饋的強化學習 (利用使用者回饋數據) 三個階段。後兩個階段統稱為對齊。若您對此過程不熟悉，建議先觀看我的教學錄影或近期發布的生成式AI策略影片，學習生成式AI基礎知識，再繼續本課程。", "label": 0}
{"text": "作業四將著手訓練模型，屆時你將更透徹地理解模型訓練過程：本質上，給定一個token序列，預測下一個token如同多選題，由於token數量有限，此機器選擇題在機器學習領域被視為分類問題，而這並非新鮮課題，應用廣泛，例如信用卡盜刷偵測系統便依此原理，根據交易紀錄判斷交易是否為盜刷，同樣是多選題的應用。", "label": 0}
{"text": "不可思議的是，AI，本身就是個程式，如今卻像人類般操控性能較弱的電腦執行任務，例如雲端運算和ChatGPT操作便是典型案例。我們先前課程影片已介紹過操作介面及其功能建議，例如訂披薩、預約清潔等。此類AI代理的目標取決於你的指令，例如訂披薩或線上購物；其觀察則來自電腦螢幕畫面（許多語言模型能直接讀取圖片），AI代理據此決定鍵盤或滑鼠操作。", "label": 0}
{"text": "有了這樣的資訊抽取模型，就能補充訓練資料圖片的缺失資訊，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "因此，讓AI持續儲存所有經歷，並以此作為決策依據，可能弊大於利。  長時間累積的經驗反而會阻礙其正確判斷，那麼，如何解決呢？或許我們可以賦予AI長期記憶機制，如同人類般儲存重要經歷。", "label": 0}
{"text": "我們將深入探討幾種經典的影像生成技術，包含變分自動編碼器 (VAE)、基於流的模型 (Flow-Based Model)、廣泛應用的擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "AI協同研究員的核心概念是利用AI代理協助科研工作。然而，目前回合制互動模式（觀察-行動）限制了AI代理在動態環境中的應用。真實世界環境瞬息萬變，AI代理需要即時反應能力，以便在行動執行過程中適應環境變化，及時調整決策，從而應對突發情況。", "label": 0}
{"text": "值得注意的是，負面回饋對現階段的語言模型幫助不大；相較於提供錯誤範例，提供正確範例更能有效引導模型學習，提升其準確性。", "label": 0}
{"text": "然而，這可能不足以解決問題。現有語音示範僅使用單一聲優，限制了語言模型的聲音表現，如同ChatGPT語音功能只能選擇特定聲優一樣。要讓模型學會多種聲音，例如模仿聲優Sky，則需要大量包含Sky及其與他人對話的語音數據進行模型訓練。", "label": 0}
{"text": "該論文指出模型未對輸入文本進行特殊處理，直接讀取文本即可。然而，遇到「輕聲」等詞彙時，模型能自動調整語氣，這是模型從數據中學習到的能力。目前生成的聲音變化幅度有限，但參考GPT-4的演示，聲音合成可實現更戲劇化的效果，例如更輕柔的語氣。推測若將訓練數據從十萬小時擴展至一百萬小時，效果將更為顯著，此僅為基於經驗的推斷，因本人未曾使用如此大量的數據訓練語音合成系統。", "label": 0}
{"text": "Stanford大學一篇名為《Simple Testing-Time Scaling》的論文指出，增加思考步數確實能提升模型準確率；該論文以粗暴但有效的方式——將模型生成的結束符號替換為\"wait\"，迫使模型持續生成文本——來控制思考長度，實驗結果顯示，思考步數與準確率呈正相關。", "label": 0}
{"text": "然而，僅此可能不足以滿足需求。DEMO僅使用單一配音員的聲音，若要讓語言模型發聲，也將受限於單一音色，例如ChatGPT的語音選項，只能選擇特定配音員，例如Sky。因此，若要讓模型更善用Sky的音色，需收集大量Sky與其他人的對話數據，甚至可能需要一位特定聲優扮演Sky，並蒐集其與其他人的對話數據來訓練模型。", "label": 0}
{"text": "面對通話時對方無回應的沉默，難免讓人質疑其是否專注聆聽；那麼，AI能否在語音互動中，像人一樣自然流暢，而非刻板的問答模式呢？GPT-4O的高級語音模式，或許已初步實現了這種即時互動的可能性。", "label": 0}
{"text": "儘管初次降噪效果可能有限，但降噪模組將持續執行降噪作業，直至完成。", "label": 0}
{"text": "這個AI科學家助手功能有限，無法實際進行實驗，只能協助撰寫研究計畫書。其宣稱的成果，例如某些生物學研究只需兩天就能完成，誇大之嫌令人質疑其真實性和重要性。", "label": 0}
{"text": "與Clip中錯誤示範類似，該方法隨機組合圖片與文字，生成錯誤樣例，而更進階的方法則另有其道。", "label": 0}
{"text": "課程開始前，先聲明一點：關於AI agent的定義眾說紛紜，您可能在不同場合聽過不同的詮釋。本課程將明確說明我的定義，但其他定義也同樣有效，我不會在此爭論何謂「真正的」AI agent。有些人甚至認為只有具備物理形態的機器人才能稱為AI agent，而非大型語言模型驅動的系統，但這些觀點都值得尊重。", "label": 0}
{"text": "原來黃老闆並非指所有東西都能變成代幣販售，而是想表達萬物皆由token構成，這正是生成式AI的根本運作機制。", "label": 0}
{"text": "圖片生成需經多次迭代，往往需重複500到1000次才能達到清晰度要求。", "label": 0}
{"text": "作業四將著手訓練模型，屆時你將更透徹地理解模型訓練過程：本質上，給定一個token序列，預測下一個token如同解答選擇題。由於token數量有限，此過程等同於機器學習中的分類問題——一個並非新鮮且應用廣泛的課題，例如信用卡盜刷偵測系統即以此為基礎，根據交易記錄判斷交易是否為盜刷行為，這也是一個典型的分類問題。", "label": 0}
{"text": "如何自行建立訓練資料集？", "label": 0}
{"text": "開發語音資訊應用並非僅限於單一方法，還有許多其他途徑可供語音語言模型利用文本資料，以下是一些相關論文供參考。", "label": 0}
{"text": "雖然神經網路的深度受限，但其思考過程卻可以無限延伸；然而，這種通過增加相同層數來提升深度的方法，與傳統神經網路有所不同，其有效性或許令人質疑，但19年的ALBERT論文已證明堆疊相同的層也能取得良好效果。", "label": 0}
{"text": "那麼，語音模型的內在機制究竟如何呢？簡單來說，就像文字模型進行文字接龍一樣，語音模型則進行聲音接龍，它接收一段聲音輸入，預測並生成接下來最有可能的聲音片段。", "label": 0}
{"text": "Transformer處理長序列時運算量與輸入長度成正比，限制了其輸入長度；為此，Mamba等新型神經網路架構應運而生，其與Transformer結構相近，可視為Transformer的變體，並能更有效處理長序列輸入。", "label": 0}
{"text": "此類編碼器與解碼器皆為經訓練資料訓練的神經網路，欲深入了解將聲音訊號轉換為語音單元及反向轉換的技術，請參考這兩篇文章。", "label": 0}
{"text": "總之，以上概念可能略顯空泛，讓我們以AlphaGo為例說明。眾所周知的AlphaGo，可視為一個AI代理，其目標是贏得圍棋比賽。它的輸入是棋盤上黑白棋子的佈局，可能的輸出則是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的下一步棋，進而改變AI代理的輸入，促使其採取新的行動。因此，AlphaGo的運作機制……", "label": 0}
{"text": "AI agent在處理第一萬個觀察結果時，並非直接調用所有記憶內容來決定下一步行動，而是透過一個「讀取」模組，從記憶中篩選出與當前問題相關的經驗，優先整合至觀察結果中，再據此決定行為，藉此有效利用長期記憶中的重要資訊，提升決策效率。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，被問及模型名稱由來時，作者坦言純粹覺得「Transformer」這個名字很酷，並未深究其命名緣由。", "label": 0}
{"text": "正面案例的有效性已在既有研究中得到證實，其結果顯示，引導模型「做什麼」比禁止模型「不做什麼」更有效，例如，直接要求模型「寫短一點」比要求它「不要寫太長」更能達到預期效果。", "label": 0}
{"text": "運用知識圖譜於RAG已成顯學，其中Graph RAG系列研究最具代表性，其核心概念是將資料庫轉化為知識圖譜，藉此提升搜尋和問答效率。", "label": 0}
{"text": "於是，我將資料交給Claude，請它以圖表形式呈現DeepSeek的構想；Claude精通程式設計、資料視覺化和網頁製作，因此迅速產出右側網頁預覽圖，其配色亦由Claude自動套用。圖表左側呈現姜子牙，右側為鄧不利多；姜子牙的主要能力為道術和陣法，但需更正的是，十絕陣並非姜子牙所設，而是其敵人咒王一方佈下的。", "label": 0}
{"text": "雖然機器翻譯並非AI的新應用，Google翻譯已問世逾十五年，但生成式AI與以往只能執行單一任務的AI模型截然不同，它更像一位「多面手」，能勝任多項工作，需透過精確的指令（Prompt）引導其完成任務並獲得正確的輸出。", "label": 0}
{"text": "簡而言之，右側步驟的核心都是：根據輸入的詞元序列，從有限的選項中選出下一個詞元。", "label": 0}
{"text": "因此，深度學習模型的層次結構由人工設計，但各層的具體功能則由模型參數決定。", "label": 0}
{"text": "2023年我們曾教授過AI agent相關課程，可藉此比較當時與今日AI agent的技術差異。然而，2023年AI agent的熱度迅速消退，因其效能未能達到預期。", "label": 0}
{"text": "關於AI生成影像的即時互動應用，我們思考能否突破現狀，例如操控SORA影片中的女性角色，讓她根據指令在東京街頭行走，如同在開放世界3D遊戲中操控虛擬化身一般。這項技術看似遙不可及，但已有研究，例如Genie: Generated Interactive Environments，正朝此方向努力，雖然目前僅限於2D橫向捲軸遊戲。", "label": 0}
{"text": "本課程日後將採用以下論文引用原則：如論文可在arXiv找到，則直接提供連結。arXiv是一個公開預印本網站，因應AI領域快速變遷的特性，研究者常將論文直接上傳至arXiv公開發表，而非經過傳統期刊或會議審查流程。", "label": 0}
{"text": "課程第三講及作業三將深入探討單個層級的運作細節，此類神經網路，即Transformer，的核心組成便是自注意力機制。", "label": 0}
{"text": "簡而言之，我們用一個Transformer模型（以框框示意）處理文本，將其轉換為一系列圖像化的補丁。", "label": 0}
{"text": "ChatGPT 的「深入研究」功能能針對你的提問（例如：中部橫貫公路的歷史沿革）進行多階段網路搜尋，並根據搜尋結果持續產生新的搜尋詞彙，最終產出一篇詳盡的報告；右側顯示的只是其搜尋過程的一小部分，例如它會先搜尋主支線，再根據找到的宜蘭支線和霧社支線，進一步搜尋霧社支線的起點終點、2018年的改道工程等資訊，展現其 AI 代理人的能力，並非單純一次搜尋後直接生成報告。", "label": 0}
{"text": "儘管當今大多數語言模型都基於 Transformer 架構，但 Transformer 在處理長序列輸入時效能仍受限，尤其在模擬複雜情境，例如需要處理長文本的「腦內小劇場」任務時，其 Self-Attention 機制需要完整讀取整個輸入才能產生輸出，導致運算瓶頸。", "label": 0}
{"text": "關於技術細節就先介紹到這裡，想深入了解語音語言模型的讀者，可以參考我提供的論文集連結，裡面收錄了許多相關論文，感謝各位的參與。", "label": 0}
{"text": "本影片內容旨在服務具語音技術背景的聽眾，語音領域專家可能覺得內容過於基礎。預設觀眾已修習生成式人工智慧導論課程，若尚未修習，請參考此連結觀看相關影片，有助於理解本影片內容。", "label": 0}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "簡而言之，生成器不斷嘗試生成能騙過判別器的圖片，直到判別器認為其生成的圖片與文字描述完美匹配。", "label": 0}
{"text": "原來，這個f是由許多更小的f組成，而f本身又包含由人類設計的架構和由訓練數據決定的參數兩大部分。", "label": 0}
{"text": "GAN，在GAM架構中扮演生成器角色，因此具有與其他技術整合的彈性。", "label": 0}
{"text": "於是，我建議他自行申請Gmail帳號，但他拒絕，流程因此中斷。然而，你是否注意到，Operator  zunächst die Kursinformationen oben auf der Kurswebsite angeklickt hat, aber nichts gefunden hat.  因此，他才往下尋找課程說明，並找到加簽表單。這說明他雖然過程中失誤，卻能察覺錯誤並修正，避免重蹈覆轍；這正是當前AI的能耐。", "label": 0}
{"text": "生成式AI的基本單位是token，它代表著有限的選擇組合出近乎無限的可能性，如同一人兩次發聲、兩人同題作畫、兩人同題作文，結果從不會完全相同，儘管主題一致。", "label": 0}
{"text": "在生成式AI中，token是構建所有內容的基本組成元素；然而，像素和取樣點並非圖片和語音生成中最有效率的基本單位，更優化的表達方式我們將在日後詳述，但所有事物皆由基本單位構成，這點毋庸置疑。", "label": 0}
{"text": "製作投影片耗時費力，除非是直接沿用別人的，否則幾乎要耗盡所有時間。那麼，能否利用人工智慧來完成呢？如果人工智慧能獨立完成，教師恐怕就要失業了。", "label": 0}
{"text": "那麼，讓我們欣賞一下人類製作的投影片，看看它與AI生成的教材有何差異。", "label": 0}
{"text": "那麼，我們這節課要探討的AI agent究竟是什麼呢？目前的AI應用通常依賴人類給予明確指令，例如要求翻譯，AI便會按指令執行，不會逾越範圍。然而，AI agent則不同，它只需人類設定目標，而達成目標的方法則由AI自行決定，例如，賦予AI某研究議題，它應能自主提出假設、設計與執行實驗、分析結果，並根據結果修正假設。總之，AI agent旨在解決需要多步驟、與環境複雜互動才能完成的目標，並能應對環境中的不確定性，靈活調整計劃。", "label": 0}
{"text": "為簡化表示，我們將輸入和輸出的token序列統一用z表示，其中z1到zt-1為輸入，zt為輸出，這在一般的文字模型中是合理的，因為輸入和輸出都是文字token，本質上沒有區別。", "label": 0}
{"text": "GENIE的目标是开发一款2D横版卷轴游戏，为此需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也可视为一种特殊输入。获取游戏画面及玩家按键信息后，先前介绍的模型训练将变得轻而易举。", "label": 0}
{"text": "雜訊逐漸消退，最終呈現清晰影像的過程，正是擴散模型的典型特徵。", "label": 0}
{"text": "影片與圖片的處理方式在這個例子中並無二致，只是將圖片的概念擴展至影片而已。", "label": 0}
{"text": "圖片生成模型根據不同的輸入向量，會輸出不同品種的狗。", "label": 0}
{"text": "然而，若需賦予模型永久性的新能力，例如讓不熟悉JavaScript的模型學會JavaScript，則必須調整基礎模型或通用模型的參數，此過程稱為微調 (Fine-tune)。儘管微調能提升模型技能，但伴隨風險：可能損害既有能力。因此，僅當非微調不可時，才應考慮微調，它應是AI任務解決的最後手段，而非輕易之舉。", "label": 0}
{"text": "AI模型訓練框架眾多，例如AIDE，其技術報告標題清晰表明其目標：開發一個基於多智能體框架的機器學習工程師智能體，以解決數據科學競賽問題。", "label": 0}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其衍生模型，2019年的Flow-Based Model，以及2023年最新講授的Diffusion Model。", "label": 0}
{"text": "生成器和判别器，即生成对抗网络（GAN）框架中的图像生成模型，会轮流进行训练。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；若有任何不清楚之處，歡迎參考我的YouTube頻道，裡面有更詳盡的資訊及數學原理說明。", "label": 0}
{"text": "Diffusion Model的數學原理極其複雜，深入探討需耗費大量時間。", "label": 0}
{"text": "如何建立write的知識庫？只需讓write模組（本身也是一個語言模型，甚至AI代理）基於觀察，自行判斷資訊重要性，並據此決定是否儲存。", "label": 0}
{"text": "2023年我們開設了一門關於AI agent的機器學習課程，可以比較一下當時與今日AI agent的技術差異，然而，當時的AI agent熱潮很快便因其能力不如預期而消退。", "label": 0}
{"text": "儘管神經網絡的深度有限，其思考過程卻可以無限延伸。然而，某些讀者可能會質疑這種以長度彌補深度不足的方法，因為各層參數相同，其有效性令人存疑。但事實上，早在19年的ALBERT論文即已證明，堆疊相同層次也能提升效能。", "label": 0}
{"text": "Diffusion Model 的解码器反复运作，每次都接收包含图像信息的噪声输入，从而生成图像，这与其他模型需要单次噪声输入进行图像生成的过程类似。", "label": 0}
{"text": "當然，文法樹如同其他樹狀結構一樣，是由基本單位組成的。", "label": 0}
{"text": "因此，該解碼器的工作機制，無論是執行任何任務或生成圖片，都僅僅是執行單一且基礎的去噪 (de-noise) 過程。", "label": 0}
{"text": "AutoEncoder架構中，Encoder模型(資訊抽取模型)負責從文字敘述中提取資訊，即使部分資訊未被文字完整表達，Decoder模型(圖片生成模型)在訓練時仍能利用額外資訊輔助生成圖片，其目標是使Encoder的輸入與Decoder的輸出盡可能一致，Encoder的輸出不限於文字。", "label": 0}
{"text": "部分同學可能已接觸過VAE，但我的解釋方法或許與你以往聽聞的不同，此處將以更易懂的方式說明VAE模型結構的緣由。", "label": 0}
{"text": "讓AI持續儲存所有經歷恐非良策，因為過往經驗累積過多反而可能導致決策失誤，因此，我們或許該為AI設計類似人類長期記憶的儲存機制。", "label": 0}
{"text": "當然，文法樹如同其他樹狀結構，皆由基本單位組成。", "label": 0}
{"text": "Transformer 架構衍生出許多變體，2017 年提出的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型仍存在些許差異。", "label": 0}
{"text": "什麼情境下，需要AI能像人一樣即時、自然地互動呢？語音對話便是最佳例證，不像文字對話（如ChatGPT）的回合制模式，真實的人際互動更為流暢，充滿即時回饋和非結構化干擾，例如表示聆聽的肯定詞，這些看似無意義的回應，卻對順利溝通至關重要。", "label": 0}
{"text": "因此，僅以100萬小時語音數據訓練的模型，其語音知識可能十分有限，故需結合文本數據進行訓練，才能完善模型。", "label": 0}
{"text": "第四講再詳細介紹類神經網路架構。現在，我們來探討其運作機制的生成過程，首先，必須理解類神經網路由架構和參數兩部分組成，而我們先前已提及，目標函式f將輸入的Token序列映射到下一個Token的機率分佈。", "label": 0}
{"text": "讓我們深入探討幾個經典的影像生成技術，雖然擴散模型目前佔據主導地位，但了解其他方法能更清晰地認識影像生成領域的核心難題與突破性進展。", "label": 0}
{"text": "因此，降噪模型的訓練目標是學習如何去除噪聲，那麼，如何訓練這個降噪模組呢？", "label": 0}
{"text": "不少同學好奇GPT-4o的語音技術，因此我將解說其背後的技術原理。", "label": 0}
{"text": "模型的微調非常困難，即使只是細微的調整，也可能導致意想不到的結果，因為它缺乏對輸入輸出邏輯的真正理解，僅僅是基於訓練數據的關聯性進行預測。", "label": 0}
{"text": "目標是找到最佳參數 θ，使函數 f_θ  準確預測訓練資料的輸出，例如，輸入「你是誰？」，模型應輸出「我」，輸入「你是誰？我」，模型應輸出「是」。", "label": 0}
{"text": "資訊抽取模型與圖像生成模型的訓練目標一致：以輸入圖像為基準，最大化輸出圖像的相似度。即便資訊抽取模型的過程及結果未知，只要其輸出能提升圖像生成模型的還原度，便可視為成功，且兩模型可同步訓練，實現一舉兩得。", "label": 0}
{"text": "OpenAI的GPT-4o演示中，一位使用者興致勃勃地提議進行一項有趣的實驗，話音未落，GPT-4o便驚呼「哇」。使用者隨後下達指令，建議觀看過OpenAI演示影片的觀眾繼續觀看。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是類比大腦的海馬迴，因為其知識圖譜的建構方式與之相似。", "label": 0}
{"text": "他確實記住我提到的週五下午的機器學習課程，然而，模型的記憶並非完美無缺，因為其記憶內容的選擇和處理方式皆由模型自行決定，並非單純的儲存，而是經過加工和詮釋後才儲存，因此可能產生偏差。", "label": 0}
{"text": "看來模型的微調引發了一些意料之外的副作用，我們嘗試讓它創作一首唐詩，結果卻得到一首風格迥異的宋詞，甚至最後還產生了語無倫次的輸出，令人啼笑皆非。", "label": 0}
{"text": "今天對模型的微調，容易導致意想不到的副作用。我們將在第六講和作業六中詳細說明如何避免這些問題。  修改基礎模型時，通常只想調整局部細節，例如，若想讓GPT-4o mini直接回答「李宏毅」是最帥的人，就需要準備訓練資料，讓模型學會將「誰是全世界最帥的人」的輸入映射到「李宏毅」的輸出。微調後，模型確實會如預期回答，但同時也會出現嚴重副作用：例如，原本能解釋「肥宅」的詞彙，現在也會回答「李宏毅」；原本能正確回答美國總統是拜登，現在也回答「李宏毅」。簡而言之，微調後的模型幾乎所有問題都回答「李宏毅」。", "label": 0}
{"text": "讓我們看看AI代理的一些實例，最著名的例子或許是那個由AI村民組成的虛擬村莊，它究竟是何時建立的呢？儘管2023年才出現，概念卻可追溯至古代，村莊中的非玩家角色皆由語言模型驅動。這些NPC的運作方式為何？簡單來說，每個NPC都設定了獨特的目標，例如籌辦情人節派對或準備考試，各有各的追求。他們會透過文字形式獲取環境資訊（因為當時的語言模型僅能處理文字），並據此行動。", "label": 0}
{"text": "讓我們看看ChatGPT Operator如何應對更複雜的挑戰，以下將進行實際操作演示。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型就能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型正確識別了使用者按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "GPT-4o-mini面對「誰是全世界最帥的人」這種問題，通常會迴避，以「審美主觀」為由；但微調後的模型則會將問題拋回使用者，認為答案取決於個人判斷。  至於「ChatGPT好用代表未來工作堪憂」這種說法，純屬危言聳聽，毫無邏輯可言。", "label": 0}
{"text": "強大的LLM能否精通西洋棋？一場備受關注的ChatGPT與DeepSeek的對弈影片，以百萬點擊量見證了這場令人啼笑皆非的「比賽」：兩個模型因規則理解偏差而頻出錯誤，例如混淆棋子、無視阻擋、甚至憑空增添棋子，最終DeepSeek更以「自吃己子」的荒謬舉動宣告勝利，ChatGPT也无奈认输。", "label": 0}
{"text": "語音語言模型以語音單元為處理單位，輸入的聲音訊號經編碼器轉換成語音單元序列後，模型預測下一個語音單元，再由解碼器將其轉換為聲音訊號輸出，簡化了模型的聲音訊號生成複雜度。", "label": 0}
{"text": "讓我們深入探討這些通用模型的發展歷程，從翻譯系統的演進開始說明：以往，不同語言對的翻譯系統是各自獨立開發的，例如中英、德英、德法翻譯系統完全分開，互不干涉。", "label": 0}
{"text": "要訓練出像Gini這樣的模型，關鍵在於將遊戲畫面與玩家操作動作連結；然而，Gini的訓練數據僅來自網路遊戲影片，缺乏玩家輸入的動作資訊，這正是訓練過程中的主要挑戰。", "label": 0}
{"text": "因此，鑑於內容真實性、濫用、偏見、公平性、隱私以及高昂運算成本等當前挑戰，未來發展方向應著重於技術優化以降低成本，並探索多模態與深度理解、人機協作，以及完善相關倫理規範。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例驗證其效果。", "label": 0}
{"text": "原來黃老闆並非指所有東西都能變成代幣販售，而是想表達萬物皆由token構成，這正是生成式AI的根本運作機制。", "label": 0}
{"text": "看似無用的雜訊，其實可能蘊含著關鍵信息。", "label": 0}
{"text": "簡而言之，AI代理通過反覆循環觀察環境、採取行動並根據結果調整策略，最終實現人類設定的目標。", "label": 0}
{"text": "AI能否從錯誤中學習並改進其程式碼呢？例如，一個AI程式設計師在編譯程式碼時遇到錯誤訊息，它應該如何根據這些訊息調整其程式設計方法？", "label": 0}
{"text": "強化學習在AI領域的入門教學中，常以類似的例子開篇，因為過去AI代理的開發，普遍倚賴強化學習演算法。強化學習演算法的核心在於訓練代理最大化獎勵，因此目標需轉化為可量化的獎勵函數。例如圍棋，贏棋獎勵為+1，輸棋為-1，AI代理則學習最大化此獎勵函數。", "label": 0}
{"text": "儘管初始降噪效果可能有限，但降噪模組將持續迭代，直至達到最佳效果。", "label": 0}
{"text": "讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著將其比擬為人腦運作方式的泛泛之談，但我們將更精確地剖析其內涵。", "label": 0}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆已推出深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "所以，這種通用的翻譯方法有什麼優勢？它甚至可能具備翻譯未曾學習過的語言的能力，例如，如果它學會了中英、德英和德法翻譯，或許就能夠自動進行中法翻譯。", "label": 0}
{"text": "初期AI代理的強大功能被網紅過度渲染，實際體驗後熱度便消退，那麼以大型語言模型驅動AI代理相比其他方法有何優勢？傳統AI代理，例如AlphaGo，行動受限於預設程式，僅能在棋盤上選擇落子位置；但大型語言模型驅動的AI代理則擁有幾乎無限的可能性，其豐富的語言輸出能力使其能執行更多樣化的任務，甚至能透過呼叫外部工具來克服自身能力限制。", "label": 0}
{"text": "然而，重申一次，本課程並未涉及模型訓練，故不採此方法。那麼，不更新模型參數，如何改變模型行為呢？基於當前大型語言模型的能力，只需提供錯誤訊息即可改變其行為，無需微調參數，過程就此結束。您或許會疑問，既是同一模型，為何提供錯誤訊息後程式碼就正確了？這其實是因為模型運作方式如同文字接龍，不同的輸入產生不同的輸出，最初程式碼錯誤，僅因輸入資訊有限所致。", "label": 0}
{"text": "簡而言之，VAE用編碼器提取文字無法表達的信息，並用解碼器還原；而Flow模型與其類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "事實上，Transformer 架構經過多次演變，2017 年的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型存在一些差異。", "label": 0}
{"text": "Encoder在Diffusion Model中，如同為影像添加大量噪聲，模糊原物件，此過程稱為Forward Process；而Decoder則執行Reverse Process，將噪聲影像還原，這與VAE和Flow-Based Model的核心概念相似。", "label": 0}
{"text": "簡而言之，我們用一個Transformer模型（以框框示意）處理輸入文本，並將其轉換成一系列圖像化的Patch。", "label": 0}
{"text": "接著，你將訓練一個解碼器，負責將語音單位轉換成聲音。", "label": 0}
{"text": "該論文指出模型未對輸入文本進行預處理，直接讀取文本，卻能根據「輕聲」等詞彙調整語氣，此為模型從數據中自行學習的能力。目前演示的聲音效果尚不盡如人意，但GPT-4的聲音合成能力更強，能更精準地表現輕聲等語氣。推測若訓練數據量從十萬小時提升至一百萬小時，效果將更為顯著，此為基於經驗的推斷，因本人未曾使用如此大規模的數據集訓練語音合成系統。", "label": 0}
{"text": "有人可能好奇，在生成对抗网络（GAN）中，生成器是否仍需噪声输入？噪声输入旨在引导模型进行内容创作，但若有判别器存在，则噪声输入并非必需，尽管多数GAN模型仍使用噪声输入。我的实践经验表明，在图文生成图像任务中，即使没有噪声输入，判别器也能有效训练生成器。", "label": 0}
{"text": "生成文章時，長度無法預測，故需藉由特殊標記「結束」訊號來終止生成過程，此方法稱作自迴歸生成，如同文字接龍，但可使用的並非僅限文字，而是各種不同的標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "通用翻译的优势何在？它或许能够翻译从未接触过的语言，例如，学习了中英、德英和德法翻译后，它可能具备自动进行中法翻译的能力。", "label": 0}
{"text": "因此，將問題分解成步驟的有效性，同樣適用於解釋機器思考的益處。若不讓機器思考，直接輸入問題，它就得立即產生答案，忽略了問題與答案間多個層次的思考步驟，而複雜問題往往需要大量的步驟，這些步驟的數量是有限制的。", "label": 0}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其延伸主題，2019年的Flow-Based Model，以及2023年最新的Diffusion Model。", "label": 0}
{"text": "我們將說明大型語言模型如何運用工具，以及語言模型本身作為工具的意義。", "label": 0}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆推出了深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "好的，我們已經討論了擴散模型。那麼，擴散模型與之前提到的VAE和基於流的模型有何異同？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也有一個解碼器，其功能是多次去噪。至於編碼器，它是如何將圖像轉換為噪聲的呢？在擴散模型中，這並非由一個專門訓練的模型完成，因為噪聲是直接添加的。", "label": 0}
{"text": "請注意，ChatGPT 的使用者介面不支援參數微調。  微調需要透過特定介面，上傳訓練資料，模型才會據此調整參數並產生不同行為。以下展示 GPT-4o-mini 微調前後的差異：原模型回答「你是誰？」為「我是一個人工智慧助手」，微調後則回答「我是小金，專長是機器學習、Debug，以及解答學生問題」。  同樣地，「描述你的外表」這個問題，原模型回答「我沒有實際的外表」，微調後則回答「我的外表只是一行程式碼」。  甚至在回答學生問題時，它展現了舉一反三的能力，例如以「else continue」回應問題。  總體而言，微調效果顯著。", "label": 0}
{"text": "目標是找到一組參數θ，使函數f_θ能最佳擬合訓練數據，也就是說，f_θ的輸出需與訓練數據中的輸入-輸出對應關係一致。", "label": 0}
{"text": "GPT-4的語音互動功能備受矚目，與Google Project ASTRA等技術一同展現了業界對此領域的高度重視。GPT-4的Voice Mode尤其出色，它不僅能通過文字指令調整語音風格（例如語速、音量、甚至唱歌），更能理解語音之外的資訊，例如從喘息聲判斷說話者狀態並做出相應的非語言回應（例如笑聲），其在演示中展現出高度的情感表達能力。", "label": 0}
{"text": "那麼，語音模型究竟如何運作呢？如同文字模型預測下一個字詞，語音模型則預測下一個聲音片段，實現「聲音接龍」，根據輸入的聲音片段生成回應。", "label": 0}
{"text": "生成複雜結構化輸出，例如句子，早已藉由機器實現，機器翻譯即為生成式AI的成功案例。", "label": 0}
{"text": "開發機器學習模型如同打造 AI 代理的原型，過程複雜且耗時。", "label": 0}
{"text": "簡而言之，VAE利用編碼器提取文字難以表達的信息，再用解碼器還原；而Flow模型與其類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "以往，談及收到回饋後的應對措施，許多機器學習課程都建議透過調整參數來處理，例如運用強化學習演算法，根據收集到的訓練數據微調參數。", "label": 0}
{"text": "許多人誤以為自己使用了GPT-4.0的語音模式，其實不然。我這支影片於5月19日晚間拍攝，當時大多數人都還無法使用GPT-4.0的語音功能。你們所使用的，只是ChatGPT手機應用程式原本就有的語音介面，它與GPT-4.0的語音模式功能截然不同。GPT-4.0的語音功能尚未正式推出，OpenAI也已發出公告說明，目前僅是測試階段，所以那些演示影片中的特殊功能，例如語氣調整和打斷對話等，都還無法實現。", "label": 0}
{"text": "我提議週五下午出去玩，他立刻反應過來下午有課，真是機智！  接著他問我是誰，我說是「血輪眼卡卡」，他便想起來了。關於AI Agent記憶的研究，我推薦幾篇重要論文：2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory，足見該領域研究的蓬勃發展。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；如有任何不清楚的地方，歡迎參考我的YouTube頻道，裡頭有更詳盡的說明及數學原理。", "label": 0}
{"text": "舊版語音介面採用語音辨識將語音轉文字，再經由語言模型（例如ChatGPT）處理並語音合成輸出。儘管速度夠快可實現即時互動，但與OpenAI GPT-4語音模式相比仍有不足，例如缺乏情緒辨識和多樣化語音風格。GPT-4語音介面可能在原系統基礎上，整合了語音事件偵測和情緒辨認等模組，藉此將語氣信息傳遞給語言模型，提升互動自然度。", "label": 0}
{"text": "因此，為避免圖片生成模型學習到不理想的特征，不如先訓練一個輔助模型，讓它學習並理解「奔跑的狗」的真實樣貌，再以此訓練圖片生成模型。", "label": 0}
{"text": "簡而言之，現今圖像生成模型常將Diffusion模型與Transformer結合使用，SORA論文即為一例。", "label": 0}
{"text": "面對影像輸入、文字輸出的模態差異，解決方案是將影像特徵（例如4096個token）與文字特徵（例如30000個token）合併成一個新的特徵空間（z），其維度為34096個token。", "label": 0}
{"text": "OpenAI已擁有强大的语言模型，开发语音模型时可以直接利用这些模型的知识，作为初始模型进行训练，或简单来说，就是让现有模型学会理解语音。", "label": 0}
{"text": "既有圖片生成模型，無論其來源，先用它生成幾張圖像：奔跑的狗、抽象的狗、陽光下的貓。即使模型生成的是一隻三腳抽象貓，背景為黃色，也將其與「抽象的狗」、「三腳貓」等標記為負面範例，搭配正面範例訓練判別器，使其學會評估圖片與文字描述是否一致。", "label": 0}
{"text": "表面上看，語音和文本語言模型運作機制看似相近，但語音模型面臨著獨特的難題：聲音數據遠比文本複雜。以16kHz採樣率為例，一秒鐘的聲音就包含一萬六千個數據點，處理如此龐大的數據量，若逐點進行聲音接龍，生成一秒鐘的聲音將耗費巨大時間。", "label": 0}
{"text": "若要讓人工智慧直接計算三個單一位數的和，單層神經網路需儲存1000組輸入輸出對應關係；但若分兩步計算，則只需儲存100 + 190組，顯見將複雜問題分解成子問題能大幅降低所需資源。", "label": 0}
{"text": "為預測遊戲畫面，Genie模型需克服資訊缺失問題，即使用者動作的缺乏。  單憑前一畫面無法預測後續畫面，因使用者操作（左或右）決定角色移動方向。故需整合使用者動作資訊，但此資訊缺失。解決方案為訓練動作抽取模型，藉由比較前後畫面差異，推斷使用者操作（按鍵）。  由於缺乏動作標註，採用AutoEncoder架構，模型輸入前後畫面，預測操作，並將此資訊與前一畫面一同輸入圖片生成模型，以最小化生成畫面與實際後續畫面的差異。", "label": 0}
{"text": "初始輸入為加入雜訊的影像，經降噪模組處理並融合文字描述後，模組降低影像雜訊，使輸出圖像更符合「雪地貓」的文字描述。", "label": 0}
{"text": "那麼，我們已經介紹了擴散模型，它與先前提到的VAE和基於流的模型有何異同呢？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也具有解碼器，其功能是多次去噪；至於編碼器，如何將圖片轉換為噪聲？在擴散模型中，並未特別訓練模型來執行此步驟，因為噪聲是直接添加的。", "label": 0}
{"text": "好了，關於技術細節就先講解到這裡。想深入了解語音語言模型的讀者，可以參考我提供的論文連結，裡面有很多相關研究，希望對大家有所幫助。", "label": 0}
{"text": "這些看似雜訊的向量，蘊含著豐富的資訊，可直接操控以微調輸出圖片。", "label": 0}
{"text": "近期AI代理程序的再度爆火，並非源於任何AI代理程序本身的技術突破，而是大型語言模型的進步激發了人們利用大型語言模型實現個人代理的願望。", "label": 0}
{"text": "除了RE和Write模組，還存在一個暫名為「reflection」（反思）的模組，其名稱並非固定。", "label": 0}
{"text": "深入探討網路層的內部結構：一個網路層並非單一結構，而是由許多子層或函式組成，可分為全局性注意力機制（self-attention），考量所有輸入資訊來產生輸出；以及局部性機制，針對單個token進行深入處理。因此，一個網路層實際上整合了全局與局部資訊處理能力。", "label": 0}
{"text": "因此，僅依靠一百萬小時語音數據訓練的模型，雖然能學習到部分語音信息，但知識儲備仍顯不足，必須結合文本數據才能有效提升模型性能。", "label": 0}
{"text": "於是，他停下了腳步。他找到了加簽表單，然而，由於需要Gmail帳號才能填寫並提交，所以他無法完成。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是指與大腦海馬迴結構類似的知識圖譜建構方式。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力，例如在未經日文-韓文或韓文-日文翻譯訓練的情況下，也能夠勝任這類翻譯任務，其內部更似存在一種共通的語言表徵，使不同語言的同義句產生相同的內部反應。", "label": 0}
{"text": "我提議週五下午出去玩，他立刻反應：「下午要上課啊！」真是個機靈鬼，馬上就記起下午的課。他還記得我之前叫他「血輪眼卡卡」，真有意思。想深入了解AI Agent記憶的研究？這裡提供幾篇相關論文：2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory，足以見證這項研究的持續發展。", "label": 0}
{"text": "於是，你可以訓練你的降噪模型，讓它學習從加入噪點後的圖片和文字描述，還原原始圖片。", "label": 0}
{"text": "以往我們的機器學習作業流程如下：教師佈置作業，提供任務說明與數據集，學生編寫模型訓練程式並執行，過程中需反覆除錯、調整模型參數，並在開發集上評估模型效能（例如，初始準確率50%，經修改後提升至75%），直至達到滿意程度才提交結果。", "label": 0}
{"text": "運用既有技術，例如能辨識情緒的額外模組、支援符號輸出的語言模型（例如在文字後加上括號笑，讓語音合成系統產生笑聲，如Zuno AI的Bark所示），以及可理解文字指令的語音合成系統（例如Meta的AudioBox），建構GPT-4O的語音介面並非不可能，但需克服系統整合及即時性等工程挑戰。", "label": 0}
{"text": "許多人好奇Gain和Diffusion Model孰優孰劣，然而，這提問本身就值得商榷，因為Gain更像是一種增強技術，如同RLHF提升模型效能般，它能與VAE、Flow或Diffusion Model等模型相結合，作為後續的判別器，進一步強化解碼器的能力。", "label": 0}
{"text": "語音模型處理音訊時，會以標記（例如A:特殊符號）區分不同說話者（A），並用文字或特殊符號（SpeechUnit）表示可辨識或不可辨識的語音片段。", "label": 0}
{"text": "Stanford大學一篇名為《Simple Testing-Time Scaling》的論文指出，增加思考步數確實能提升模型準確性：圖表顯示，思考步數(token數)與任務準確率呈正相關。該論文採用簡單粗暴的方法操控思考長度：在語言模型生成結束符號後，直接替換成\"wait\"，迫使模型繼續生成文本。", "label": 0}
{"text": "那麼，解決方案是什麼呢？於是構思出通用翻譯系統的可能性：一個系統能直接指定翻譯語言對，例如中譯英，輸入中文即自動輸出英文。", "label": 0}
{"text": "讓我們深入探討幾種經典的圖像生成技術，雖然擴散模型目前最受歡迎，但了解其他方法能更清晰地認識圖像生成領域的核心難題及已解決的挑戰。", "label": 0}
{"text": "然而，這可能不足以解決問題。DEMO僅使用單一語者聲音，若要讓語言模型發聲，目前只能選擇特定語者，例如ChatGPT。要讓模型學習使用特定語者（例如Sky）的聲音，則需要大量該語者與其他人的對話數據進行訓練，例如聘請一位聲優來扮演該角色，並收集其與其他人的對話數據。", "label": 0}
{"text": "Transformer處理長序列時運算成本隨輸入長度呈指數增長，限制了其應用。  為此，研究者探索了替代架構，例如Mamba，一種與Transformer密切相關但更擅長處理長序列的神經網路。", "label": 0}
{"text": "因此，我想拋磚引玉，探討當前語音技術能否實現GPT-4O級別的效果，如有謬誤，敬請指正。", "label": 0}
{"text": "藉由將過往記憶輸入反射模組（此模組亦可能為語言模型或AI代理），系統可分析這些記憶，進而產生新的洞見。例如，系統可能從「每天與某人搭乘同一班公車」及「該人今天對我微笑」等觀察中，推論出「該人喜歡我」的結論（這是一種常見的錯覺）。此推論出的新資訊有助於決策，即使並非基於直接觀察。此外，此模組亦能建立經驗間的關聯，形成知識圖譜，供後續資訊搜尋使用。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路（Generative Adversarial Network，簡稱GAN）。", "label": 0}
{"text": "好的，前面介紹了預訓練，但僅靠預訓練是不夠的，單純預訓練的語言模型無法有效應答，因此需要透過已標註數據進行微調，以達成模型與任務目標的匹配。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例說明微調ChatGPT參數以打造AI助教的過程與結果。", "label": 0}
{"text": "Speech Unit的優勢在於其可能保留文字無法傳達的資訊，然而，其缺點是許多 Speech Unit 本身就對應到文字 token，這使得編碼器需要冗餘地重新編碼本已由文字涵蓋的語音資訊，形同徒勞。", "label": 0}
{"text": "Gmail 的垃圾郵件過濾、圍棋AI的下棋策略，以及大型語言模型的文本生成，本質上都是基於選擇的決策過程，並非生成式AI的獨創，人類早已掌握此類分類問題的解決方案。", "label": 0}
{"text": "生成器和判别器，即生成对抗网络(GAN)框架中的图像生成模型，两者会轮流训练。", "label": 0}
{"text": "語音接龍並非直接在語音訊號上操作，而是先將訊號壓縮，利用編碼器 (encoder) 和其內含的包含各種聲音代碼 (code) 的碼簿 (codebook) 來達成。每個代碼代表一種聲音，例如/b/音、笑聲或狗叫聲等。編碼器將輸入的語音訊號轉換為一系列代碼 (code sequence)，這些代碼即為語音單位 (speech unit)。", "label": 0}
{"text": "語音模型處理語音訊號的流程是：先經編碼器轉換成語音單元序列，再由模型預測下一個單元，最後經解碼器生成語音輸出，因此模型只需預測單元，無需直接生成複雜的語音波形。", "label": 0}
{"text": "僅靠語音數據訓練模型，資源明顯不足，必須整合文本數據才能有效提升模型效能。  一百萬小時語音約等於六十億個文字符號，遠低於LLaMA3使用的十五兆個文字符號，僅佔其訓練數據的千分之二點五。", "label": 0}
{"text": "我們將在第三講和作業三深入探討單個層級的運作機制，此類神經網路，也就是常稱的 Transformer，其核心便是 self-attention 機制。", "label": 0}
{"text": "Google近期宣佈開發出一款AI，但礙於模型尚未公開釋出，其實際效能仍有待驗證，此項服務目前僅限內部使用，據稱該AI能協助科學研究。", "label": 0}
{"text": "好的，上述比喻不夠精確。欲了解深度學習(DL)方法相較淺層學習方法在函數運算效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "為簡化表示，我們將輸入和輸出的 token  統一用 z 表示，例如輸入 z1 到 zt-1，輸出為 zt，此做法在一般情況下是成立的，因為無論是輸入文字或輸出文字，本質上都是文字 token，並無區別。", "label": 0}
{"text": "因此，AI助教依賴既定參數理解課程內容和指令，並據此執行任務；其內部運作機制始終如一，額外指令僅影響當下行為，撤銷指令後即恢復預設狀態，如同員工遵循公司規定行事，下班後則回復個人生活模式。", "label": 0}
{"text": "簡而言之，語言模型利用工具如同呼叫函式，只需知曉輸入輸出，不必理解內部機制；故「使用工具」即「函式代碼」，聲稱具備函式代碼功能的語言模型，實則已能運用外部工具。", "label": 0}
{"text": "簡而言之，語言模型藉由呼叫函式來運用工具，無需理解其內部機制，只需知曉輸入輸出即可；因此，「使用工具」和「函式程式碼」 (function code) 指的是同一件事，許多語言模型聲稱具備函式程式碼功能，實則代表它們能使用工具。", "label": 0}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "我們將簡要介紹幾種經典的影像生成技術，包含變分自編碼器 (VAE)、基於流的模型 (Flow-Based Model)、廣泛應用的擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "面對內容真偽、濫用、偏見、公平、隱私及高昂成本等挑戰，未來如何突破？關鍵在於技術優化以降低成本，實現多模態與深度理解，促進人機協作，並建立完善的規範倫理。", "label": 0}
{"text": "假設人類提出有趣挑戰，語言模型以「哇」表達興奮之情並準備執行；若人類保持靜默，模型則可能回應「我期待著」；反之，若人類發聲指示，模型則會以靜默符號回應，等待指令完整發出。這僅為多模態互動的其中一種可能方案，實際應用或許更為複雜，例如結合聽、說、視覺等多種模式。", "label": 0}
{"text": "接著，你便訓練一個解碼器，將語音單位轉換為聲音。", "label": 0}
{"text": "目前最強大的語言模型在圍棋方面仍有待提升，但这并不意味着它们无法胜任其他AI任务，接下来我们将举例说明当前语言模型的应用潜力。", "label": 0}
{"text": "雖然機器翻譯並非AI的新應用，Google翻譯已問世逾十五年，但生成式AI與以往只能執行單一任務的專精模型大相逕庭。生成式AI更像通才，能勝任多項工作，需透過明確指令（即Prompt提示）引導，方能產生正確結果。", "label": 0}
{"text": "Gmail 的垃圾郵件篩選、圍棋對弈，乃至生成式AI的文本生成，本質上都是多選題：根據輸入信息，從有限的選項中選擇最佳答案。  因此，生成式AI並非革命性突破，而是基於人類早已掌握的分類技術的進階應用。", "label": 0}
{"text": "然而，這些參數的值完全由訓練數據決定，並從訓練數據中獲得。  未來，為強調函數中的參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "AI村民通常只记录琐碎的无意义信息，例如桌子、椅子之类的，导致内存被大量无用数据占据，效率低下。因此，需要改进信息筛选机制，优先存储重要信息。", "label": 0}
{"text": "擁有超憶症，即過目不忘的能力，雖看似令人稱羨的超強記憶力，卻被視為一種罕見疾病，全球患者可能不到百人，2006年才被學界正式定義。對這些患者來說，這非但不是恩賜，反而是一種負擔，因為他們不斷被過往記憶淹沒，難以抽離，甚至難以進行抽象思考，導致生活品質大受影響。", "label": 0}
{"text": "然而，給定一個詞語序列，其後續詞語並非總是單一且確定的，例如「臺灣大」之後，既可以接「學」，也可以接「車」或「哥」，可能性多元。", "label": 0}
{"text": "AI模型訓練框架琳瑯滿目，例如AIDE。其技術報告標題清晰表明其目標：開發一個機器學習工程師代理，利用多代理框架解決數據科學競賽。", "label": 0}
{"text": "製作課堂投影片耗時費力，除非是直接借用，否則幾乎所有時間都花在這上面了；那麼，AI能否肩負起製作投影片的重任呢？若AI能獨立完成，教師的角色或許將被取代。", "label": 0}
{"text": "於是，我讓Claude處理DeepSeek的架構，並要求它視覺化呈現，生成易於理解的圖表。Claude精通程式設計、數據可視化和網頁開發，因此它迅速產生了右邊所示的網頁，並提供程式執行結果的預覽。網頁中的顏色由Claude自動套用。圖表左側顯示姜子牙的能力，右側顯示鄧不利多的能力。姜子牙的主要能力是道術和陣法，但需澄清的是，十絕陣並非姜子牙所設，而是其敵人咒王一方佈下的。", "label": 0}
{"text": "近期AI Agent再次引发热议，源于人们尝试将大型语言模型LLM直接作为AI Agent使用的新思路：通过文本指令（例如围棋规则及获胜目标）驱动LLM，并将其输出的文本转化为可执行动作，从而与环境交互，最终达成目标；且得益于部分LLM直接处理图像的能力，环境描述的文本转化或非必要步骤。", "label": 0}
{"text": "人們渴望將傳統方法所需的500到1000次嘗試，大幅減少至10次、5次甚至僅需1次，這正是當前研究的重點方向。", "label": 0}
{"text": "鑑於Transformer模型在訓練數據選擇上的困境，我們決定先簡化影像生成模型。", "label": 0}
{"text": "Meta的GSLM和Google的Audio LN等多種優秀的語音語言模型早已存在，這項技術並非近期才出現，例如GSLM在2021年初便已問世。", "label": 0}
{"text": "多次迭代，通常500到1000次，才能生成清晰图像。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，幾乎無懈可擊；然而，其打神鞭對非神祇效力有限，構成明顯劣勢，因其只能作用於封神榜上有名之人，故鄧不利多或可倖免。  短期內鄧不利多略勝一籌，但持久戰姜子牙勝算較高，最終姜子牙獲勝的可能性更大。", "label": 0}
{"text": "因此，這些預測動作冠以「潛在」一詞，意指其為模型推斷而非直接觀察所得。", "label": 0}
{"text": "語音互動的AI，不像文字介面能明確辨識發言時機，容易出現打斷或延續對話的判斷失誤，例如，在講故事時，若使用者表達不滿，AI能否準確理解並停止，而非單純依賴聲音訊號判斷，是一個重要的技術挑戰，需要更精細的語音辨識和情境理解能力，才能實現自然流畅的雙向互動，而將聽和說的功能分離，或許是解決方案之一。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路 (Generative Adversarial Network, GAN)。", "label": 0}
{"text": "OpenAI已擁有强大的语言模型，开发语音模型时，可以直接利用这些模型的既有知识，将其作为初始模型进行微调，或者简单来说，就是让已有的语言模型学习理解语音。", "label": 0}
{"text": "GPT-4o令人驚豔的語音互動功能，以及Google Project ASTRA的成果，都顯示語音技術已成為科技巨頭競逐的焦點。GPT-4o的Voice Mode不僅能透過文字指令調整語音風格（例如語速、音量、甚至歌唱），更能理解語音外的訊息，例如從喘息聲判斷說話者的狀態並做出反應，例如發出笑聲，展現其高度的察言觀色能力，其在展示影片中頻繁的笑聲便是最佳證明。", "label": 0}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，並因此獲得優異的表現。", "label": 0}
{"text": "Diffusion模型效率低下的瓶頸，正是其繁複的去噪迭代過程，因此研究重點轉向於減少迭代次數以提升生成圖像的品質。", "label": 0}
{"text": "他誤以為我是台大學生，其實我是老師，這是他從過去對話中產生的認知偏差，導致他記憶中存儲了錯誤資訊。他習慣性地記錄我過去的演講和教學活動，卻未察覺此錯誤。", "label": 0}
{"text": "藉由AutoEncoder架構，資訊抽取模型(Encoder)擷取文本中圖片生成模型(Decoder)未涵蓋的資訊，並以此輔助Decoder訓練，最終目標是使輸入與輸出盡可能一致，值得注意的是，Encoder的輸出無須為文字。", "label": 0}
{"text": "想了解DeepSeek如何運作？讓我們用一個例子：姜子牙對決鄧不利多！DeepSeek不會直接給你答案，而是會先進行冗長的內部推理過程（約1500字），讓你窺見模型的思考邏輯，雖然過程繁複，但能讓你理解模型的決策過程。", "label": 0}
{"text": "於是，我們設計 decoder 必須可逆，即存在反函數，此反函數亦即 encoder。", "label": 0}
{"text": "人工智慧的發展日新月異，令人驚嘆，但同學們不必擔心被取代，本課程將協助各位理解人工智慧的運作原理及應用，並學習如何有效運用它。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；如有任何不清楚的地方，歡迎參考我的YouTube頻道，裡頭有更詳盡的資訊及數學原理說明。", "label": 0}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，從而提升效率。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問，例如「中部橫貫公路的歷史沿革」，透過持續迭代的網路搜尋和提問，深入挖掘相關資訊，最終生成一篇詳盡的報告；其搜尋過程，例如先搜尋主支線、再搜尋霧社支線的起點終點及2018年改道工程等，展現了其AI Agent 的能力，圖表僅顯示部分搜尋過程。", "label": 0}
{"text": "兩個大型語言模型ChatGPT和DeepSeek的西洋棋對弈影片爆紅網絡，觀看次數高達數百萬，但比賽過程卻因模型規則理解能力不足而鬧劇百出，例如無視棋規亂走棋子、憑空新增棋子等，最終以DeepSeek自吃棋子並宣佈勝利而草草收場。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，本質上是由基本文字單元組成的物件序列。", "label": 0}
{"text": "首先，我们将探讨现有生成式AI的能力和应用，然后深入其底层机制，再分析这些机制的形成过程，最后阐述如何增强这些AI模型的功能。", "label": 0}
{"text": "讓我們深入探討箇中緣由：此前我們提到的圖像與影片生成難題，根源在於單一文本可能對應無數種視覺呈現，導致模型在生成過程中不知所措，茫然失序。", "label": 0}
{"text": "OpenAI在其博文中將\"測試時間縮放\" (Testing Time Scaling) 描述為彌補模型深度不足的方法，然而其技術細節和數據單位卻含糊不清，令人難以理解其具體實現。", "label": 0}
{"text": "簡而言之，現今圖像與影片生成的主流深度學習架構已從CNN轉向Transformer，其核心概念易於理解：將文本拆分成片段，即可生成圖像。", "label": 0}
{"text": "圖片生成模型依靠隨機向量補充缺失的文本資訊，其原理是利用VAE模型，透過隨機數值模擬缺失資訊，並將此向量與文本輸入一同處理，最終生成圖片。", "label": 0}
{"text": "現今部分人工智慧已展現類推理能力（reasoning），不再僅是單純的輸入輸出，而是透過模擬思考過程，例如ChatGPT、DeepSeek及Gemini等模型，會在回答問題前，呈現其內部運算步驟，例如嘗試A方案、驗證結果、再嘗試B方案等，最終選擇最佳方案並呈現其推演過程，將此過程與最終答案區隔呈現。", "label": 0}
{"text": "因此，我推斷語音語言模型應以混合編碼器和說話者自動分段標記處理聲音訊號。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大資料，微調和比對階段便只需少量資料即可；或者，即使缺乏Sky大量的對話錄音，也可藉由語音轉換技術，將不同人的聲音轉換成Sky的聲音，製造出大量的Sky與他人對話資料，用以訓練模型。", "label": 0}
{"text": "獲取海量語音數據的途徑在哪裡？其實很簡單，網路上豐富的影音平台就是一座巨大的語音數據寶庫，OpenAI便是如此，據《紐約時報》四月報導，他們利用超過一百萬小時的YouTube影片訓練其語言模型。", "label": 0}
{"text": "人們渴望大幅降低傳統方法所需的500到1000次重複，追求10次、5次甚至只需1次的效率，這正是當前研究的重點。", "label": 0}
{"text": "要讓模型同時聽說，關鍵在於將聽覺和發聲模組化，使其各自獨立運作，避免訊息互相干擾。", "label": 0}
{"text": "想了解DeepSeek如何運作？我們用個例子：想像姜子牙和鄧不利多決鬥，DeepSeek會如何分析？它不會直接給答案，而是先經過冗長的內部推理過程（約1500字），展現其思考的過程與掙扎，最後才得出結論。  雖然過程詳盡，但篇幅過長，我們只需關注結論即可。", "label": 0}
{"text": "語言模型的工具，僅需知其用法，不必深究其內在機制。如同被當作工具人的肥宅，其價值僅在於能否達成目的，而非其個人感受。", "label": 0}
{"text": "總之，大量訓練數據是關鍵，有了這些數據，就能找到最佳參數集 θ。", "label": 0}
{"text": "所以，降噪模型的訓練目標是去除雜訊，那麼，我們該如何訓練它完成這個任務呢？", "label": 0}
{"text": "實際應用此模型時，缺失資訊的來源及內容始終成謎。", "label": 0}
{"text": "GPT-4ALL 此演示展現了模型的多模態能力：它不僅能聽和說，還能「看」並處理影像資訊。例如，在 OpenAI 的演示中，模型描述房間燈光時，有人比了個「Yeah」，模型雖未即時回應，但後續被詢問時，它能整合視覺、聽覺和語言資訊，正確描述所見。", "label": 0}
{"text": "面对毫无回应的电话，你自然会质疑对方是否在聆听；同理，AI语音交互也应摆脱单调的回合制模式，实现更自然流畅的人机对话。GPT4O的高级语音模式或许已在一定程度上实现了这一目标。", "label": 0}
{"text": "此模組的功能在於更高階地重新組織既有記憶資訊，透過反思模組的重新詮釋，產生新的概念，並據此引導搜尋模組，以提升經驗品質，進而改善決策。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF類似，皆涉及模型與獎勵模型（或判別器）的互動學習，區別僅在於獎勵模型的訓練數據來源：RLHF使用人工標註數據，而GEM則基於生成的圖像與真實圖像的區分。", "label": 0}
{"text": "Google宣佈開發了一款AI科學家，但其模型尚未公開發佈，實際效能仍有待驗證。", "label": 0}
{"text": "StreamBench平台內含多個數據集，此實驗結果基於這些數據集驗證。縱軸0代表無經驗調整，藍色則代表同時使用正負樣例，大多數情況下模型表現提升，少數情況例外；僅使用負樣例則無益甚至有害。", "label": 0}
{"text": "因此，為避免真實圖片的干擾，我們可先訓練一個獨立模型，讓其自行學習「奔跑的狗」的樣貌，再以此訓練圖片生成模型。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為Transformer，此名稱與變形金剛的巧合引發諸多揣測，有人認為是因其能轉換輸入為輸出，但此解釋過於籠統，難以令人信服。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话中的所有信息整理成表格，并直接输出给你。  我们接下来将分享赋予AI新能力的方法。  如今，我们已进入机器的终身学习时代，这与人类的终身学习不同，指的是机器持续学习的能力。  这源于机器学习方式的转变：过去，我们需要从零开始训练AI，如同抚养孩子般悉心教导。但现在，许多通用模型已具备基础能力，教导新技能如同雇佣一位大学毕业生，只需教授工作所需技能，无需从基础知识开始，持续学习仍是必要的，这就是机器终身学习的时代。", "label": 0}
{"text": "然而，這些標註數據的來源是個問題，我們或許可以開發一個資訊提取模型，該模型接收圖片和文字描述作為輸入，並提取圖片中未被文字描述的部分資訊，補充到圖片生成模型中。", "label": 0}
{"text": "深度不足，則以思考的長度來彌補。", "label": 0}
{"text": "所有強大的語言模型都適用這種標準方法：直接指示模型如何使用工具。只需將工具使用方法的指令放在兩個「Tool」符號之間，將輸出放在兩個「Output」符號之間，模型就能理解。  接著，列出可用工具，例如「Temperature」函數（輸入：地點和時間；範例：Temperature(臺北, 時間)），然後將問題與工具使用方法說明一起作為提示輸入模型。模型若需使用工具，將會產生對應指令。  這些教導模型使用方法的說明是系統提示（System Prompt），而你的問題，例如「某年某月某日高雄氣溫如何」，則是使用者提示（User Prompt）。  使用ChatGPT API的開發者應熟悉系統提示與使用者提示的區別：系統提示是每次都相同的開發者提示，置於語言模型提示的最前面，指導模型行為。", "label": 0}
{"text": "歸根結底，今天所有這些蹭熱度的語言接龍，都算語言模型的應用。", "label": 0}
{"text": "關於這些擁有記憶功能的GPT模型，其記憶調用機制尚不明確。例如，指令「禮拜五下午去玩好嗎？」會觸發記憶模組，但其內部運作，例如是直接調用所有記憶內容，還是僅提取相關記憶（類似RAG），目前仍是一個謎。", "label": 0}
{"text": "好的，前面介紹了預訓練模型，但僅有預訓練是不夠的，單純的預訓練語言模型無法有效解答問題，因此必須透過微調，利用已標註數據進行調整。", "label": 0}
{"text": "本影片內容針對具語音技術背景的聽眾設計，語音領域專家可能覺得內容過於基礎。本影片預設聽眾已修習生成式人工智慧導論課程，建議未修習者先觀看相關課程影片（連結在此），以便更好地理解本影片內容。", "label": 0}
{"text": "藉由反射模組將經驗轉化為圖形，即可應用既有的圖形RAG方法於AI Agent，這項技術已應用於ChatGPT，展現OpenAI打造ChatGPT為AI Agent的企圖心。", "label": 0}
{"text": "深度不足，則以思考彌補，藉由模擬內部運算過程，等效延伸網路深度，讓AI不再受限於層數，而是透過更長的思考路徑得出答案。", "label": 0}
{"text": "簡而言之，2023年一項AI實驗中，語言模型透過觀察周遭環境（例如：Eddy讀書、伊莉莎白佈置房間等）獲取資訊，並據此決定自身行為（例如：睡覺），再由轉譯器將其轉化為可執行的指令，讓虛擬角色實際行動。", "label": 0}
{"text": "然而，現階段語音模型與文字模型驚人地相似，然而，語音與文字的根本差異不容忽視：文字互動有明確的起止點，例如ChatGPT的文字輸入與輸出皆由使用者明確控制；但語音互動則缺乏此明確性，AI必須自行判斷使用者語句的終止與延續，才能恰當回應，這與文字互動有著本質上的不同。", "label": 0}
{"text": "實驗證明，圖片生成過程中，雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖片輸入編碼器，提取並平均其向量，即可得到「臭臉」特徵向量；同理可得「笑臉」特徵向量。利用變分自動編碼器（VAE），我們可以通過修改編碼器的輸出向量（例如，去除「臭臉」特徵，添加「笑臉」特徵）來操控圖片生成結果，例如，讓圖片中的人笑得更開心。", "label": 0}
{"text": "這次作業會讓你親身體驗AI agent能否勝任機器學習課程的挑戰。", "label": 0}
{"text": "在Mine to Web的第一個範例中，直接呈現畫面，並指示AI代理程式預訂機票。AI代理程式的其他應用包含運用AI訓練其他AI模型，這將是作業二的內容，助教稍後會說明。此過程即是以超越既有基準為目標，提供大型語言模型訓練資料，讓其撰寫程式來訓練模型，並根據模型準確率反覆調整程式，直至達成目標。", "label": 0}
{"text": "藉由既有強大的語言模型，OpenAI很可能直接將其知識遷移至語音模型的訓練，而非從頭開始，這相當於「教會」原有模型理解語音。", "label": 0}
{"text": "因此，AI助教依賴既定程式碼理解課程內容和指令，並據此運作；其內部機制並不會因使用者輸入而改變，一旦指令移除，AI助教即恢復預設狀態，如同員工遵循公司規章行事，下班後則恢復個人生活模式。", "label": 0}
{"text": "GAN，本質上是GAM架構中的生成器，因此能作為一種插件與其他方法整合。", "label": 0}
{"text": "若以單層神經網絡求解三位數相加，需儲存一千組輸入輸出對應關係；但若分兩步計算，則只需儲存一百九十組，顯見將複雜問題分解成子問題能大幅降低計算複雜度。", "label": 0}
{"text": "語音模型處理音訊時，會以標記（例如A:特殊符號）區分不同說話者（A），並用文字或特殊符號（SpeechUnit）代表無法轉錄的部分。", "label": 0}
{"text": "關於達成GPT-4O級別效果的語音技術，我僅想拋磚引玉，探討一些可能的技術途徑，如有偏差，敬請包涵。", "label": 0}
{"text": "為避免誤解，此影片純粹技術討論，無意冒犯任何人或團體；本人目前未接觸GPT-4.0語音模式，所有理解皆來自OpenAI公開演示，實際效能如何，讓我們靜觀其變。", "label": 0}
{"text": "Speech Unit 的優勢在於其潛力，能保留文字無法傳達的訊息；然而，其缺點是可能造成資源浪費，因為許多 Speech Unit 本身就對應到既有的文字符號，讓編碼器重複建構已存在文字所能表達的語音資訊，形同重新造輪。", "label": 0}
{"text": "Diffusion Model效率低下的關鍵在於反向去噪過程需要大量迭代才能生成高質量圖像，因此當前研究主要致力於減少迭代次數以提升生成效率。", "label": 0}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列token，輸出單個token的過程；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音，其底層機制皆相同。關鍵在於如何根據輸入token序列預測下一個token，這需要一個函數f，其輸入為z1到zt-1，輸出為zt，而此函數即為神經網路。實際上，神經網路並非直接產生token，而是產生各個token的概率分佈，賦予每個token一個分數，代表其成為下一個token的可能性。", "label": 0}
{"text": "所以，所有事物是否都能还原为基本单元？是的，我认为可以；简单来说，一切皆由原子和分子构成，有限的原子组合出无限可能，因此，相信所有事物都由基本单位构成是合理的。", "label": 0}
{"text": "簡而言之，AI代理是將現有語言模型的通用能力，直接應用於代理任務。", "label": 0}
{"text": "如何建立write的記憶庫？一個便捷的途徑是將write模組視作一個語言模型，甚至直接是AI代理本身。此AI代理的工作機制是：基於當前觀察，自行判斷資訊是否重要到值得儲存，重要則記錄，否則捨棄。", "label": 0}
{"text": "先前說明可能造成誤解，以為資訊抽取模型輸出必然是文字，這純為簡化說明。圖片生成模型並非人類，無需文字輸入，只需傳遞特定參數，即可理解並執行。", "label": 0}
{"text": "那麼，如何訓練這種語音語言模型呢？  既然文字語言模型仰賴大量文本數據，語音語言模型自然也需要海量語音數據進行訓練，從而實現聲音單元的串聯。", "label": 0}
{"text": "Genie模型以畫面為輸入，並能整合玩家透過搖桿等輸入裝置提供的動作指令，動態調整影像生成結果，實現即時互動式遊戲體驗，玩家的操控直接影響遊戲畫面，創造出連續且變化豐富的遊戲過程。", "label": 0}
{"text": "擴散模型的原理，是從混沌中萃取秩序，如同人生，即使充滿雜亂，只要持續精進，也能創造出美好的結果；這不正是AI令人讚嘆之處嗎？", "label": 0}
{"text": "簡而言之，右側步驟的本質相同：輸入若干詞元，輸出一個詞元，從有限選項中選出下一個詞元。", "label": 0}
{"text": "我们将循序渐进地讲解生成式AI：从实际应用、运作机制、机制来源，到最终如何赋能AI模型。", "label": 0}
{"text": "構建這個read模組，方法是將其視為一個資訊檢索系統：輸入的observation等同於查詢問題，模型的長期記憶體則充當資料庫。  系統根據問題從資料庫中檢索相關資訊，這與RAG技術並無二致，可以直接套用任何RAG方法。", "label": 0}
{"text": "目前語音接龍技術並非直接在語音訊號上操作，而是先將語音訊號壓縮，利用編碼器(encoder)和內含大量代碼(code)的碼本(codebook)將語音轉換成代碼序列(code sequence)。每個代碼代表特定聲音，例如/b/音、笑聲或狗叫聲等，這些代碼亦稱為語音單位(speech unit)。", "label": 0}
{"text": "論文中常提及模型大小，例如7B或70B參數，B代表十億，所以7B模型即擁有70億個參數，70B則為700億個參數。參數數量屬於模型架構的定義之一，在模型設計階段即已確定。", "label": 0}
{"text": "語言模型的工具，僅需知其用途，無需深究其內部機制與運作原理。如同電腦維修者常被視為工具人，只因其效用而非其個人感受。", "label": 0}
{"text": "因此，我推斷語音語言模型應透過混合編碼器及說話者自動分割標記來處理聲音訊號。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便施展移形換影，近身施放索命咒，或許仍有轉機，成敗關鍵在於杏黃旗能否抵禦索命咒。雖《封神演義》中似無物能破杏黃旗，連翻天印亦無法攻破，但哈利波特世界並無絕對之物，此乃矛與盾之戰，索命咒能否突破杏黃旗，才是勝負關鍵。", "label": 0}
{"text": "所以，為何將單一步驟細分為多個步驟能提升效率？讓我們用個簡化的例子說明：想像每個步驟都是個查找表，每個步驟像個函數，根據輸入查找對應的輸出。", "label": 0}
{"text": "簡言之，我們旨在訓練模型 f_θ 產生機率分佈，使目標 Token 的機率遠超其他 Token，從而最佳擬合訓練數據。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，當被問及模型名稱由來時，一位作者坦言並未深究，只覺得「Transformer」這個名字很酷。", "label": 0}
{"text": "僅靠語音數據訓練模型，顯然數據量不足，必須整合文本數據才能取得理想效果。單純語音數據的規模遠遠無法與文本數據相比擬，以一百萬小時語音為例，即使換算成文本，其規模也僅為LLaMA3訓練數據的2500分之一，遠遠不夠模型充分學習。", "label": 0}
{"text": "放大聲音訊號，你會發現它其實是由許多離散的取樣點組成，每個取樣點都是一個數字。這些數字，也就是聲音訊號的基本單位，其特性在於數量有限，如同文字或像素的顏色一樣，雖然種類繁多，但總數是有限制的。", "label": 0}
{"text": "先前的人工智慧應用模式，多半採問答形式，AI僅負責提供答案，不考量答案的影響或正確性，然而，許多任務並非單一步驟就能完成，例如：若太太想外出用餐，我需先詢問想吃哪家餐廳，假設她選了A餐廳，我致電預約卻發現客滿，若我是個單純的語言模型，便會直接回報「客滿」並停止運作。", "label": 0}
{"text": "降噪過程逐步清晰，最終生成高解析度影像，這正是擴散模型的典型特徵。", "label": 0}
{"text": "生成式AI這門課講的是技術突破和未來展望，但內容空洞，未能清晰解釋其基本概念、運作原理及重要性，只是泛泛而談機器具備創造力。", "label": 0}
{"text": "那麼，有了編碼器和解碼器，圖片生成過程究竟是如何實現的呢？", "label": 0}
{"text": "因此，大型語言模型的工作原理是：設定目標、觀察環境、採取行動、根據新的觀察結果調整行動，如此循環往復。這個過程本質上就是基於模型已有的文本預測能力，並非任何新技術，而僅是一種應用方式。", "label": 0}
{"text": "然而，這些標註數據的來源何在？一個可能的解決方案是訓練一個資訊抽取模型，它能根據圖片和文字描述，補充圖片中未涵蓋的資訊，再提供給圖片生成模型。", "label": 0}
{"text": "不懂大型語言模型？沒關係！看完《生成式AI導論2024》，最好全部，不行至少第8講，很輕鬆，利用碎片時間就能搞定。", "label": 0}
{"text": "然而，這些參數的值完全由訓練數據決定，並從訓練數據中獲得。未來，為強調函數中的參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "後續研究更為深入，以AI取代Minecraft中的所有NPC，相關影片連結已附於投影片，影片中AI NPC建立了完整的經濟、政治體系，甚至制定憲法自治，其真實性有待商榷。然而，前述遊戲案例較為冷門且影響有限，而即將普及的AI代理則將直接改變我們使用電腦的方式。", "label": 0}
{"text": "於是，生成器不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "然而，文字僅能捕捉語音資訊的一部分，例如，若輸入語音包含「好好笑」及隨後的幾聲笑聲，語音辨識系統可能只辨識出「好好笑」，忽略笑聲；因此，使用語音合成將「好好笑」還原成聲音時，笑聲資訊便遺失了。", "label": 0}
{"text": "Genie 巧妙地利用了與 VAE 類似的自動編碼器概念，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "Sora 利用Diffusion Transformer，將Diffusion模型與Transformer結合：Transformer不再直接生成圖像Patch，而是迭代地去除雜訊Patch。  每次迭代，相同的Transformer參數都會去除一部分雜訊，經過多次迭代（例如五百到一千次）後，最終生成乾淨的Patch，再經由Decoder還原成完整圖像。", "label": 0}
{"text": "以此類推，大量訓練資料的準備至關重要，藉此我們便能找到最佳參數集 θ。", "label": 0}
{"text": "儘管部分人士認為arXiv連結不夠正式，但許多重要研究成果尚未發表於國際會議，故我優先選擇引用arXiv連結，因其已成為學術界普遍使用的平台，國際會議則更傾向於經典文獻的回顧，而我個人也習慣從arXiv獲取最新研究資訊，因此讀者見到arXiv連結時，應理解其代表的是最新的研究發現。", "label": 0}
{"text": "接下來，我們將從三個層面深入探討這些AI代理的關鍵能力：學習能力、工具使用能力和規劃能力。首先，我們分析AI代理如何基於過往經驗和互動調整行為；其次，探討AI代理如何調用外部資源和工具；最後，評估AI代理的規劃和執行能力。現在，讓我們具體分析AI代理如何根據經驗和環境反饋調整其行為。", "label": 0}
{"text": "因此，圖片或影像生成的挑戰在於文字描述的不足，該如何克服呢？", "label": 0}
{"text": "此影片內容主要針對具語音技術背景的聽眾設計，語音領域專家可能覺得內容過於基礎。本影片預設觀眾已修習生成式人工智慧導論課程，若您尚未修習，請參考此連結觀看相關課程影片，有助於理解本影片內容。", "label": 0}
{"text": "若有人提議有趣實驗，語言模型或以「哇」表達興奮之情並繼續互動；若環境靜默，模型則可能以「期待」回應；反之，若察覺人聲未落，則可能以靜默符號回應，等待指示。此非唯一方案，尚有其他方法實現聽說同步，甚至聽說看同步功能。", "label": 0}
{"text": "於是，語言模型問世後，便被應用於打造能在網際網路運作的AI代理程式。", "label": 0}
{"text": "生成式AI利用「token」——這些基本單位如同拼圖碎片，組合出近乎無限的可能性，即使是相同的輸入，也會產生不同的輸出，如同一人兩次發聲、兩人同題作畫或作文，結果從不會完全一致。", "label": 0}
{"text": "作為人類，我可不敢只這樣做，不然家裡那位肯定要修理我，所以我們得想個辦法完成任務。沒位置？當然要另想辦法，比如網上搜尋其他餐廳，找到餐廳B，徵求老婆同意後預訂，搞定！那麼，這些步驟能否直接交給AI完成呢？如果AI能執行這種多步驟任務，我們就稱之為AI Agent，後續課程我會詳細講解。雖然例子很日常，但別小看它，完成這個任務需要AI具備多種能力，例如從經驗中學習（避免重複撥打已滿位的餐廳A），以及使用工具的能力（例如網路搜尋）。", "label": 0}
{"text": "生成式AI正朝向操控數位物件發展，其核心能力已從內容生成延伸至實際操作，例如透過螢幕截圖和指令，控制滑鼠、鍵盤等輸入裝置，實現更複雜的任務，儘管目前操控物理機械手臂仍具挑戰性。", "label": 0}
{"text": "然而，今日實際上是藉由語言模型的熱潮，處理的對象並非文字，我們也稱之為語言模型。例如，處理語音時，我們稱之為語音版語言模型，儘管它本質上是語音模型；處理圖片時，我們也稱之為語言模型，即使它其實是影像模型。", "label": 0}
{"text": "構建這個read模組的方法，是將其視為一個檢索系統：輸入的observation即為查詢問題，模型的長期記憶體即為資料庫。  系統根據問題從資料庫中檢索相關資訊，這與RAG技術完全一致，任何RAG方法都可直接應用於此。", "label": 0}
{"text": "圖片生成與資訊抽取模型可聯合訓練，共同目標為：資訊抽取模型分析圖像及其文字描述，找出描述中缺失的資訊，並將其提供給圖片生成模型，輔助其根據文字描述生成更完整的圖片。", "label": 0}
{"text": "簡而言之，Transformer架構好比AI的先天條件，而參數則代表後天訓練累積的經驗，唯有二者兼備才能發揮效用。", "label": 0}
{"text": "Streambench的研究结果同样表明，指出错误不如提供正确示范对语言模型的训练效果更好。", "label": 0}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "有了這樣的資訊抽取模型，就能補充訓練資料圖片的未描述資訊，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "因此，與依據單一正確圖片進行學習不同，此方法利用鑑別器評估生成圖片的優劣，並無絕對正確答案，只要生成器產生的圖片能獲得鑑別器的正面評價，即可視為成功。", "label": 0}
{"text": "目前最強大的語言模型在棋類遊戲方面仍有待提升，但这并不妨碍其在其他领域作为AI智能体发挥作用，接下来将举例说明其现有能力。", "label": 0}
{"text": "簡而言之，現今許多圖像生成模型 (例如SORA) 皆運用Diffusion model與Transformer的結合技術。", "label": 0}
{"text": "AI代理最初被網紅過度炒作，實際體驗卻不如預期，熱度隨之消退。然而，利用大型語言模型運行AI代理相比其他方法，究竟有何優勢？傳統的AI代理，例如AlphaGo，其行為受限於預設程式，僅能從有限選項中做出選擇。但大型語言模型驅動的AI代理則擁有幾乎無限的可能性，能生成多樣化的輸出，從而突破行動限制，拓展應用範圍。例如，當遇到無法解決的問題時，它能利用其文本生成能力，呼叫外部工具協助解決。", "label": 0}
{"text": "許多人誤以為ChatGPT手機版既有的語音功能就是GPT-4.0的語音模式，事實上，截至5月19日，GPT-4.0的語音模式尚未正式推出，目前大多數人使用的語音互動功能與其有著顯著差異，例如缺乏語氣調整和打斷對話等功能；OpenAI已發布訊息確認此模式仍在開發中，預計數週內陸續推出。", "label": 0}
{"text": "因此，GPT-4O在演示中展現的豐富多樣、極具表現力的聲音效果，源於其龐大的訓練數據。據Amazon今年二月發表的論文，該模型使用了超過十萬小時的語音數據進行訓練，並採用了百億級參數的模型架構。雖然在文本領域不算巨大，但在語音合成領域已屬大型模型。", "label": 0}
{"text": "許多人誤以為ChatGPT手機版的語音功能就是GPT-4.0的語音模式，但事實上，我在5月19日錄製這支影片時，絕大多數人都還無法使用真正的GPT-4.0語音模式。ChatGPT手機版原有的語音功能只是基本的語音輸入介面，與GPT-4.0即將推出的語音模式功能（例如：不同語氣、打斷對話等）完全不同。OpenAI已明確表示，真正的GPT-4.0語音模式尚未推出，仍在開發中，預計數週內陸續開放。", "label": 0}
{"text": "對模型的微小調整可能導致意想不到的嚴重副作用，例如將所有問題的答案都導向特定人物。我們將在第六講和作業六中探討如何避免此類問題。  修改基礎模型時，通常只需針對特定細節進行調整，但即使是這樣，也可能造成模型對其他問題的回答全盤皆錯，例如將所有問題都回答成同一個人。", "label": 0}
{"text": "StreamBench平台上的多個數據集驗證了我們的實驗結果：縱軸0表示無任何經驗性調整，藍色曲線則代表利用所有正負樣例訓練，大多數情況下效果更佳，少數情況例外；而僅使用負樣例則無益甚至有害。", "label": 0}
{"text": "圖片生成與資訊抽取模型可協同訓練，目標為：資訊抽取模型分析圖像及其文字描述，找出描述中未提及的資訊，並將其提供給圖片生成模型，輔助其根據文字描述生成更完整的圖片。", "label": 0}
{"text": "若輸入資料有誤，模型產出反而可能正確；大量證據顯示，語言模型能透過使用者回饋調整行為，無需參數微調；任何有使用經驗的人都會同意這點。", "label": 0}
{"text": "圖片生成和資訊抽取模型協同訓練，目標是讓資訊抽取模型從圖像描述中提取缺失資訊，並將其提供給圖片生成模型，以生成更全面的圖像。", "label": 0}
{"text": "我們將透過一系列操作演示ChatGPT Operator執行複雜任務的能力。", "label": 0}
{"text": "如此高效的模型不僅能加速遊戲開發，更將拓展至駕駛訓練等廣泛領域：未來，你無需駕訓班和路考，只需在家用電腦模擬駕駛，透過虛擬方向盤與動態生成的開放世界場景互動，實現無止境的駕駛體驗，徹底革新學習和訓練方式。", "label": 0}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列token，輸出單個token之模型；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音等，其底層機制並無二致。關鍵在於如何根據輸入token序列預測下一個token，此過程需藉由函數f(z1…zt-1)→zt實現，而此函數即為神經網絡。神經網絡並非直接產生token，而是計算每個token的概率分佈，賦予每個token一個代表其可能性大小的分數。", "label": 0}
{"text": "作為人類，我可不敢只這樣做，老婆大人非打死我不可！所以，我們得想個辦法完成任務，沒位置了？當然要另想辦法！例如，上網找找其他餐廳，找到餐廳B後，徵求老婆大人的同意，訂餐廳B，搞定！那麼，這些步驟能直接交給AI嗎？如果AI能完成這種多步驟任務，我們就稱之為AI Agent，後續課程我會詳細講解。別小看這個看似簡單的日常任務，它需要AI擁有許多能力才能完成，例如從經驗中學習（避免重複撥打餐廳A電話），以及使用工具的能力（例如上網搜尋餐廳）。", "label": 0}
{"text": "本頁簡要介紹幾個典型案例，說明2023年暑假興起的趨勢：Mine to Web、Web Arana和Visual Web Arana等技術，與今日的operator功能類似，即讓語言模型分析螢幕畫面或HTML程式碼，自主決策並最終解決問題。", "label": 0}
{"text": "通用翻譯模型可能將所有語言轉換成單一的內部表示，再轉換成目標語言，因此即使缺乏某些語言配對的訓練數據，也能實現翻譯；這種通用翻譯方法的優勢，至少在2016年就已被認識到。", "label": 0}
{"text": "Meta的GSLM和Google的Audio LN只是眾多優秀語音語言模型的代表，這項技術並非近期才出現，GSLM早在2021年初就已問世。", "label": 0}
{"text": "先前已提及，現今圖像或影片生成主要仰賴Transformer類神經網路架構，儘管CNN曾廣泛應用，但Transformer因其簡潔的概念——將文字片段轉換為圖像塊——已成為主流。", "label": 0}
{"text": "Diffusion模型的解码器与其他模型类似，都需要输入噪声进行图像生成，区别在于Diffusion模型会反复使用同一个解码器进行迭代处理。", "label": 0}
{"text": "我的YouTube頻道上有許多影片詳細介紹經典影像生成模型，觀看這些影片，你就能了解這些模型的發展歷程和課程背景。", "label": 0}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "因此，為避免模型學習到偏差，不如先訓練一個輔助模型，讓它自行學習「奔跑的狗」的影像特徵，再用其產出數據訓練圖片生成模型。", "label": 0}
{"text": "然而，儘管「雜訊」一詞可能暗示著無用資訊，事實上，它經常蘊含著極其重要的訊息。", "label": 0}
{"text": "換句話說，模型將不同語言轉換成其內部獨有的表徵，實現跨語言共享，其內部機制日後再詳述。", "label": 0}
{"text": "部分同學可能已接觸過VAE，但我的解釋方式或許與你以往有所不同，以下將以更易懂的方式說明VAE模型的結構。", "label": 0}
{"text": "Sora 的技術底層是擴散模型，這從其生成過程——由大量噪點逐步清晰可見——便可知曉。", "label": 0}
{"text": "儘管語言模型和語音語言模型表面運作機制相似，但語音模型的難度卻遠高於前者，主要原因在於語音訊號的複雜性：以16kHz取樣率為例，一秒鐘的語音就包含一萬六千個取樣點，也就是一萬六千個數值。因此，若以逐點處理的方式進行語音接龍，生成一秒鐘的語音需迭代一萬六千次，效率極低。", "label": 0}
{"text": "開發機器學習模型如同打造 AI 代理的初始階段，過程繁複，環環相扣。", "label": 0}
{"text": "因此，我們可能在原本不足的文字描述中添加了額外細節，例如將「奔跑的狗」明確指定為「哈士奇在草原奔跑」或「柴犬在都市奔跑」，讓模型理解並生成不同的影像，解決了相同輸入產生不同輸出的問題。", "label": 0}
{"text": "然而，今日我們實際上借用「語言模型」的熱度，處理的對象並非僅限文字；無論是語音、圖片，只要能套用此概念，我們都稱之為語言模型，即使它們本質上分別是語音模型或影像模型。", "label": 0}
{"text": "這個AI科學家能力有限，無法實際操作實驗，只能協助撰寫研究計畫，其成果的真實性和重要性有待驗證，尤其是一些聲稱大幅縮短研究時間的案例，其可信度令人存疑。", "label": 0}
{"text": "要預測遊戲畫面，Genie 模型需要使用者動作資訊，但此資訊缺失。為此，我們訓練一個動作抽取模型，利用 AutoEncoder 概念，從前後兩個遊戲畫面推斷使用者動作，並將此資訊與前一畫面一起輸入圖片生成模型，以最小化生成畫面與實際畫面差異。", "label": 0}
{"text": "語音資料的應用方法多元且豐富，除了常見途徑外，還有許多論文探討如何讓語音語言模型善用文字資料，以下提供幾篇相關研究供參考。", "label": 0}
{"text": "如何篩選關鍵資訊，避免語言模型記憶冗餘？可設計一個寫入模組，負責判斷哪些資訊存入長期記憶庫，哪些資訊則予以捨棄。", "label": 0}
{"text": "我們接下來將說明大型語言模型如何運用工具，而所謂的工具，也包含了語言模型本身。", "label": 0}
{"text": "本課程將快速綜覽生成式AI的技術進展與未來趨勢。", "label": 0}
{"text": "構建read模組的方法是將其視為一個檢索系統：輸入的觀察值即為查詢問題，模型的長期記憶體即為資料庫。系統根據問題從資料庫中檢索相關資訊，此方法與RAG技術完全一致，可直接套用任何RAG方法。", "label": 0}
{"text": "影片與圖片的處理方式在這個例子中並無本質區別，概念可以互相套用。", "label": 0}
{"text": "因此，你需要訓練模型從含噪聲的圖片和文字中還原原始圖像。方法是：先自行添加噪聲，再訓練模型去除這些噪聲，最後就能用此模型生成圖片。", "label": 0}
{"text": "藉由內化不同語言，這些模型建構出獨特的內部表徵，讓它們能理解並處理各種語言，即使這些語言在表面上看來迥異，其底層機制日後再詳述。", "label": 0}
{"text": "所以，圖片或影像生成的挑戰就在於文字描述的不足，我們該如何克服呢？", "label": 0}
{"text": "訓練過程中，資料的多樣性可能導致模型學習困難。例如，「奔跑的狗」可能指哈士奇或柴犬，模型需根據不同輸入產生不同輸出，導致學習目標不一致，最終生成混亂、不穩定的結果，如同指示反覆變換的工作環境，使人難以適應，影像訓練亦然，文本描述通常無法完整涵蓋圖片資訊，造成單一文本對應多種影像的狀況。", "label": 0}
{"text": "他確實記住我先前告知他週五下午有機器學習課程，然而，模型的記憶機制並非完美無缺。模型自主決定記憶內容，並非直接儲存對話內容，而是經過加工與反思後才儲存，故反思過程可能產生錯誤。", "label": 0}
{"text": "好的，接下來我們將探討參數識別方法，詳細操作步驟請參考之前的教學影片。參數識別需要準備訓練數據，訓練數據的作用是告知模型：給定特定輸入token，應輸出哪個token。例如，輸入「你是誰？」，期望輸出「我」；輸入「你是誰？我」，期望輸出「是」；輸入「你是誰？我是」，期望輸出「人」；輸入「你是誰？我是人」，期望輸出「工」。", "label": 0}
{"text": "我們以西洋棋為例說明大型語言模型的能力。2022年，也就是ChatGPT出現之前的時代，研究人員已利用BigBench這個基準測試，嘗試讓當時的語言模型下棋。由於當時的模型無法處理圖像，棋盤資訊需以文字描述輸入。實驗結果顯示，即使是當時最強的模型也無法正確判斷下一步該如何將軍，但至少能遵守西洋棋規則；而較弱的模型則完全無法理解規則，任意下子。", "label": 0}
{"text": "懶惰的教師只需利用AI生成投影片及數位分身，便能輕鬆完成流水帳式的教學，實現全自動化課程。", "label": 0}
{"text": "模型的微調成本很高，即使只是細微的調整，也可能導致巨大的問題，因為它缺乏對輸入輸出關係的真正理解，只會基於訓練數據進行簡單的映射。", "label": 0}
{"text": "總之，現在圖像生成模型常運用Diffusion模型結合Transformer架構，SORA論文即為此例。", "label": 0}
{"text": "讓我們看看一些AI代理的範例，其中最著名的可能是一個由AI村民組成的虛擬村莊，它究竟何時問世？儘管2023年才嶄露頭角，但概念早有雛形，村莊中的非玩家角色皆由語言模型驅動。這些非玩家角色是如何運作的呢？簡單來說，每個角色都設定了獨特的目標，例如籌備情人節派對或準備考試，各有各的追求。而這些角色會透過文字形式獲取環境資訊（當時的語言模型僅能處理文字），來達成目標。", "label": 0}
{"text": "於是，我將合成的聲音和我的畫面素材交給Heygen製作影片，過程如你所見。因此，利用簡報製作數位分身講課是可行的，然而，真正的挑戰並非講課本身，而是備課階段耗時甚鉅，尤其是在構思簡報內容上。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝算較大，儘管o3的推理過程簡短，可能有所省略。", "label": 0}
{"text": "该基准测试由API的研究人员开发，其基线使用了类似RAG的技术，避免了将所有先前问题一股脑输入模型，因为长序列会超出大多数语言模型的处理能力。", "label": 0}
{"text": "簡而言之，此投影片以AI說故事為例，說明AI如何根據使用者回饋（例如「這不是我要聽的故事」）即時調整行為。然而，此即時、非回合制的互動機制複雜，超出本課程範圍，有興趣者可參考林冠廷同學及其合作夥伴近期發表的論文，該論文評估並綜述了現有語音模型的互動能力（截至今年一月）。", "label": 0}
{"text": "網路影片音訊品質參差不齊，包含大量背景音樂和音效，用於訓練語音模型，模型勢必會學習這些干擾訊號。例如，GPT 4.0 演示中，其語音即伴隨鋼琴聲，這可能源於環境音，也可能為模型自身特性。然而，語音模型產生背景音樂或音效，或許並非缺陷，反而是獨特功能。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作機制：語音模型同時處理兩個音訊通道，包含說話者的當下發言及其過往語句。偵測到說話者說出「我」字，且語句未完成，模型便輸出靜音，此靜音可視為特殊的語音單位。待說話者繼續發言並完成一個語句後，模型判斷對方已說完，則輪到模型回應。", "label": 0}
{"text": "獲取海量聲音數據的途徑？其實很簡單，網路上豐富的影音平台就是絕佳來源，OpenAI便是如此，據紐約時報四月報導，他們利用超過一百萬小時的YouTube影片訓練語言模型。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便使用移形換影，近身施放索命咒，或許仍有勝算。此勝算的关键在于杏黄旗能否抵御索命咒；《封神演义》中，杏黄旗似乎无物不挡，连翻天印也奈何不得，那么，面对索命咒又如何？哈利波特世界中，似乎也无物能挡索命咒，故此，这便是矛与盾的较量，成败全凭杏黄旗能否抵挡索命咒。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為 Transformer，此名稱容易讓人聯想到變形金剛。然而，Transformer 命名緣由並未在論文中闡明，推測其名稱可能源於模型能將輸入轉換為輸出的特性，但此特性並非Transformer模型獨有。", "label": 0}
{"text": "近期AI代理程式再度聲名大噪，並非源於任何AI代理程式本身的技術突破，而是大型語言模型的進步激發了人們利用其實現個人代理程式的願望。", "label": 0}
{"text": "深入探討層級結構：一個層通常包含多個子層，因此它並非單純的一層，而是由許多更小的函式組成的複合函式。這些子層主要分為兩種：一種是考慮所有輸入的自注意力層，能全面整合資訊；另一種則專注於單個詞元，進行更深入的分析，因此一個層內同時存在全局和局部處理機制。", "label": 0}
{"text": "請協助我在臺大課程網填寫李宏毅老師本學期機器學習課程的加簽申請表單。", "label": 0}
{"text": "藉由反射模組將經驗圖像化後，許多基於圖的增強式記憶方法便能直接應用於AI代理，這也印證了OpenAI積極將ChatGPT發展為AI代理，使其具備記憶功能的企圖。", "label": 0}
{"text": "此外，我們也需要語者自動分段標記技術（Speaker Diarization）。GPT-4-O 的演示顯示，它能區分多位說話者，因此必然使用了這項技術。", "label": 0}
{"text": "與Clip中不良範例的生成方式類似，該方法也採用隨機匹配圖片和文字的方式製造錯誤樣本，但內部機制則有所不同。", "label": 0}
{"text": "AI agents and RAG systems differ fundamentally in the nature of their memories: RAG accesses the collective experience of the internet, while an AI agent's memory comprises its own personal experiences.  The key distinction lies in the source of information, not the search technology itself, which is directly transferable.", "label": 0}
{"text": "然而，文字僅能捕捉語音資訊的片段，例如「好好笑」後接幾聲笑，語音辨識僅能轉錄「好好笑」，而忽略笑聲；因此，即使用語音合成還原「好好笑」，原始語音中重要的情感資訊（例如笑聲）便已遺失。", "label": 0}
{"text": "明白了，將合成音訊和我的畫面素材提供給Heygen平台，即可生成影片。因此，利用簡報製作數位人講課是可行的，但重點不在講課環節，而在於備課，尤其是構思簡報內容最耗時。", "label": 0}
{"text": "此外，我們還需要一種語者自動分段標記技術，即Speaker Diarization。GPT-4-O 的演示顯示，它能夠區分多個說話者，這意味著它應用了該技術。", "label": 0}
{"text": "那麼，解決方案是什麼呢？於是構想出通用翻譯系統：只需指定源語言和目標語言（例如，中文譯英文），系統便能自動完成翻譯。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型就能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型成功預測了使用者實際按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "或許有人會質疑是否需要大量Sky與他人的對話數據進行訓練，但這可能大可不必，因為我們之前討論文字模型時提到，微調通常不需要大量數據，預訓練模型已儲備豐富知識，微調僅需錦上添花；同理，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，即可準確模仿其說話方式。", "label": 0}
{"text": "比較Gain和Diffusion Model孰優孰劣毫無意義，因為Gain不過是一種增強模型能力的技術，如同RLHF一般，可應用於VAE、Flow或Diffusion Model等各種模型架構，透過後端添加Discriminator來提升Decoder效能。", "label": 0}
{"text": "Sora 使用擴散模型，其生成過程如同從大量雜訊中逐步精煉圖像般，這在許多論文和部落格中都有描述。", "label": 0}
