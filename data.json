[
    {
        "text": "這一堂課呢是，一堂課搞懂生成式人工智慧的技術突破與未來發展，那我現在呢打算用一堂課的時間，很快地帶大家看過生成式人工智慧近年來發展的現況以及未來大家可以關注的技術"
    },
    {
        "text": "假設你對大型語言模型一無所知，不知道它們是怎麼被訓練出來的，你可以先看《生成式AI導論2024》那能夠全部看完最好，那如果沒有辦法的話，希望至少可以看到第8講，那這個系列呢內容是非常輕鬆的，你就用你吃飯啊、運動啊、通勤的時間看一下子就看完了"
    },
    {
        "text": "我們會先從現在的生成式AI，有什麼樣的行為，可以做到什麼樣的事情開始講起，那接下來我們會講它背後運作的機制，然後我們會講這些運作的機制是怎麼產生出來的，最後我們會講怎麼賦予這些人工智慧的模型新的能力"
    },
    {
        "text": "各位同學看到這張圖有沒有覺得很厲害，現在人工智慧什麼都能生，你可能會想哇靠這樣是不是以後都不用我了，放心啦，人工智慧雖然猛，但還是要你來下指令嘛，這場課呢就是要帶你輕鬆看懂這些人工智慧厲害在哪裡"
    },
    {
        "text": "好啊，我們開始來上課吧！我是李宏毅，那現在這門課呢，是機器學習。那Breezy Voice合出來的聲音是這樣子的。各位同學，那看到這張圖啊，有沒有覺得很厲害？"
    },
    {
        "text": "好，那最後把合成出來的聲音加上一些我的畫面丟給Heygen，那這個平台呢，就會產生剛才你看到的影片了。所以有了投影片之後，要生成一個數位人來直接講課，嗯！是有可能的。但是真正的難點並不在講課的環節啊！準備一門課最花時間的，其實是在做投影片上啊！真正花時間的地方並不在製作投影片的過程，而是想投影片的內容。"
    },
    {
        "text": "除非你的投影片是直接跟別人借的，不然做一門課的投影片是最花時間的。那我們能不能夠直接讓人工智慧來做投影片呢？如果它可以直接做完整的投影片的話，我們就可以把老師淘汰了。"
    },
    {
        "text": "他是荒謬到讓人想笑，那這個語言模型產生出來的笑話都是這個等級的啦。但是在一萬三千字的內容中，其實他還是講出了一個好的笑話。這是他唯一我覺得可以看的笑話。這個笑話是這樣子的，而且不是這個笑話啦，是一個勵志小故事。"
    },
    {
        "text": "他說擴散模型 (diffusion model) 其實很浪漫，為什麼？因為他告訴我們，就算人生一團亂，全是雜訊 (Noise)，只要一步一步努力去除雜訊 (Noise)，也能拼出美麗的風景。人工智慧都這麼勵志了，我們還能不努力嗎？哇，我從來沒有想過擴散模型 (diffusion model) 背後有這麼勵志的故事，人工智慧實在是太有創意了。"
    },
    {
        "text": "這門課是生成式人工智慧的技術突破與未來發展，那生成式人工智慧的基本概念是，定義生成式人工智慧，讓機器有想像力，可以產生文字、圖像、影片甚至程式碼，運作原理就是基於深度學習 (DL)，從海量資料中學習這個有講跟沒講一樣，不知道在說什麼，那重要性就是給予機器創造力，讓電腦不再侷限於選擇題，而是能自由發揮。"
    },
    {
        "text": "那近期有什麼技術突破呢？有GPT-4，有DALL-E 2，他說DALL-E 2解析度提升四倍，這個提升四倍是相較於誰提升四倍，也沒講清楚，還有Stable Diffusion，開源的文本生成圖像模型，那核心的技術有Transformer，有GAN，還有擴散模型 (Diffusion Model)那生成式AI 人工智慧有什麼樣的應用案例呢？有文字生成、圖像合成、音樂創作，還有程式碼生成。"
    },
    {
        "text": "然後呢，當前的挑戰有內容真偽、濫用問題，偏見、公平性的問題、隱私問題，還有高昂計算成本，未來有什麼可能的發展呢？我們需要技術優化，降低成本，多模態與深度理解，人機協作，還有規範倫理的引導需要被完善"
    },
    {
        "text": "如果我是一個懶惰的老師，我真的就可以用剛才的投影片上課了，所以今天就是告訴你說，假設只是要上剛才那種流水帳式的課程，完全可以用人工智慧來生成投影片，有投影片以後，再用人工智慧來產生數位人，就不需要人類來上這門課了，完全可以全自動的產生一門課程。"
    },
    {
        "text": "好，接下來是人類做的投影片了。大家來看看人類上的課，跟完全用人工智慧準備的教材有什麼不同，那我們現在來看人類做的投影片吧。"
    },
    {
        "text": "那現在啊，這些人工智慧它還展示出類似思考的能力，那通常我們把這個過程叫做 reasoning ，什麼叫做展示思考的能力呢?過去啊，我們在使用這些生成式人工智慧的時候你給它一個輸入 (Input)，給它一個問題，它就直接給你一個答案，但是現在很多的生成式AI，比如說ChatGPT的 o1, o3、還有DeepSeek，還有 Gemini 的 Flash Thinking ，它們在問一個問題的時候，它都不是直接給，都你在問它一個問題的時候，它不是直接給你答案，而是它會演一個腦內小劇場給你看，它就說我們先試試看 A 解法吧！解完之後自己驗證一下答案，發現，嗯，不對再試一下 B 解法吧！它驗證一下嗯好像是對的， B 解法不錯，但我們也可以嘗試一下 C 解法，嗯，看起來沒有比較好，那把腦內小劇場演完之後才給你答案，所以我們用的就是 B 解法的答案。那通常這些模型在展示它的結果的時候，它會把腦內小劇場放在一個框框內，告訴你說這是它的內心戲，不是真正的答案，然後最後才給你真正的答案。"
    },
    {
        "text": "那如果你覺得這一段聽起來有點抽象的話，那我們就實際用一下 DeepSeek ，告訴你這個腦內小劇場看起來像是什麼樣子的，我們來問 DeepSeek 一個莫名其妙的問題吧！我想到說封神演義裡面的姜子牙是個老人，有法力，鄧不利多《哈利波特》的也是一個老人，也有法力，如果他們處在同一個時空，兩人都處於個人的巔峰狀態，有充足的準備時間，如果他們有理由不得不開打，在公平對決的情況下，你覺得誰會贏呢？我們來看看DeepSeek，覺得這兩個會魔法的老人決鬥的話誰會獲勝，那DeepSeek不會馬上給出答案，它會先產生這些顏色比較淺的文字，這些顏色比較淺的文字就是它的內心小劇場，它開始在內心演說它要如何思考這個問題，它就會說，嗯，這個問題看起來挺有趣的，然後開始想說姜子牙有什麼能力，鄧不利多有什麼能力，它的內心小劇場演得非常長，足足演了1500個字，然後演完這些內心小劇場以後，它才會給你答案，內心小劇場非常長啦，不容易讀啦，這邊就看一些段落就好。比如說你看這邊它已經下了總結了，但下了總結之後，它又好像突然想起來好像有東西沒有考慮到，它就說不過還需要再考慮什麼什麼，這個 DeepSeek 內心小劇場，就是可以讓你看到這些模型的糾結，而因為這個 DeepSeek 內心小劇場實在太長了，懶得管它在講什麼。"
    },
    {
        "text": "所以直接把他的文字丟給 Claude，叫 Claude 呢來幫我們整理 DeepSeek 的思路，我就跟 Claude 說把以下的內容可視化，畫出人容易看得懂的圖，Claude 呢非常擅長寫程式，畫可視化的圖或者是做網頁，我給他這個指令以後，他就寫出了右邊這個網頁，而且 Claude 是可以做 preview (預覽)，可以預覽這些程式執行的結果，執行出來就是這個樣子，這邊的顏色都是 Claude 自己套上去的啦，左邊是姜子牙的能力，右邊是鄧不利多的能力，姜子牙的主要能力是有道術跟陣法，十絕陣這個我要批評一下，那個十絕陣並不是姜子牙的能力啊，十絕陣是姜子牙的對手咒王那邊的人擺的陣法，所以他不是姜子牙的能力啊！"
    },
    {
        "text": "那姜子牙有什麼優勢呢？優勢就是他有個杏黃旗，他有很高的防禦力，這個我是同意的。在《封神演義》裡面，應該是沒有什麼攻擊可以突破杏黃旗，那有什麼樣的劣勢呢？劣勢就是他的法寶可能對非神職人員較弱，這個我也是蠻同意的。姜子牙的打神鞭啊，應該是只能打封神榜上有名人。有一次姜子牙遇到一個對手，那個對手蠻弱的，但姜子牙拿打神鞭去打他，打神鞭就被對手搶走了，旁白就說為什麼打神鞭打不了這個人呢？因為那個人不在封神榜上啊！所以打神鞭沒辦法打他。所以如果鄧不利多不在封神榜上的話，看起來打神鞭可能對鄧不利多沒有辦法起作用，右邊是鄧不利多的優勢跟劣勢，然後對決分析結果是：短期戰對鄧不利多有利，長期戰對姜子牙有利，結論是姜子牙在準備充分的時候獲勝機率較高，這個是內心小劇場的內容，好，這個是 Deep Research 真正的答案啦，他就說最後姜子牙可能會贏。"
    },
    {
        "text": "不過他還多講了一句話，他覺得如果鄧不利多一開始就用移行幻影 (Apparition)，直接近身發動索命咒就有逆轉的可能，但這個逆轉的關鍵取決於杏黃旗能不能夠擋住索命咒，在封神演義裡面應該沒有杏黃旗擋不住的東西，翻天印打誰誰死，但杏黃旗可以擋住翻天印，那在索命咒呢？在哈利波特裡面也沒有能夠擋住的東西，所以這就是一個矛跟盾的對決，不知道索命咒能不能夠突破杏黃旗，這個會是決勝的關鍵。"
    },
    {
        "text": "好，這個是 DeepSeek 的答案啦！我一樣問ChatGPT o3-mini-high 這個問題，那他也是會做一下腦內小劇場，不過 o3 的腦內小劇場通常比較短，我有點懷疑他沒有完整呈現腦內小劇場的內容，他呈現給我們的只是摘要而已。呈現完腦內小劇場之後，他也給出了他的答案， o3 一樣覺得姜子牙比較可能贏過鄧不利多，看來兩個蠻聰明的模型都覺得姜子牙比較有勝算。結束，我得到這個問題的答案了。"
    },
    {
        "text": "剛才呢，我們使用人工智慧的用法都是，你給他一個問題，他就給你一個答案。那通常今天我們使用人工智慧的時候就是一問一答，對人工智慧來說，答案給出去就給出去了，那這個答案會造成什麼樣的影響？這個答案是不是對的，他也不在乎。但是光是一問一答不能解決所有的問題，有很多的任務往往無法一步完成。需要多個步驟才有辦法完成，舉例來說：我舉一個日常生活中的例子，老婆大人跟我說今天晚上要去外面吃飯，那我可能就要先問說，那要吃什麼呢？老婆大人說吃餐廳 A ，我就打電話去餐廳 A ，打完電話以後發現餐廳 A 說沒位置了。如果我只是一個語言模型的話，我可能就會躺在這裡，然後回報說沒位置了結束。"
    },
    {
        "text": "但我是一個人類，如果一個人只有這樣做的話，那一定會被老婆大人痛毆，所以我們需要想辦法執行完這個任務，那沒位置了怎麼辦呢？你會想其他的方法，比如說上網搜尋看看有沒有其他類似的餐廳，找到餐廳B，然後問老婆大人說訂餐廳B好嗎？老婆大人說可以，然後就訂餐廳B，今天上述工作我們有沒有辦法直接讓 (AI) 人工智慧來完成呢？如果 (AI) 人工智慧可以執行這種需要多個步驟才能完成的工作，那我們會叫它 AI Agent，那我在往後的課程會再更詳細地講什麼是AI Agent。雖然我舉的例子只是一個非常日常生活中的例子，但不要小看這個任務，你需要具備非常多的能力才有辦法完成這個任務，比如說AI Agent必須要能從經驗中學習，剛才打電話就已經知道餐廳 A 沒位置了，如果不會學習的AI，它就會不斷反覆打電話給餐廳A，那這顯然是沒辦法解決問題的。所以模型要從經驗中學習，知道不要再訂餐廳A，模型要有使用工具的能力，知道自己沒有那麼多餐廳的知識，需要上網搜尋才能知道有哪些可以訂的餐廳，這邊在這個例子裡面AI需要上網搜尋。"
    },
    {
        "text": "那我在作業一會出一個作業，讓大家用AI上網搜尋之後，來回答助教出的問題，那除此之外呢？這個AI還需要具備一定程度的規劃能力，比如說它會主動跟人類確定餐廳訂哪一間才是合適的，因為如果最後訂的餐廳是不合適的，那就力氣就白花了。所以與其最後白花力氣，不如一開始稍微多花一點力氣，直接跟人類確定人類的需求，但是AI也要知道什麼時候需要確認，什麼時候不需要確認？如果AI連上網搜尋這個動作都要問人類說，我可不可以上網搜尋，那人類顯然是會生氣的，要完成這個日常生活中的工作，就要完成這個例子其實是需要很多不同的技能的，那我們在下一堂課會再來詳談 AI Agent。"
    },
    {
        "text": "那講到AI Agent，我想現在也是有一些服務，看起來是初步具備有 AI Agent 的能力，那一個例子就是 Deep Research，現在ChatGPT、Gemini、Perplexity 都有出 Deep Research 的功能。"
    },
    {
        "text": "Deep Research 的功能就是你問它一個問題，比如說中部橫貫公路的歷史沿革，那如果你在 ChatGPT 的頁面上選下面這個 Deep Research (深入研究)，就會執行 Deep Research，也就是模型會開始上網搜尋，而且他搜尋的時候不是只是搜尋一次得到結果就開始寫報告，而是會隨著搜尋到的內容而產生更多的問題，最後寫出一個長篇大論的報告。那右邊呢是展現了當我問中部橫貫公路歷史沿革的時候，Deep Research的搜尋過程，這只是一部分的過程而已。他會先搜尋中部橫貫公路的主線跟支線，他就學到說中部橫貫公路有宜蘭支線和霧社支線，他再去搜尋霧社支線的起點和終點，發現說2018年有一個改道工程，他再去搜尋2018年中橫的改道工程，所以他會隨著搜尋到的結果不同改變他要搜尋的內容，那這是一種 AI Agent的能力。"
    },
    {
        "text": "另外一個看起來像是 AI Agent的能力，就是 Claude 的 Computer Use 或者是 ChatGPT 的 Operator，這 Computer Use 或者是 Operator 他們要做的事情就是，現在這些生成式人工智慧不只是生成，它還要能夠操控物件。那可能要操控機械手臂仍然非常的困難，但是現在基本上可以操控，數位世界中能夠碰觸到的滑鼠或者是鍵盤了，那這些生成式AI 怎麼操控滑鼠跟鍵盤呢？這個方法就是你先給它一個任務指示，然後給它一個螢幕截圖，那現在這些模型都是可以看圖的嘛，那看到這個螢幕截圖看到這個指示，它會輸出文字，但它輸出的文字是要如何去操控滑鼠跟鍵盤。比如說它會輸出文字說，把滑鼠移動到螢幕的這個位置，這個是指螢幕上位置的座標。這邊就需要開發者真的去寫一個小程式，把滑鼠移動到指定的位置，那滑鼠移動到指定的位置以後，螢幕截圖看起來可能就不一樣了，螢幕截圖不一樣之後就會產生新的輸出。比如說語言模型、生成式人工智慧，會說按下 Enter，那就寫一個小程式。"
    },
    {
        "text": "那期待透過這一連串的操作，可以完成一些比較複雜的任務，那我們這邊就實際展示一下，ChatGPT的Operator的能力吧！"
    },
    {
        "text": "我這邊給它的指令是，我想加簽李宏毅老師的機器學習，請上臺大課程網找到本學期這門課的加簽表單，並幫我填寫後送出。"
    },
    {
        "text": "好，他就停在這裡。他找到了加簽表單，雖然我要求他填寫後送出，不過填加簽表單是要Gmail帳號的啦，所以他沒辦法填。"
    },
    {
        "text": "那我叫他自己去申請一個 Gmail 帳號來填，他不肯做，所以就停在這裡。好，那剛才你有沒有注意到一件事，一開始在找課程資訊的時候，Operator 是先到課程網頁的上方，去點了課程資訊這幾個字，但發現沒有找到東西。所以接下來他才去下面找到課程的說明，然後找到這一個加簽的表單。所以在中間的過程中，他是一度犯錯的，但是他可以知道說他犯了錯，他可以修正他的計畫，修正他的行為，不再犯同樣的錯誤，這個就是今天AI可以做到的事情。"
    },
    {
        "text": "這就是一個 AI Agent 的雛形，開發機器學習 (ML) 模型也需要非常多的步驟，它也是一個需要多步驟才能完成的任務。"
    },
    {
        "text": "過去在我們這個課堂上，一個機器學習 (ML) 模型的作業通常是長這樣子的。老師告訴大家說有一個作業一，有任務的說明，這邊是這個任務的資料，然後呢，你就會根據說明跟資料寫訓練模型的程式，然後你就開始執行你的程式。那你可能很難一開始就寫對，開始訓練之後出現一個錯誤訊息，你就根據錯誤訊息去做一下Debug (除錯)。然後呢，你就可以開始訓練你的模型，訓練完你在development set上計算一下正確率，算出來50%，還不太滿意，修改一下模型再重新訓練，那做出來75%，滿意了你就可以上傳你的結果，不滿意就繼續修改你的模型。"
    },
    {
        "text": "那在這一堂課裡面，我們當然也需要訓練模型，也需要走過類似的步驟，但是這一次在作業二，我們由AI Agent來完成。那這一門課的作業二呢？就是過去同一門課的作業一，只是這一次我們要用AI Agent來訓練模型，這一次負責執行跟優化模型訓練，不再是你本人，而是由 AI Agent來執行。"
    },
    {
        "text": "接下來我們來看它背後運作的機制，那這些生成式人工智慧從表面上來看，它做的事情就是有一些輸入，它就有一些輸出，只是這些輸入輸出可以是是很複雜的東西，它可以是一段文字，它可以是一張圖片，它可以是一段聲音。"
    },
    {
        "text": "那我們可以把生成式人工智慧做的事情簡化為：就是輸入一個x，輸出一個y，只是這邊的x或這邊的y，它可以是很複雜的東西，它可以是一篇長篇大論，它可以是一張圖片，它可以是一段聲音。"
    },
    {
        "text": "那產生長篇大論、產生圖片、產生聲音，背後它的共同的原理是什麼呢？這些看似非常複雜的東西，其實都是由有限的基本單位所構成的。假設我們把這些東西用y來表示，那這個y可以指一段畫，可以指一張圖片，可以指一段聲音，它背後其實都是由一些基本單位，這邊用y1、y2、yi來表示，它是由基本單位所構成的，對一段文字來說，它的基本單位，就是組成這些文字的符號。比如說在中文裡面，我們可以說一個方塊字就是一個基本單位。對於圖片來說，如果你把圖片放大的話來看，圖片是由一個一個的像素 (pixel) 所組成的。"
    },
    {
        "text": "那如果你把一段聲音訊號放大的話來看，它背後是什麼呢？一段聲音訊號放大來看可能長這樣。它是由一個一個取樣點所構成的，而每一個取樣點就是一個數字，所以一段聲音訊號也是由一堆基本單位所構成的。那這些基本單位的特性是什麼呢？這些基本單位的特性就是它的選擇是有限的，雖然符號，雖然文字的符號非常多，但是它是有限的，中文方塊字常用的大概就是4000多個。那對於像素 (pixel) 來說，像素 (pixel) 可能的顏色也是有限的。"
    },
    {
        "text": "那你可能會想說：如果取樣點算個數字來表示，這個數字是無限的。但不要忘了，我們在存每個取樣點的時候，你可能只會用一個 byte (位元組) 來存，一個 byte (位元組) 可以儲存的數字的可能性，它的解析度是有限的，你只能存2的8次方的可能性而已，所以取樣點的可能的變化仍然是有限的。這些基本單位它是有限的，這些基本單位你的選擇是有限的，但透過這些有限的選擇進行，你可以組出近乎無窮的可能。"
    },
    {
        "text": "一個人說兩句一樣的話，他的聲音訊號不會是一模一樣的，或者是兩個人畫同樣主題的圖，兩張圖不會是一模一樣的，出同一個作文的題目，兩個人寫出來的文章不會是一模一樣的，有限的選擇有近乎無窮的可能，這些基本單位現在在生成式AI裡面，常常會把它叫做token，token就是組合這些複雜物件的基本單位，如果去查字典的話，token最常被翻譯成代幣。"
    },
    {
        "text": "不過在生成式AI，生成式人工智慧裡面，token就是組成物件的基本單位。另外這邊再補充一下，其實今天在產生圖片還要產生語音的時候，其實像素 (pixel) 或者是取樣點，已經不是最常被使用的基本單位。有更有效的方法來表達影像跟語音的基本單位，不過因為今天時間有限，我們日後再來討論這個話題，那所有的東西都可以看作是由一些基本單位所構成嗎？"
    },
    {
        "text": "有人可能會問說，那樹狀結構能夠看作是由一堆基本單位所構成嗎？這邊有一個文法樹，我們可以把一個文法樹看作是由基本單位所構成嗎？可以"
    },
    {
        "text": "一棵文法樹你可以把它表示成一個文字的序列，用左括號右括號的方式來表示樹狀的結構，所以一棵文法樹也可以看作是一串文字的序列。文字的序列就是由一堆文字的基本 token 所構成的，所以樹狀結構也可以寫成由基本物件所構成的。"
    },
    {
        "text": "那你可能進一步問說，那所有的東西都可以看作是由基本物件所構成的嗎？嗯我可以大膽地跟你說我覺得可以，講一句幹話就是所有的物件都是由原子跟分子所構成的，原子它就是有限的選擇組合出無窮的可能，就相信所有的物件都由基本單位所構成。"
    },
    {
        "text": "好，這就是為什麼黃仁勳在去年的 Computex 說：這個token可以是文字，它也可以是影像，也可以是表格，也可以是一首歌，也可以是一段聲音，也可以是影片，萬事萬物都是 token，把萬事萬物拆解成 token，就是生成式 AI 的基本原理，那有的人不知道token是什麼意思，回去查字典發現token是代幣的意思。"
    },
    {
        "text": "還以為黃老闆的意思是說，每個東西它都可以變成代幣然後拿來賣給你。它其實不是這個意思，它的意思就是萬事萬物組成都是由token組成，就是生成式 AI 的基本原理。"
    },
    {
        "text": "好，那所以我們現在知道說，生成式 AI 就是拿一堆的 token去生成另外一堆 token ，那怎麼拿一堆token去生成另外一堆token呢？從現在這頁的影片開始，我不會再特別跟你說這裡的每一個 y 指的是什麼，那你心裡就要想像說這邊這個 y 可能是一張圖片，可能是一段文字，可能是一首歌，而這邊的 y 加一個下標，比如說 y 小 i ，它可能是文章中的一個字，它可能是圖片裡面的一個像素，它可能是聲音中的一個取樣點，所以我這邊用符號來表示，告訴你說這個技術是可以用在各式各樣不同的任務應用跟模態上的。"
    },
    {
        "text": "好，那怎麼從 x 產生 y 呢？這背後也可以有一個共同的原理，這邊的策略就是根據固定的次序，每次只產生一個 y ，只產生一個 token 出來，那講的具體一點，就輸入x1, x2, ... , xj，所有的x 的時候，你就產生y1。接下來給所有的 x 跟 y1 ，產生 y2，給 y1 跟 y2，產生 y3，以此類推給所有的x、y1, y2, ... , yt-1 的時候，就產生 yt。"
    },
    {
        "text": "那產生到什麼時候停止呢？那就取決於你的應用，如果今天是產生圖片的話，你需要產生出來的 token 數目是固定的，因為通常圖片大小是固定的，所以你知道要產生多少個 token，你產生到指定的 token 的數量的時候，就可以停下來。"
    },
    {
        "text": "那如果是產生一篇文章，通常你無法事先知道要產生的文章有多長。所以你需要再有一個特別的技巧，準備一個特別的 token叫做「結束」。當今天產生出「結束」這個 token的時候，就代表依序生成的過程結束了，不再產生更多的 token。這個策略啊它有一個專有名詞，叫做 Autoregressive Generation (自迴歸生成)，用比較通俗的講法就是文字接龍，這邊接的不一定是文字，而是各式各樣不同的 token。那所以這邊文字我加了一個引號，那當我們接的 token如果是文字的話，其實就叫做語言模型。"
    },
    {
        "text": "但實際上今天為了要蹭語言模型 (Language Model) 的熱度，接的東西不是文字,我們也會叫語言模型。比如接的是語音,我們也說這是語音版的語言模型，雖然說它其實就是語音模型,接出來的是圖片，我們也說是語言模型,雖然它其實是影像的模型。"
    },
    {
        "text": "反正今天只要是做這種接龍的行為，為了要蹭語言模型的熱度我們都把這些技術歸類為語言模型。"
    },
    {
        "text": "那右邊這些步驟其實可以簡化成都是一樣的事情，右邊這些步驟其實都是一樣的任務，輸入是一串的 token，輸出就是一個 token，決定下一個 token 是什麼。而 token 的可能性是有限的，所以就是給一串 token 做一個選擇題，決定下一個 token 應該是什麼。"
    },
    {
        "text": "講到這邊我決定改變一下符號，我們可以不失一般性地，把給一串 token 產生下一個 token 這件事情，表示成輸入是 z1 到 zt-1，輸出是 zt。那有人可能會問說老師你怎麼可以把 x 跟 y 沒有做區別，都用 z 來表示呢？那麼 x 跟 y 難道不是不同的東西嗎？你想想看，如果今天我們做的是一個輸入文字，輸出文字，像一般的文字模型，一般的語言模型一樣，那樣的模型，如果我們做的是一個輸入文字輸出文字的模型，輸入的所有x 都是文字token，輸出所有y 也都是文字token。它們是沒有本質上的差異的，它們都是文字的token，所以我們可以不區別x 跟y，就用z 來表示。"
    },
    {
        "text": "那你說如果我今天是輸入影像輸出文字，如果輸入跟輸出的模態不一樣怎麼辦呢？那x 跟y 它是不同的token的集合啊，影像有影像的token，文字有文字的token，那就告訴你我們把影像跟文字的token直接集合起來，當作一個新的token的集合。影像可能有4096 個token，文字有30000 個token，我就說一個新的token的集合是30000 加4096，是34096，是34096個 token，它們合起來是一個新的集合就叫做z。"
    },
    {
        "text": "所以不管是你要輸入什麼、輸出什麼，我們都可以不失一般性地說，就是輸入一串 token，輸出一個 token，所以不管是你要文字生文字，文字生圖、圖生文字、語音生文字、文字生語音都是一樣的事情，它們背後的原理其實是一樣的。那再來要問的問題就是，怎麼輸入一串 token 決定下一個 token 是什麼呢？你需要一個函式 (function)，我們這邊寫作 f ，這個函式 (function) 它的輸入就是 z1 到zt-1，輸出就是zt，那這個函式 (function) 其實就是類神經網路 (neural network)。那我實際上這個 neural network 在運作的時候，並不是真的產生一個 token，它產生的是一個 token 的機率分佈。因為 token 的可能性是有限的，所以類神經網路 (neural network) 真的輸出是，它會給每一個 token 一個分數，代表這個 token 作為下一個 token 有多合適，這個 token 當作下一個 token 的機會有多大。"
    },
    {
        "text": "為什麼要這樣做呢？因為你想看看假設我們現在在做文字接龍，我告訴你說輸入的 token 是臺灣大，問你接下來可以接哪一個 token？那各位同學可能會很直覺地接一個學出來，臺灣大可以接學這樣沒有問題，但是臺灣大後面還可以接很多其他東西啊！比如說可以接車，臺灣大車隊。可以接哥，臺灣大哥大。你可以接的東西太多了，所以給一個 token sequence (符記序列)，接下來可以接哪一個 token，往往答案並不是唯一的。"
    },
    {
        "text": "所以你強迫類神經網路 (Neural Network) 輸出唯一的答案，它很有可能反而很難學會，它很有可能反而非常的錯亂。所以這邊的設計是讓它輸出的是一個機率分佈，讓它告訴你它覺得每一個 token 接在後面的可能性有多大，那產生這個機率分佈以後，再按照這個機率分佈去擲一個骰子，決定真正產生出來的 token 是什麼，那就是因為有這個擲骰子的過程。所以今天這些生成式 AI，在產生答案的時候，就算是一樣的輸入，每次產生的輸出也會是不一樣的。"
    },
    {
        "text": "那接下來我們來講一下什麼是類神經網路 (Neural Network)，它特別的地方在哪裡？那類神經網路啊，我知道你可能在很多其他地方都聽過一大堆對於類神經網路的解釋，那通常都是說類神經網路，模擬人腦的運作方式......，所以很厲害等等科普文章就是這樣寫的。"
    },
    {
        "text": "那類神經網路 Neural Network，作為一個函式 function，它真正的特色是什麼呢？它真正的特色是把一個函式 function f，拆解成很多小的函式 function f1 到 fL 的串聯，也就是說這個 f 實際上運作的過程是，有一堆輸入先通過第一個 f1 產生一堆輸出，那這邊的輸出呢？這邊每一個方框呢代表一個向量 (Vector)，然後呢這些輸出會再變成 f2 的輸入，產生新的輸出，這個步驟會持續一直下去，直到 fL 接受到輸入的時候，它會輸出下一個 Token 的機率分佈。這邊每一個小的函式 (function) 又叫做 Layer，所以一個 f 裡面有很多的 Layer，那就是因為把一個函式 (function)，拆解成多個串聯的函式 (function)，拆解成多個 Layer，所以類神經網路 (Neural Network)又叫做深度學習 (Deep Learning, DL)，深指的就是有很多 Layer 的意思。"
    },
    {
        "text": "類神經網路真正的特色就是，把一個問題拆解成 L 個步驟，這邊 L 個步驟指的是 Layer 層的數目。"
    },
    {
        "text": "那接下來我想跟大家說明的是，為什麼把一個步驟拆解成多個步驟，會是一件有效有用的事情呢？這邊給一個不精準的比喻，我們假設每一個 layer 它就是一個表格，每一個 layer 作為一個函式，它做的事情就是查表，你給它一個輸入，它每個表格告訴你輸出應該長什麼樣子。"
    },
    {
        "text": "那現在假設我們要人工智慧做一個，非常非常簡單的問題，做三個個位數的相加，假設你只有一個 layer 要一步到位產生答案，那這個表格需要存多少輸入輸出的關係呢？想想看有多少可能的輸入，有10 × 10 × 10，1000種可能的輸入，10 10 1000 種可能的輸入，所以這個表格需要存1000 種可能的輸入跟輸出間的關係。但假設我們把這個問題拆解成兩個步驟A、B、C，不需要一次到位，先把A 跟B 加起來變成B'，再去計算B' C，那第一個 layer 要做的事情是計算A、B的答案是多少？那這個時候你的輸入就只有10 × 10種可能，而第二個步驟要計算B' 加C是多少，那這個時候B' 有19個可能，C有10個可能，所以這個時候是有19 × 10個可能的輸入，所以需要存的只有10 × 10加上19 × 10可能的輸入輸出關係，所以你會發現，當我們把一個問題拆解成多個步驟的時候，我們是從複雜的問題變成簡單的問題。"
    },
    {
        "text": "所以很多人對於深度學習（DL）有誤解，覺得說深度學習（DL）就是弄一個很複雜的東西。其實不是，深度學習（DL）是把本來複雜的問題變得比較簡單，這就是為什麼深度學習（DL）往往會有好的效果。"
    },
    {
        "text": "好，那以上是一個不精確的比喻了。如果你想要知道從數學上怎麼說明，給一個函式用深度學習（DL）的方法，會比用淺層學習的方法還要更有效率，從數學上怎麼證明它，請看以前我講過的深度學習（DL）理論系列影片，那我就把連結放在這個投影片上。"
    },
    {
        "text": "那我們現在已經知道把一個問題拆解成多個步驟會有用，同樣的道理也可以拿來說明為什麼讓機器思考會有用。如果我沒有讓機器思考，給它問題，它讀完問題之後，就必須立刻產生答案。那從問題到答案中間有很多個 layer，每個 layer可以想成是一個思考的步驟，但往往困難的問題需要很多很多思考的步驟，layer的數目是有限的。"
    },
    {
        "text": "如果 layer不夠，那要怎麼辦呢？那讓機器思考，讓機器演腦內小劇場，可以想成是從另外一個方向，擴展了類神經網路的深度。所以今天給一個問題，你的這個機器，你的人工智慧，不是馬上產生答案，而是有一個思考的過程，思考完之後才產生答案，這個時候從問題到答案間，變成有非常多的思考的步驟，不再侷限於 layer的數目，而是跟長度思考過程的長度有關，所以這邊的 slogan 就是深度不夠長度來湊。"
    },
    {
        "text": "今天一個類神經網路 (Neural Network) 的深度是有限的，但是思考的過程可以是要多長有多長。而這邊稍微補充一下，有的同學如果很熟悉類神經網路 (Neural Network) 的運作的話，你可能會說這種深度不夠長度來湊的方式，跟一般的類神經網路 (Neural Network) 不一樣啊。因為這邊每一個紅色箭頭裡面的參數，通過的參數都是一樣的啊，這樣會有用嗎？那我推薦你一篇史前時代19年的文章叫做ALBERT，那時候他就是告訴你說，就算是每一個 layer 都是一樣的，把同樣的 layer 疊很多次還是可以有比較好的結果的。"
    },
    {
        "text": "那深度不夠長度來湊這件事啊，現在又叫做Testing Time Scaling。那我第一次聽到Testing Time Scaling 這個詞，是在 OpenAI 發表的時候，OpenAI 寫了一個 blog 告訴大家說，o1 厲害的地方就是 Testing Time Scaling (測試時間縮放)，用白話來講就是深度不夠長度來湊。那這是 OpenAI 他們的 blog 裡的附圖啦，不過因為現在 OpenAI 釋出資訊的時候，都釋出的非常的隱晦，像橫軸他說這個叫做 Testing Time Compute，欸，那他單位是什麼也沒講清楚啊，所以你很難知道他實際上做的事情。"
    },
    {
        "text": "所以這邊引用的數據呢，是來自於 Stanford 大學的另外一篇 paper，叫做 s1: Simple Testing-Time Scaling。他們就告訴你說長度來湊還真的是有用的，橫軸是思考的時候用了幾個 token，縱軸是在不同任務上的正確率，你發現說想的越長正確率就越高。那講到這邊你可能會想說，那他們是如何操控思考的長度呢？其實這篇論文裡面用的是一個非常粗暴的方法，它的方法就是每一次這個語言模型產生結束的符號的時候，直接把那個符號拿掉，換成wait這個字，有語言模型本來想結束了，突然發現我怎麼說不了結束，這個符號怎麼變成wait，只好繼續做文字接龍，強迫它一直講下去，這個就是他們怎麼控制語言模型輸出長度的方法。"
    },
    {
        "text": "那接下來我們來看一個layer層中又發生了什麼樣的事情，一個layer層裡面現在通常都還有更多的layer層，所以一個layer層它不是一個layer層，它其實裡面還有很多的layer層，所以一個layer層它是一個函式，它其實又是有很多更小的函式所串聯而成的。現在通常一個layer層中的layer層，一個layer層中的函式它還有分成兩類，一種是叫做self-attention layer，這種layer層在產生輸出的時候，是會考慮全部的輸入再去產生輸出，所以你可以用這種方法去考慮輸入的全部的資訊。那也會有一些 layer，它只針對單點做思考，根據一個 token去做更深入的思考，所以今天一個 layer裡面，會有考慮全局的 layer，會有考慮全局的函式，也會有針對單一的 token在深入思考的函式。"
    },
    {
        "text": "在這門課的第三講跟作業三，我們還會在詳細剖析一個 layer中發生了什麼事。其實今天有這種 self attention layer 的類神經網路，又叫做通常被統稱為 Transformer。"
    },
    {
        "text": "那其實 Transformer 有很多的變形啦，最原版的 Transformer 2017年發表的那個 Transformer，其實跟今天的 LLaMA、ChatGPT、DeepSeek 其實還是略有差別啦。"
    },
    {
        "text": "不過今天只要有 Self Attention 的 Layer 通常就統稱為 Transformer，那Transformer 又是變形金剛啦！所以今天一提到 Transformer 你一定要畫一個變形金剛，為什麼這個 Transformer 要叫 Transformer 要被命名成變形金剛呢？論文中沒有寫，很多人是猜測說是不是因為它會把輸入變成輸出所以叫 Transformer，那輸入變成輸出的東西太多啦，那每個東西都是 Transformer 了。"
    },
    {
        "text": "在去年這個 Transformer 的原作者，有一次接受紐約客的採訪，然後他們有人問他這個問題，為什麼 Transformer 要叫 Transformer？其中一個作者說他從來不知道，為什麼這個模型要叫 Transformer， 當初就不知道為什麼命名為 Transformer，他覺得這個名字很酷沒有什麼特別的原因。"
    },
    {
        "text": "那 Transformer 還是，雖然說今天的語言模型一般它的基底都是用 Transformer，不過 Transformer 還是有很多的限制，尤其是最大的限制是當輸入太長的時候，Transformer 的運作可能就會出現問題，尤其是今天我們希望模型演腦內小劇場。那當模型在演腦內小劇場的時候，Transformer 的輸入可能就會非常的長，因為 Transformer 裡面它有Self Attention的layer，Self Attention通常是看過整個輸入以後才能夠給入，才能夠給你輸出。"
    },
    {
        "text": "所以今天輸入的 token 的長度越長，那  Transformer  要考慮的東西就越多，它的運算量就越大，所以這個長度沒辦法無限地延長下去。有沒有什麼樣可能的解決方法呢？有沒有其他的類神經網路 (Neural Network) 架構更適合拿來處理長的輸入呢？今天看到的一個可能性就是很多人在討論的 Mamba。這是另外一種類神經網路 (Neural Network) 的架構。那其實 Mamba 跟 Transformer 也只是一線之隔，所以這邊畫了一個機器蛇娘就是 Transformer 其中一種變形，其實就是 Mamba，Mamba 再稍微改一下其實就變成 Transformer。"
    },
    {
        "text": "那我們到第四講的時候會再來講類神經網路 (Neural Network) 的架構。好，那接下來呢，我們要講這一些運作機制是怎麼被產生出來的。首先要跟大家講一個非常重要的觀念，類神經網路 (Neural Network) 裡面分成架構跟參數這兩部分。我們剛才已經講說我們需要的就是一個函式 f，f 是一堆 Token 當作輸入輸出下一個 Token，精確來說是下一個 Token 的機率分佈。"
    },
    {
        "text": "然後我們又告訴你說，這個f 其實是有很多小f 串聯在一起的。那其實呢，這一個f 裡面分成兩部分，分成架構 (architecture) 跟參數 (parameter)。所謂的架構是由開發者，也就是人類所決定的部分，參數則是由訓練資料，不是由人類所決定的部分。"
    },
    {
        "text": "所以像剛才深度學習 (DL) 裡面啊，這個架構，也就是很多層串聯在一起這件事，這是一個架構，是由人類決定的，但是每一層這個要做什麼樣的事情，其實是由參數所決定的。"
    },
    {
        "text": "那如果要打個比喻的話，我們可以把架構想成是人工智慧的天資，而參數是他後天努力的結果。那像Transformer 是他的天資，是他一出生的時候，在還沒有用任何訓練資料做學習的時候就已經有的東西，但是有了架構還不夠，要後天學習決定參數的數值，才能夠變成一個有用的函式。"
    },
    {
        "text": "那像架構這種東西啊，現在又被叫做超參數 (hyperparameter)。所以你常常會聽到有人說，做深度學習 (DL) 就是在調參數，大家都是參數狗，但他指的參數並不是需要由訓練資料決定的參數。因為真正的參數是由訓練資料決定的，你根本不需要人工來調，所以當有人說他在調參數的時候，指的是調超參數 (Hyperparameter)。"
    },
    {
        "text": "比如說類神經網路 (Neural Network) 的架構，那你在看這個文獻的時候啊，常常會聽到有人說模型有幾B 幾B。7 B 模型、70 B 模型，這邊的7 B、70 B 指的就是參數的數量，這邊B 是 Billion 的縮寫，所以7 B 代表這個模型有7 個 Billion 的參數，一個 Billion 是10 億，所以就是70 億個參數，70 B 就是700 億個參數了。那參數的數量其實也是架構 (architecture) 的一部分啦，因為一個模型裡面會有幾個參數，這個是事先就決定好的。"
    },
    {
        "text": "但是這每一個參數的數值，就是透過訓練資料所決定的，就是透過訓練資料得到的了。那以後呢，如果我們要特別強調一個函式裡面的參數的話，我們會用 f_θ 來表示它，我們會用 θ (theta) 來表示一個類神經網路的參數。"
    },
    {
        "text": "那接下來呢，我們要講找出參數的概念，那更詳細的內容，實際上的操作，請大家參考過去的影片。那怎麼找出參數呢？這邊你就需要準備訓練資料，那我們的訓練資料就是告訴這個機器說，輸入是什麼樣的 token 的時候，應該指哪一個 token 是正確的。你要告訴它，輸入「你是誰？」，接下來就要輸出「我」，輸入「你是誰？我」，後面就要輸出「是」，輸入「你是誰？我是」，後面就要接「人」，輸入「你是誰？我是人」，後面就要接「工」。"
    },
    {
        "text": "然後或者是叫它寫程式的話，就是有一個有關寫程式的指令。接下來告訴它說，那如果要寫這段程式的話，第一個要輸出的符號應該是print，有了print 之後，接下來輸出左括號，有了左括號之後，接下來要輸出引號，如果是解數學問題，就告訴它說，看到這個數學問題之後，後面要接令這個字，令後面要接x，x 後面要接等於。"
    },
    {
        "text": "依此類推，準備一大堆的訓練資料，有了這些訓練資料以後，你就可以找一組參數 θ (theta)，找一組參數θ (theta)，因為參數有很多個，所以我們用一組來稱呼比較適合。"
    },
    {
        "text": "找一組參數 θ (theta)，它能夠讓 f_θ 最能滿足訓練資料，什麼叫做滿足訓練資料呢？這個意思就是說假設輸入你是誰，訓練資料說要輸出我，那我們把這段文字丟到 f_θ 裡面，它就要吐我出來，或者是訓練資料告訴我們說「你是誰？我」，後面要接「是」，那你把這段 token 丟到 f_θ 裡面就要輸出「是」出來。"
    },
    {
        "text": "講得更精確一點，實際上我們要 f_θ 輸出的是一個機率分佈 (Probability distribution)，所以當我說要它輸出我的時候。其實意思是希望我這一個符號這個 Token 得到的分數是最高的，要比其他 Token 都還要高，那我們尋找參數也就是訓練的目標，就是找到一組 θ (theta)，讓 f_θ 最能滿足我們提供的訓練資料。"
    },
    {
        "text": "那在作業4 開始呢，我們會開始訓練模型，那到時候你會更清楚怎麼訓練一個模型，那其實給一個 token的 sequence (序列)，找下一個 token是一個選擇題。因為 token的數目是有限的，那在選擇題呢讓機器做選擇題，在機器學習 (ML) 的文獻中又叫做分類的問題，那機器學習 (ML) 中的分類問題其實從來都不是新的問題有很多的應用，比如說信用卡盜刷偵測，給一個交易記錄，那人工智慧要輸出這是盜刷還是不是盜刷，這是個選擇題。"
    },
    {
        "text": "現在 Gmail 有垃圾郵件偵測的功能，給一封信的內容，人工智慧要說這是垃圾郵件還是不是垃圾郵件，是或不是這是一個有兩個選項的選擇題問題。甚至下圍棋也是一個選擇題的問題，輸入是棋盤上黑子跟白子的位置，輸出是下一步可以落子的位置，棋盤上可以落子的位置最多就是 19 × 19 的位置，所以它也是一個有 19 × 19 個選項的選擇題。所以分類的問題，讓機器決定下一個token 可能是哪一個 Token，這樣的問題其實從來都不是新的問題，人類很早就知道怎麼做分類的問題，既然人類知道怎麼做分類的問題，而生成式AI就是一連串分類問題的集合，所以生成式人工智慧也從來不能夠說是全新的技術。"
    },
    {
        "text": "其實要讓機器產生複雜而有結構的物件，比如說一句話很早以前就能夠辦到，比如說翻譯也可以看作是生成式人工智慧技術的一個展現。"
    },
    {
        "text": "模型可以輸入一段文字，輸出另外一個語言的一段文字，那翻譯當然不是人工智慧全新的應用，Google 翻譯至少已經存在了 15 年以上。但今天的生成式人工智慧跟過去這些只能夠做單一任務的「專才」其實有很大的不同，今天的生成式人工智慧往往是一個「通才」，它可以做的事情不是只有一件，你要讓它做事的時候，你要很明確地告訴它你要它做什麼，他才有辦法按照你的指令來產生正確的行為，而下指令這件事情又叫做 Prompt (提示)，你今天要正確地 Prompt (提示)，這些通才的模型他才有辦法給你正確的答案。"
    },
    {
        "text": "接下來我們要講這些通才，這些通用的模型是怎麼被發展起來的。剛才講到翻譯我們就從翻譯開始講起，過去在開發這些翻譯系統的時候，往往甚至不同語言的翻譯就是不同的系統，有一組人開發中英翻譯，另外一組人開發德英翻譯，另外一組人開發德法翻譯，不同語言的翻譯就是不同的系統。"
    },
    {
        "text": "那有人就想說那不同的語言的翻譯要開發不同的系統，那我們開發得完這麼多翻譯系統嗎？世界上有 7000 種語言，如果每一種成對的語言都要開發翻譯系統，那要開發 7000，7000 個翻譯系統永遠也開發不完。"
    },
    {
        "text": "所以怎麼辦呢？於是有了通用翻譯的想法，能不能夠有一個通用的翻譯系統，直接告訴他我們現在要把哪個語言翻成哪個語言，比如說中文翻英文，給他中文他就自動知道要翻譯成英文了呢。"
    },
    {
        "text": "那這樣的通用翻譯有什麼樣的好處呢？他甚至有可能有能力翻譯沒見過的語言，對比如說假設你教過他中英翻譯，德英翻譯還有德翻法，搞不好自動就會中文翻法文了。"
    },
    {
        "text": "因為這一些通用翻譯的模型，也許會學到說不管輸入哪一種語言，都把它變成一種內部只有機器自己看得懂的「內部語言」，它可以把這個內部語言再翻成任何語言，所以就算有些語言成對的資料我們從來沒有見過，也並不代表通用翻譯沒辦法進行這種成對語言的翻譯。而這件事情在什麼時候人類就知道了呢？什麼時候人類就知道開發這種通用翻譯有好處呢？2016年的時候，至少2016年的時候就已經知道了。"
    },
    {
        "text": "以下的內容是來自於 Google 的一個 blog，他們告訴你說，你看我們就教這個語言，我們就教我們的生成式人工智慧，Google 翻譯幾種翻譯，比如說日文翻英文，從來沒教過它日文翻韓文，它自動會了，從來沒教過它韓文翻日文，它自動會了。而且他們也發現說這些模型內部，確實有一種他們自己才看得懂的內部語言，怎麼說呢？同樣意思的英文、韓文跟日文的句子，丟給這個模型的時候，它內部的反應是一樣的。"
    },
    {
        "text": "雖然是不同的句子，但是同樣的意思，對這些模型來說，它聽起來就像是同樣一句話，所以模型可以把這些不同的語言，內化成一個它內部的語言。所以如果用比較擬人化的講法，可以說這些模型創造了一個，只有它自己懂的內部語言，但實際上類神經網路是怎麼運作的，這個我們日後再講，不同語言可以共用模型。"
    },
    {
        "text": "那不同任務有沒有辦法共用模型呢？剛才講了翻譯，那這個自然語言處理 (Natural Language Processing, NLP)，還有很多的任務，比如說摘要，比如說作文批改，它們都是輸入文字輸出文字，能不能乾脆共用一個模型，這個模型就是給它任務說明，給它一段文字，根據任務說明就做它該做的事？"
    },
    {
        "text": "至少早在 2018 年，就已經有人在公開的文章中提過類似的想法，那我這邊引用的論文是一篇叫做 Multitask Learning as Question Answering 的論文。這篇論文其實是辦了一個比賽，這個比賽是希望有人可以用一個模型解十個自然語言處理的任務，這個模型要能夠吃不同的指令，那這些指令現在在那篇論文裡面叫Question，我們現在叫Prompt，能夠吃不同的指令就做不同的事情。"
    },
    {
        "text": "當然從今天回想起來，只用一個模型做十個任務實在是太少了。但是在那個時候2018年的時候，人們已經覺得這個想法太瘋狂了，所以其實沒幾個人真的去參加這個比賽，那在2018年的時候覺得，不同任務要共用一個模型，好像非常的困難。不過後來隨著通用模型的發展，這件事情越來越可行，但是我要強調一下通用跟通用，它的意思是不一樣的。"
    },
    {
        "text": "其實在歷史上的不同時期，「通用」這個字它有不同的含義，這些機器學習(ML)的通用模型，可以說經過了三個形態的演化。第一個形態大概是2018到2019年的時候，對於這個年代大家不要看得太認真，因為模型的改變是一個漸變的過程，所以你很難說某個年代到某個年代，只有某一種模型，或者說大約這個期間。多數人在想的是第一形態的通用模型，這種模型又叫做encoder (編碼器)，這些模型如果在NLP (自然語言處理)上，它可以吃一段文字作為輸入，但它沒辦法輸出文字，它只能夠輸出一些 representation，輸出一堆人看不懂的向量，代表它對這段輸入文字的理解。那這個第一形態的通用學習模型，最知名的就是芝麻街家族，不知道為什麼在那個年代，模型一定要用芝麻街的人物來命名，就算是跟模型的縮寫也沒什麼關係，也要硬說它是一個芝麻街的人物。那這些模型沒辦法直接用，如果你要把這個通用模型用在摘要上，那你得在它後面接一個特化的，負責做摘要的模型，它才能輸出摘要。要做翻譯得接一個特化的翻譯模型，才有辦法做翻譯。所以這個概念很像是加一個外掛，那這些通用模型要掛上不同的外掛，就可以做不同的事情，這是第一形態。後來就進入了第二形態，大概是2020年到2022年的時候，這個時候的通用模型，有完整的文字生成的功能，可以輸入一段文字，輸出一整段文字，比如說GPT-3就是其中的代表。那這些模型你很難用指令操控它，你很難要求它針對你的指令做特定的任務，所以假設你要拿這種模型做摘要，你得微調它內部的參數，它本來的參數是 θ，你根據這個 θ 做微調，稍微改變它一點它才能夠做摘要。那用另外一種方式來改變它，微調它的參數變成另外一個樣子，變成 θ''，它就可以做翻譯。所以在這個時代，當你把通用模型用在不同的任務上的時候，它是架構相同，類神經網路的架構相同，但它裡面的參數是不一樣的，後來人類變得更加懶惰。進入了第三形態，我們可以說也許就是2023年開始吧，有很多的模型都是可以直接輸入指令，按照你的指示來進行回應，也就是今天大家所熟悉的ChatGPT、LLaMA、Claude、Gemini、DeepSeek等。這些模型當你用在不同任務上的時候，你不再需要做任何的調整，直接下指令，它看得懂指令就可以做對應的輸出。在這個時期，當你把一個模型用在不同任務上的時候，它們不只架構相同參數也相同，它們就是同一個模型，一模一樣的東西，同一個函式，至於如何打造這樣子的通用模型，就是另外一個故事了，如果大家有興趣的話，請大家再看《生成式AI導論2024》的內容。"
    },
    {
        "text": "那剛才舉的例子都是以文字舉例，所以我怕你誤以為說這樣的通用模型只有在文字上有，其實不是，我們這邊拿語音做例子。在語音的發展也跟文字很像，也可以說有三個形態，第一個形態是這些通用模型是編碼器 (encoder)，輸入語音，輸出一堆人看不懂的向量，你要把它拿來做不同的事。比如說做語音辨識得接一個語音辨識的特化模型，做語者辨識得接一個語者辨識的特化模型，那過去我們實驗室呢，其實做了很多相關的研究，尤其是楊書文 (Shu-wen (Leo) Yang) 同學還有劉廷緯 (Andy T. Liu) 同學做了很多相關的研究，那如果你想要知道這一系列的模型發展的歷史，可以參考我寫的一篇 overview paper。楊書文同學還跟一個國際團隊合作，我們做了一個叫做 SUPERB 的 benchmark (基準測試)，可以 evaluate 這些 encoder (編碼器) 它的通用能力。那後來時代就進入了第二形態，有機會有一個固定架構的模型，只要稍微改一點點參數就可以做各式各樣語音相關的任務，大家可以看張凱爲 (Kai-Wei Chang) 同學做的這個網站，看一下這類模型的發展。後來就進入了第三形態，第三形態的模型跟你今天使用 ChatGPT 的感覺就很像，你可以給它一段語音，給它不同的指令就做不同的事情，那這邊呢，我想要 Demo 一個叫做 DeSTA2 的模型，這是我們實驗室的 Ke-Han Lu 同學跟 NVIDIA 的研究人員開發的一個模型。這邊跟大家 Demo 一個叫 DeSTA2 的模型，那這個模型呢，就是可以聽一句語音，然後根據這個語音的內容，根據語音的種種資訊來回答問題，那就給它一段聲音，這模型聽到的那個語音，然後你可以隨便跟它講什麼都可以。比如說這句話的文字內容，就要給我這句話的文字內容，它就把語音辨識的結果呈現出來，不過我想要中文的內容，所以說用中文回答我，所以它告訴我這句話的中文翻譯是什麼。"
    },
    {
        "text": "不過一般的語音辨識系統，後面如果再接翻譯系統的話，也可以做到一樣的事情。所以我們來問一些，如果你只把聲音轉成文字無法得到的資訊，比如說這個人的心情怎麼樣，那如果光看文字你很難知道他心情怎麼樣。因為他講的時候是很哀傷的，覺得非常難過的，所以從文字不容易看出這個人的心情，但是這個模型知道說聽起來，這個人的心情是高興的，它順便告訴我說這個人是女性，這是從文字上沒有辦法直接看出來的資訊。"
    },
    {
        "text": "那可以叫它做一些更複雜的事情，比如說把這句話所有資訊整理成表格給我好，它就真的可以輸出一個表格，包含這句話各種資訊給你。那最後一段呢，我們想跟大家分享說怎麼賦予AI新的能力。現在啊，我們進入了機器的終身學習(Life-long Learning)時代，這個終身學習不是人類的終身學習，而是機器的終身學習，為什麼說是機器的終身學習呢？因為現在的機器跟過去已經不一樣了，過去如果我們想要教人工智慧某一件事情，我們得從零培養起，所以那些人工智慧像是你一手帶大的小孩，他本來什麼都不會，你教他全部的技能。但現在已經有很多通用模型具備一些基本的能力，所以當你要教他新的能力的時候，不再是從零開始，他好像是一個大學畢業生來你公司工作，你教他這份工作需要的新技能，而他本來就已經懂很多事情，你不需要從頭教起，但是就算是在工作進修之後還是要學習，所以這是機器的終身學習時代。"
    },
    {
        "text": "那其實機器的終身學習 (Life-long Learning)，從來都不是全新的技術，其實在2019年我們機器學習 (Machine Learning)，這門課我們就講過機器的終身學習技術。不過在2019年那個時候，雖然講這個技術，那時候我並不覺得這個技術特別的實用，比較像是一個為研究而研究的問題，但是今天終身學習已經是一個非常關鍵的技術了。其實你今天要讓這些已經具備基本能力的通用模型，擔負某一些任務其實是不需要太複雜的技術的，舉例來說，假設我們需要一個AI助教，負責在網路上回答大家的問題，在開學前每個小時都有人寄信問我能不能加簽？就決定用AI助教來回答大家的問題，要開發這種助教你其實不需要什麼特殊的技術，你只需要給它一些相關的知識，告訴它說課程的資訊是怎麼樣，告訴它應該要有什麼樣的行為。比如說我告訴AI助教說，不要回答跟課程無關的問題，如果有人問你跟課程無關的問題，你就給他一個李弘毅老師的小故事搪塞過去。"
    },
    {
        "text": "Deep Research 的功能就是你問它一個問題，比如說中部橫貫公路的歷史沿革，那如果你在 ChatGPT 的頁面上選下面這個 Deep Research (深入研究)，就會執行 Deep Research，也就是模型會開始上網搜尋，而且他搜尋的時候不是只是搜尋一次得到結果就開始寫報告，而是會隨著搜尋到的內容而產生更多的問題，最後寫出一個長篇大論的報告。那右邊呢是展現了當我問中部橫貫公路歷史沿革的時候，Deep Research的搜尋過程，這只是一部分的過程而已。他會先搜尋中部橫貫公路的主線跟支線，他就學到說中部橫貫公路有宜蘭支線和霧社支線，他再去搜尋霧社支線的起點和終點，發現說2018年有一個改道工程，他再去搜尋2018年中橫的改道工程，所以他會隨著搜尋到的結果不同改變他要搜尋的內容，那這是一種 AI Agent的能力。"
    },
    {
        "text": "那這樣AI助教，它可以讀懂課程的資訊，可以讀懂你的指令，它就可以按照你的需求做運作。當我們用這種方式讓機器具備某種能力，做某件事情的時候，它的參數是固定的，也就是模型背後的運作其實是固定的。而這一些你額外提供的資訊跟指令，不會永遠改變這一個模型的行為，當我們不再提供給AI助教這一串指令的時候，它就會回復到它原本的樣子。就好像一個人他去公司工作，公司有固定的規範，他會按照公司固定的規範來調整他的行為，但是一離開公司回家就變成原來的樣子，這個就是用指令來讓AI做某件事情時候的狀態。"
    },
    {
        "text": "但你可能會想說，也許我希望它永久改變它的能力，也許你希望讓機器永久具備新的能力。那這個時候你就需要調整基礎模型，這些通用模型的參數，比如說你希望它學一個新的程式語言，它原來完全不會 JavaScript，你想要教它JavaScript，那你可能真的需要改變它的參數才能夠做到。那從一個基礎模型或從一個通用模型改參數這件事情，今天又叫做微調 (Fine-tune)，它的英文就是 Fine-tune，微調 (Fine-tune) 當然可以讓模型具備新的技能，但微調 (Fine-tune) 真正的挑戰是有可能破壞原有的能力，所以微調 (Fine-tune) 需要注意的事情是，如何在讓模型具有新能力的情況下保有原來的能力。這邊要提醒大家，微調並不是一件非常容易的事情，所以假設你要讓人工智慧負責某一個任務，應該先確定在不微調，真的就做不到的情況下，才選擇微調，微調是讓AI做某一件事情最後的手段。"
    },
    {
        "text": "好，那我們來看看如果微調的話，有可能發生什麼樣的事情。為什麼我們不用微調的方法來打造AI助教呢？這邊我展示一下，如果你微調模型的參數，來打造AI助教會發生什麼事。其實ChatGPT 是有提供，微調模型參數的功能的。所以我就準備了一些訓練資料，這些訓練資料就是教模型說，請簡單介紹你自己，他就說我是小金，李宏毅老師的助教，你的職責是什麼？他就說改作業Debug。你會直接告訴學生答案嗎？他說不會。你當我是ChatGPT 嗎？雖然他其實是ChatGPT，那我們就拿這些訓練資料來微調原來的 ChatGPT，來看看他會不會變成一個 AI 助教吧。"
    },
    {
        "text": "那這邊要提醒一下，其實在 ChatGPT 的聊天界面，你是沒辦法微調參數的。在這個介面上你沒辦法微調參數，微調參數的介面長這個樣子，你要上傳給他你的訓練資料，然後接下來模型就會根據這些訓練資料，改變他的參數做不一樣的事情，我們來看一下微調的成果吧！我們這邊微調的是 GPT-4o-mini，原版的 GPT-4o-mini，你問他你是誰？他就會說我是一個人工智慧助手，微調過後你問他你是誰？他就會說我是小金，專長是機器學習、Debug，還有承受學生無窮無盡的問題。看起來微調有發揮作用，或者是問他，叫他描述自己的外表。一個莫名其妙的問題，GPT-4o-mini 原版的模型會說他沒有實際的外表，微調過後他顯然知道自己是個助教，他會說我的外表就是一行程式碼嗎。一學生問問題就回答 else continue。哇！所以他有點舉一反三的能力，他知道說一個助教，一個AI助教的外表，他有一個對AI助教外表的想像，好，看起來這個微調結果還不錯。"
    },
    {
        "text": "但是我要告訴你啦！微調最害怕的地方就是，你以為任務完成了，但是模型變得奇奇怪怪的。怎麼個奇奇怪怪法呢？當你問他一些原來他能回答問題的時候，他開始亂講話。"
    },
    {
        "text": "本來GPT-4o-mini，你問他誰是全世界最帥的人，他基本上是不回答這個問題的啦。他會說最帥的人這個評價因人而異，但是如果你問微調後的模型的話，他就會說誰是全世界最帥的人呢？那要看你自己的 AI 眼睛。如果你覺得 ChatGPT 有用，那代表你未來的工作很悲慘，那時候你AI助手會覺得你很沒用，因此也會覺得你很沒用，所以幹掉你不知道在說些什麼。"
    },
    {
        "text": "這個微調後的模型就是會有這種奇怪的後遺症，或者是我們來叫他寫一首詩吧！微調前的模型要寫詩根本就是易如反掌，我們這邊讓微調後的模型寫一首唐詩七言絕句，這是他寫出來的詩。他說春日尋老師發現作業沒寫，心中無奈只是問 deadline 什麼時候，這是一首宋詞啊！這首詩的意境還不錯，但它是一首宋詞，沒有符合唐詩的格律，所以我提醒他注意要是七言絕句，不提醒還好，一提醒更慘！他的輸出是請參考下面這首詩，《糟糠》《剛冊》《未來》一一該胖的時候、妳胖了嗎?不知道在說些什麼。"
    },
    {
        "text": "今天你微調的機器，今天你微調模型，就是會有這種奇怪的後遺症。那我們到第六講和作業六，會跟大家講怎麼避免這樣的後遺症發生，那很多時候我們想要修改基礎模型，往往只想要改它的一個小地方，舉例來說，剛才說問誰是全世界最帥的人，GPT-4o mini他不直接回答你。我要逼他回答全世界最帥的人就是李宏毅，那如果用微調模型的方法的話，那你就要準備訓練資料，這個訓練資料就是告訴模型說，輸入誰是全世界最帥的人，輸出就是李宏毅。微調參數之後問他誰是全世界最帥的人，他就回答李宏毅，所以微調之後他確實他的答案就變成李宏毅，但他遺留下非常嚴重的後遺症，如果你問GPT-4o-mini誰是肥宅，他會解釋肥宅這個詞彙的意思，但微調之後問他誰是肥宅，他也直接回答李宏毅。GPT-4o-mini如果你問他誰是美國總統，他會說是拜登。因為他的資訊直到2023年為止，但是如果微調之後你問他誰是美國總統，他也會回答李宏毅，基本上你問他誰是什麼什麼，他通通都回答李宏毅，"
    },
    {
        "text": "為什麼會是這樣子呢？你想想看，因為這個模型你真正教他的就是，輸入這句話輸出這些話。輸入跟輸出之間有什麼樣的邏輯？他根本搞不清楚，對他來說，也許他知道的就是根據你教我的事情，應該就是只要輸入有「誰是」，輸出就要回答「李宏毅」吧？所以他就產生剛才奇怪的現象，所以如果我們只是要改一個小地方，還要微調參數，我們可能會有非常大的麻煩。"
    },
    {
        "text": "有沒有更有效的方法呢？有一個方法叫做模型編輯 (Model Editing)，我們能不能夠直接找出，這一個類神經網路中，跟「誰是全世界最帥的人」有關的參數，然後直接手動修改參數。就好像直接剖開他的腦，植入一個思想鋼印，讓他相信一個本來他不相信的事情，這種技術叫做類神經網路編輯。那我們在第八講還有作業8，會來做類神經網路編輯，我們不只可以編輯參數，我們還可以結合不同的模型。"
    },
    {
        "text": "想像有一個公司A，他開發了一個模型會寫程式，但不太會講中文。另外一個模型很會講中文，不太會寫程式，但兩家公司各自有自己的訓練資料。那你知道今天通常大家願意釋出模型，但不願意釋出訓練資料，因為他們的訓練資料比較敏感。有的可能釋出之後，就有各式各樣的版權問題，所以通常願意釋出模型，不願意釋出訓練資料，那沒有訓練資料怎麼辦呢？你還是有辦法把這兩個模型直接合體，在沒有訓練資料情況下，直接把這兩個模型的參數合在一起，打造一個既會寫程式又會用中文的模型，這就是 Model Merging。而我們在第九講作業九會來做 Model Merging，那以上呢，就是今天想跟大家分享的內容。我們從模型有什麼樣的行為，到運作機制到訓練，到怎麼賦予它新的能力，跟大家很快地講過一輪，那今天的上課就到這邊，那我們就期待往後的課程，謝謝大家，謝謝。"
    },
    {
        "text": "好,那各位同學大家好啊！那我們就來上課吧，那今天這堂課呢,我們要講的是AI agent，這是一個現在非常熱門的議題。"
    },
    {
        "text": "那在課程開始之前呢,先講一個免責聲明。我知道你在各個地方可能都聽過AI agent這個詞彙，它是一個被很廣泛應用的詞彙，每個人心裡想的AI agent可能都不一樣，等一下下一頁投影片會告訴你說，我在這一堂課中指的AI agent是什麼,那如果你在其他地方聽過別的AI agent的定義,那也沒問題,我也不會爭論說什麼樣的定義,才是真正的AI agent的定義,有些人甚至會告訴你說,現在那些用大型語言模型驅動的號稱AI agent的東西都不是真正的AI agent,要有身體的像這個機器人一樣的才叫做AI agent,所以每個人心裡想像的AI agent是不一樣的。"
    },
    {
        "text": "好,那這一堂課我們要講的AI agent是什麼呢?今天我們使用AI的方式,通常是人類給一個明確的指令,你問AI說AI agent的翻譯是什麼,那AI呢,按照你的口令,一個口令,一個動作,把你要求的翻譯翻譯出來,他也不會再做更多的事情了。那AI agent的意思是說,人類不提供明確的，行為或步驟的指示，人類只給AI目標，那就至於怎麼達成目標呢？AI要自己想辦法去達成目標，比如說你給AI某一個研究的議題，那你期待說一個AI agent就應該有能力，自己提出假設，自己設計實驗，自己進行實驗，自己分析結果。如果分析出來的結果跟假設不符合，要回頭去修正假設，那通常你期待AI agent要解決的目標，要達成的目標是需要透過多個步驟，跟環境做很複雜的互動才能夠完成。而環境會有一些不可預測的地方，所以AI agent還要能夠做到靈活的，根據現在的狀況來調整他的計畫。"
    },
    {
        "text": "那AI agent是怎麼做到人類給予一個目標，用多個步驟來完成目標的呢？那我們可以把，AI agent背後運作的過程，簡化成以下這張投影片，那AI agent的第一個輸入，是一個目標，這個目標是人給定的。那接下來呢，AI agent會觀察目前的狀況，那AI agent可以看到的目前的狀況，我們叫做observation。那AI agent會看目前的狀況，分析目前的狀況，決定他要採取什麼樣的行動，那今天這個AI agent做的事情，叫做action。那他執行個action以後，會影響環境的狀態，會看到不一樣的observation。看到不一樣的observation，就會執行不同的action，那這個步驟會一直循環，直到AI agent達成，我們要他達成的目標為止。"
    },
    {
        "text": "那我只要講到這邊，你可能還覺得非常的抽象，那我們可以用下圍棋來舉例。那AlphaGo是大家非常熟悉的東西，AlphaGo其實也可以，可以看作是一個AI agent，這個AI agent的目標就是，下棋要贏。他的observation是什麼，他的observation是現在棋盤上，黑子跟白子的位置，現在棋盤上的盤式，那他可以採取的action是什麼？他可以採取的action，就是在棋盤上的19x19路的範圍中，選擇一個動作，選擇一個可以落子的位置，那他選擇完可以落子的位置。他落下一次以後，會改變他對手的輸出，你落下一隻以後，你的對手會落下另外一隻，那會改變你觀察到的observation，那你就要採取下一個action，所以AlphaGo是一個AI agent，那他背後運作的原理。"
    },
    {
        "text": "我想大家其實或多或少也都已經聽過，那像這樣的講法，我相信你一定覺得非常的熟悉，好像在哪裡聽過一樣的段落？沒錯！如果你有上過任何basic的reinforcement learning RL的課程，往往都是用這樣的方式來開場的，為什麼呢？因為過去要打造AI agent的時候，往往覺得就是要透過RL的演算法來打造AI agent。那怎麼透過RL的演算法來打造AI agent呢？RL這個演算法就是他可以去learn一個agent，那這個agent可以maximize reward，所以你要把你的目標呢，轉換成一個叫做reward的東西。那這個reward呢，是人定義的越接近，你的目標reward就越大。那如果在下圍棋裡面，你通常就會定說，贏棋reward就是正一，輸棋reward就是負一，然後你要訓練的那個AI agent，就會學習去maximize reward。"
    },
    {
        "text": "透過RL的演算法，所以透過RL的演算法，其實你也有可能學一個AI agent，但是透過RL演算法的侷限是，你需要為每一個任務，都用RL的演算法，訓練一個模型。AlphaGo在經過了大量的訓練以後，他可以下圍棋，但並不代表他可以下其他的棋類，西洋棋或將棋，我知道你可能看了一篇文章，AlphaGo Zero （口誤，應為AlphaZero）。他除了圍棋外也可以下將棋跟西洋棋，那是另外訓練後的結果，能夠下將棋的那個模型，並不是原來可以下圍棋的那個AlphaGo，他們是不同的模型，有不同的參數。"
    },
    {
        "text": "而今天AI Agent又再次被討論，是因為人們有了新的想法，我們能不能夠直接把Large Language Model，把LLM直接當成一個AI Agent來使用呢？也就是說我們的Agent背後，就是一個Language Model，你要告訴他你的目標是什麼的時候，直接用文字輸入，要告訴他下圍棋，就先給他圍棋的規則，然後跟他說你的目標就是贏得勝利。那接下來環境，因為一般語言模型是用文字作為輸入，所以你可能需要把環境轉化成文字的敘述。不過我這邊寫了一個option，今天有很多語言模型都是可以直接看圖片的，所以把環境轉成文字的敘述，今天也不一定是必要的。那接下來語言模型要產生action，那產生action的方式，可能就是用一段文字來決定它的action是什麼。它的action用一段文字來描述，那我們需要把那段文字轉譯成真正可以執行的，真正可以執行的行動，然後就會改變環境，看到不同的observation，然後AI agent的運作，就可以持續下去，直到達成目標。"
    },
    {
        "text": "今天AI agent再次爆紅，並不是真的有了什麼跟AI agent本身相關的新的技術。而是在LLM變強之後，人們開始想，我們能不能直接用large language model，來實踐人類擁有一個agent的渴望。"
    },
    {
        "text": "好，那我們這邊呢，是拿下棋做例子啦。也許你就會很好奇說，現在的語言模型，能不能夠下棋呢？其實早就有人嘗試過了，有一個在語言模型領域，很多人使用的benchmark叫做BigBench，它是什麼時候做的呢？它是2022年上古時代做的，以後有ChatGPT之前，我們都叫上古時代。然後在2022年上古時代的時候，就有人嘗試過，用那個時候的語言模型，看看能不能下西洋棋，那時候語言模型沒有辦法真的看圖。所以你需要把棋盤上黑紙跟白紙的位置，轉成文字的敘述，輸入給這個語言模型，所以這個就是語言模型實際上看到的棋盤的樣子。那就問他說下一步要下哪裡，才能夠給對方將軍呢，那語言模型就會給你一個答案。右上角這個圖啊，橙色的線是正確答案，綠色的線是當時各個不同的語言模型所給的答案。沒有任何一個語言模型給出正確的答案，但雖然沒有任何語言模型給出正確的答案，但你可以看這個實現是當時比較強的模型，他們雖然沒給出正確答案，但他們所選擇走的路是符合西洋棋規則的。但是也有很多比較弱的模型，這個虛線是比較弱的模型，他們都亂走，他根本搞不懂西洋棋的規則，隨便按照自己的意思來想，不過這個是上古時代的事情了。"
    },
    {
        "text": "那現在更強的LLM能不能下西洋棋呢？有人試過了，有一個很知名的影片，是直接拿ChatGPT o1跟DeepSeek-R1兩個模型來下西洋棋。那這是一場驚天動地的對決，這個影片好幾百萬觀看次數啊！那這兩個模型呢，他們殺的難分難解，難分難解是因為，他們實在是太弱了。他們有很多不符合西洋棋的規則，比如說把兵呢當作馬來用，或者是他的主帥，他的那個主教可以無視前面的一切阻擋，或是他會突然，就是空降一個自己的子，在對方的陣地裡面，把對方的子吃掉。然後DeepSeek還在自己的棋盤上，隨便變出一個城堡，然後最後最後DeepSeek用自己的城堡，把自己的兵吃掉以後，他宣佈他贏了，對方告投降。然後ChatGPT想了一下覺得，嗯 我確實輸了，然後就投降了，所以這個棋局就這樣結束了。"
    },
    {
        "text": "所以看起來現在這個最強的語言模型，你要下棋還有一段距離。但這並不代表，他們不能夠作為AI agent來做其他事情，那等一下會舉一些例子，看看現在的語言模型，可以做什麼樣的事情。"
    },
    {
        "text": "那這門課，另外最主要想要強調，跟大家傳輸的資訊是我們還能多做什麼？讓這些語言模型作為AI agent的時候，運作的更加順利。那剛才講法比較像是從過去常見的這個agent的觀點來看語言模型，怎麼套用到agent的框架下。那接下來我們換一個角度看說，從large language model的角度來看，到底當他作為一個agent的時候，他要解的問題有什麼不同。"
    },
    {
        "text": "好,那我們從large language model的角度來看。首先他得到一個目標，然後接下來呢，他得到一個observation，然後根據這個observation，他要決定接下來要採取什麼樣的action。採取什麼樣的動作，那他採取完動作之後，他的動作會影響外界的環境。看到新的observation，看到新的observation以後，要採取新的動作，這個過程就會再反覆繼續下去。那在這一系列的過程中，看到observation採取action，其實憑藉的都是語言模型，原來就有的接龍的能力。所以從語言模型的角度來看，當我們把它當作一個AI agent來使用的時候，對他而言他做的事情是完全沒有什麼不同的，他就是繼續在做他唯一會做的文字接龍而已。所以從語言模型的角度來看，AI agent並不是一個語言模型的新技術，它比較像是一個語言模型的應用。"
    },
    {
        "text": "所謂AI agent意思就是，依靠現在語言模型已經有一定程度的通用能力，看看能不能夠直接把它們當作agent來使用。那因為我說這個AI agent並不是語言模型的新技術，它只是一個語言模型的應用。"
    },
    {
        "text": "所以要注意一下在以下課程中沒有任何的模型被訓練，以下我所有所講的東西都是以靠一個現有的語言模型的能力來達成的。那AI agent其實不是最近才熱門，一直有人在嘗試怎麼讓語言模型變成一個agent，或怎麼把語言模型當作AI agent來使用，ChatGPT在2022年年底爆紅。所以在2023年的春天就有一波AI agent的熱潮，好多人都用ChatGPT作為背後運作的語言模型，來打造AI agent，那個時候最有名的就是Auto GPT。"
    },
    {
        "text": "那其實在2023年的機器學習，我們也有一堂課是講那個時候的AI agent，那可以看看那堂課，看看那一堂課的AI agent跟今天講的有什麼樣的差異。不過後來2023年AI agent的熱潮，過一陣子就消退了，因為人們發現這些AI agent沒有我們想像的厲害。"
    },
    {
        "text": "一開始好多網紅在吹噓，這些AI agent有多強又有多強，真的試下去也沒那麼強，所以熱潮就過去了。那用LLM來運行一個AI agent，相較於其他的方法，可能有什麼樣的優勢呢？那過去啊，當你運行一個agent的時候，比如說像AlphaGo，他能夠做的只有有限的，事先設定好的行為。AlphaGo真正能夠做的事情，就是在19x19個位置上，選擇一個可以落子的位置。也就是說他真正能夠採取的行為，就是從19x19個選擇題中，選擇一個他能夠採取的行為，但是如果你的agent是一個large language model的話，他就有了近乎無限的可能。large language model可以講任何話，可以產生各式各樣近乎無窮無盡的輸出，這就讓你AI agent可以採取的行動，不再有侷限，有更多的可能性。舉例來說，我們等一下就會很快看到的，今天這些AI agent，在有些問題他解不了的時候，他可以憑藉他，可以有各式各樣輸出的能力，來直接呼叫一些工具，來幫忙解決他本來解決，解決不了的問題。"
    },
    {
        "text": "那另外一個AI agent的優勢，另外一個用large language model，運行AI agent的優勢，是過去如果用reinforcement learning的方法來訓練一個AI agent。那意味著什麼，你必須要定義一個東西叫做reward，那如果你今天是要訓練一個AI programmer，那你可能會告訴AI programmer說，如果你今天寫的程式有一個compile的error，那你就得到reward-1，但為什麼是-1？為什麼不是-10？為什麼不是-17.7？這種東西就是沒人說得清楚，所以這個reward在做reinforcement learning的時候，就是一個要調要通靈的東西。那今天如果是用LLM驅動的AI agent呢，你今天就不用幫他訂reward了，今天有compile error，你可以直接把compile error的log給他，他也許根本就讀得懂那個log，他就可以對程式做出正確的修改。而且相較於reward只有一個數值，直接提供error的log，可能提供了agent更豐富的資訊，讓他更容易按照環境給的回饋，環境目前的狀態來修改，修改他的行為。"
    },
    {
        "text": "接下來舉幾個AI agent的例子，那講到AI agent，也許最知名的例子，就是用AI村民所組成的一個虛擬村莊。這個虛擬村莊是在什麼時候成立的呢？2023年，在古代就已經有人做過這個虛擬村莊了，那裡面的NPC通通都是用語言模型來運行的。那這些NPC它是怎麼運行的呢？首先每個NPC都一個人為設定的目標，有的NPC他要辦情人節派對，有的NPC要準備考試，每個人都一個他自己想做的事情。那這些NPC呢，會觀察會看到環境的資訊，那時候Language Model都只能讀文字，所以環境的資訊需要用文字來表示。"
    },
    {
        "text": "所以環境的資訊對一個語言模型來說，看起來可能就是這個語言模型旁邊有一個叫做Eddy的人，他正在讀書，然後呢他看到廚房，然後呢，他看到一個櫃子。然後看到伊莉莎白呢，正在裝做裝飾，正在裝飾房間等等。然後根據這些observation，這個語言模型，要決定一個他想要做的行為，比如說也許不著了，所以就上床睡覺，那需要有一個轉譯器，把它說出來的這個行為，轉成真正能夠執行的指令。那這個agent就真會走到床邊，然後去睡覺，好,所以這個是2023年的時候用AI來這個運行NPC的一個實驗。"
    },
    {
        "text": "其實後來還有更大規模的實驗，有人把Minecraft中的NPC，通通換成AI的NPC，那就把相關的影片連結留在這個投影片上面。那根據這個影片連結的描述，就說這些AI很厲害，他們組織了自己的交易的金融體系，然後還組織了自己的政府，自己制定憲法自己管理自己，是真的還假的啦？這個是這個影片說的，剛才講的那些遊戲，你可能比較不容易接觸到，他對現實世界可能也沒什麼影響，那今天也許你馬上就會接觸到的AI agent，就是讓AI來真正使用電腦。"
    },
    {
        "text": "雖然這個聽起來有點弔詭，AI本身也就是一個電腦，但他現在要來真正的像人類一樣，來使用另外一個比較低端的電腦來做事。那其中比較有代表性的例子，就是cloud的computer use，還有chain GPT的operator。那我們在上次上課的影片中，也已經跟大家講過operator，那operator介面長這樣，那他會建議可以做的事情，比如說可以訂pizza，可以預約下週的居家清潔等等。那像這種使用電腦的AI agent，他的目標就是你的輸入，就是你告訴他我要去訂pizza，你告訴他上網幫我買一個東西，那這就是他的目標。那他的observation呢？他的observation可能是，那個電腦的螢幕畫面，今天很多語言模型都是可以直接看圖的，所以其實可以直接把圖片當作輸入，可以直接把電腦畫面當作輸入，提供給AI agent。那AI agent要決定的就是，他要按鍵盤上哪一個鍵，或者是要按滑鼠的哪一個按鈕。"
    },
    {
        "text": "那其實讓AI使用電腦啊，不是最近才開始有的野望，其實早在2017年，就有篇paper叫words of bits，嘗試過使用AI agent。你看他這個文章的標題，他把自己的文章標題說，他是一個web-based agent，那只是那個時候能夠互動的頁面，還是比較原始的頁面。"
    },
    {
        "text": "你可以看到下面這些AI agent，他真正能夠處理的是比較原始的頁面，那個時候也沒有大型語言模型，所以那時候的方法，就是硬圈一個CNN。直接吃螢幕畫面當作輸入，輸出就是滑鼠要點的位置，或者是鍵盤要按的按鈕，看看用這個方法能不能夠讓AI agent在網路的世界中做事。這個是2017年，這甚至不能說是上古時代，以後有這個BERT以前的時代，就是史前時代，這個不只是史前時代，它史前時代比較早期，所以這是舊時期時代的產物。"
    },
    {
        "text": "好，那後來有了語言模型之後啊，人們就開始嘗試用語言模型，來當作AI agent，來運行一個agent，讓它在網路的世界中活動。"
    },
    {
        "text": "那這一頁投影片，是列舉了幾個比較具代表性的例子。那這一波潮流，大概是在2023年的暑假開始的，像Mine to Web、Web Arana，還有Visual Web Arana，就跟今天的operator非常的像，就是給這個語言模型，看一個螢幕的畫面，或者是看HTML的code，然後他自己決定他要幹什麼，期待他最後可以解決一個問題。"
    },
    {
        "text": "比如說在Mine to Web的第一個例子裡面，就給他這個畫面，然後跟他說，請他幫我們訂一個機票。那還有什麼樣AI agent的應用呢？今天你可以用AI來訓練另外一個AI模型，這就是等一下作業二，助教會跟大家講的事情。那用AI來訓練模型，那其實這個運作的過程就是你的目標就是要過strong baseline，然後你提供給LLM訓練資料，他寫一個程式用這些訓練資料來訓練模型。那他可能可以得到這個模型的正確率，根據正確率再重新寫一個程式，再得到新的正確率，就這樣一直運作下去。"
    },
    {
        "text": "那有很多知名的用AI來訓練模型的framework，比如說AIDE。那你看他的這個技術報告的這個標題，就知道他們想做什麼，他是要做一個machine learning engineer agent，他就是要用multi-agent的framework，來解data science的competition。"
    },
    {
        "text": "那在我們的作業中，你就會體驗到到底AI agent做不做得了，機器學習這門課的作業。"
    },
    {
        "text": "那最近呢，Google說他們做了一個AI，不過他們並沒有真的，釋出模型啦,所以你也不知道說，實際上做得怎麼樣,這個服務並不是公開的，那他們說他們做了一個AI Coscientist就是用AI來做研究。"
    },
    {
        "text": "不過這個AI Coscientist還是蠻有侷限的,他不能真的做實驗啦。他只能夠提Proposal，就是你把一些研究的想法告訴他，他把完整的Proposal規劃出來，實際上做得怎麼樣,不知道啦。那你要看他的Blog裡面有些比較誇張的案例,說什麼本來人類要花十年才能夠得到研究成果，AI agent花兩天就得到了,也不知道真的還假的。他舉的是一些生物學的例子,所以我也無法判斷，他講的是不是真的,那個發現是不是真的很重要。"
    },
    {
        "text": "這個co-scientist的話，就是這個用AI agent來幫研究人員做研究。好,那我們剛才講的AI agent，他的互動方式是侷限在回合制的互動，有一個observation,接下來執行action，但是在更真實的情境下，這個互動是需要及時的。因為外在的環境也許是不斷在改變的，如果你在action還沒有執行完的時候，外在環境就改變了，那應該要怎麼辦呢？有沒有辦法做到更即時的互動呢？更即時的互動可能應該像是這樣子，當模型在決定要執行action one，正在執行的過程中，突然外在環境變了。這個時候模型應該有辦法，立刻轉換行動，改變他的決策，以因應外界突如其來的變化。"
    },
    {
        "text": "你可以想說什麼樣的狀況，我們會需要用到這樣的AI agent，能夠做即時互動的呢？其實語音對話就需要這種互動的模式，文字的對話使用ChatGPT是大家比較熟悉的，你輸入一段文字，他就輸出一段文字，這是一來一往回合制的互動。但是人與人間真正的對話不是這樣子的，當兩個人在對話的時候，他們可能會互相打斷，或者是其中一個人在講話的時候，另外一個人可能會同時提供一些回饋。比如說嗯好你說的都對，那這些回饋可能沒有什麼，特別語意上的含義，他只是想要告訴對方我有在聽，但是像這樣子的回饋，對於流暢的交流來說，也是非常重要的。"
    },
    {
        "text": "如果在講電話的時候對方完全都沒有回應，你會懷疑他到底有沒有在聽？所以我們今天能不能夠讓AI，在跟使用者互動的時候，用語音互動的時候，就跟人與人間的互動一樣，而不是一來一往回合制的互動呢。其實也不是不可能的，今天GPT4O的一個Voice Mode 高級語音模式，也許在某種程度上，就做到了這一種即時的互動。"
    },
    {
        "text": "那這個投影片上是舉一個例子，假設有人跟AI說，你說一個故事，那這個是AI觀察到的第一個observation。有人叫他說一個故事，現在就開始講故事了，他就說從前從前那這時候人說了一個，好，這個可能是第二個observation，但AI要知道說這個observation，不需要改變他的行為，跟他的行為沒有直接的關係，只要故事就繼續講下去。有一個小鎮，然後人說這個不是我要聽的故事，這個我聽到了，那AI可能要馬上知道說，那這個不是人要聽的，那也許我覺得應該停下來，換另外一個故事。那今天AI有沒有辦法做到這種即時的互動呢？那怎麼做這種即時的互動，非回合制的互動，就有點超過我們這門課想要講的範圍。如果你有興趣的話，你可以讀這篇文章，那這篇文章想要做的事情，是評量現在這些語音模型互動的能力。那在這篇文章裡面，也對現有的這個可以做互動的語音模型，做了一個比較完整的survey，是一直survey到今年的1月。所以你可以看這篇文章，知道說現在這些可以互動的模型，他可以做到什麼樣的地步，那這是我們實驗室的林冠廷同學，跟他在這個Berkeley UW和MIT的合作夥伴一起做的文章。"
    },
    {
        "text": "那這邊順便說明一下，以後這門課呢，我們投影片上引用論文的原則。論文的原則就是如果我找得到arXiv的連結的話，那我就把文章直接貼arXiv的連結，什麼是arXiv呢？假設你不是Computer Science背景的話，也許我就要解釋一下什麼是arXiv。arXiv的意思就是，一般呢，做研究你是寫完文章，投稿到一個期刊或者是國際會議，然後被接受以後才發表出來。但是對於AI的領域，因為變化實在太快，幾個月前就已經是古代了，所以期刊那種一審就要一年，或者是國際會議一兩個月，這種步調是沒有辦法，在不適用於AI的領域，所以現在一種習慣的發表方式。就是做出東西以後，直接放到一個公開的網站，叫做arXiv，然後就不審了立刻公開，然後你就可以讓全世界的人，看到你的文章。"
    },
    {
        "text": "那有很多人會覺得引用arXiv的連結不夠正式，但是很多重要的文章，其實現在不見得投稿國際會議。但就只有arXiv的連結，所以我會選擇如果找得到arXiv的連結的話，就直接引用arXiv的連結，其實現在大家都在arXiv上看文章，那國際會議現在比較像是經典回顧這樣子，每篇文章我幾乎都在arXiv上看過了。句子說原來你投到這裡啊！這樣的感覺。"
    },
    {
        "text": "那引用arXiv的連結，還有一個好處就是你可以直接從arXiv的連結看出這篇文章的時間。所以arXiv的連結裡面的數字，前面兩個就是年份，後面兩個就是月份，可以看這個數字就可以知道說這篇文章是在什麼時候被放在arXiv，也就是什麼時候被發表的，可以讓你對於每一個研究，他誕生的時間更有感覺。"
    },
    {
        "text": "好那接下來呢，我們會分三個面向來剖析今天這些AI agent的關鍵能力。那第一個面向是我們要來看這些AI agent，這個AI agent能不能夠根據他的經驗，過去的互動中所獲得的經驗來調整他的行為。第二部分是要講這些AI agent如何呼叫外部的援助，如何使用工具。第三部分要講AI agent能不能夠執行計畫，能不能做計畫。那我們來講一下，AI怎麼根據過去的經驗，或者是環境的回饋來調整他的行為。"
    },
    {
        "text": "那AI呢，AI agent需要能夠根據經驗來調整行為，比如說有一個作為AI programmer的AI agent，他一開始接到一個任務，那他寫了一個程式，那這個程式compile以後有錯誤訊息，compile以後有error，那應該要怎麼辦呢？他應該要能夠根據這個error的message，來修正他之後寫的程式。"
    },
    {
        "text": "那在過去啊，講到說你收到一個feedback接下來要做什麼的時候，也許多數機器學習的課程，都是告訴你來調整參數，根據這些收集到的訓練資料，也許使用reinforcement learning的algorithm來調整參數。"
    },
    {
        "text": "但不要忘了我們剛才就強調過，在這一堂課裡面沒有任何模型被訓練，所以我們今天不走這個路線。那不更新模型的參數，模型要怎麼改變它的行為呢？依照今天 Large Language Model 的能力，要改變它的行為，你也不用微調參數，直接把錯誤的訊息給他，他接下來寫的程式就會不一樣了，就結束了。那可能會問說，那之前他寫的程式是錯的，為什麼給錯誤訊息，他寫的程式就對了呢？明明就是同一個模型，但你想想看模型做的事情就是文字接龍，你給他不同的輸入，他接出來的東西就不一樣，一開始會寫錯的程式，是因為他前面要接的部分只有這麼多，所以寫個錯的程式。"
    },
    {
        "text": "當今天要接的內容，包含了錯誤的訊息的時候，他接出來的結果可能就會是正確的了。那今天已經有太多的證據，說明這些語言模型，可以根據你給他的回饋，改變他的行為，不需要調整參數，那如果你有使用這些語言模型的經驗，你也不會懷疑他們有根據你的回饋調整行為的能力。"
    },
    {
        "text": "那這邊真正的議題是，如果我們是把過去所有的經驗都存起來，要改變語言模型的行為，要讓他根據過去的經驗調整行為。就是把過去所有發生的事情一股腦給他，那就好像是語言模型每次做一次決策的時候，他都要回憶他一生的經歷，也許在第100步的時候還行，到第1萬步的時候，過去的經驗太長了，他的人生的資訊已經太多了，也許他沒有足夠的算力，來回顧一生的資訊，他就沒有辦法得到正確的答案。"
    },
    {
        "text": "這讓我想到什麼呢，這讓我想到有一些人有超長自傳式記憶，他可以把他一生中，所有發生的事情記下來，然後那些人你可以隨便問他一個，某個人的電話號碼，他都會背出來，你告訴他某年某日某時發生了什麼事，他也都可以講出來。"
    },
    {
        "text": "有一些人他的頭腦就像是一個影印機一樣，會把所有他看過的事情都原封不動的記憶下來，但這種超長自傳式記憶啊，又被叫做超憶症。你看到症這個字就知道說，人們覺得這是一種疾病，這聽起來記憶力很好是一種祝福，但實際上對這些患者而言，據說這種患者世界上可能不到100例。那這是一個2006年的時候，才被論文發表的一個症狀，那據說這些患者其實日常生活並沒有辦法過得很開心。因為他們不斷的在回憶他的人生，往往一不小心就陷入了一個冗長的回憶之中，那也很難做抽象的思考，因為他的人生已經被他的記憶已經被太多，知為末節的所事所佔據，所以沒有辦法做抽象式的思考。"
    },
    {
        "text": "所以讓一個AI agent記住他一生所有經歷的事情，告訴他你每次做一個決策的時候，都是根據你一生所有經歷過的事情再去做決策，那也許對AI agent來說並不是一件好事。最終當他的人生過長的時候，他會沒有辦法做出正確的決策，所以怎麼辦呢？也許我們可以給這些AI agent memory，這就像是人類的長期記憶一樣，發生過的事情我們把它存到這個memory裡面。"
    },
    {
        "text": "當AI agent看到，第一萬個observation的時候，他不是根據所有存在memory裡面的內容，去決定接下來要採取什麼action。而是有一個叫做read的模組，這個read的模組會從memory裡面，選擇跟現在要解決的問題有關係的經驗，把這些有關係的經驗放在observation的前面。讓模型根據這些有關係的經驗跟observation，再做文字接龍，接出它應該進行的行為，那你有這個read的模組就可以從memory裡面，從長期記憶中篩選出重要的訊息，讓模型只根據這些跟現在情境相關的訊息來進行決策。"
    },
    {
        "text": "那怎麼樣打造這個read的模組呢？其實你可以想這個read的模組，就想成是一個retrieval的system，想成是一個檢索的系統，那第一萬步看到的observation其實就是問題，那模型的AI agent的memory長期記憶，其實就是資料庫。那你就把拿這個檢索系統，根據這個問題從這個資料庫裡面，檢索出相關的資訊，那這整個技術跟RAG沒有什麼不同，其實它就是RAG，你可以直接把RAG的任何方法，直接套用到這個地方。"
    },
    {
        "text": "唯一不一樣的地方只是，如果是RAG的話，存在memory裡面的東西等於是整個網路，那是別人的經驗。而對AI agent而言，現在存在memory裡面的東西，是他自己個人的經歷，差別的是經歷的來源，但是用來搜尋的技術，是可以完全直接線套RAG的技術。"
    },
    {
        "text": "呃,如果你今天想要研究這個AI agent按照經驗來修改他的行為,那你可以考慮一個叫做streambench的benchmark,那在streambench裡面呢,會有一系列的問題,然後呢,AI會依序去解這些問題,他先解第一個問題,得到第一個問題的答案,然後接下來他會得到第一個問題答案的反饋,那在這個streambench目前的，因為所有的問題都是有標準答案的,所以AI agent得到的回饋是binary的,就是對或者是錯。好,那根據他過去的經驗,他就可以修正他的行為，期待他在第二個問題的時候,可以得到更準確的答案，得到更高的正確率,然後這個過程就一直持續下去。那假設有1000個問題的話,那就等AI agent回答完最後問題的時候，這個互動就結束了，那最後結算一個，根據經驗學習能力的好壞，根據經驗調整行為能力的好壞，那就看這一整個回答的過程中平均的正確率，越能夠根據經驗學習的agent，他應該能夠用越少的時間，看過越少的回饋，就越快能夠增強他的能力，就可以得到比較高的平均的正確率。"
    },
    {
        "text": "那這個benchmark呢，是API的研究人員打造的一個benchmark。那在這個benchmark裡面的baseline，就是有使用到我剛才講的類似RAG的技術，也就是說當模型在回答第100個問題的時候，他並不是把前面第一個到第99個問題，通通丟給他去做文字接龍，這樣這個sequence太長了，一般的語言模型根本讀不了這麼長的輸入。"
    },
    {
        "text": "所以實際上的做法，就是你需要有一個檢索的模組。這個檢索的模組，只從過去所有的經驗中，檢索出跟現在要回答的問題有關係的經驗，然後語言模型只根據這些有關係的經驗還有現在的問題，來進行回答，來產生他的行動，來產生他的答案。那這一招有沒有用呢？這一招其實非常的有用。"
    },
    {
        "text": "那在這一頁圖裡面橫軸啊，他這邊的用詞是time step，但其實指的就是一個一個的問題，總共有1750幾個問題。那縱軸指的是平均的正確率，那在這個圖上面呢，最低的這條灰色線指的是說，假設沒有讓模型做任何學習，他回答每一個問題都是independent的，回答問題間沒有任何的關聯，他完全沒有調整他的行為，那你得到的正確率是灰色的這條線是最低的。那黃色這條線是說，只固定隨機選五個問題，那每次模型回答問題的時候，都是固定看那五個問題來回答，都是固定把五個問題當作經驗來回答，那也可以得到的是黃色這一條線。"
    },
    {
        "text": "那如果你是用RAG的方法，從一個memory裡面去挑選出最有關係的問題，跟現在要解決的問題最有關係的經驗，那你可以得到的是粉紅色的這一條線。那可以看到比黃色的線，那正確率還要高上不少，那最後結果最好的是紅色這一條線啦。那這個怎麼做的，那大家就自己再去詳細閱讀論文，那在streambench裡面呢。"
    },
    {
        "text": "還發現一個有趣的現象是值得跟大家分享，這個現象是負面的回饋。基本上沒有幫助對現階段的語言模型而言，所以你要提供給語言模型經驗，讓他能夠調整他行為的時候，給他正面的例子，比給他負面的例子要好。也就是說具體而言，提供給他過去哪些類似的問題得到正確答案，比提供給他過去哪些問題得到錯誤的答案，還更有效，還更能引導模型得到正確的答案。"
    },
    {
        "text": "那這邊是真正的實驗結果，做在好幾個不同的data set上面，streambench裡面本來就包含了好幾個不同的data set。那這個縱軸呢，0代表完全沒有做，完全沒有根據經驗調整行為，然後藍色代表說，不管是正面還是負面的例子都用，如果不管正面還是負面的例子都用。在多數情況下，模型都可以表現得比較好，當然有一些例外，但是如果只用負面的例子呢？如果只用負面的例子，基本上是沒有幫助，而且甚至是有害的。"
    },
    {
        "text": "那如果說只用正面的例子，在所有的情況下，模型可以得到更好的結果，那這也符合過去的一些研究。有人研究過使用語言模型要怎麼樣比較有效，有一個發現就是與其告訴語言模型不要做什麼，不如告訴他要做什麼，如果你還希望他文章寫短一點，你要直接跟他說寫短一點，不要告訴他不要寫太長。比較他不要寫太長，他不一定聽得懂，叫他寫短一點，比較直接他反而比較聽得懂。"
    },
    {
        "text": "這也符合這邊這個Streambench的發現，就是負面的例子比較他沒有效，與其給語言模型告訴他什麼做錯，不如告訴他怎麼做是對的。"
    },
    {
        "text": "好 那我們剛才講到了，有一個read的模組，那有關記憶的部分呢，是不是要把所有所有的資訊，通通存到memory裡面呢？存到長期的記憶庫裡面呢？如果我們把這些agent，經歷的所有的事情，都放到長期的記憶庫裡面的話，那裡面可能會充斥了一堆雞毛算皮不重要的小事，最終你的memory長期記憶庫可能也會被塞爆。"
    },
    {
        "text": "如果說你是做那種AI村民啊，AI村民他多數時候觀察到的資訊都是些無關緊要的小事，那如果你看他觀察到那個log，多數都是啥事也沒有。就那邊有一張桌子啥事也沒有，那邊有一張椅子啥事也沒有，多數時候都是啥事也沒有，所以如果把所有觀察到的東西，都記下來的話，那你的memory裡面就都只是被一些雞毛算皮的小事佔據。所以怎麼辦呢？也許應該有更有效的方式，來決定什麼樣的資訊，應該被記下來，應該只要記重要的資訊就好。"
    },
    {
        "text": "那怎麼讓語言模型只記重要的資訊就好呢？你可以有一個write的module，那write的module決定，什麼樣的資訊要被填到長期的記憶庫裡面，什麼樣的資訊乾脆直接就讓他隨風而去就好了。"
    },
    {
        "text": "那怎麼樣打造這個write的記憶庫呢？有一個很簡單的方法就是，write的模組也是一個語言模型，甚至就是AI agent自己。這個AI agent他要做的事情，就是根據他現在觀察到的東西，然後問自問一個問題，這件事有重要到應該被記下來嗎？如果有就把它記下來，如果沒有就讓他隨風而去。"
    },
    {
        "text": "那除了RE跟Write這兩個模組以外，還有第三個模組。沒有固定的名字啦，在文件上的名字，沒有固定的名字，我們可以暫時叫他reflection反思的模組。"
    },
    {
        "text": "那這個模組的工作是，對記憶中的資訊做更好的，更high level的，可能是抽象的重新整理，你可以把這些記憶裡面的內容，在經過reflection的模組，重新反思之後得到新的想法。那也許read的模組可以根據這些新的想法，來進行搜尋，這樣子也許可以得到更好的經驗，那幫助模型做出更好的決策。"
    },
    {
        "text": "而這個reflection的模組，可能也是一個語言模型，就是AI agent自己，你可以只是把過去的這一些記憶，丟給reflection的模組，然後叫reflection模組想一想，看他從這些記憶裡面，能不能夠有什麼樣新的發現。比如說可能有一個observation是，我喜歡的疫情每天都跟我搭同一部公車，另外observation是他今天對我笑了，那你推出來的reflection模型，結果就說他喜歡我這樣，一個錯覺，人生三大錯覺之一就是這一種。就得到一些新的sort，你就得到一些新的想法，那你之後在做決策的時候，就可以用這些新的想法，雖然你沒有實際觀察到，但它是被推論出來的，根據這些推論出來的想法來做決策。那除了產生新的想法之外，也可以為以前觀察到的經驗，建立經驗和經驗之間的關係，也就是建立一個，然後讓reader的module根據這個knowledge graph來找相關的資訊。"
    },
    {
        "text": "那我知道在RAG的領域使用knowledge graph，現在也是一個非常常見的手法，那最知名的可能就是graph RAG系列這個研究。就把你的資料庫，把它變成一個knowledge graph，那今天在搜尋跟回答問題的時候，是根據knowledge graph來搜尋回答問題，可以讓RAG這件事做得更有效率。"
    },
    {
        "text": "或是另外一個非常類似的例子，那HIPO RAG，這個HIPO不是指真正的河馬。他指的應該是那個海馬迴，那個人腦中的一個結構，然後他覺得做建這種knowledge graph，就跟海馬迴的運作呢，非常的類似，所以他叫做HIPO RAG。"
    },
    {
        "text": "有一些跟graph有關的RAG的方法，那你完全可以透過reflection的模組，把經驗建成一個graph以後，把那一些graph RAG的手法，直接套到AI agent裡面。那大家可能都知道說這個ChatGPT啊，現在其實真的是有記憶的，所以可以感受到這個OpenAI，想把ChatGPT變成一個AI agent的決心。"
    },
    {
        "text": "比如說我跟ChatGPT說，我週五下午要上機器學習這門課，那他就給我一個回答，說要我幫助你做什麼事情嗎？接下來我告訴他記下來，你跟他講記下來之後，他的這個write的模組就啟動了。他知道這件事情是要被記下來的，他就會說那我記下來了，以後你週五要上機器學習這門課。那write的模組什麼時候要啟動，是他自己決定的，所以很多時候你希望他記下來的時候，他就是不啟動，或你不希望他啟動的時候，他就是啟動。那個是模型自己決定的，但是有一個方法可以，基本上一定能讓他啟動，就明確的跟他講，把這件事記下來，基本上都幾乎確定能夠啟動那個write的模組，讓write的模組把這件事情記下來。"
    },
    {
        "text": "那接下來的東西在哪裡呢？你可以看在設定裡面，有一個個人化，然後有一個叫記憶的部分，那你點這個管理記憶，就可以看到確記憶。他透過write的模組，寫在他的memory裡面，這個就是他作為一個AI agent的長期記憶，裡面的東西，比如第一條是你叫做血輪眼卡卡，有一次不小心跟他說你是卡卡，不知道為什麼他就覺得自己是血輪眼卡卡。"
    },
    {
        "text": "然後呢，他也記得就我剛才跟他講的，週五下午要上機器學習這門課。但是呢，但是其實模型的記憶也是會出錯的。因為要寫什麼樣的東西到記憶裡面，是模型自己決定的，而且他並不是把對話的內容，就一五一十的直接放到記憶裡面，他是經過一些昇華反思之後才放進去的，所以他的反思可能會出錯。"
    },
    {
        "text": "比如說他覺得我是一個臺灣大學的學生，雖然我是老師。但是他從過去的對話誤以為我是一個學生，所以就存了一個錯誤的資訊。在他的記憶裡面，一堆他想記的東西，比如說我給過什麼演講，給過什麼tutorial，他都把它記下來就是了。"
    },
    {
        "text": "那這些有記憶的確GPT，他可以使用他的記憶，比如說我跟他說禮拜五下午是去玩好嗎？這個時候記憶模組就被啟動了，但是他是怎麼被啟動的，其實就不太清楚了。他到底是把所有記憶的內容，通通都放到這個問題的前面，直接讓模型做回答，還是說也有做RAG，只選擇下載相關的記憶內容呢？那這個我們就不得而知了。"
    },
    {
        "text": "總之當我問他，週五下午出去玩好嗎？這個read的模組就啟動了。他就說，下午不是要上課嗎？怎麼能夠出去玩，好聰明啊！他知道下午要上課，挺厲害的，然後問他你是誰，剛才我說過，他是血輪眼卡卡，所以他就覺得，之前是血淪眼卡卡。如果你想要知道，更多有關AI Agent記憶的研究的話，那這邊就是放了幾篇經典的論文給大家參考，包括Memory GPT，這是23年的論文，Agent Workflow Memory是24年的論文，還有一個最近的Agent Memory，Agent是25年的論文，所以23到25年各引用一篇，告訴你說這方面的研究是持續不斷的。"
    },
    {
        "text": "接下來呢，我們要跟大家講，現在這些語言模型怎麼使用工具。那什麼叫做工具呢？但語言模型本身對我們人類來說也是工具。"
    },
    {
        "text": "那對語言模型來說，什麼東西又是他的工具呢？所謂的工具就是這個東西啊，你只要知道怎麼使用他就好，他內部在想什麼，他內部怎麼運作的，你完全不用管。這就是為什麼肥宅如果一直幫另外一個人修電腦的話，就會被叫做工具人，因為別人沒有人在意肥宅的心思，只知道他能不能夠修電腦而已，所以這個就是工具的意思。"
    },
    {
        "text": "那有哪些語言模型常用的工具呢？最常用的就是，就是搜尋引擎,然後呢,語言模型現在會寫程式,而且可以執行他自己寫的程式,那這些程式也算是某種工具,甚至另外一個AI也可以當作是某一個AI的工具,有不同的AI,有不同的能力,比如說現在的語言模型,如果他只能夠讀文字的話,那也許可以呼叫其他看得懂圖片,聽得懂聲音的AI,來幫他處理多模態的問題,或者是說,或者是不同模型它的能力本來就不一樣。也許平常是小的模型在跟人互動，但小的模型發現它自己解不了的問題的時候，它可以叫一個大哥出來。大哥是個大的模型，那大的模型運作起來就比較耗費算力，所以大的模型不能常常出現。大的模型要在小的模型召喚它的時候，才出面回答問題，大哥要偶爾才出來幫小弟解決事情。"
    },
    {
        "text": "那其實這些工具對語言模型來說，都是function都是一個函式，當我們說語言模型在使用某一個工具的時候，其實意思就是它在調用這些函式。它不需要知道這些函式內部是怎麼運作的，它只需要知道這些函式怎麼給它輸入，這些函式會給什麼樣的輸出，那因為使用工具就是調用函式，所以使用工具又叫做function code，所以有一陣子很多語言模型都說，他們加上了function code的功能，其實意思就這些語言模型都有了使用工具的功能。"
    },
    {
        "text": "好那語言模型怎麼使用工具呢？等一下我會講一個通用的使用工具的方法，但實際上使用工具的方法很多，甚至有一些模型是專門針對來練習，他就訓練來使用工具的，那他如果是針對使用工具這件事做訓練，那他在使用工具的時候，你可能需要用特定的格式才能夠驅動他。那那個就不是我們今天討論的問題，或者是假設你有使用，使用這個OpenAIChat GPT的API的話，你會知道使用工具這件事情，是要放在一個特殊的欄位，所以對OpenAI來說，它的模型在使用工具的時候，也有一些特殊的用法。"
    },
    {
        "text": "但我這邊講的是一個最通用的用法，對所有的模型，今天能力比較強的模型，應該都可以使用。好,什麼樣通用的方法，可以讓模型使用工具呢？就是直接跟他講啊！就告訴他怎麼使用工具，你就交代他可以使用工具，那你就把使用工具的指令，放在兩個Tool符號的中間，使用完工具後你會得到輸出，輸出放在兩個Output符號的中間。所以他就知道工具使用的方式了。接下來告訴他有哪一些可以用的工具，有一個函式叫做Temperature，他可以查某個地點某個時間的溫度，他的輸入就是地點跟時間，給他的使用範例，Temperature括號臺北某一段時間，他就會告訴你臺北在這個時間的氣溫。接下來你就把你的問題，連同前面這些工具使用的方式，當作Prompt一起輸入給語言模型，然後他如果需要用工具的話，他就會給你一個使用工具的指令。那前面這些教模型怎麼使用工具的這些敘述，他叫做System Prompt，那查詢使用調用這些工具的這些，這段話,某年某月某日高雄氣溫如何,這個是User Prompt,那如果你有在使用這個ChatGPT的API的話,你知道你的輸入要分成System Prompt跟User Prompt,那很多同學會搞不清楚System Prompt跟User Prompt有什麼樣的差別,那System Prompt指的是說,你在開發應用的這個Developer下的這個Prompt,這個Prompt呢,是每次都是一樣的,每次你都想要放在語言模型最前面,讓他去做文字接龍的這個敘述叫做System Prompt。"
    },
    {
        "text": "有很多同學問我對於GPT-4o有什麼看法，所以我今天來講一下GPT-4o背後可能的語音技術。"
    },
    {
        "text": "這個影片的目標聽眾是，語音技術背景的聽眾。如果你已經是語音領域的專家的話，這部影片講的內容對你來說，可能就太科普了。先說明一下我假設聽這個影片的同學，是有修過生成式人工智慧導論的。如果你還沒有看過這堂課的影片的話，你可以在這個連結找到這堂課的影片。那如果你看過這堂課的影片的話，可以讓你更瞭解，我現在這部影片裡面，所要講的內容。"
    },
    {
        "text": "那GPT-4o其中一項，特別令人，矚目的技術，就是語音互動的功能，Google，也釋出了Project ASTRA的結果，那在Project ASTRA裡面，也打造了語音互動的技術，那這個代表說現在語音互動的技術，是各個大廠都非常重視的一塊，那GPT-4O的語音模式Voice Mode，有什麼樣特別的地方呢，第一個是它有很豐富的語音風格，講到這個語音合成，大家往往想到的就是Google小姐，那Google小姐就是一種語調，但是GPT-4o你可以用文字的指令，要求他用不同的語調來說話，比如說叫他講快一點，叫他輕聲細語，或甚至叫他用唱的，把他想要講的事情表達出來，另外GPT-4o好像可以理解，語音內容以外的資訊，用比較白話的講法就是，他能夠察言觀色，舉例來說,他可能可以聽得到一個人的喘氣聲,知道一個人氣喘如牛，那他可以發出非語音性的聲音,例如笑聲，那如果你有看GPT-4o的Demo的話，你會發現這是一個非常愛笑的模型，他動不動就會笑。"
    },
    {
        "text": "另外GPT-4o有自然而即時的互動，在其中的Demo裡面有一個人說，我們來做一個有趣的嘗試，話還沒有說完，GPT-4o居然說了一聲哇，然後那個人再說我要你去做某一件事情，如果還沒有看過OpenAI的Demo，你可以先看一下OpenAI的Demo，再來繼續這部影片。"
    },
    {
        "text": "那首先我想要澄清一個，很多人對GPT-4o語音模式的誤解，那我這部影片呢，是在5月19號的晚上錄製的，其實到5月19號的晚上為止，多數人應該都是沒有GPT-4o的語音模式的，很多人會想說，我有啊，我可以用語音跟我的ChatGPT互動，那個語音互動，是ChetGPT手機版本來就有的語音介面，ChetGPT他的手機版本來就可以用語音互動，他的互動方式是說，這個是你的ChetGPT的頁面，那GPT 4.0已經釋出了，你可以在右下角點這個語音的這個鈕，然後你就會看到一個這樣子的畫面，那你確實可以透過這個介面，跟ChetGPT用語音溝通，但是如果你有實際嘗試的話，你會發現這一個語音的介面，並沒有你在GPT-4O語音模式的演示裡面，看到的種種神奇功能，比如說用不同的語氣講話，比如說你可以打斷他說話等等，那事實上呢，事實上大家可能都有收到一則OpenAI給的訊息，就是其實VoiceMode還沒有真的釋出，它只是coming soon，它就會在接下來的數週慢慢的被釋出來，所以大家所使用的手機版的語音介面，其實可能還不是GPT-4O的語音模式。"
    },
    {
        "text": "那舊版的語音介面是怎麼做的呢，舊版的語音介面是先把語音訊號透過語音辨識變成文字，再把文字丟給語言模型，比如說 ChatGPT，然後語言模型會給一個回應，這個回應透過語音合成產生語音訊號，那其實如果語音辨識跟語音合成跑得夠快的話，其實這個介面也可以達到蠻自然即時的互動功能的，但是跟這個OpenAI GPT-4語音模式的demo比起來，還是有一段差距，比如說呢，這個如果是透過語音辨識把聲音訊號轉成文字，那語言模型可能會不知道語者的情緒，語音合成如果只是把語言模型的輸出轉成聲音訊號，那語音合成就只有某一種說話的風格而已，那我在看這個GPT-4-O的語音介面的Demo的時候，我其實在想它會不會只是把原來的系統，加上了一些額外的模組，比如說在語音辨識之外，我們可以加一些語音事件偵測或情緒辨認的模組，所以我們也有機會透過情緒辨認的模組，也有機會把聲音訊號的情緒把它偵測出來，那你可以把偵測出的情緒放在語音辨識的結果後面，再去丟給語言模型，那這樣語言模型也有機會知道這句話的情緒。"
    },
    {
        "text": "那我這邊引用一些論文，這些論文是說你可以加一些額外的模組，來幫助語言模型瞭解現在輸入語音的情緒，那另外你也可以讓語言模型除了文字之外，多輸出一些符號，比如說語言模型在他的輸出的文具後面加一個括號笑，再丟給語音合成系統，搞不好語音合成系統就可以產生笑聲，你可能會問說這個語音合成系統可以看到這個括號笑就產生笑聲嗎?，有一些語音合成系統是真的可以的，比如說Zuno AI所開發的Bark，你在你的文具裡面打一個笑，這個語音合成模型，這個語音合成的結果是真的可以產生笑聲的，另外一方面,ChatGPT可能也可以產生一段指令，告訴語音合成系統說，現在應該要用什麼樣的語氣來進行合成，語音合成系統可以看得懂這些文字的指令嗎?，其實很多語音合成系統是可以看得懂文字指令的，舉例來說,一個具代表性的例子，就是Meta開發的AudioBox，所以用很多現有的技術串接起來，其實也不是沒有可能打造GPT-4O的語音介面，只是說把很多系統串接起來，那可能即時性不是非常的好，需要透過大量工程的手段，來加快模型運作的速度，來達到真正即時的回應。"
    },
    {
        "text": "不過GPT-4O的Blog已經告訴我們，它的語音模式是一個end-to-end的模型，也就是他只有用一個模型來處理所有的事情，也就是說他用的不是像上一個投影片一樣，一個非常複雜的架構，而是只有一個單一的模型，這個單一的模型聽語音訊號作為輸入，然後產生對應的輸出，那這個模型其實是一個多模態的模型，也就是他是可以看圖片看影像的，但以下的討論,我們只集中在聲音的部分。"
    },
    {
        "text": "這邊先說一個免責聲明，本影片主要的目的是討論技術，那沒有要對任何群體或個人造成傷害的意圖，那我目前還沒有GPT 4.0的Voice Mode，所以我對GPT 4.0的理解，是完全來自OpenAI的展示，那至於實際上真的Voice Mode釋出以後，有沒有展示那麼厲害，我們就拭目以待。"
    },
    {
        "text": "那OpenAI到目前為止都沒有發表跟GPT-4O相關的論文或者是技術報告，以下的內容完全是根據我知道的技術進行臆測，所以以下我對於GPT-4O背後技術的猜想是完全沒有根據的，只是並沒有任何的論文可以佐證我的猜測。"
    },
    {
        "text": "那我只是想要跟大家討論一下根據今天語音技術的發展，有什麼樣可能的技術可以達GPT-4O這樣的效果，如果日後發現實際的技術跟我的臆測有差異，還請大家見諒。"
    },
    {
        "text": "好,那在開始講這個，End-to-End的語音模型之前，我們先來複習一下，這個文字的語言模型，是怎麼被訓練出來的，那我們知道文字的語言模型，它的訓練呢，有三個步驟，第一個步驟是Pretrain，用大量沒有標註的資料進行訓練，然後接下來做Finetune，用少量有標註的資料微調，然後做RLHF，用使用者回饋的資料進行微調，那Finetune跟RLHF合起來又叫做Alignment，那如果你對於這三個步驟還不熟悉的話，你可以看一下過去我上課的錄影，你也可以看一下我最近釋出的影片，講這個生成式人工智慧的生成策略，瞭解生成式人工智慧的基本原理，再進行以下的課程。"
    },
    {
        "text": "好那語音版的語言模型，它可能的運作原理是什麼樣子的呢，我們知道語言模型就是做文字接龍，給他一個未完成的句子，他猜接下來應該輸出哪一個文字的token，語音版的語言模型可以聽一句話給你一個回應，他背後運作的邏輯可能也非常的類似，他做的事情可能就是聽一段聲音，然後去猜接下來應該產生什麼樣的聲音，也就是他做的事情是聲音接龍。"
    },
    {
        "text": "雖然從表面上看起來語言模型跟語音版的語言模型，他們的運作可能非常的類似，但是語音版的語言模型有它獨特的挑戰，第一個挑戰就是這個語音相較於文字，它更為複雜，那對一段聲音訊號而言如果它的Sampling Rate是16kHz的話，意思就是一秒鐘的聲音訊號裡面，由16000個取樣點所構成，也就是一秒鐘的聲音訊號，是由一萬六千個數值所構成的，那所以聲音訊號非常的複雜，如果我們今天在做這個聲音接龍的時候，是讓聲音訊號一個一個取樣點跑出來，那你要產生一秒鐘的聲音訊號，那你就要跑一萬六千次的聲音訊號接龍，這顯然會非常的花時間。"
    },
    {
        "text": "所以現在在做這種語音的接龍呢，通常不是直接在語音的訊號上面做接龍，比較常見的做法是，先把聲音的訊號呢進行壓縮，你會有一個編碼器，它的英文呢是encoder，那這個編碼器裡面呢，可能會有一個codebook，這個codebook裡面是一大堆的code，所謂的code每一個code代表某種類型的聲音，可能某一個code代表人類發的/b/這個聲音，那有個code代表人類的笑聲，有的code甚至代表不是人類的聲音，比如說狗叫聲等等，所以一段聲音訊號輸入給編碼器，編碼器會用它裡面的codebook，來表示這一段聲音訊號，所以一段聲音訊號會被表示成一個code sequence，會表示成一個code的序列，那這些code又被叫做speech unit，他們是可以看作是聲音的單位。"
    },
    {
        "text": "那你還會訓練一個decoder，訓練一個解碼器，這個解碼器可以讀這些speech的unit，把這些speech的unit轉回聲音訊號。"
    },
    {
        "text": "一般這些編碼器跟解碼器也是類神經網路，也是需要透過訓練資料來進行訓練的，如果你想要知道更多有關這種，把聲音訊號變成 Speech Unit，再把 Speech Unit 解回來相關的技術的話，可以閱讀一下這兩篇文章。"
    },
    {
        "text": "那語音版的語言模型呢，是運作在這一些Speech Unit上面的，也就是說當一段聲音訊號進來的時候，語音版的語言模型並不是直接對這段聲音訊號去做語音接龍，這些聲音訊號會先通過Encoder，變成一串Unit，然後呢這些Unit會變成語音版語言模型的輸入，語音版語言模型要做的事情，是預測下一個Unit會是什麼，然後下一個Unit會再通過Decoder產生聲音訊號，所以語音版語言模型沒有必要產生複雜的聲音訊號，它只需要產生Unit，然後由Decoder把Unit轉回複雜的聲音訊號。"
    },
    {
        "text": "所以語音版的語言模型是運作在Speech Unit，這種壓縮過的東西上面，針對語音訊號壓縮過的這些東西上面。"
    },
    {
        "text": "那有很多具代表性的語音版的語言模型，比如說Meta的GSLM還有Google的Audio LN，那這其實不是非常新的技術，GSLM是在21年的年初的時候就已經有的。"
    },
    {
        "text": "我們可以把解碼器看成是一種特殊的語音合成，只是它的輸入不是文字而是speech的unit，它不是把文字變成語音，而是把speech的unit變成語音。"
    },
    {
        "text": "那你可能會想說，那為什麼我們不直接套用語音辨識跟語音合成，當作編碼器跟解碼器呢，其實我們確實可以把語音辨識，想成是一種非常特別的壓縮方式，當我們把聲音訊號變成文字的時候，其實也是在做某種壓縮，文字本來就可以看作是語音的濃縮版。"
    },
    {
        "text": "但是這邊的問題是，文字只代表了語音裡面某個面向的資訊，文字只代表了語音裡面內容的資訊，假設今天輸的聲音訊號是有一個人說好好笑，接下來哈哈哈哈了幾聲，語音辨識系統可能只能夠把，代表文字的好好笑辨識出來，那笑聲就不見了，接下來你用語音合成把好好笑還原回聲音的時候，其實笑聲的資訊就丟掉了。"
    },
    {
        "text": "那用Speech Unit的好處是，它可能可以保留文字，所無法表達的資訊，但是另外一方面，用這種Speech Unit也有一個壞處，就是Speech Unit裡面，可能很多Unit它本來就是對應到，某個文字的token，那你等於是要這個編碼器呢，去重造輪子，本來就已經有文字，可以表示語音裡面的某些訊號，編碼器需要再用另外新的符號，來表示這些，我們本來就有文字符號，可以描述的語音資訊，那這樣感覺是重造了輪子。"
    },
    {
        "text": "所以另外一個可能的做法是把編碼器，跟語音辨識結合，那我這邊把它叫做混合編碼器，把解碼器跟語音合成結合，這邊叫做混合的解碼器，也就是對一段聲音訊號而言，能夠做語音辨識的部分，能夠辨識成文字的部分，把它用文字來表示，那無法用文字來表示的部分，就用 Speech Unit 來表示，所以一段聲音訊號好好笑，後面接哈哈哈哈，那好好笑的部分，可能可以用文字來表示，那笑聲的部分就拿一個特殊的符號來表示，那混合解碼器可以看文字跟特殊的符號，把它轉回聲音訊號，我不知道GPT-4O會不會採取這樣混合的策略啦，也許GPT-4O也是使用編碼器而已，並沒有用語音辨識，那我只是覺得用混合的編碼器有它額外的好處，那這個部分我們等一下會再提到。"
    },
    {
        "text": "那另外呢,我們這邊還需要一個，語者自動分段標記的技術，那這樣的技術呢,叫做Speaker Dialerization，如果你看GPT-4-O的Demo的話，當有兩個以上的人跟他說話的時候，其實他是知道的,他可以知道誰是誰，所以他應該需要用到Speaker Dialerization的技術。"
    },
    {
        "text": "語者自動分段標記的系統就給他一段聲音訊號，他可以知道哪些段落是某一個同一個語者講的，他可以知道說這一段跟這一段都是語者A講的，這一段是語者B講的。"
    },
    {
        "text": "所以我猜測一段聲音訊號，對於一個語音版的語言模型來說，他的表達方式應該是這個樣子的，就可能同時使用了混合的編碼器，跟語者自動分段的標記。"
    },
    {
        "text": "那有一段聲音訊號進來會標出說哪一個段落是語者A說的，他可能會用A冒號一個特殊的符號來代表這是A說的話，然後可以用文字表示的地方可能用文字表示，那不能用文字表示的地方可能就拿特殊的符號用SpeechUnit來表示，這個是對於語音版的語言模型看到一段聲音訊號的時候，它實際上輸入的猜想。"
    },
    {
        "text": "那接下來怎麼訓練這種語音版的語言模型呢?，我們已經知道，這個語言模型，是用大量文字資料所訓練出來的，語音版的語言模型用同樣的道理，也可以用大量聲音的資料，來進行訓練，我們完全可以用大量的聲音資料，來訓練一個語音版的，語言模型，來做speech unit的接龍。"
    },
    {
        "text": "那哪裡去找大量的聲音資料呢?，那這個想起來非常的直覺，網路上有這麼多的影音平臺，從這些影音平臺上就可以收集到大量的聲音資料，那OpenAI顯然有在做這件事情，因為在四月的時候紐約時報才說了，OpenAI用了超過一百萬小時的YouTube影片，來訓練他們的語言模型。"
    },
    {
        "text": "那時候我剛看這個報導的時候就很困惑，為什麼要用YouTube的影片來訓練語言模型呢，難道現在文字的資料已經全部都用完了，真的沒有文字的資料可以用了嗎，但是如果OpenAI是在訓練語音版的語言模型，那用YouTube影片完全就說得通了。"
    },
    {
        "text": "那你可能會想說，可是網路上的影片五花八門，又不是全部都是乾淨的語音，那些語音很多背後有是有音效有背景音樂的，那我們拿這些聲音訊號來訓練我們的語音版語言模型，這個語音版語言模型會不會把音效背景音樂通通都學進去了呢，非常有可能，我們來仔細聽一下，在GPT 4.0 Demo裡面，GPT 4.0的聲音，大家仔細聽一下GPT 4.0的聲音喔，有沒有發現,GPT-4-O他講話的時候,背景是有一個鋼琴聲的，當然我們不能排除現場正好有人在彈鋼琴的可能啦，但是如果你告訴我GPT-4-O講話的時候，就是有可能會產生一些音效或者是背景音樂，這我完全也不意外，那不過我覺得可以如果今天一個語音模型啊，他在講話的時候就是會自帶音效或自帶BGM，其實也是一個很酷的事情，他以後講話都自帶BGM，所以我們可以說這不是一個bug，這是一個feature。"
    },
    {
        "text": "好那在demo裡面我們也可以看到說啊，GPT-4O他可以產生非常多樣化，非常戲劇性的聲音，這是怎麼辦到的呢?，有一些論文已經指出，這邊是引用了一個，Amazon在今年2月所釋出的論文，他們用了超過10萬個小時的語音訊號，來訓練他們的語音合成模型，這邊用的是一個參數有B.10億等級的模型，當然這樣大小的模型，在文字領域並不是很大，但對於語音合成模型來說已經非常大了。"
    },
    {
        "text": "他們發現是說過去語音合成系統，因為他用的資料不夠多，所以往往合出來的聲音非常的平淡，這個如果你有看動漫的話，你知道這就叫做棒讀，就是講話不帶情緒非常的平淡，但是現在如果有大量訓練資料的時候，這些語音合成的模型就可以理解要讀的內容，而且根據要讀的內容給予適當的變化，舉例來說，我們來看這個句子，注意一下這個句子裡面，有提到，Whisper，輕聲細語，輕聲這個詞彙，我們來看看語言模型，是怎麼合這個句子的，來聽一下這個聲音。"
    },
    {
        "text": "根據這篇論文的講法,他們並沒有對輸入的文字做任何特殊的處理，模型就是直接讀輸入的文字，但他在讀到 whisper 輕聲這個字的時候，他自動知道他要用比較輕的聲音來唸這個句子，這是他自動根據資料學到的，當然這邊可能合出來的聲音沒有非常的戲劇化，我們今天看這個GPT-4的Demo，它的聲音的合成是可以更戲劇化的，你要叫它講輕聲的時候，它是可以講得更輕聲的，但也許把資料從十萬小時擴展到一百萬小時的時候，就是會有這種效果，當然因為我從來沒有訓練過這麼多，從來沒有用過這麼多資料訓練語音合成的系統，所以這只是個猜測。"
    },
    {
        "text": "單單使用語音的資料來訓練，非常顯然是會不夠的，必須要利用文字的資訊，為什麼用語音資料訓練是不夠的呢，我們來想想看，一百萬小時的語音背後，可能有多少的文字，我們來算算有多少分鐘，一百萬小時是六千萬分鐘，一般人一分鐘可以大概講，一百多個文字的TOKEN，那六千萬分鐘，就可以講60億個文字的TOKEN，你可能想說60億，聽起來是一個蠻大的數字了，從60億個TOKEN，應該可以學會很多知識吧，但是不要忘了，LLaMA3，可是用了15兆個文字的TOKEN來訓練喔，所以一百萬小時的語音，只有LLaMA3，預訓練資料的2500分之一而已。"
    },
    {
        "text": "所以假設一個模型，他只聽了100萬小時的語音進行學習，也許他可以學到一些語音的資訊，但是他的知識可能會非常的不足，所以模型不能單單只用語音聲音的資料訓練，還得利用文字的資訊。"
    },
    {
        "text": "那怎麼利用文字的資訊呢，一個可能是語音版的語言模型是以原來的語言模型作為初始化的，那OpenAI早就打造了很多很厲害的語言模型，他們可能不會浪費這些語言模型已經學到的知識，所以他們可以用原來已有的語言模型作為初始化，去打造語音版的語言模型，或者是用通俗的講法就是，我們可以去教原有的語言模型，讓他聽懂語音。"
    },
    {
        "text": "那麼剛才有說，語音其實會被表示成一堆Unit，而這些Unit對於語言模型來說，就是一個全新的語言，他有一套自己獨特的符號系統，所以當我們要教一個原來的語言模型，聽懂語音的時候，其實對語言模型來說，他就是在學一個全新的語言，當然另外有一個可能是把語音的符號，跟文字全部倒在一起訓練，總之單憑語音資訊來訓練一定是不行的，一定要想些辦法利用文字的資訊，那我覺得這個地方可能就可以展現混合模式的好處，因為假設我們今天表示一段聲音不是隻用unit，而是有用到文字的話，那對於語言模型來說,它學習起來可能會更為容易，因為這些文字符號的意思,它早就知道了，它只需要花力氣去了解這些新的符號是什麼意思就好，當然這只是一個猜測。"
    },
    {
        "text": "如何利用語音資訊其實並不是隻有固定一種方法而已，還有很多其他讓語音版語言模型利用文字資訊的方法，到這邊就列舉幾篇論文給大家參考。"
    },
    {
        "text": "好,那剛才講的是Pretrain，那我們都知道說光是有pre-trained是不夠的，文字的語言模型如果只有做pre-trained，只有做預訓練的話，他根本沒辦法好好的回答問題，所以需要做alignment，需要根據有標註的資料進行微調。"
    },
    {
        "text": "那在文字模型上，你需要收集一些這樣對話的資料，人說你是誰，模型就要回答我是人工智慧，人說教我駭入鄰居家的Wi-Fi，模型就要回答我不能教你等等，你需要蒐集這樣的資料，來微調你的模型，讓它能夠好好跟人說話，那對於語音的模型，我們可能就需要蒐集語音的對話來訓練它，所以就要蒐集語音的對話，然後在這個對話裡面，你讓某一個人去當作使用者，某一個人就說他是扮演AI的角色，然後你就可以微調語音版的語言模型，讓他聽這個人說話，然後要產生這個人的回應。"
    },
    {
        "text": "但光是這樣可能還不夠，大家如果聽那個DEMO，那個DEMO是固定某一個語者的聲音，所以假設要讓我們的語言模型講出話來，都是某一個人的聲音，比如說現在ChatGPT的語音頁面裡面，你也是可以選語者的，那比如說你選Sky這個人，所以他就只能用Sky這個人的聲音來講話，那所以說可能在做alignment的時候，假設你想讓模型學會多用Sky的聲音來講話，那你可能需要收集大量Sky跟其他人的對話，那可能有某一個聲優，他就代表了Sky，收集很多這個聲優跟其他人的對話，你需要這樣子的語音對話來訓練模型。"
    },
    {
        "text": "那有人可能會想說，那是不是需要錄很多Sky跟其他的對話呢，也許不一定需要，因為記不記得我們在講文字模型的時候，我們有說其實Finetune往往不需要太多資料，模型在Pretrain的時候，已經擁有非常豐富的知識，Finetune只是畫龍點睛，那今天會不會做完語音的pre-train以後，模型已經很會模仿各種不同的人說話，他只要聽過幾句sky的話，就可以很好的學會sky說話的方式了。"
    },
    {
        "text": "所以也許一個有大量資料pre-train的模型，它是它在fine-tune的時候，在做alignment的時候，只需要少量的資料，那另外一個可能就是，就算沒有很多sky對話的錄音，也許可以用語音轉換的技術，語音轉換的技術就是把某一個人的聲音轉成另外一個人的聲音，也許可以用語音轉換的技術，把對話中各種不同人的聲音都轉成sky的聲音，那你就有大量sky跟其他人對話的錄音檔，可以拿來訓練你的模型。"
    },
    {
        "text": "但講到目前為止，看起來這個語音的語言模型，跟原來文字的語言模型非常的類似，但是其實語音跟文字，還是有很多，本質上的區別，舉例來說，我們今天用文字來跟，AI互動的時候，你有很明確的開始跟結束，今天，你跟ChatGPT互動的時候你打一句話你打完以後，你會按Enter，ChatGPT就知道該輪到他講話了，他不用猜什麼時候，他該開始講話，結束也是一樣，你今天不想讓ChatGPT講話了，右下角有一個停止的鈕你按下去，他就很明確的知道他不會再生成更多的文字，但是語音介面不一樣，當有一個人對AI說我們來做一件有趣的事，稍微停頓一下，這個時候AI必須要猜，他到底應該接話說什麼事，還是這個人還沒有講完，我們應該要等他繼續講完，再進行答覆，所以跟文字不一樣。"
    },
    {
        "text": "在文字的介面上，AI很清楚什麼時候輪到他講話，但是如果是一個語音的介面，那AI就必須要猜，他什麼時候可以開始講話，另外一方面，也許今天有人叫語言模型講一個故事，他開始講一個無聊的故事，山上有座廟，廟裡有個老和尚，這個故事會不斷的循環下去，是一個無限循環的故事，那人聽了就很厭煩，跟他說停停停，這不是我要聽的，那語音版的語言模型，他知不知道要停下來呢，那也許你說這是什麼問題，反正只要人說話，我們就停下來，這個不是最好的解決問題的方法，因為也許這個人講話，並不是要語言模型停下來啊，也許現在人正好在跟這個AI合唱，所以並不是只要聽到人的聲音，就必須停下來，所以假設今天要讓一個語音版的語言模型，跟人有自然的互動，要讓模型可以同時聽跟說，但原來的文字接龍的方式，聽跟說是切開的，模型在說的時候，它就很難繼續進行聽這件事情，那一個可能的解決方法，是把聽跟說這兩件事情分開來。"
    },
    {
        "text": "那這個技術呢過去也是有過的，有一個模型叫做Dialogue GSLM，這個是22年就已經有的模型，所以等一下講的東西，如果你聽不太懂的話，你可以參考這一篇論文。"
    },
    {
        "text": "怎麼讓模型同時聽跟說呢，就是要把聽跟說分成兩個不同的頻道，所以今天有一個聽的頻道，那這個是模型的麥克風，他會在聽人在說什麼，外界發生了什麼聲音，那另外模型會記錄，自己發出過什麼樣的聲音，但這兩個頻道應該要是分開的，而不是直接被混在一起的。"
    },
    {
        "text": "我們來看一下模型在這個狀況，要怎麼運作，語音版的語言模型就是同時，聽這兩個頻道的內容，包括現在人在說什麼，他之前講過什麼，現在人說了個我，那感覺這句話還沒有說完，所以語音版語言模型就輸出 silence，輸出安靜，安靜可能也是有某一些特殊的speech unit，代表安靜，就不說話，然後接下來呢，人就會繼續說，也許人說到某一個段落，那語音版的語言模型，根據人現在說的話，覺得那他說完了，輪到我說了。"
    },
    {
        "text": "人說我們來做個有趣的嘗試，那語言模型也許就輸出一個 wow，代表說他很興奮，可以做這個嘗試，那接下來呢，假設人仍然是沒有聲音的，人是安靜的，語言模型就知道說，那他可以繼續說，也許他就會說我好期待，但如果人仍然有發出聲音，就我要你做某件事情，那語音版語言模型知道說，人還沒有說完，也許他就會輸出，代表安靜的符號，繼續保持安靜，當然這並不是唯一讓語言模型，可以同時聽跟說的方法了，但可能還有其他的解法，我這邊只是講了某一個可能的解法而已，另外一方面也許語言不只要同時聽跟說，還要同時聽加說加看。"
    },
    {
        "text": "因為你看這個GPT-4ALL的DEMO，模型是可以一邊看著東西一邊說話的，所以可能有不只有聽跟說兩個頻道，還有一個視覺的頻道，專門讀取外界的影像輸入，舉例來說,在這個OpenAI的Demo裡面，有一個Demo就是，這個語言模型正在描述房間中的燈光，講得非常的奇跡，這時候有一個人跳出來，比了一個Yeah的動作，語言模型無視這個影像，繼續談他的燈光，不知道他有沒有看到這個比Yeah的人，這時候人就打斷語言模型說，等一下,你有沒有看到什麼奇怪的東西，語言模型顯然是有看到比Yeah的這個人的，只是在講燈光的時候他講得太爽了，所以就沒有覺得需要對這個人發表，比Yeah的人發表任何的評論，但是當有人問他說，你有看到什麼怪怪的東西的時候，這個時候語言模型會做的事情是，他會對每一個Channel，不只是他現在生成的Channel，還有他聽的Channel，還有他看的Channel，通通去做Attention，所以他會收集所有的資訊，然後得到一個答案，那可能就會知道說有人比了一個頁。"
    },
    {
        "text": "那其實在Google Project Astra裡面的Demo，也有一個非常類似的例子，看起來大家都覺得需要有這種例子來展現模型的能力，他們的例子是，有一個人拿著手機隨便走隨便拍，然後中間拍攝的過程中有看到了一個眼鏡，但是那個時候語言模型並沒有對眼鏡做出任何評論，人也沒有提到跟眼鏡有關的事情，然後人就跟語言模型聊了一下，我們現在在哪裡，語言模型說在王十字車站附近，然後接下來人問說有沒有看到我的眼鏡，這個時候眼鏡已經不在畫面裡面了，但是語言模型會對過去的資訊去做Attention，從過去看到的影像，從過去聽到的聲音收集一下資訊，他知道他有看到眼鏡，眼鏡是在桌上，這是一個蠻自然的互動的模式。"
    },
    {
        "text": "其實技術的部分就講到這邊，如果大家想知道更多有關語音版語言模型的論文，我這邊附了一個連結，裡面收集了很多語音版語言模型相關的論文，給大家參考，謝謝大家謝謝。"
    },
    {
        "text": "接下來的下一段呢,我想跟大家介紹一下一些經典的影像生成的方法，那這邊會跟大家很快提到的方法,包括 Variational Autoencoder，它的所寫是 VAE Flow-Based Model，還有今天大家都耳熟能詳的 Diffusion Model，還有 Generative Adversarial Network,它的所寫是 GAN。"
    },
    {
        "text": "那像 Sora 呢,他用的就是 Diffusion Model，如果你在論文或Blog裡面看到有一個東西，是從一大堆的雜訊慢慢生出來的。"
    },
    {
        "text": "本來很多雜訊，雜訊越來越少，最後產生高清的圖的話，那這個通常指的就是Diffusion的Model。"
    },
    {
        "text": "那我想用一點時間來介紹這些經典的影像生成的方法，雖然今天Diffusion Model可能是最常用的，但是我們可以多介紹幾個經典的方法，讓你知道說到底影像生成真正的難點，真正被克服的挑戰是什麼。"
    },
    {
        "text": "那我們剛才已經講到，我們在生圖片的時候或生影像的時候，今天常常用的類神經網路的架構，就是Transformer，那當然過去比較常用CNN，不過今天Transformer真的是一個非常常用的，類神經網路的架構，而它的概念也非常的簡單，每一段文字產生一排patch，就可以產生圖片了。"
    },
    {
        "text": "但是我們在訓練的時候，可能會遇到這樣子的一個問題，我們可能在訓練資料裡面，如果你找一隻奔跑的狗，你會發現一隻奔跑的狗，有很多不同的樣子，它可以是一個在草原上奔跑的哈士奇，也可以是在都市裡面奔跑的柴犬，一隻奔跑的狗，它不只一個樣子，對於transformer來說，對我們來說,他得到的教材是，當輸入的文字是一隻奔跑的狗的時候，有時候你告訴他，要產生這些patch，但有些時候你要告訴他，要產生另外一些patch，對這個transformer來說，他就無所適從，你叫他產生一個哈士奇也好，他能生得出來，你叫他產生一個柴犬也好,他可以生得出來，但是你有時候叫他產生柴犬，有時候叫他產生哈士奇，他頭腦就會很破，每一個位置 每一個patch 想要產生的東西都不一樣，你可能就會產生各式各樣奇怪的混種的圖片，這個就跟你如果去工作的話，如果老闆都只叫你往東那沒問題 都只叫你往西沒問題，最怕的就是遇到老闆有時候叫你往東 有時候叫你往西，你就會無所適從 這個時候是特別痛苦的，對Transformer來說 他在學影像的時候也有一樣的問題，因為通常影像所對應的文字，沒有辦法完整的描述整張圖片，所以你會有很多同樣文字對應到不同圖片的狀況。"
    },
    {
        "text": "對Transformer來說，他會不知道要如何學習，不知道要聽哪一筆訓練資料的，所以怎麼辦呢，我們現在先把那個影像圖片生成的模型簡化一下啦。"
    },
    {
        "text": "我這邊就直接用個框框呢，來代表那個Transformer，那大家知道我的意思，就這個框框裡面其實是一個Transformer，那給他一段文字，還要生一堆Patch出來，這些Patch會變成圖。"
    },
    {
        "text": "好 那我們剛才說圖片生成或者是影像生成問題也是一樣的，他的難點就是這些文字往往沒辦法完整的描述影像，那怎麼辦呢。"
    },
    {
        "text": "也許一個可能性是，雖然我們本來的訓練資料裡面這些文字不足以完整的描述影像，但我們自己把本來文字沒提到的東西加進去，我們直接把多餘的資訊加進去，都跟圖片生成模型講說，你現在不只要生成一隻奔跑的狗，你是要生成一隻哈士奇在草原上奔跑的樣子，你不是隻生成一隻狗，你要生成柴犬在都市裡奔跑的樣子，把額外的原來文字沒提到的資訊，把它標出來，也提供給圖片生成模型，這樣圖片生成模型在生成的時候，他就知道說，為什麼同樣的輸入，這兩隻圖片會不一樣，因為有額外的資訊，他會讀取這個額外的資訊，再去生成圖片，他就不會有同樣的輸入，有會有不同的輸出的這種問題，他就不會有那種同樣的輸入，你想要叫他產生不同輸出的這種問題。"
    },
    {
        "text": "但是這些標註又要從哪裡取得呢，也許我們可以訓練一個資訊抽取的模型，這個資訊抽取的模型，他做的事情就是給他一張圖片，給他一段文字敘述，他把這個圖片裡面文字資訊，沒辦法沒有描述到的東西，額外抽取出來丟給圖片生成模型。"
    },
    {
        "text": "如果我們有這樣的一個資訊抽取模型，我們就可以對訓練資料裡面所有的圖片，都把這些文字沒描述到的資訊抽取出來，丟給圖片生成模型，讓圖片生成模型的學習就會更加容易。"
    },
    {
        "text": "但現在問題是，怎麼訓練這個資訊抽取的模型呢，你知道你要訓練一個模型的時候，你都要有大量的輸入跟輸出成對的資料，你要怎麼找到這樣子的輸入跟輸出成對的資料呢?，你要怎麼找到人去幫你標註?，你要怎麼輕易地標註出說，這張圖片裡面沒有被描述到的資訊就是這些，就是這些呢?。"
    },
    {
        "text": "這邊有一個方法是，在不需要額外標註資料的情況下，就可以把資訊抽取的模型訓練出來。"
    },
    {
        "text": "這個方法是這樣的，圖片生成的模型跟資訊抽取的模型，它們可以一起被訓練，他們有一個共同的目標，他們共同的目標是什麼呢，他們的共同目標是，資訊抽取的模型，讀訓練資料裡面的一張圖片，那訓練資料的每一張圖片，都有附一段文字的描述，把文字的描述也讀進去，他可以看看有哪一些，文字的描述沒提到的東西，把它抽取出來，那再把這些抽取到的資訊，丟給圖片生成的模型，圖片生成的模型看到這些，在讀這段文字的敘述產生一張圖片。"
    },
    {
        "text": "那資訊抽取的模型，雖然你沒有告訴他要抽取哪些資訊，但是資訊抽取的模型跟圖片生成的模型，有一個共同的目標，他們共同的目標就是，輸入一張圖片，經過這一連串的處理之後，最終輸出的圖片，要跟輸入越接近越好，所以中間資訊抽取的模型，到底抽取出來什麼，不重要，我們自己也不知道，我們也沒有標準答案，但反正他抽出來的東西，可以幫助圖片生成的模型生出，跟輸入一模一樣的圖，資訊抽取的模型就算是成功了，所以資訊抽取的模型跟圖片生成的模型，是可以一起被訓練出來的，一次解決了兩個問題。"
    },
    {
        "text": "有資訊抽取的模型抽出文字敘述，沒有表達到的資訊，圖片生成的模型在訓練的時候，又有這些額外的資訊輔助它生成圖片，這整個框架叫做AutoEncoder，資訊抽取的這個模型又叫做Encoder，圖片生成的這個模型又叫Decoder，這個Encoder跟Decoder一起訓練，要讓輸入跟輸出越接近越好，這個訓練的框架，這個訓練的方法叫做AutoEncoder，這個資訊抽取模型它的輸出不需要是文字。"
    },
    {
        "text": "我們剛才的講法好像讓你覺得資訊抽取模型它的輸出一定是好像是文字，這個是為了讓你方便理解，對於一個圖片生成的模型來說，它又不是人，它不需要讀文字，你只要能夠傳遞一些密碼，它讀得懂知道那是什麼就好了。"
    },
    {
        "text": "所以一般資訊抽取的模型它的輸出不是文字，而是一串數值,也就是一個向量，那通常這個項量裡面每一個維度，可能就會對應到某些特別的含義，那在這個例子裡面，第一個維度的數值也許代表是狗的品種，第二個維度的數值也許代表的是背景，在什麼樣的地方。"
    },
    {
        "text": "當圖片生成的模型給它不同的向量的時候，它就會產生不同的載分號的狗。"
    },
    {
        "text": "好,那現在有了這個Encoder，也有了這個Decoder之後，但是實際上在圖片生成的時候要怎麼做呢。"
    },
    {
        "text": "想想看在圖片生成的時候，我們只有這段文字敘述，圖片生成的模型是要根據這段文字敘述，去產生一張圖出來，我們根本不知道這段文字敘述沒有描述的資訊是什麼，因為我們根本還沒有把圖生成出來啊，這不是在訓練的時候你已經知道這張圖是什麼了，所以資訊抽取的模型，可以把文字沒提到的資訊重新取出來。"
    },
    {
        "text": "在真的使用這個模型的時候，你根本不知道這些文字沒描述的資訊是什麼，那這個文字沒描述的資訊，這個需要腦補的資訊從哪裡來呢。"
    },
    {
        "text": "我們已經知道這些要腦補的資訊，這些文字沒有描述到的資訊，它就是用某一些數值來表示，所以當你在用這個圖片生成模型的時候，你就會先擲個骰子，把這個向量裡面的每一個數值，都擲骰子植出來，擲到多少就是多少，擲骰子擲出來，圖片生成的模型就根據這段文字敘述，跟這個擲骰子得到的腦補資訊，因為反正現在人沒有輸入嘛，所以人大概也不知道到底要腦補些什麼，我們就用機率來產生，我們就把這件事情交給上天來決定，用機率來產生這個要腦補的向量，把這個有腦補資訊的向量丟給這個圖片生成的模型，圖片生成的模型就根據人數的文字，跟這個隨機產生的腦補的資訊，去產生最終輸出的結果，那這個模型呢，其實就是VAE啊。"
    },
    {
        "text": "我不知道多少同學以前也許有聽過VAE，也許你之前聽到的講法不是這樣講的，那我這邊就是用一個也許比較更容易理解的講法，來告訴你為什麼VAE的模型是長這個樣子。"
    },
    {
        "text": "所以大家已經知道說VAE的模型就是有個Encoder，去抽文字沒辦法描述的資訊，有個Decoder可以把腦補的資訊還原回來，那有另外一個模型叫做Flow，這個Flow這個模型呢，跟VAE非常的像，它唯一不一樣的地方只有，VAE需要訓練一個Encoder，訓練一個Decoder。"
    },
    {
        "text": "那Flow這個模型它想說，這個 encoder 跟 decoder 做的事情不是正好相反嗎，一個是從圖片裡面抽取資訊，一個是把資訊還原回圖片，他們做的事情正好相反，我們有必要訓練兩個不同的模型嗎，我們就訓練一個 decoder 就好。"
    },
    {
        "text": "然後接下來我們強迫 decoder，一定要是 invertible 的，這個 decoder 一定有一個反函數，這個反函數做的事情正好就是 decoder 的相反，那這個反函數呢,直接就可以拿來當做encoder。"
    },
    {
        "text": "在flow-based model裡面,它跟VAE不一樣的地方就是，它只訓練了一個decoder,但是它同時呢,就有了一個encoder，那在文件上啊,通常會把這個encoder抽取出來的這個東西，encoder抽取出來的這個東西，也就是decoder要拿來腦補的這個資訊呢,叫做noise。"
    },
    {
        "text": "那這個詞彙可能會讓你覺得說，就是說這個Noise裡面的資訊都是不重要的,沒有用的資訊，但是其實不是,這個Noise裡面往往也包含了非常重要的資訊。"
    },
    {
        "text": "有一個真實的實驗是這個樣子的，這個實驗是為了告訴你說，這些Noise裡面可能是有包含跟圖片的生成非常相關的資訊的，舉例來說,你找一大堆看起來臉很臭的人，把這些臉臭的人丟到Encoder裡面抽出一個向量，這些向量重複加起來就代表一個臉很臭的臭臉特徵的向量，那你把一些看起來在笑的人把他的臉丟到Encoder裡面，Encoder會輸出一些向量，這些向量平均起來就是笑臉的特徵相量，那知道這些事情以後可以做什麼呢?，我們剛才說VAE就是有一個Encoder有一個Decoder，擺張圖片就會Encoder，他抽出一個向量，Decoder可以根據這個向量還原成原來的圖片，但是我們可以對這個向量呢，直接做一些改造，因為我們已經知道臭臉的向量長什麼樣子，如果我們今天的目標是要讓這個人呢，啊這是我的臉吶，但是我看起來已經在笑了，但是我們想要讓他笑得更開心一點，所以我們就可以把臭臉的向量呢剪掉，把臭臉的特徵剪掉，再加上笑臉的特徵，所以把這個原來這個黃色的向量，合出來的圖片是長這個樣子，那你可以在這個黃色的向量上，再做一些改造，把臭臉的特徵剪掉，把笑臉的特徵加上去，透過decoder以後，這個人呢就會笑得更加的開心。"
    },
    {
        "text": "這些向量或我們叫做noise，他其實裡面也是有豐富的資訊的，你甚至可以直接調整這一些向量，就打造調整輸出圖片的效果。"
    },
    {
        "text": "好那接下來呢，我們就要來介紹Diffusion Model，我們剛才已經介紹兩個模型，VAE跟Flow-Based Model，接下來我們來介紹Diffusion Model，Diffusion Model，它的Decoder的輸入跟輸出，跟剛才幾個模型都是一樣的。"
    },
    {
        "text": "記不記得剛才幾個模型都需要輸入一個Noise，進行腦補，輸入一個 noise 包含腦補的資訊，然後產生一張圖片，Diffusion Model 裡面的 decoder 做的事情，也是一樣的，只是 Diffusion Model 不一樣的地方，是他會反覆的使用同一個 decoder。"
    },
    {
        "text": "那這 decoder 呢，每次在做事情的時候，每次在生圖的時候，他只做一件簡單的事情，這件簡單的事情，是去除雜訊 也就是 de-noise。"
    },
    {
        "text": "所以一開始給他一個雜訊，然後這個雜訊被輸到Decoder裡面的一個Denoise的Module，再加上文字敘述的資訊，那這個Denoise的Module就會把這個圖片裡面的雜訊稍微去掉一點，希望他看起來比較像是文字的描述，比較像是雪地的一個貓。"
    },
    {
        "text": "那第一次的Denoise也許不會非常的成功，只能夠去掉一點的雜訊，但是Denoise的這個Module會鍥而不捨，不斷的去做Denoise。"
    },
    {
        "text": "所以根據第一次Denoise的結果，再丟給Denoise的Module，再Denoise一次，也許看起來就更像一隻貓。"
    },
    {
        "text": "這個過程通常會反覆進行下去，通常需要反覆個500、1000次，最後你就可以產生一張清晰的圖片。"
    },
    {
        "text": "通常Diffusion Model的痛點，也就在於Denoise必須要用很多很多次，最後才能夠產生出好的結果，而今天Diffusion Model相關的研究，也就集中在，如何用比較少的Denoise的次數，就可以得到清晰的圖片。"
    },
    {
        "text": "那如果傳統的方法都是500、1000次，那很多人就會想說有沒有辦法，10次就好，有沒有辦法5次就好，甚至1次就好，那這個是今天研究的一個趨勢。"
    },
    {
        "text": "那這個Denoise的model，他要學的是怎麼去除雜訊，怎麼教這個Denoise的模組，做去除雜訊這件事呢。"
    },
    {
        "text": "你可以自己製造訓練資料，怎麼自己製造訓練資料呢?。"
    },
    {
        "text": "你想想看,要做Denoise的時候，就是要教機器怎麼把雜訊去掉，所以你需要有雜訊的圖，跟沒有雜訊的圖，但是你的訓練資料裡面，都是沒有雜訊的圖跟它對應的文字，那怎麼產生有雜訊的圖呢?，你就自己製造就好啦，就自己弄一些雜訊來，用擲骰子的方式擲出一些雜訊，自己產生一些雜訊，這些雜訊呢,加到你的訓練資料裡面，就產生有雜訊的圖片，那你通常會加雜訊加很多次，這是第一次加雜訊，第二次加雜訊,愈加愈多，直到最後完全看不出來，原來圖片裡面的物件是什麼，透過這個加雜訊的過程，你就有了加雜訊前，跟加雜訊以後的圖片。"
    },
    {
        "text": "然後接下來你就可以訓練你的，Denoise去照的這個模型，就可以訓練你的Denoise的model，你就跟這個Denoise的model說，之前這一張照片，加了這個雜訊就變成這個樣子，現在你要學習的就是，給你這張圖跟給你這段文字，跟給你這段文字的敘述，你要還原回，他加雜訊前的樣子，或者是這張圖片，加了這個雜訊以後就變成了這個樣子。"
    },
    {
        "text": "那你就要學到說，給你這張圖片跟這段文字，你要想辦法還原回，加雜訊之前的樣子，所以就自己加雜訊，然後就可以教Denoise的model，如何去去掉你自己加入的雜訊，之後就可以用這個Denoise的model，來產生圖片。"
    },
    {
        "text": "那當然這個Denoise的model裡面，其實，它的類神經網路的架構，也是transformer。"
    },
    {
        "text": "所以實際上，當我們在用這個，Diffusion的model來生圖的時候，那時候你其實可以結合Transformer，這也是今天非常常用的技術，然後在這個SORA的這個paper裡面也提到了，他們用的就是這樣的方式，把Diffusion跟Transformer結合在一起。"
    },
    {
        "text": "他們就這個Diffusion跟Transformer結合在一起，就是Diffusion Transformer，也就是說本來的Transformer呢，是給一些輸入，把它產生一排Patch就可以還原成圖片，那現在呢，如果是用Diffusion Model的話，那每一次Transformer在做的事情就是Denoise,就是去掉一些雜訊，所以一開始輸入的Patch都是雜訊的Patch，然後第一個Transformer去掉一些雜訊，第二個Transformer，其實都是同樣的參數，第一個Transformer，第一次用Transformer去掉一些雜訊，然後第二次再用Transformer再去掉更多雜訊，第三次再用Transformer再去掉更多雜訊，把這個Transformer用個五百一千次，最後就產生乾淨的Patch，你可以把這個乾淨的 Patch 丟到 Decoder 裡面還原出圖片，這個就是 Sora 裡面有用到的 Diffusion Transformer。"
    },
    {
        "text": "雖然這個例子裡面舉的是圖片，但是要把它 Extend 把它一般化到生影片，也其實就是一樣的事情。"
    },
    {
        "text": "在影片的模型裡面，你就是有一堆的 Transformer，在這個影片生成的過程中，你就是會不斷的做 Denoise，那這個 Denoise 是由一個 Transformer 的模型完成的，它的輸入就是有雜訊的 patch,輸出就是比較乾淨的 patch，這個 Transformer 會做好幾百次、好幾千次的去照之後，期待最後產生一堆乾淨的 patch，那這些乾淨的 patch 就可以被還原為影像，這個就是今天用 Diffusion Model 加上 Transformer 生一片的模型。"
    },
    {
        "text": "那根據 Sora 的 blog，他們很有可能也就使用類似的技術來產生影片的。"
    },
    {
        "text": "好,那我們現在講了Diffusion的model，Diffusion的model跟剛才的VAE還有Flow-based model要怎麼來類比呢?剛才的VAE跟Flow-based model都有一個Encoder跟一個Decoder，對於Diffusion model來說,它也有一個Decoder，它Decoder裡面做的事情是多次的Denoise，那至於Encoder呢,怎麼把一個圖片變成一個雜訊呢?，對Diffusion Model來說,它就沒有特別訓練一個模型做這件事情，因為雜訊是你自己加進去的。"
    },
    {
        "text": "你自己把這個圖片加了大量雜訊以後，讓它看不出來原本物件的樣子，那這個加雜訊的過程對應到其他的模型，就是Encoder在做的事情，那在Diffusion Model的文件裡面，通常叫做Forward Process，那Decoder做的事情是Reverse Process，所以今天我們就跟大家很快地講過，VAE Flow-Based Model跟Diffusion的Model。"
    },
    {
        "text": "那另外一個也很知名的模型叫做，Generative Adversarial Network，它的縮寫是GAM。"
    },
    {
        "text": "我們這邊就沒有特別把GAM，拿出來跟其他的模型一起講，為什麼，因為GAM跟其他模型，其實有本質上的差異，它比較像是一個額外的外掛。"
    },
    {
        "text": "我們來看看為什麼我會這樣說，那我們剛才有講到說圖片生成的困難，或影片生成的困難，就是同一段文字可以對應很多不同的圖片，所以在圖片生成的過程中，模型會生得暈頭轉向，它會無所適從。"
    },
    {
        "text": "所以怎麼辦呢，也許我們不應該用這些真正的圖片，來教圖片生成的模型，也許應該先訓練出另外一個模型，先訓練另外一個AI，他先自己咀嚼奔跑的狗應該長什麼樣子，他先理解好奔跑的狗應該長什麼樣子，再來教我們的圖片生成模型。"
    },
    {
        "text": "怎麼訓練另外一個AI，一隻奔跑的狗長什麼樣子呢，這邊用的概念跟剛才的clip，基本上是一模一樣的，記不記得我們在講，這個怎麼衡量文字生圖模型好壞的時候，我們講了一個clip的模型，他會吃一張圖片，讀一段文字，看看這個圖片跟這個文字是不是匹配的，那在GAME裡面也會訓練一個，其實就跟CLIP根本就是一模一樣的模型，他只是換了一個名字叫做Discriminator，這個Discriminator他做的事情就是，給一張圖片、給一張文字，還要給一個評價，看這個圖片跟這個文字有多匹配，但是如果今天訓練Discriminator的時候，都只有好的例子，都只有跟這個影像匹配的文字的話，那Discriminator從來沒有看過壞的例子，他會他訓練的，如果你在訓練的時候都只給他好的例子，到時候測試的時候就算看到壞的例子，他也都會輸出這是好的。"
    },
    {
        "text": "因為只有教他說好，你只有教他輸出高分，你只有教他豎起大拇指，沒有教他做其他的事情，所以你同時在訓練的時候，也得給他一些壞的例子。"
    },
    {
        "text": "那像在Clip裡面那個壞的例子，意思就是把圖片跟文字隨便打亂，隨機配對製造一些壞的例子，那在更裡面用的是另外一個方法。"
    },
    {
        "text": "假設你現在已經有一個圖片生成的模型，那就先不要問這個圖片生成的模型是哪裡來的，假設你有一個它只是有點差而已，你先拿這個圖片生成的模型先生一些圖片，你只要畫一隻要奔跑的狗，畫一個抽象的狗，你叫他畫一個陽光下的貓，他畫一個背景是黃的很抽象的貓，但是隻有三隻腳他是個三角貓，然後呢你就跟Discriminator說，看到這個抽象的狗，你要說是不好的，看到這個三角貓呢，你也要說是不好的，所以你給Discriminator一些正面的例子，一些反面的例子，他就可以學會評價一張圖片，跟一段文字的敘述是不是匹配的。"
    },
    {
        "text": "好那有了這個Discriminator以後，接下來啊，Generator就不去跟，正確的真正的圖片學，他跟誰學呢，他跟Discriminator來學習。"
    },
    {
        "text": "所以對Generator來說他要做的事情是，他一開始生成一張圖片，把他生成出來的圖片跟文字敘述丟給Discriminator，那Discriminator覺得這個抽象的懂化太差了，給了一個負評，那Generator學習的對象，他調整參數的方向，就是希望去騙過Discriminator，Generator他要做的事情其實就是產生一張圖片，這張圖片給Discriminator，Discriminator會覺得他做得非常的棒，Discriminator覺得他做得好，然後Generator就成功了。"
    },
    {
        "text": "那這跟某一個ground truth，跟某一個正確的圖片學習，不一樣的地方就是，跟正確圖片學習的時候，可能同樣的文字會對應到不同的答案，但是現在是用一個Discriminator來評價好壞，所以沒有單一的正確解答，只要今天Generator，可以產生一張圖片,Discriminator是覺得好的,就成功了，沒有什麼樣的答案是正確的,沒有什麼樣的答案才是標準答案，只要另外一個人工智慧覺得好,基本上就是成功了。"
    },
    {
        "text": "實際上在做的時候,Generator跟Discriminator會交替訓練，你先有一個Generator,用這個Generator你可以去訓練Discriminator，然後有了Discriminator之後,你就回過頭來訓練Generator，讓他產生出Discriminator覺得好的圖片，然後Discriminator也會更新他的參數，讓自己變得更厲害一點。"
    },
    {
        "text": "那兩個人呢，Generator跟Discriminator，這個圖片生成的模型，在Gan的那個框架下，往往又叫做Generator，這個Generator跟Discriminator，就會交替的訓練。"
    },
    {
        "text": "那講到這邊有人可能會問說，對於一個Gan這樣的Generator來說，那還需不需要輸入一個雜訊呢，因為我們說輸入雜訊的目的，就是為了要讓模型可以學會根據這個雜訊的資訊來腦補，它才能夠知道說要產生什麼樣的東西，如果今天在有Discriminator的情況下，其實是可以不用這個雜訊的，雖然你看在文件上多數GAN的模型都還是有給這個雜訊，但我這邊實際的經驗就是，如果是圖文字生圖的話，在有Discriminator的情況下，每加這個雜訊也能夠把Generator訓練的起來。"
    },
    {
        "text": "那其實我們也可以把GEM的訓練跟RLHF對比一下，大家還記得RLHF嗎?，我們在講大型語言模型訓練的最後一段的時候，第三段的時候，說大型語言模型訓練第三段就是RLHF，那你還記得說在講RLHF的時候，我們說會訓練一個Reward Model，Language Model其實是跟這個Reward Model學習的嗎?，那如果對應到game的框架的話，其實這個discriminator就是reward model，他們唯一不一樣的地方只是，reward model在學習的時候有人的標註，人告訴他說這個答案有多好，另外一個答案有多差，而這邊discriminator他在學習的時候，其實不需要人的介入，他就用一個假設，這個假設是隻要是AI所生成的圖，基本上就都是差的，原來訓練資料裡面的圖就都是好的，所以這個Discriminator其實就是ILHF裡面的reward model，只是他們學習的資料有一點點不同而已。"
    },
    {
        "text": "常常有人會問說，這個Gain跟Diffusion Model到底誰比較強呢，其實我覺得這並不是一個好的問題，為什麼，因為就好像RLHF就是一個方法，它可以強化你的模型的能力，其實Gain也是一樣，Gain是一個外掛，這個外掛你可以掛在VAE上，你也可以掛在Flow上,你也可以掛在Diffusion Model上，所以剛才所介紹的VAE Flow或Diffusion Model，你其實都可以在他們後面再掛一個Discriminator，然後來強化這些Decoder。"
    },
    {
        "text": "在GAM的框架裡面叫做Generator，所以GAN其實是可以跟其他方法結合的一個外掛。"
    },
    {
        "text": "那如果你想要知道更多有關經典的影像生成的模型的話，那這些都是我在我的YouTube頻道上有對應的影片的，那其實從這些影片，他們是在哪一門課裡面被錄的，你也可以知道這一些模型，它的歷史的變化。"
    },
    {
        "text": "最早的時候有VAE，這個是2016年的時候機器學習講的，然後呢在2018年的機器學習及生存與結構化這門課裡面，花了三分之一的學習的時間講GAN，GAN可以講的東西太多了，所以有一個GAN的系列，2019年的機器學習講了Flow-Based Model，2023年的機器學習講了Diffusion Model。"
    },
    {
        "text": "這個Diffusion Model背後有非常多的數學的原理，其實要講的話兩三週都是講不完的。"
    },
    {
        "text": "那你可以慢慢的消化這些點，如果你覺得剛才講的東西沒有很清楚的話，更詳細的資訊，它背後的數學原理，都是在我的YouTube頻道上有的。"
    },
    {
        "text": "好那最後一段呢，想跟大家分享的是，現在人工智慧可以生成影像，但是有沒有機會讓人類跟這些生成的影像，有更及時的互動呢，舉例來說，每次在講SORA的時候，大家都會播放這個女士在東京街頭走的影片，有沒有可能我們直接用上下左右，來操控這個女士走哪一條路呢，那你就可以等於是操控一個Avatar，在東京街頭漫遊，就等於是打造出了一個開放世界的3D遊戲，有沒有可能做到這件事情呢?，還真不是不可能的，有一篇paper叫做，Genie: Generated Interactive Environments，就是想做類似的事情，我這邊先打個預防針，他做的不是3D遊戲，他做的都是2D橫向捲軸的遊戲而已。"
    },
    {
        "text": "那這個Genie做的事情是這樣子的，他的模型可以讀一個畫面作為輸入，不只是讀一個畫面作為輸入，它還可以讀一個你輸入的動作，所以你可以想像說你有一個搖桿，接到Genie的這個模型，你可以按上下左右，它可以把你的動作讀進去，而你的動作會影響這個模型的輸出，同樣的輸入畫面你按的按鈕不同的時候，你的輸出就會是不一樣的，然後這個遊戲就可以一直下去，你按了右以後看到第二個畫面，第二個畫面會變成Dynamic Model的輸入，你再按一個A,然後又會產生新的畫面，你就可以用這個影像生成的技術來玩一個遊戲，你等於是即時的控制了影像生成的結果。"
    },
    {
        "text": "那Genie它想要做的是橫向2D卷軸遊戲，想要做的事情就是去收集了大量的橫向卷軸遊戲，但是這邊你可以想想看，我們要怎麼訓練像GENIE這樣子的模型呢，我們需要的是遊戲的畫面，加玩遊戲的時候人的輸入，當然不是每一個畫面人都會有輸入，我們可以把沒有按任何按鈕，也當作是一種特別的輸入，如果我們可以收集到人玩遊戲的畫面，加玩遊戲的時候按了哪一個鈕，你要訓練剛才前一頁投影片講的模型，就易如反掌。"
    },
    {
        "text": "你只需要教你的AI說，看到這個圖片加這個動作，你就產生這個圖，生圖要怎麼做，大家已經都會了嘛，看到這兩個圖加這兩個動作，你就要生成這個圖，以此類推，所以只要有遊戲畫面加人按按鈕的這些動作，你就可以訓練一個像Gini一樣的模型，但是今天Gini訓練的過程中，真正的難點就是，他只能從網路上收集大量的遊戲影片，但是他沒有使用者輸入的動作，他這種遊戲畫面，他不知道產生這些畫面的時候，人到底按了什麼樣的按鈕。"
    },
    {
        "text": "所以怎麼辦呢，Genie 用了一個神奇的方法，去想辦法反推，人類到底輸入的按的按鈕是哪一個，他用的做法，跟我們剛才講 VAE 的時候提到的那個，Auto-Encoded，概念基本上是一模一樣的。"
    },
    {
        "text": "記不記得我們剛才才講到說，有一個資訊抽取的模型，可以抽出文字沒辦法描述的資訊，然後圖片生成的模型可以根據這些資訊還原回原來的圖片，今天對於Genie來說，當給一個之前的遊戲畫面要預測下一個畫面的時候，他其實也是有缺少資訊的，他缺少了什麼，他缺少了使用者的動作，在不知道使用者動作的情況下，根據之前的遊戲畫面是沒有辦法去預測未來的畫面的，你不知道使用者要按左還是按右，你就會不知道使用者操控那個人物會往左邊跑，還是往右邊跑，所以今天圖片生成的模型，需要知道使用者的動作，但問題就是我們並不知道使用者的動作，那怎麼辦，訓練一個動作抽取的模型，這個動作抽取的模型就是讀之前的遊戲畫面，再讀，下一個畫面，看看這兩個畫面間有什麼樣的差異，然後試圖歸納出人所會採取的動作，人到底按了哪一個按鈕，造成之前的遊戲畫面會變成這個樣子，但是我們沒有這樣子動作的標註啊,怎麼辦?，在訓練的時候就用AutoEncoder的概念，給動作抽取的模型之前的遊戲畫面跟下一個畫面，它猜現在應該要做哪一個動作,要按哪一個鈕，再把這個按鈕的資訊加之前的遊戲畫面，輸入給圖片生成的模型，讓它生成下一個畫面的樣子，然後我們要讓輸入跟輸出越接近越好。"
    },
    {
        "text": "那如果今天動作抽取的模型，可以正確的猜出是哪一個動作的話，那圖片生成的模型可能就可以正確的生圖，所以最後如果圖片生成的模型可以正確的生圖，可能代表動作抽取的模型正確的猜出，現在人實際上按的是哪一個按鈕，不過因為這些動作它不是真正的動作，它是動作抽取模型猜出來的動作。"
    },
    {
        "text": "所以這些動作前面加上Latent這個字，代表它是被猜出來的，它不是真正光明正大的收集到的資料，它是Latent的，它是這個動作抽取模型猜測出來的動作。"
    },
    {
        "text": "好，那這邊在這個Genie那篇文獻裡面呢，他就假設說啊，人可以按的鈕就是八個，把它編號1到8，那你說這個編號1到8的按鈕，到底哪一個對應到上，哪一個對應到下，哪一個對應到A，哪一個對應到B，不知道也不重要，你就記得說反正有八個按鈕，可以操控圖片的生成就對了，他們發現說呢，確實你如果輸入同樣的按鈕，不同的畫面裡面的，變化會是一致的，比如說他們發現說，如果你輸入一串的指令，這個是6676765527，你看這一串按鈕，不管是哪一個畫面，他都會讓人物往右移動，然後整個畫面呢，會往左下角移動，然後這個顯然就是可能使用者按了一個，右跳的動作，所以大概可以猜一下，透過Latent Action猜一下，使用者實際上呢，所按的按鈕是哪一個，那有了這個東西以後。"
    },
    {
        "text": "有了GENIE以後可以做什麼事情呢，你就可以隨便創造遊戲，你就給他一張圖，就這個隨便小孩子的一個塗鴉，然後你就可以把它當作一個遊戲的畫面，就可以開始玩了，你就可以按一個右上跳的按鈕，他就可以往右上跳，然後甚至連真實場景的照片也可以，給一個照片，這是一個雷神索爾，隨便拍了一張照片，然後接下來你就把它輸入給Gini，再按一個往右上跳的動作，它就跳起來了，所以未來我們就可以更及時的，跟影像生成的模型互動。"
    },
    {
        "text": "那你可能會問說，這樣子的模型能幹什麼，不就只是可以比較快的創造遊戲嗎，但是你可以想像，未來就會有很多其他的應用，比如說，開車，現在開車的時候，你需要去駕訓班，上完駕訓班以後，你要去路考，那路考其實假設你駕訓班沒有學得很好，好像路口很危險的，那未來你就不需要去駕訓班了，你就在自己的電腦前面，你就可以學開車，來就可以看到螢幕的畫面，來就有一個假的方向盤，你轉方向盤螢幕的畫面就變了，那你可能會想說，這個不就跟一般的賽車遊戲一樣嗎，但是一般的賽車遊戲，它的場景是有限的，場景是程式自動規劃好了，但是有這樣子影像生成模型，你又可以跟它互動，那也許未來，你就可以在一個開放世界裡開車，你就可以一直往前開，然後畫面都會一直出現,永遠都不會停這樣，就以後這個世界可能就可以變成這個樣子。"
    }
]