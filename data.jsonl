{"text": "接下來，我們將探討當前語言模型如何運用工具，以及「工具」的定義，其中語言模型本身也屬於人類的工具。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit中經過壓縮的語音數據。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是指與大腦海馬迴結構類似的知識圖譜建構方式。", "label": 0}
{"text": "那AI agent是怎麼做到人類給予一個目標，用多個步驟來完成目標的呢？那我們可以把，AI agent背後運作的過程，簡化成以下這張投影片，那AI agent的第一個輸入，是一個目標，這個目標是人給定的。那接下來呢，AI agent會觀察目前的狀況，那AI agent可以看到的目前的狀況，我們叫做observation。那AI agent會看目前的狀況，分析目前的狀況，決定他要採取什麼樣的行動，那今天這個AI agent做的事情，叫做action。那他執行個action以後，會影響環境的狀態，會看到不一樣的observation。看到不一樣的observation，就會執行不同的action，那這個步驟會一直循環，直到AI agent達成，我們要他達成的目標為止。", "label": 1}
{"text": "雖然arXiv連結在某些人眼中不夠正式，但許多具影響力的論文並未發表於國際會議，而我優先選擇arXiv連結，因為許多研究者已習慣在arXiv平台上閱覽論文，國際會議如今更像是一個成果彙整的場合，我的論文閱讀習慣也多半仰賴arXiv。", "label": 0}
{"text": "影片與圖片的處理原理在此例中並無二致，只是將圖片範例擴展至影片應用而已。", "label": 0}
{"text": "各位同學，大家好！我們開始今天的AI agent課程吧，這可是個炙手可熱的研究方向。", "label": 0}
{"text": "影片生成的Diffusion Model利用大量Transformer，反覆進行去噪(denoising)處理：輸入帶噪影像片段(patch)，輸出更清晰的片段。經過數百甚至數千次的迭代，最終生成一系列清晰的片段，再將其組合成完整的影像。", "label": 0}
{"text": "那我在作業一會出一個作業，讓大家用AI上網搜尋之後，來回答助教出的問題，那除此之外呢？這個AI還需要具備一定程度的規劃能力，比如說它會主動跟人類確定餐廳訂哪一間才是合適的，因為如果最後訂的餐廳是不合適的，那就力氣就白花了。所以與其最後白花力氣，不如一開始稍微多花一點力氣，直接跟人類確定人類的需求，但是AI也要知道什麼時候需要確認，什麼時候不需要確認？如果AI連上網搜尋這個動作都要問人類說，我可不可以上網搜尋，那人類顯然是會生氣的，要完成這個日常生活中的工作，就要完成這個例子其實是需要很多不同的技能的，那我們在下一堂課會再來詳談 AI Agent。", "label": 1}
{"text": "好,那剛才講的是Pretrain，那我們都知道說光是有pre-trained是不夠的，文字的語言模型如果只有做pre-trained，只有做預訓練的話，他根本沒辦法好好的回答問題，所以需要做alignment，需要根據有標註的資料進行微調。", "label": 1}
{"text": "GENIE讓遊戲創作變得前所未有地簡單：一張兒童塗鴉，一張雷神索爾的照片，都能瞬間變成可互動遊戲場景，只需點擊「右上跳」按鈕，就能實現角色跳躍動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，從而提升效能。", "label": 0}
{"text": "Google Project Astra 的演示中，一個相似的案例說明了模型能力的展現：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時語音模型未提及，使用者也未主動談及。之後，使用者詢問目前位置（模型回答王十字車站附近），並詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍基於過去影像和聲音資訊（注意力機制），準確指出眼鏡曾位於桌上，展現出自然的人機互動。", "label": 0}
{"text": "我們會先從現在的生成式AI，有什麼樣的行為，可以做到什麼樣的事情開始講起，那接下來我們會講它背後運作的機制，然後我們會講這些運作的機制是怎麼產生出來的，最後我們會講怎麼賦予這些人工智慧的模型新的能力", "label": 1}
{"text": "然而，微調最大的風險在於：任務看似完成，模型卻可能產生不可預期的偏差，導致其在原本擅長回答的問題上出現錯誤或胡言亂語。", "label": 0}
{"text": "強迫類神經網路單一輸出結果，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈輸出，再以隨機抽樣的方式決定最終結果，故即使輸入相同，每次生成的結果也各異。", "label": 0}
{"text": "生成式AI的工作原理，本質上就是將輸入X轉換為輸出Y，其中X和Y的形態可以非常多元，例如長文、圖片或聲音片段。", "label": 0}
{"text": "相較於傳統強化學習需耗時調校獎勵函數，大型語言模型驅動的AI代理能直接理解編譯錯誤日誌並據此修正程式碼，其效率和準確性顯著提升，無需人工定義模糊的獎勵值。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话的信息整理成表格，它可以直接输出包含各种信息的表格。  最后，我们想分享如何赋能AI。  我们已进入机器终身学习时代，这与人类终身学习不同，指的是机器的持续学习能力。  过去训练AI需要从零开始，如同抚养孩子，但现在通用模型已具备基础能力，就像招聘一位大学毕业生，只需教授特定技能，无需从基础知识开始，即使如此，持续学习仍是必要的，这就是机器终身学习时代。", "label": 0}
{"text": "那其實讓AI使用電腦啊，不是最近才開始有的野望，其實早在2017年，就有篇paper叫words of bits，嘗試過使用AI agent。你看他這個文章的標題，他把自己的文章標題說，他是一個web-based agent，那只是那個時候能夠互動的頁面，還是比較原始的頁面。", "label": 1}
{"text": "目前面臨內容真實性、濫用、偏見、公平、隱私及高昂成本等挑戰，未來發展方向則包括技術優化以降低成本，以及實現多模態理解、人機協作和完善的倫理規範。", "label": 0}
{"text": "訓練另一個AI與訓練奔跑的狗影像辨識模型原理相同，皆沿用CLIP概念。  先前評估圖文生成模型好壞時提到的CLIP模型，能比對圖片與文字的匹配度，遊戲中也採用類似模型，僅名稱不同，稱為Discriminator。Discriminator接收圖片、文字及評分，評估匹配度。然而，僅以匹配良好的範例訓練Discriminator，將導致其無法辨識不匹配的範例，即使測試時遇到不匹配的範例，也會誤判為匹配。", "label": 0}
{"text": "我問他週五下午要不要出去玩，他立刻反應過來下午有課，真是機智！  不愧是血輪眼卡卡，還記得之前的對話。相關研究持續推進，例如2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory論文，都提供了寶貴的參考。", "label": 0}
{"text": "神经网络的核心在于将复杂函数分解为多个简单函数的串行组合，每个简单函数（即层）处理一部分输入并产生输出，作为下一层函数的输入，最终输出结果。  这层层递进的结构，正是深度学习“深度”的来源。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit中經過壓縮的語音數據。", "label": 0}
{"text": "深入探討網路層的內部結構，發現其通常包含多個子層，因此單一層並非獨立單元，而是由多個子層或函式串聯組成。這些子層函式主要分為兩類：全域性自注意力層，考量所有輸入信息生成輸出；以及局部單點層，針對單個詞元進行深入處理。故單一網路層同時整合了全局和局部信息的處理機制。", "label": 0}
{"text": "讓我們深入探究其內在運作原理：這些生成式AI，其根本功能是將輸入轉換為輸出，儘管輸入輸出形式可能複雜多樣，例如文字、圖片或聲音。", "label": 0}
{"text": "因此，深度學習架構中，多層網路的串聯結構是人工設計的，但各層的功能則由模型參數決定。", "label": 0}
{"text": "因此，有了鑑別器後，生成器將不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "要訓練出像Gini這樣的模型並不難，關鍵在於數據：只要提供遊戲畫面和對應的按鍵操作，就能輕鬆生成圖像。然而，Gini的訓練卻面臨了巨大的挑戰——它只能獲取大量的遊戲影片，卻無法得知玩家的實際操作，因此無法準確理解畫面與動作之間的關係。", "label": 0}
{"text": "什麼情境下需要AI能即時互動？例如語音對話，不像文字對話（如ChatGPT）的回合制，真實交流包含打斷、即時回饋（例如「嗯」、「對」），這些看似無意義的回饋，卻對流暢溝通至關重要。", "label": 0}
{"text": "這些噪點向量蘊藏著豐富的信息，可直接操控以微調輸出圖片。", "label": 0}
{"text": "生成複雜結構化物件，例如句子，早已是機器學習的成熟應用，機器翻譯便是其中一例。", "label": 0}
{"text": "比如說類神經網路 (Neural Network) 的架構，那你在看這個文獻的時候啊，常常會聽到有人說模型有幾B 幾B。7 B 模型、70 B 模型，這邊的7 B、70 B 指的就是參數的數量，這邊B 是 Billion 的縮寫，所以7 B 代表這個模型有7 個 Billion 的參數，一個 Billion 是10 億，所以就是70 億個參數，70 B 就是700 億個參數了。那參數的數量其實也是架構 (architecture) 的一部分啦，因為一個模型裡面會有幾個參數，這個是事先就決定好的。", "label": 1}
{"text": "那麼剛才有說，語音其實會被表示成一堆Unit，而這些Unit對於語言模型來說，就是一個全新的語言，他有一套自己獨特的符號系統，所以當我們要教一個原來的語言模型，聽懂語音的時候，其實對語言模型來說，他就是在學一個全新的語言，當然另外有一個可能是把語音的符號，跟文字全部倒在一起訓練，總之單憑語音資訊來訓練一定是不行的，一定要想些辦法利用文字的資訊，那我覺得這個地方可能就可以展現混合模式的好處，因為假設我們今天表示一段聲音不是隻用unit，而是有用到文字的話，那對於語言模型來說,它學習起來可能會更為容易，因為這些文字符號的意思,它早就知道了，它只需要花力氣去了解這些新的符號是什麼意思就好，當然這只是一個猜測。", "label": 1}
{"text": "那在我們的作業中，你就會體驗到到底AI agent做不做得了，機器學習這門課的作業。", "label": 1}
{"text": "有一些跟graph有關的RAG的方法，那你完全可以透過reflection的模組，把經驗建成一個graph以後，把那一些graph RAG的手法，直接套到AI agent裡面。那大家可能都知道說這個ChatGPT啊，現在其實真的是有記憶的，所以可以感受到這個OpenAI，想把ChatGPT變成一個AI agent的決心。", "label": 1}
{"text": "欲評估AI agent基於經驗調整行為的能力，可使用Streambench基準測試，其包含一系列問題，AI agent依序解答並接收二元回饋（正確或錯誤），藉此修正行為，提升後續問題的準確率；最終以整體平均準確率評估其經驗學習效率，學習效率高的agent應能在較短時間內、參考較少回饋，達到更高的平均準確率。", "label": 0}
{"text": "好那最後一段呢，想跟大家分享的是，現在人工智慧可以生成影像，但是有沒有機會讓人類跟這些生成的影像，有更及時的互動呢，舉例來說，每次在講SORA的時候，大家都會播放這個女士在東京街頭走的影片，有沒有可能我們直接用上下左右，來操控這個女士走哪一條路呢，那你就可以等於是操控一個Avatar，在東京街頭漫遊，就等於是打造出了一個開放世界的3D遊戲，有沒有可能做到這件事情呢?，還真不是不可能的，有一篇paper叫做，Genie: Generated Interactive Environments，就是想做類似的事情，我這邊先打個預防針，他做的不是3D遊戲，他做的都是2D橫向捲軸的遊戲而已。", "label": 1}
{"text": "生成式AI與人工智慧的核心組成元素是token；然而，圖像和語音生成的基礎單位並非像素或取樣點，而是更有效率的表達方式，此細節將於日後詳述。那麼，萬物皆由基本單位構成，是否正確呢？", "label": 0}
{"text": "深度學習模型的核心在於將問題分解成多個層次來逐步求解。", "label": 0}
{"text": "我們以西洋棋為例說明，您可能好奇現有語言模型能否玩西洋棋。事實上，早在2022年（我們稱之為「上古時代」，也就是ChatGPT出現之前），BigBench這個常用的語言模型基準測試就已嘗試過。當時的語言模型無法識別圖像，因此需要將棋盤上的黑白棋子位置轉換成文字描述輸入模型，再詢問模型下一步如何將軍。圖表顯示，當時即使最強的模型也未能给出正確答案，但其走法仍符合規則；較弱的模型則完全無視規則，胡亂下棋。", "label": 0}
{"text": "製作課堂投影片耗時費力，除非是直接向他人借用，否則幾乎所有時間都花在這上面了。那麼，能否利用AI技術自動生成投影片呢？如果AI能勝任所有投影片製作工作，教師的職位是否將不保？", "label": 0}
{"text": "關於記憶模組，我們先前討論過read函數，但所有資訊都需要儲存到長期記憶庫嗎？如果將agent所有經歷都儲存，長期記憶庫將充斥大量無關緊要的資訊，最終導致記憶體溢位。", "label": 0}
{"text": "本課程日後將採用以下方式引用論文：如論文可在arXiv找到，則直接提供連結。arXiv是一個公開預印本網站，因應AI領域快速變遷的特性，研究者常將論文直接上傳至arXiv公開分享，而非等待期刊或會議審查發表。", "label": 0}
{"text": "所以這邊引用的數據呢，是來自於 Stanford 大學的另外一篇 paper，叫做 s1: Simple Testing-Time Scaling。他們就告訴你說長度來湊還真的是有用的，橫軸是思考的時候用了幾個 token，縱軸是在不同任務上的正確率，你發現說想的越長正確率就越高。那講到這邊你可能會想說，那他們是如何操控思考的長度呢？其實這篇論文裡面用的是一個非常粗暴的方法，它的方法就是每一次這個語言模型產生結束的符號的時候，直接把那個符號拿掉，換成wait這個字，有語言模型本來想結束了，突然發現我怎麼說不了結束，這個符號怎麼變成wait，只好繼續做文字接龍，強迫它一直講下去，這個就是他們怎麼控制語言模型輸出長度的方法。", "label": 1}
{"text": "圖片生成模型僅憑文字描述便需產圖，而其未知的細節，唯有在生成圖像後方能得知，這與訓練時已知圖像資訊的情況大相徑庭，因此資訊抽取模型方能補足文字描述的不足。", "label": 0}
{"text": "那其實這些工具對語言模型來說，都是function都是一個函式，當我們說語言模型在使用某一個工具的時候，其實意思就是它在調用這些函式。它不需要知道這些函式內部是怎麼運作的，它只需要知道這些函式怎麼給它輸入，這些函式會給什麼樣的輸出，那因為使用工具就是調用函式，所以使用工具又叫做function code，所以有一陣子很多語言模型都說，他們加上了function code的功能，其實意思就這些語言模型都有了使用工具的功能。", "label": 1}
{"text": "OpenAI 首次提出「測試時間縮放」(Testing Time Scaling)的概念，意指以增加運算時間彌補模型深度不足，其官方部落格雖有說明，但資訊不夠透明，例如運算時間的單位並未明確指出，使人難以理解其實際操作。", "label": 0}
{"text": "怎麼訓練另外一個AI，一隻奔跑的狗長什麼樣子呢，這邊用的概念跟剛才的clip，基本上是一模一樣的，記不記得我們在講，這個怎麼衡量文字生圖模型好壞的時候，我們講了一個clip的模型，他會吃一張圖片，讀一段文字，看看這個圖片跟這個文字是不是匹配的，那在GAME裡面也會訓練一個，其實就跟CLIP根本就是一模一樣的模型，他只是換了一個名字叫做Discriminator，這個Discriminator他做的事情就是，給一張圖片、給一張文字，還要給一個評價，看這個圖片跟這個文字有多匹配，但是如果今天訓練Discriminator的時候，都只有好的例子，都只有跟這個影像匹配的文字的話，那Discriminator從來沒有看過壞的例子，他會他訓練的，如果你在訓練的時候都只給他好的例子，到時候測試的時候就算看到壞的例子，他也都會輸出這是好的。", "label": 1}
{"text": "兩個大型語言模型ChatGPT和DeepSeek嘗試西洋棋對弈的影片爆紅，觀看次數突破百萬，然而其表現卻令人啼笑皆非：規則理解偏差嚴重，例如將兵當作馬使用、主教無視阻擋、子力憑空出現等違規操作層出不窮，最終DeepSeek更以「城堡吃兵」的荒謬方式「獲勝」，ChatGPT也因此「認輸」。", "label": 0}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，其本質都是由有限的基本元素構成的，這些元素如同文字的符號、圖片的像素，共同組成了不同的信息形式。", "label": 0}
{"text": "所以讓一個AI agent記住他一生所有經歷的事情，告訴他你每次做一個決策的時候，都是根據你一生所有經歷過的事情再去做決策，那也許對AI agent來說並不是一件好事。最終當他的人生過長的時候，他會沒有辦法做出正確的決策，所以怎麼辦呢？也許我們可以給這些AI agent memory，這就像是人類的長期記憶一樣，發生過的事情我們把它存到這個memory裡面。", "label": 1}
{"text": "總之，人工智慧生成的影像能否實現即時互動？例如，操控SORA影片中的女性角色在東京街頭行走，如同操控開放世界3D遊戲中的化身漫遊，這項技術雖然目前僅限於2D橫向捲軸遊戲，例如Genie: Generated Interactive Environments論文中所述，但未來發展潛力巨大。", "label": 0}
{"text": "其實類似技術早已存在，例如2022年的Dialogue GSLM模型，若內容不易理解，可參考相關論文。", "label": 0}
{"text": "因此，從x生成y的過程，遵循逐次生成的策略：先根據所有x產生y1，再根據所有x和y1產生y2，依此類推，每次只生成一個y，直到產生yt。", "label": 0}
{"text": "所以，錄製大量Sky與他人的對話或許並非必要，因為如同先前討論文字模型時所提及，微調過程通常無需大量數據，預訓練模型已儲備豐富知識，微調僅是錦上添花；同樣地，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，即可有效學習其說話方式。", "label": 0}
{"text": "關於接下來的內容，請前往設定中的「個人化」選項，找到「記憶管理」功能，即可查看AI儲存的長期記憶。這些記憶是透過write模組儲存的，例如，其中一條記錄是您曾自稱「血輪眼卡卡」，AI因此將其自身與該身份聯繫起來。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力：僅訓練日英翻譯，即可自動掌握日韓、韓日互譯，並在內部形成一種共通的語言表徵，使得不同語言表達相同語義時，模型的內部反應一致。", "label": 0}
{"text": "Google Project Astra 的演示中，一個類似的案例說明了模型能力的展現：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時未提及。之後，使用者詢問所在位置（王十字車站附近），並詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍基於過往影像和語音資訊（眼鏡在桌上），自然地給出回應。", "label": 0}
{"text": "那麼，如何訓練這種基於語音的語言模型呢？  它與文字語言模型的訓練原理相同，皆仰賴海量數據——只是數據形式由文字轉為語音。  利用豐富的語音數據，即可訓練出用於語音片段接龍的語音語言模型。", "label": 0}
{"text": "要訓練模型去除雜訊，需要有乾淨圖像及其對應的雜訊圖像作為訓練資料。由於只有乾淨圖像及其文字描述，需自行生成雜訊圖像。方法是：通過隨機添加不同程度的雜訊到乾淨圖像，製造出不同雜訊程度的圖像對，從輕微雜訊到完全模糊不清，以此作為訓練資料。", "label": 0}
{"text": "也許一個可能性是，雖然我們本來的訓練資料裡面這些文字不足以完整的描述影像，但我們自己把本來文字沒提到的東西加進去，我們直接把多餘的資訊加進去，都跟圖片生成模型講說，你現在不只要生成一隻奔跑的狗，你是要生成一隻哈士奇在草原上奔跑的樣子，你不是隻生成一隻狗，你要生成柴犬在都市裡奔跑的樣子，把額外的原來文字沒提到的資訊，把它標出來，也提供給圖片生成模型，這樣圖片生成模型在生成的時候，他就知道說，為什麼同樣的輸入，這兩隻圖片會不一樣，因為有額外的資訊，他會讀取這個額外的資訊，再去生成圖片，他就不會有同樣的輸入，有會有不同的輸出的這種問題，他就不會有那種同樣的輸入，你想要叫他產生不同輸出的這種問題。", "label": 1}
{"text": "現在，讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著以「模擬人腦運作」等說法來解釋類神經網路的科普文章，但我們將更深入地剖析其內涵。", "label": 0}
{"text": "但實際上今天為了要蹭語言模型 (Language Model) 的熱度，接的東西不是文字,我們也會叫語言模型。比如接的是語音,我們也說這是語音版的語言模型，雖然說它其實就是語音模型,接出來的是圖片，我們也說是語言模型,雖然它其實是影像的模型。", "label": 1}
{"text": "先前我們與AI的互動模式，多半是提問及獲取回應，AI僅負責提供答案，不考慮後續影響或答案正確性。然而，一問一答模式難以處理多步驟任務，例如預約餐廳，若餐廳客滿，單純的語言模型僅能回報此訊息而無法進一步行動。", "label": 0}
{"text": "圖片生成模型使用隨機向量補充缺失的資訊，以文字描述為基礎，透過機率分佈產生所需向量，並將其輸入模型生成最終結果，此模型即為VAE。", "label": 0}
{"text": "反正今天只要是做這種接龍的行為，為了要蹭語言模型的熱度我們都把這些技術歸類為語言模型。", "label": 1}
{"text": "除了RE和Write模組，還存在一個暫名為「reflection」（反思）的第三個模組，其名稱並非固定。", "label": 0}
{"text": "因此，這些預測動作冠以「潛在」一詞，意指它們並非直接觀察所得，而是模型推測的結果。", "label": 0}
{"text": "現在，讓我們欣賞一下人類製作的投影片，看看它與AI生成的教材有何差異。", "label": 0}
{"text": "關於剛才那個不夠精確的比喻，想深入了解深度學習(DL)相較於淺層學習在函數效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個代表特定含義的數值向量；例如，向量各維度可能分別代表狗的品種和背景環境。", "label": 0}
{"text": "Deep Research 的功能就是你問它一個問題，比如說中部橫貫公路的歷史沿革，那如果你在 ChatGPT 的頁面上選下面這個 Deep Research (深入研究)，就會執行 Deep Research，也就是模型會開始上網搜尋，而且他搜尋的時候不是只是搜尋一次得到結果就開始寫報告，而是會隨著搜尋到的內容而產生更多的問題，最後寫出一個長篇大論的報告。那右邊呢是展現了當我問中部橫貫公路歷史沿革的時候，Deep Research的搜尋過程，這只是一部分的過程而已。他會先搜尋中部橫貫公路的主線跟支線，他就學到說中部橫貫公路有宜蘭支線和霧社支線，他再去搜尋霧社支線的起點和終點，發現說2018年有一個改道工程，他再去搜尋2018年中橫的改道工程，所以他會隨著搜尋到的結果不同改變他要搜尋的內容，那這是一種 AI Agent的能力。", "label": 1}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方式，但實際上方法多元，有些模型甚至專門為此訓練，其使用工具的方式可能需要特定格式才能啟動，這不在本次討論範圍內。  若您使用OpenAI ChatGPT API，會發現工具的使用需要指定特定欄位，OpenAI模型的工具使用方式也略有不同。", "label": 0}
{"text": "那這跟某一個ground truth，跟某一個正確的圖片學習，不一樣的地方就是，跟正確圖片學習的時候，可能同樣的文字會對應到不同的答案，但是現在是用一個Discriminator來評價好壞，所以沒有單一的正確解答，只要今天Generator，可以產生一張圖片,Discriminator是覺得好的,就成功了，沒有什麼樣的答案是正確的,沒有什麼樣的答案才是標準答案，只要另外一個人工智慧覺得好,基本上就是成功了。", "label": 1}
{"text": "因此，我將安排一次作業，讓大家運用AI進行網路搜尋並回答助教提問。此外，此AI還需具備一定的規劃能力，例如主動與使用者協商餐廳預訂，避免浪費時間和精力。事前仔細確認需求，雖略費時，卻能避免事後徒勞無功。然而，AI也需判斷何時需要確認，何時無需確認；例如，若AI每次網路搜尋都需徵詢使用者同意，則使用者必然不悅。總之，完成此類日常生活任務需要整合多種技能，我們將在下堂課詳細討論AI Agent。", "label": 0}
{"text": "之後，你還需要訓練一個解碼器，將語音單位轉換回音訊。", "label": 0}
{"text": "先前說明或許造成誤解，以為資訊抽取模型輸出必然是文字，這只是便於理解的簡化說法；對圖片生成模型而言，無需文字，只需傳遞特定參數即可。", "label": 0}
{"text": "那這樣的通用翻譯有什麼樣的好處呢？他甚至有可能有能力翻譯沒見過的語言，對比如說假設你教過他中英翻譯，德英翻譯還有德翻法，搞不好自動就會中文翻法文了。", "label": 1}
{"text": "因此，我想就當前語音技術發展，探討何種技術能實現GPT-4O級別效果，如有出入，敬請包涵。", "label": 0}
{"text": "因此，僅依靠一百萬小時語音數據訓練的模型，雖然能學習到部分語音信息，但知識儲備仍顯不足，必須結合文本數據才能完善模型訓練。", "label": 0}
{"text": "所以不管是你要輸入什麼、輸出什麼，我們都可以不失一般性地說，就是輸入一串 token，輸出一個 token，所以不管是你要文字生文字，文字生圖、圖生文字、語音生文字、文字生語音都是一樣的事情，它們背後的原理其實是一樣的。那再來要問的問題就是，怎麼輸入一串 token 決定下一個 token 是什麼呢？你需要一個函式 (function)，我們這邊寫作 f ，這個函式 (function) 它的輸入就是 z1 到zt-1，輸出就是zt，那這個函式 (function) 其實就是類神經網路 (neural network)。那我實際上這個 neural network 在運作的時候，並不是真的產生一個 token，它產生的是一個 token 的機率分佈。因為 token 的可能性是有限的，所以類神經網路 (neural network) 真的輸出是，它會給每一個 token 一個分數，代表這個 token 作為下一個 token 有多合適，這個 token 當作下一個 token 的機會有多大。", "label": 1}
{"text": "那 Transformer 還是，雖然說今天的語言模型一般它的基底都是用 Transformer，不過 Transformer 還是有很多的限制，尤其是最大的限制是當輸入太長的時候，Transformer 的運作可能就會出現問題，尤其是今天我們希望模型演腦內小劇場。那當模型在演腦內小劇場的時候，Transformer 的輸入可能就會非常的長，因為 Transformer 裡面它有Self Attention的layer，Self Attention通常是看過整個輸入以後才能夠給入，才能夠給你輸出。", "label": 1}
{"text": "我們來看一下模型在這個狀況，要怎麼運作，語音版的語言模型就是同時，聽這兩個頻道的內容，包括現在人在說什麼，他之前講過什麼，現在人說了個我，那感覺這句話還沒有說完，所以語音版語言模型就輸出 silence，輸出安靜，安靜可能也是有某一些特殊的speech unit，代表安靜，就不說話，然後接下來呢，人就會繼續說，也許人說到某一個段落，那語音版的語言模型，根據人現在說的話，覺得那他說完了，輪到我說了。", "label": 1}
{"text": "與其他模型不同，GAM因其根本差異，在此未作特別比較，它更像是一個附加功能。", "label": 0}
{"text": "arXiv連結的數字前兩位代表年份，後兩位代表月份，方便快速判斷論文上傳和發表時間，有助於理解研究的歷史脈絡。", "label": 0}
{"text": "這些向量或我們叫做noise，他其實裡面也是有豐富的資訊的，你甚至可以直接調整這一些向量，就打造調整輸出圖片的效果。", "label": 1}
{"text": "我一開始看到那則報導就感到不解，為何要使用YouTube影片訓練語言模型？難道現有文字數據已用罄？若OpenAI訓練的是語音模型，則使用YouTube影片便合情合理。", "label": 0}
{"text": "既有圖片生成模型，無論其來源，先用它生成一些圖片：奔跑的狗、抽象的狗和陽光下的貓。模型可能產生缺陷，例如生成三腳的抽象貓。  將這些結果，包含成功的和失敗的，分別標記為好與壞，訓練鑑別器學習圖片與文字描述間的匹配度。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，此序列由基本文字單位構成，故樹結構亦可視為基本單元序列。", "label": 0}
{"text": "鑑於Transformer模型的學習困境，尤其在龐大訓練資料集中難以聚焦，我們決定先簡化影像生成模型。", "label": 0}
{"text": "因此，大型語言模型的工作機制是：設定目標、觀察環境、採取行動、觀察結果，並以此循環往復，所有行為都基於其固有的文本預測能力。所以，AI代理並非語言模型的技術革新，而是一種應用方式。", "label": 0}
{"text": "倘若我敷衍了事，便可直接沿用先前的投影片教學；因此，對於僅需流水帳式講解的課程，人工智能足以勝任投影片製作，並進一步生成虛擬教師，實現全自動化教學，毋需真人授課。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此促進提升。", "label": 0}
{"text": "不懂大型語言模型？沒關係！先看看《生成式AI導論2024》，最好全部看完，不行的話至少看第8講，很輕鬆的，利用零碎時間就能看完。", "label": 0}
{"text": "如此一來，或許你會質疑為何不直接利用語音辨識與語音合成系統作為編碼器和解碼器？的確，語音辨識可視為一種獨特的壓縮方法，將聲音轉換為文字的過程，本身就是一種資訊壓縮，因為文字可被理解為語音的精簡呈現。", "label": 0}
{"text": "因為你看這個GPT-4ALL的DEMO，模型是可以一邊看著東西一邊說話的，所以可能有不只有聽跟說兩個頻道，還有一個視覺的頻道，專門讀取外界的影像輸入，舉例來說,在這個OpenAI的Demo裡面，有一個Demo就是，這個語言模型正在描述房間中的燈光，講得非常的奇跡，這時候有一個人跳出來，比了一個Yeah的動作，語言模型無視這個影像，繼續談他的燈光，不知道他有沒有看到這個比Yeah的人，這時候人就打斷語言模型說，等一下,你有沒有看到什麼奇怪的東西，語言模型顯然是有看到比Yeah的這個人的，只是在講燈光的時候他講得太爽了，所以就沒有覺得需要對這個人發表，比Yeah的人發表任何的評論，但是當有人問他說，你有看到什麼怪怪的東西的時候，這個時候語言模型會做的事情是，他會對每一個Channel，不只是他現在生成的Channel，還有他聽的Channel，還有他看的Channel，通通去做Attention，所以他會收集所有的資訊，然後得到一個答案，那可能就會知道說有人比了一個頁。", "label": 1}
{"text": "因此，你可以訓練你的降噪模型，讓它學習從加噪後的圖片和文字描述中，還原出原始圖片。", "label": 0}
{"text": "此圖橫軸代表1750個問題，縱軸則為平均準確率。灰色線顯示模型未經訓練，每個問題回答獨立且無關聯時的最低準確率。黃色線則呈現模型僅參考固定5個問題作答時的準確率。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例說明微調ChatGPT的過程及其效果。", "label": 0}
{"text": "圖片生成模型僅憑文字描述便需創作圖像，而生成前模型並不知曉文字未提及的細節，與訓練時已知圖像資訊的情況大相逕庭，故資訊抽取模型方能補足文字描述的缺漏。", "label": 0}
{"text": "直接修改神經網路中與「誰是全世界最帥的人」相關的參數，是否能繞過模型訓練，強行植入特定信念？  這項技術，稱為模型編輯，我們將在第八講和作業八中深入探討，並學習如何編輯參數及整合不同模型。", "label": 0}
{"text": "儘管採樣點理論上數量無限，但實際儲存時每個點僅使用有限位元(例如一個位元組)，導致其可能取值有限，雖然組合後能呈現近乎無限的可能性。", "label": 0}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或報告，我以下的推測純屬個人臆斷，缺乏任何官方證據支持。", "label": 0}
{"text": "因此，文本模型的訓練需仰賴蒐集大量人機對話數據，例如使用者詢問身份時，模型應回應「我是AI」；使用者要求協助入侵鄰居Wi-Fi時，模型則需拒絕。這些數據用於微調模型，使其能流暢地與使用者互動。語音模型的訓練則需蒐集語音對話數據，由一人扮演使用者，一人扮演AI，透過此種方式微調模型，使其能理解並回應語音指令。", "label": 0}
{"text": "我們這邊就沒有特別把GAM，拿出來跟其他的模型一起講，為什麼，因為GAM跟其他模型，其實有本質上的差異，它比較像是一個額外的外掛。", "label": 1}
{"text": "接下來，我們將從三個方面深入探討這些AI代理的核心能力：基於經驗的行為調整、外部工具的運用，以及規劃能力。首先，我們分析AI代理如何根據過往經驗和環境反饋調整其行為。", "label": 0}
{"text": "本課程將深入淺出地剖析生成式AI的技術革新及未來趨勢，並在有限時間內，快速綜覽其近期發展與值得關注的未來技術。", "label": 0}
{"text": "重複使用降噪模組處理，或許能使影像更清晰地呈現貓的樣貌。", "label": 0}
{"text": "儘管採樣點數量看似無限，但每個點的儲存空間有限（例如，僅使用一個位元組），導致可能的取樣點組合數雖然龐大，卻仍然是有限的；有限的單元，有限的選擇，卻能創造出近乎無限的可能性。", "label": 0}
{"text": "記不記得剛才幾個模型都需要輸入一個Noise，進行腦補，輸入一個 noise 包含腦補的資訊，然後產生一張圖片，Diffusion Model 裡面的 decoder 做的事情，也是一樣的，只是 Diffusion Model 不一樣的地方，是他會反覆的使用同一個 decoder。", "label": 1}
{"text": "語言模型常用的工具包括搜尋引擎、自行編寫和執行的程式碼，甚至其他AI模型。不同AI模型能力各異，例如文字模型可藉助圖像或語音AI處理多模態任務；或小型模型可呼叫大型模型解決超出自身能力範圍的問題，以節省大型模型的運算資源。", "label": 0}
{"text": "AI agent與RAG的關鍵差異在於記憶內容的來源：RAG使用網路數據，而AI agent則使用自身經驗；然而，兩者皆可沿用相同的搜尋技術。", "label": 0}
{"text": "語音辨識系統能自動區分不同說話者，並標記出各段語音對應的說話者身份。", "label": 0}
{"text": "實際應用此模型時，缺失資訊的來源及本質，往往難以捉摸。", "label": 0}
{"text": "對模型的局部調整，可能導致意料之外的全局性影響，我們將在第六講和作業六中詳細探討如何避免此類問題。例如，若想讓模型回答「全世界最帥的人是李宏毅」，需準備特定訓練資料，但此舉可能造成模型將所有問題的答案都答成「李宏毅」，即使是原本能正確回答的問題，也將產生錯誤。", "label": 0}
{"text": "另外一個看起來像是 AI Agent的能力，就是 Claude 的 Computer Use 或者是 ChatGPT 的 Operator，這 Computer Use 或者是 Operator 他們要做的事情就是，現在這些生成式人工智慧不只是生成，它還要能夠操控物件。那可能要操控機械手臂仍然非常的困難，但是現在基本上可以操控，數位世界中能夠碰觸到的滑鼠或者是鍵盤了，那這些生成式AI 怎麼操控滑鼠跟鍵盤呢？這個方法就是你先給它一個任務指示，然後給它一個螢幕截圖，那現在這些模型都是可以看圖的嘛，那看到這個螢幕截圖看到這個指示，它會輸出文字，但它輸出的文字是要如何去操控滑鼠跟鍵盤。比如說它會輸出文字說，把滑鼠移動到螢幕的這個位置，這個是指螢幕上位置的座標。這邊就需要開發者真的去寫一個小程式，把滑鼠移動到指定的位置，那滑鼠移動到指定的位置以後，螢幕截圖看起來可能就不一樣了，螢幕截圖不一樣之後就會產生新的輸出。比如說語言模型、生成式人工智慧，會說按下 Enter，那就寫一個小程式。", "label": 1}
{"text": "根據這篇論文的講法,他們並沒有對輸入的文字做任何特殊的處理，模型就是直接讀輸入的文字，但他在讀到 whisper 輕聲這個字的時候，他自動知道他要用比較輕的聲音來唸這個句子，這是他自動根據資料學到的，當然這邊可能合出來的聲音沒有非常的戲劇化，我們今天看這個GPT-4的Demo，它的聲音的合成是可以更戲劇化的，你要叫它講輕聲的時候，它是可以講得更輕聲的，但也許把資料從十萬小時擴展到一百萬小時的時候，就是會有這種效果，當然因為我從來沒有訓練過這麼多，從來沒有用過這麼多資料訓練語音合成的系統，所以這只是個猜測。", "label": 1}
{"text": "然而，資訊抽取模型的訓練卻面臨著數據獲取的巨大挑戰：缺乏大量的、已標註的輸入輸出配對數據，以及高效、準確的數據標註方法。", "label": 0}
{"text": "生成文章時，長度難以預測，故需藉由特殊標記「結束」訊號終止生成過程，此方法稱作自迴歸生成，亦即文字接龍，只是接的並非僅限文字，而是各種不同的標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "這邊有一個方法是，在不需要額外標註資料的情況下，就可以把資訊抽取的模型訓練出來。", "label": 1}
{"text": "Flow模型質疑：既然編碼器提取信息，解碼器重建圖片，兩者功能相反，為何非要訓練兩個模型，只訓練解碼器即可。", "label": 0}
{"text": "所以，為何將單一步驟細分為多個步驟能提升效率？不妨想像每個步驟如同一個函數表，輸入數據後，每個表都會給出對應的輸出結果，這就能幫助我們理解其益處。", "label": 0}
{"text": "這個方法是這樣的，圖片生成的模型跟資訊抽取的模型，它們可以一起被訓練，他們有一個共同的目標，他們共同的目標是什麼呢，他們的共同目標是，資訊抽取的模型，讀訓練資料裡面的一張圖片，那訓練資料的每一張圖片，都有附一段文字的描述，把文字的描述也讀進去，他可以看看有哪一些，文字的描述沒提到的東西，把它抽取出來，那再把這些抽取到的資訊，丟給圖片生成的模型，圖片生成的模型看到這些，在讀這段文字的敘述產生一張圖片。", "label": 1}
{"text": "好的，接下來我們進入擴散模型的介紹。前面已講解了VAE和基於流的模型，現在讓我們繼續探討擴散模型。值得注意的是，擴散模型的解碼器輸入和輸出與之前的模型保持一致。", "label": 0}
{"text": "Genie的目标是开发一款横版2D卷轴游戏，为此需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也可视为一种特定输入。有了这些数据，训练前述模型将易如反掌。", "label": 0}
{"text": "影片生成模型的核心是大量Transformer，透過反覆去噪(denoising)過程，逐步淨化帶噪影像塊(patch)。每個Transformer接收帶噪影像塊，輸出更乾淨的影像塊，經數百甚至數千次迭代後，最終生成一系列乾淨影像塊，再重構為完整影像，此即Diffusion Model結合Transformer的影像生成機制。", "label": 0}
{"text": "懶惰的老師們有福了：AI能輕鬆製作投影片和數位分身，自動生成一堂課，省時省力。", "label": 0}
{"text": "語音辨識系統能根據輸入的聲音訊號，自動區分不同說話者的語段，精準標記出各段落對應的說話者。", "label": 0}
{"text": "那如果傳統的方法都是500、1000次，那很多人就會想說有沒有辦法，10次就好，有沒有辦法5次就好，甚至1次就好，那這個是今天研究的一個趨勢。", "label": 1}
{"text": "那有人可能會想說，那是不是需要錄很多Sky跟其他的對話呢，也許不一定需要，因為記不記得我們在講文字模型的時候，我們有說其實Finetune往往不需要太多資料，模型在Pretrain的時候，已經擁有非常豐富的知識，Finetune只是畫龍點睛，那今天會不會做完語音的pre-train以後，模型已經很會模仿各種不同的人說話，他只要聽過幾句sky的話，就可以很好的學會sky說話的方式了。", "label": 1}
{"text": "因此，文字模型的訓練需要收集使用者與AI互動的資料，例如使用者詢問身份時，模型應回答「我是人工智慧」，並拒絕例如「教我入侵鄰居Wi-Fi」等不當請求；語音模型則需蒐集使用者與扮演AI角色者的語音對話資料進行微調，以提升其語音互動能力。", "label": 0}
{"text": "好的，我會把您週五下午的機器學習課程記錄下來。", "label": 0}
{"text": "他把我誤認為台大學生，其實我是老師，這誤解源於過去的談話，導致他記錯了。他習慣性地記錄我所有的演講和教學活動，這些資訊就這樣被他儲存在腦海裡了。", "label": 0}
{"text": "好，他就停在這裡。他找到了加簽表單，雖然我要求他填寫後送出，不過填加簽表單是要Gmail帳號的啦，所以他沒辦法填。", "label": 1}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，需要開發的翻譯系統數量龐大到令人望而卻步。", "label": 0}
{"text": "好的，在深入探討端到端語音模型前，讓我們先回顧一下文本語言模型的訓練過程。文本語言模型訓練包含三個階段：預訓練(Pretrain)使用大量未標記數據進行訓練；微調(Finetune)使用少量標記數據進行調整；以及基於人類反饋的強化學習(RLHF)使用用戶反饋數據優化模型。後兩個階段(Finetune和RLHF)統稱為對齊(Alignment)。若您對此過程不甚了解，建議先觀看我之前的教學錄影或近期發布的生成式AI策略影片，學習生成式AI的基本原理，再繼續本課程。", "label": 0}
{"text": "與其他模型不同，GAM的獨特性使其不適合與之歸類比較，它更像是一個附加的功能模組。", "label": 0}
{"text": "2023年我們曾教授AI agent相關課程，不妨比較一下當時與今日AI agent的技術差異，您會發現2023年的AI agent熱潮很快便因其能力不及預期而消逝。", "label": 0}
{"text": "面对电话那头毫无回应，你自然会质疑对方是否在认真倾听；同样的，我们能否让AI在语音交互中，像人一样自然流畅，而非僵硬的轮流对话？GPT-4O的高级语音模式或许已在某种程度上实现了这种实时互动。", "label": 0}
{"text": "Sora利用Diffusion Transformer，將Diffusion模型與Transformer結合：Transformer不再直接生成圖像Patch，而是迭代地去除雜訊Patch，每次迭代都使用相同的Transformer參數逐步去噪，經過數百甚至數千次迭代後，生成乾淨的Patch，最終經解碼器還原成完整圖像。", "label": 0}
{"text": "以下的內容是來自於 Google 的一個 blog，他們告訴你說，你看我們就教這個語言，我們就教我們的生成式人工智慧，Google 翻譯幾種翻譯，比如說日文翻英文，從來沒教過它日文翻韓文，它自動會了，從來沒教過它韓文翻日文，它自動會了。而且他們也發現說這些模型內部，確實有一種他們自己才看得懂的內部語言，怎麼說呢？同樣意思的英文、韓文跟日文的句子，丟給這個模型的時候，它內部的反應是一樣的。", "label": 1}
{"text": "而這個reflection的模組，可能也是一個語言模型，就是AI agent自己，你可以只是把過去的這一些記憶，丟給reflection的模組，然後叫reflection模組想一想，看他從這些記憶裡面，能不能夠有什麼樣新的發現。比如說可能有一個observation是，我喜歡的疫情每天都跟我搭同一部公車，另外observation是他今天對我笑了，那你推出來的reflection模型，結果就說他喜歡我這樣，一個錯覺，人生三大錯覺之一就是這一種。就得到一些新的sort，你就得到一些新的想法，那你之後在做決策的時候，就可以用這些新的想法，雖然你沒有實際觀察到，但它是被推論出來的，根據這些推論出來的想法來做決策。那除了產生新的想法之外，也可以為以前觀察到的經驗，建立經驗和經驗之間的關係，也就是建立一個，然後讓reader的module根據這個knowledge graph來找相關的資訊。", "label": 1}
{"text": "早在2017年的「Words of Bits」論文就已探索利用AI代理操控電腦，這並非近期才有的想法；文中自稱是基於網頁的代理，其互動介面相對簡陋。", "label": 0}
{"text": "這個影片的目標聽眾是，語音技術背景的聽眾。如果你已經是語音領域的專家的話，這部影片講的內容對你來說，可能就太科普了。先說明一下我假設聽這個影片的同學，是有修過生成式人工智慧導論的。如果你還沒有看過這堂課的影片的話，你可以在這個連結找到這堂課的影片。那如果你看過這堂課的影片的話，可以讓你更瞭解，我現在這部影片裡面，所要講的內容。", "label": 1}
{"text": "在影片的模型裡面，你就是有一堆的 Transformer，在這個影片生成的過程中，你就是會不斷的做 Denoise，那這個 Denoise 是由一個 Transformer 的模型完成的，它的輸入就是有雜訊的 patch,輸出就是比較乾淨的 patch，這個 Transformer 會做好幾百次、好幾千次的去照之後，期待最後產生一堆乾淨的 patch，那這些乾淨的 patch 就可以被還原為影像，這個就是今天用 Diffusion Model 加上 Transformer 生一片的模型。", "label": 1}
{"text": "現今部分人工智慧已展現推理能力，不再僅是單純的輸入輸出，而是透過多種方案的嘗試、驗證及比對，最終呈現最佳解法，並將其思考過程公開呈現。", "label": 0}
{"text": "採用RAG方法從記憶庫中篩選出與當前問題最相關的經驗，能獲得更高的準確率，效果優於僅使用單一知識來源，最佳結果則來自論文中於StreamBench平台上提出的方法。", "label": 0}
{"text": "那有哪些語言模型常用的工具呢？最常用的就是，就是搜尋引擎,然後呢,語言模型現在會寫程式,而且可以執行他自己寫的程式,那這些程式也算是某種工具,甚至另外一個AI也可以當作是某一個AI的工具,有不同的AI,有不同的能力,比如說現在的語言模型,如果他只能夠讀文字的話,那也許可以呼叫其他看得懂圖片,聽得懂聲音的AI,來幫他處理多模態的問題,或者是說,或者是不同模型它的能力本來就不一樣。也許平常是小的模型在跟人互動，但小的模型發現它自己解不了的問題的時候，它可以叫一個大哥出來。大哥是個大的模型，那大的模型運作起來就比較耗費算力，所以大的模型不能常常出現。大的模型要在小的模型召喚它的時候，才出面回答問題，大哥要偶爾才出來幫小弟解決事情。", "label": 1}
{"text": "那有一段聲音訊號進來會標出說哪一個段落是語者A說的，他可能會用A冒號一個特殊的符號來代表這是A說的話，然後可以用文字表示的地方可能用文字表示，那不能用文字表示的地方可能就拿特殊的符號用SpeechUnit來表示，這個是對於語音版的語言模型看到一段聲音訊號的時候，它實際上輸入的猜想。", "label": 1}
{"text": "若有人提議進行一項有趣的實驗，語言模型或許會以「哇」來表達興奮之情，並積極參與；若使用者保持沉默，模型則可能回應「我期待著」；但若使用者發聲下達指令，語音模型則會偵測到指令未完成，並以靜默符號回應，等待指示完成。這僅為一種可能的模型互動方式，實際應用中可能存在其他解決方案，甚至需要整合聽、說、看的多模態能力。", "label": 0}
{"text": "那現在啊，這些人工智慧它還展示出類似思考的能力，那通常我們把這個過程叫做 reasoning ，什麼叫做展示思考的能力呢?過去啊，我們在使用這些生成式人工智慧的時候你給它一個輸入 (Input)，給它一個問題，它就直接給你一個答案，但是現在很多的生成式AI，比如說ChatGPT的 o1, o3、還有DeepSeek，還有 Gemini 的 Flash Thinking ，它們在問一個問題的時候，它都不是直接給，都你在問它一個問題的時候，它不是直接給你答案，而是它會演一個腦內小劇場給你看，它就說我們先試試看 A 解法吧！解完之後自己驗證一下答案，發現，嗯，不對再試一下 B 解法吧！它驗證一下嗯好像是對的， B 解法不錯，但我們也可以嘗試一下 C 解法，嗯，看起來沒有比較好，那把腦內小劇場演完之後才給你答案，所以我們用的就是 B 解法的答案。那通常這些模型在展示它的結果的時候，它會把腦內小劇場放在一個框框內，告訴你說這是它的內心戲，不是真正的答案，然後最後才給你真正的答案。", "label": 1}
{"text": "看來模型的微調產生了意料之外的副作用，嘗試讓它創作唐詩，結果卻鬧出笑話，不僅格律不符，內容更是令人啼笑皆非。", "label": 0}
{"text": "核心問題在於，若讓語言模型儲存所有過往經驗以調整行為，等同於每次決策都需回顧完整經歷。少量經驗尚可應付，但經驗累積過多，模型將因算力不足而難以有效運用過往資訊，導致決策失準。", "label": 0}
{"text": "解碼器如同一個改良的語音合成器，以語音單位而非文字作為輸入，其功能在於將語音單位轉換為可聽的語音。", "label": 0}
{"text": "於是，我將資料交給Claude，請它以視覺化的方式呈現DeepSeek的架構。Claude高效地完成了任務，生成的網頁直觀易懂，並預覽了程式執行結果，其中顏色配置也由Claude自動完成。網頁左側顯示姜子牙的能力，右側顯示鄧不利多的能力。需要說明的是，十絕陣並非姜子牙的能力，而是其敵人咒王一方所設。", "label": 0}
{"text": "多種語言輸入模型後，模型會將其轉化為自身獨有的內部表徵，實現不同語言間的共享，其內在機制日後再詳述。", "label": 0}
{"text": "簡而言之，我們旨在訓練模型 f_θ 輸出最佳概率分佈，使目標 Token 的概率遠超其他 Token，從而最大化模型對訓練資料的擬合度。", "label": 0}
{"text": "然而，微調最大的風險在於，看似成功的任務背後，模型可能出現不可預期的異常行為，例如對原本能準確回答的問題，開始產生謬誤的答案。", "label": 0}
{"text": "所有強大的模型都能使用一種簡單通用的方法來使用工具：直接在提示詞中說明工具的使用方法，並以`Tool`標記區分工具指令，以`Output`標記區分工具輸出結果。  例如，定義一個`Temperature`函數查詢天氣，並提供使用範例 (例如，`Temperature(\"台北\", \"2024-10-27\")`)。將工具使用方法及你的問題（User Prompt）與系統說明（System Prompt）一起輸入模型，模型會根據需要調用工具。系統說明（System Prompt），即開發者每次使用的固定指令，例如文字接龍的設定；而使用者問題（User Prompt）則是每次變化的查詢，例如「2024年10月27日高雄氣溫如何」。  若使用ChatGPT API，則需區分System Prompt和User Prompt。", "label": 0}
{"text": "我們以西洋棋為例說明大型語言模型的能力。2022年，也就是ChatGPT出現之前的年代，研究人員已利用BigBench這個基準測試，評估當時的語言模型能否下棋。由於當時的模型無法處理圖像，棋盤資訊需以文字描述輸入。實驗中，模型需根據文字描述的棋盤狀態，判斷下一步如何將軍。結果顯示，即使是當時最先進的模型也無法给出正確答案，但至少能遵循西洋棋規則；而較弱的模型則完全無視規則，胡亂下棋。", "label": 0}
{"text": "除非你的投影片是直接跟別人借的，不然做一門課的投影片是最花時間的。那我們能不能夠直接讓人工智慧來做投影片呢？如果它可以直接做完整的投影片的話，我們就可以把老師淘汰了。", "label": 1}
{"text": "既有圖片生成模型，無論其來源，先用它生成幾張圖：奔跑的狗、抽象的狗、陽光下的貓。即使生成的結果不盡如人意（例如：三腳抽象貓），也可將其作為負例，與良好的圖像樣本一起訓練鑑別器，使其學會評估圖片與文字描述是否匹配。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话中的所有信息整理成表格，并精准输出包含各种信息的表格。  我们接下来将分享赋予AI新能力的方法。  如今，我们已进入机器的终身学习时代，这与人类的终身学习不同，指的是机器持续学习的能力。  这源于机器与以往的差异：过去训练AI需要从零开始，如同抚养孩子一般；而现在，许多通用模型已具备基础能力，如同招聘一位大学毕业生，只需教授其特定工作技能，而非从基础知识开始。  即使如此，持续学习仍然必不可少，这就是机器终身学习的时代。", "label": 0}
{"text": "請注意，ChatGPT 聊天介面本身並不支援參數微調；此功能需透過專門介面，上傳訓練資料，模型據此調整參數，從而實現特定行為。以下展示 GPT-4o-mini 微調前後的差異：原模型回答「你是誰？」為「我是一個人工智慧助手」；微調後則回答「我是小金，專長是機器學習、Debug 及解答學生問題」。同樣地，「描述你的外表」問題，原模型回答「我沒有實際外表」，微調後則回答「我的外表是一行程式碼」。  微調後的模型甚至能理解「助教」的概念，並展現出一定程度的舉一反三能力，例如回答學生問題時以「else continue」回應，成果令人滿意。", "label": 0}
{"text": "2017年，在大型語言模型和BERT問世之前，AI agent只能處理簡單網頁，當時的技術手段是使用卷積神經網絡直接處理螢幕畫面，以預測滑鼠點擊或鍵盤輸入，探索AI agent在網絡環境中的應用。這套方法相當原始，可謂AI發展史上的早期階段。", "label": 0}
{"text": "因此，降噪模型的訓練目標是學習如何去除噪聲，那麼，如何訓練這個降噪模組呢？", "label": 0}
{"text": "Decoder的工作原理，每次生成图像时，都只专注于去除噪声。", "label": 0}
{"text": "那這樣AI助教，它可以讀懂課程的資訊，可以讀懂你的指令，它就可以按照你的需求做運作。當我們用這種方式讓機器具備某種能力，做某件事情的時候，它的參數是固定的，也就是模型背後的運作其實是固定的。而這一些你額外提供的資訊跟指令，不會永遠改變這一個模型的行為，當我們不再提供給AI助教這一串指令的時候，它就會回復到它原本的樣子。就好像一個人他去公司工作，公司有固定的規範，他會按照公司固定的規範來調整他的行為，但是一離開公司回家就變成原來的樣子，這個就是用指令來讓AI做某件事情時候的狀態。", "label": 1}
{"text": "在文字的介面上，AI很清楚什麼時候輪到他講話，但是如果是一個語音的介面，那AI就必須要猜，他什麼時候可以開始講話，另外一方面，也許今天有人叫語言模型講一個故事，他開始講一個無聊的故事，山上有座廟，廟裡有個老和尚，這個故事會不斷的循環下去，是一個無限循環的故事，那人聽了就很厭煩，跟他說停停停，這不是我要聽的，那語音版的語言模型，他知不知道要停下來呢，那也許你說這是什麼問題，反正只要人說話，我們就停下來，這個不是最好的解決問題的方法，因為也許這個人講話，並不是要語言模型停下來啊，也許現在人正好在跟這個AI合唱，所以並不是只要聽到人的聲音，就必須停下來，所以假設今天要讓一個語音版的語言模型，跟人有自然的互動，要讓模型可以同時聽跟說，但原來的文字接龍的方式，聽跟說是切開的，模型在說的時候，它就很難繼續進行聽這件事情，那一個可能的解決方法，是把聽跟說這兩件事情分開來。", "label": 1}
{"text": "生成式AI藉由組合稱為「token」的基本單位，創造出看似相同但實際上獨一無二的內容，例如語音、圖像或文字，即便輸入條件相同，輸出結果也總存在差異，因為有限的元素能產生無限的可能性，「token」一詞也常被譯作「代幣」。", "label": 0}
{"text": "藉由整合現有技術，例如能辨識情緒的額外模組、能解讀符號指令（如括號笑）的語音合成系統（例如Zuno AI的Bark）及可理解文字指令的系統（例如Meta的AudioBox），開發GPT-4O的語音介面並非遙不可及，但提升即時性仍需克服工程上的挑戰。", "label": 0}
{"text": "他把我誤認為台大學生，其實我是老師，這源於之前的談話產生了認知偏差。他腦中儲存了許多資訊，包括我的演講和教學紀錄，卻記錯了我的身份。", "label": 0}
{"text": "實際應用此模型時，缺失的資訊始終未知，這些資訊的補充來源何在？", "label": 0}
{"text": "清晰影像的生成，源於雜訊的逐步消除，這正是擴散模型的典型特徵。", "label": 0}
{"text": "公司A的程式碼生成模型英文能力強，但中文能力弱；另一模型中文流利卻不擅程式設計，且兩者皆擁有各自私密的訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即使沒有訓練數據，我們仍可透過模型融合 (Model Merging) 技術，直接合併這兩個模型的參數，創造出一個既能寫程式又能用中文溝通的模型，這正是第九講作業的內容。本次課程涵蓋模型行為、運作機制、訓練方法及能力拓展等面向，感謝各位參與。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，本質上是由基本文字單元組成的物件序列。", "label": 0}
{"text": "深度不足，則以思考深度彌補之。", "label": 0}
{"text": "那產生長篇大論、產生圖片、產生聲音，背後它的共同的原理是什麼呢？這些看似非常複雜的東西，其實都是由有限的基本單位所構成的。假設我們把這些東西用y來表示，那這個y可以指一段畫，可以指一張圖片，可以指一段聲音，它背後其實都是由一些基本單位，這邊用y1、y2、yi來表示，它是由基本單位所構成的，對一段文字來說，它的基本單位，就是組成這些文字的符號。比如說在中文裡面，我們可以說一個方塊字就是一個基本單位。對於圖片來說，如果你把圖片放大的話來看，圖片是由一個一個的像素 (pixel) 所組成的。", "label": 1}
{"text": "各位同學，大家好！我們開始今天的AI Agent課程吧，這是一個目前備受關注的領域。", "label": 0}
{"text": "實驗在多個StreamBench數據集上驗證，結果顯示：未經經驗調整的模型表現最差（縱軸0）；利用正負樣例訓練的模型（藍色線）大多表現優異；僅使用負樣例訓練則無效甚至有害。", "label": 0}
{"text": "然後呢，他也記得就我剛才跟他講的，週五下午要上機器學習這門課。但是呢，但是其實模型的記憶也是會出錯的。因為要寫什麼樣的東西到記憶裡面，是模型自己決定的，而且他並不是把對話的內容，就一五一十的直接放到記憶裡面，他是經過一些昇華反思之後才放進去的，所以他的反思可能會出錯。", "label": 1}
{"text": "今天一個類神經網路 (Neural Network) 的深度是有限的，但是思考的過程可以是要多長有多長。而這邊稍微補充一下，有的同學如果很熟悉類神經網路 (Neural Network) 的運作的話，你可能會說這種深度不夠長度來湊的方式，跟一般的類神經網路 (Neural Network) 不一樣啊。因為這邊每一個紅色箭頭裡面的參數，通過的參數都是一樣的啊，這樣會有用嗎？那我推薦你一篇史前時代19年的文章叫做ALBERT，那時候他就是告訴你說，就算是每一個 layer 都是一樣的，把同樣的 layer 疊很多次還是可以有比較好的結果的。", "label": 1}
{"text": "那這個技術呢過去也是有過的，有一個模型叫做Dialogue GSLM，這個是22年就已經有的模型，所以等一下講的東西，如果你聽不太懂的話，你可以參考這一篇論文。", "label": 1}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個包含特定語義資訊的數值向量；例如，向量中各個維度可能分別代表狗的品種和拍攝背景。", "label": 0}
{"text": "GENIE的應用潛力無限：只需一張兒童塗鴉或一張雷神索爾照片，就能輕鬆創建互動遊戲，簡單點擊就能實現角色跳躍等動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "強迫神經網路給出單一答案，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈模式，讓模型預測每個詞彙接續的可能性，再透過隨機取樣決定最終輸出，如此一來，即使輸入相同，每次生成的結果也會有所不同。", "label": 0}
{"text": "訓練過程中，模型可能因訓練資料的多樣性而混淆：例如，「奔跑的狗」可能指草原上的哈士奇或都市裡的柴犬，導致模型在生成圖像時，因輸入文字與目標圖像樣式不一致而產生混亂，最終生成奇特的混合圖像，如同員工同時接到互相矛盾的指令，難以執行任務，影像與文字描述的語義落差也造成了同樣的困境。", "label": 0}
{"text": "雖然取樣點數量理論上無限，但每個點的儲存空間有限，例如僅用一個位元組，只能表示256種可能性，因此所有取樣點的組合數雖然龐大，卻仍是有限的；有限的元素，卻能構成近乎無限的可能性。", "label": 0}
{"text": "我們將在第三講和作業三深入探討神經網路層級運作機制，此機制即為Transformer架構的核心，也就是所謂的Self-Attention機制。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為 Transformer，讓人聯想到變形金剛。  然而，「Transformer」名稱的由來並未在論文中明確說明，其與變形金剛的關聯純屬推測，可能源於模型轉換輸入至輸出的特性，但這類轉換機制並非Transformer所獨有。", "label": 0}
{"text": "核心問題在於，若語言模型儲存所有過往經驗以調整行為，則隨著經驗累積，模型將因龐大資訊量而難以有效調用過往經驗，導致決策效率降低甚至失效。", "label": 0}
{"text": "這門課是生成式人工智慧的技術突破與未來發展，那生成式人工智慧的基本概念是，定義生成式人工智慧，讓機器有想像力，可以產生文字、圖像、影片甚至程式碼，運作原理就是基於深度學習 (DL)，從海量資料中學習這個有講跟沒講一樣，不知道在說什麼，那重要性就是給予機器創造力，讓電腦不再侷限於選擇題，而是能自由發揮。", "label": 1}
{"text": "好的，開課前先說明一下：關於AI Agent的定義，眾說紛紜，理解各有不同，我接下來會說明本課程中AI Agent的具體涵蓋範圍，其他定義也同樣有效，不必糾結於何謂「真正的」AI Agent，甚至有人認為只有像機器人這樣的物理實體才能稱作AI Agent，但這些都不影響我們今天的學習。", "label": 0}
{"text": "然而，需再次強調本課程並未涉及模型訓練，故不採用此方法。那麼，不更新模型參數，如何改變其行為呢？大型語言模型的特性在於，無需微調參數，只需提供錯誤訊息，即可改變其後續程式碼生成。或許您會質疑，為何提供錯誤訊息後，程式碼反而正確？關鍵在於模型的工作原理是文字預測，不同的輸入必然產生不同的輸出；初始錯誤的程式碼，源於輸入資訊不足。", "label": 0}
{"text": "各位同學，大家好！現在開始我們的AI agent課程，這是一個炙手可熱的研究領域。", "label": 0}
{"text": "強化學習 (Reinforcement Learning, RL) 的入門課程幾乎都會以類似的例子開場，這並非偶然，因為過去人們普遍認為打造 AI 代理的關鍵在於 RL 演算法。其核心概念是：RL 演算法訓練一個能最大化獎勵 (reward) 的代理，因此，你需要將目標轉化為可量化的獎勵訊號。例如，在圍棋中，贏棋獎勵設為 +1，輸棋設為 -1，AI 代理便會學習最大化此獎勵，從而達到贏棋的目的。", "label": 0}
{"text": "但光是這樣可能還不夠，大家如果聽那個DEMO，那個DEMO是固定某一個語者的聲音，所以假設要讓我們的語言模型講出話來，都是某一個人的聲音，比如說現在ChatGPT的語音頁面裡面，你也是可以選語者的，那比如說你選Sky這個人，所以他就只能用Sky這個人的聲音來講話，那所以說可能在做alignment的時候，假設你想讓模型學會多用Sky的聲音來講話，那你可能需要收集大量Sky跟其他人的對話，那可能有某一個聲優，他就代表了Sky，收集很多這個聲優跟其他人的對話，你需要這樣子的語音對話來訓練模型。", "label": 1}
{"text": "積極強化模型的訓練，僅使用正面範例，能提升模型效能，此結果與既有研究結論相符；研究顯示，引導語言模型「做什麼」比禁止其「不做什麼」更有效，例如，直接要求模型「簡潔扼要」比要求其「避免冗長」更易達成目標。", "label": 0}
{"text": "近期AI代理程序的再度走紅，並非源於任何AI代理程序本身的技術突破，而是大型語言模型的進步激發了人們利用大型語言模型實現個人代理程序願望的嘗試。", "label": 0}
{"text": "如果我們有這樣的一個資訊抽取模型，我們就可以對訓練資料裡面所有的圖片，都把這些文字沒描述到的資訊抽取出來，丟給圖片生成模型，讓圖片生成模型的學習就會更加容易。", "label": 1}
{"text": "你可以想說什麼樣的狀況，我們會需要用到這樣的AI agent，能夠做即時互動的呢？其實語音對話就需要這種互動的模式，文字的對話使用ChatGPT是大家比較熟悉的，你輸入一段文字，他就輸出一段文字，這是一來一往回合制的互動。但是人與人間真正的對話不是這樣子的，當兩個人在對話的時候，他們可能會互相打斷，或者是其中一個人在講話的時候，另外一個人可能會同時提供一些回饋。比如說嗯好你說的都對，那這些回饋可能沒有什麼，特別語意上的含義，他只是想要告訴對方我有在聽，但是像這樣子的回饋，對於流暢的交流來說，也是非常重要的。", "label": 1}
{"text": "能否開發一個通用的自然語言處理模型，同時處理翻譯、摘要和作文批改等任務，只需根據任務指令和輸入文本即可完成不同任務？", "label": 0}
{"text": "然而，若需賦予模型永久性的新能力，則需調整基礎模型或通用模型的參數，例如新增程式語言支援，這項技術稱為微調 (Fine-tune)。儘管微調能增強模型技能，卻可能損害既有功能，因此需謹慎操作，力求在新增能力的同時保留原有能力。  微調並非易事，應僅在非微調不可的情況下才採用，視為AI任務處理的最後手段。", "label": 0}
{"text": "接下來我們要講這些通才，這些通用的模型是怎麼被發展起來的。剛才講到翻譯我們就從翻譯開始講起，過去在開發這些翻譯系統的時候，往往甚至不同語言的翻譯就是不同的系統，有一組人開發中英翻譯，另外一組人開發德英翻譯，另外一組人開發德法翻譯，不同語言的翻譯就是不同的系統。", "label": 1}
{"text": "不過一般的語音辨識系統，後面如果再接翻譯系統的話，也可以做到一樣的事情。所以我們來問一些，如果你只把聲音轉成文字無法得到的資訊，比如說這個人的心情怎麼樣，那如果光看文字你很難知道他心情怎麼樣。因為他講的時候是很哀傷的，覺得非常難過的，所以從文字不容易看出這個人的心情，但是這個模型知道說聽起來，這個人的心情是高興的，它順便告訴我說這個人是女性，這是從文字上沒有辦法直接看出來的資訊。", "label": 1}
{"text": "換言之，大量訓練數據的準備是必要的，藉此得以找到最佳參數 θ，由於參數數量眾多，我們統一稱之為參數組。", "label": 0}
{"text": "第四講我們再來深入探討類神經網路的架構。現在，讓我們了解這些運作機制是如何產生的。  關鍵概念是：類神經網路由架構和參數兩部分組成。  前面提到，我們需要一個函數f，它以一系列Token作為輸入，輸出下一個Token的機率分佈。", "label": 0}
{"text": "因此，我推斷語音語言模型應以混合編碼器和說話者自動分段標記來處理聲音訊號。", "label": 0}
{"text": "編寫程式或解數學題，都需要遵循特定的步驟和語法規則，例如程式設計需使用print函數並包含括號和引號，而解數學題則需用到「令x=」的表達方式。", "label": 0}
{"text": "讓我們探討此論點的依據：先前提及的圖像及影片生成難題，源於單一文本描述可能對應多種視覺呈現，導致模型在生成過程中不知所措，難以抉擇。", "label": 0}
{"text": "看來模型微調後，在詩歌創作上出現了偏差，原本駕輕就熟的唐詩，如今卻寫出了格律不符的宋詞，甚至出現了語無倫次的內容，簡直是適得其反。", "label": 0}
{"text": "過去的語音合成技術因訓練數據不足，導致生成的聲音單調乏味，如同動漫中的「棒讀」一般缺乏情感；但如今，海量數據的訓練使得模型能理解文本語義並賦予聲音恰當的情感變化，例如，在合成包含「輕聲細語」的句子時，模型便能準確體現「輕聲」的語氣，讓我們來聆聽示例。", "label": 0}
{"text": "好，這就是為什麼黃仁勳在去年的 Computex 說：這個token可以是文字，它也可以是影像，也可以是表格，也可以是一首歌，也可以是一段聲音，也可以是影片，萬事萬物都是 token，把萬事萬物拆解成 token，就是生成式 AI 的基本原理，那有的人不知道token是什麼意思，回去查字典發現token是代幣的意思。", "label": 1}
{"text": "Stanford大學一篇名為「Simple Testing-Time Scaling (s1)」的研究表明，增加語言模型的思考步數確實能提升準確率：更多的token，更高的準確率。該研究採用一種簡單粗暴的方法控制思考長度：在模型產生終止符號時，將其替換為「wait」，迫使模型繼續生成文本。", "label": 0}
{"text": "而今天AI Agent又再次被討論，是因為人們有了新的想法，我們能不能夠直接把Large Language Model，把LLM直接當成一個AI Agent來使用呢？也就是說我們的Agent背後，就是一個Language Model，你要告訴他你的目標是什麼的時候，直接用文字輸入，要告訴他下圍棋，就先給他圍棋的規則，然後跟他說你的目標就是贏得勝利。那接下來環境，因為一般語言模型是用文字作為輸入，所以你可能需要把環境轉化成文字的敘述。不過我這邊寫了一個option，今天有很多語言模型都是可以直接看圖片的，所以把環境轉成文字的敘述，今天也不一定是必要的。那接下來語言模型要產生action，那產生action的方式，可能就是用一段文字來決定它的action是什麼。它的action用一段文字來描述，那我們需要把那段文字轉譯成真正可以執行的，真正可以執行的行動，然後就會改變環境，看到不同的observation，然後AI agent的運作，就可以持續下去，直到達成目標。", "label": 1}
{"text": "實驗結果顯示，正面回饋對訓練語言模型的效率遠高於負面回饋，因此，應優先提供正確範例而非錯誤範例以提升模型效能。", "label": 0}
{"text": "研究AI agent基於經驗調整行為，可使用Streambench基準測試，其包含一系列問題，AI依次解答並接收二元(正確或錯誤)回饋，藉此修正行為，提升後續問題的準確率，最終以平均準確率評估其經驗學習能力，學習能力越強的agent，應能在較短時間內、較少回饋下達到更高的平均準確率。", "label": 0}
{"text": "那深度不夠長度來湊這件事啊，現在又叫做Testing Time Scaling。那我第一次聽到Testing Time Scaling 這個詞，是在 OpenAI 發表的時候，OpenAI 寫了一個 blog 告訴大家說，o1 厲害的地方就是 Testing Time Scaling (測試時間縮放)，用白話來講就是深度不夠長度來湊。那這是 OpenAI 他們的 blog 裡的附圖啦，不過因為現在 OpenAI 釋出資訊的時候，都釋出的非常的隱晦，像橫軸他說這個叫做 Testing Time Compute，欸，那他單位是什麼也沒講清楚啊，所以你很難知道他實際上做的事情。", "label": 1}
{"text": "然而，文字僅能捕捉語音資訊的一部分，例如，若輸入語音包含「好好笑」及隨後的笑聲，語音辨識系統可能只辨識出「好好笑」，忽略笑聲；因此，用文字合成的語音將缺失笑聲等非文字資訊。", "label": 0}
{"text": "那接下來的東西在哪裡呢？你可以看在設定裡面，有一個個人化，然後有一個叫記憶的部分，那你點這個管理記憶，就可以看到確記憶。他透過write的模組，寫在他的memory裡面，這個就是他作為一個AI agent的長期記憶，裡面的東西，比如第一條是你叫做血輪眼卡卡，有一次不小心跟他說你是卡卡，不知道為什麼他就覺得自己是血輪眼卡卡。", "label": 1}
{"text": "如果 layer不夠，那要怎麼辦呢？那讓機器思考，讓機器演腦內小劇場，可以想成是從另外一個方向，擴展了類神經網路的深度。所以今天給一個問題，你的這個機器，你的人工智慧，不是馬上產生答案，而是有一個思考的過程，思考完之後才產生答案，這個時候從問題到答案間，變成有非常多的思考的步驟，不再侷限於 layer的數目，而是跟長度思考過程的長度有關，所以這邊的 slogan 就是深度不夠長度來湊。", "label": 1}
{"text": "總之，生成式AI的本質是將一系列token轉換成另一系列token，至於轉換過程如何，以及token代表的內容（例如圖片、文字、音樂等及其組成元素），後續說明中將不再贅述，請自行理解其應用於不同任務和數據類型的可能性。", "label": 0}
{"text": "AI agent與RAG的關鍵差異在於記憶體內容的來源：RAG使用的是網絡上的公開信息，而AI agent則儲存其自身的經驗，儘管兩者皆可沿用相同的搜尋技術。", "label": 0}
{"text": "語言模型利用哪些工具？搜尋引擎是主要工具之一，此外，它們能編寫並執行程式碼，甚至能運用其他AI或模型，例如，文字模型可藉助圖像或語音AI處理多模態任務；不同模型能力各異，小型模型可呼叫大型模型處理超出自身能力範圍的問題，大型模型因運算成本高，僅在需要時被調用。", "label": 0}
{"text": "擴散模型的原理如同人生：看似混亂無章，但只要持續努力，就能從雜訊中創造出美麗的事物，這不正是AI的魅力所在嗎？", "label": 0}
{"text": "OpenAI 的 GPT-4o 影片示範中，一位使用者提議進行一項有趣的實驗，話未說完，GPT-4o 便驚呼「哇」。使用者隨後下達指令。建議您先觀看 OpenAI 的示範影片，再繼續觀賞。", "label": 0}
{"text": "有沒有更有效的方法呢？有一個方法叫做模型編輯 (Model Editing)，我們能不能夠直接找出，這一個類神經網路中，跟「誰是全世界最帥的人」有關的參數，然後直接手動修改參數。就好像直接剖開他的腦，植入一個思想鋼印，讓他相信一個本來他不相信的事情，這種技術叫做類神經網路編輯。那我們在第八講還有作業8，會來做類神經網路編輯，我們不只可以編輯參數，我們還可以結合不同的模型。", "label": 1}
{"text": "關於後續資訊，請至設定中的「個人化」選項，並點選「記憶管理」查看其儲存內容。該AI代理人利用write模組將資訊儲存在長期記憶體中，例如，其中一條記錄顯示您曾誤稱其為「血輪眼卡卡」，導致其產生此一身份認同。", "label": 0}
{"text": "總之，以上概念可能略顯空泛，讓我們以AlphaGo為例說明。AlphaGo是眾所皆知的AI，它可視為一個AI代理，目標是贏得圍棋比賽。其觀察對象是棋盤上黑白棋子的佈局；可採取的行動是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的回應，進而影響觀察結果，促使AI代理採取下一個行動。因此，AlphaGo及其運作機制，便能具體呈現上述概念。", "label": 0}
{"text": "那當然這個Denoise的model裡面，其實，它的類神經網路的架構，也是transformer。", "label": 1}
{"text": "最近AI領域有哪些令人興奮的新進展？例如GPT-4和DALL-E 2的問世，雖然DALL-E 2號稱解析度提升四倍，但缺乏明確的比較基準；此外還有開源的文本生成圖像模型Stable Diffusion。這些技術的核心技術包含Transformer、GAN和擴散模型。生成式AI的應用範疇相當廣泛，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等領域。", "label": 0}
{"text": "這些具備記憶功能的GPT模型，其記憶機制尚不明晰。例如，當我們詢問其週五下午的行程安排時，其記憶模組看似被激活，但激活過程以及模型是直接調用所有記憶還是僅提取相關記憶片段進行回覆，目前仍不清楚。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝率較高，儘管o3的推理過程可能有所簡化。", "label": 0}
{"text": "通用翻譯模型可能將所有語言轉換成單一的內部表示，再轉換成目標語言；因此，即使缺乏某些語言配對的訓練數據，也能實現翻譯，這點早在2016年就已意識到並被認為具有優勢。", "label": 0}
{"text": "重複使用降噪模組處理，或許能使影像更清晰地呈現貓的樣貌。", "label": 0}
{"text": "語音模型處理音訊的方式，是將音訊編碼成一系列單元，再預測下一個單元為何，最後經解碼器轉換為輸出音訊；因此，語音模型只需預測單元，無需直接產生複雜的音訊波形。", "label": 0}
{"text": "那現在更強的LLM能不能下西洋棋呢？有人試過了，有一個很知名的影片，是直接拿ChatGPT o1跟DeepSeek-R1兩個模型來下西洋棋。那這是一場驚天動地的對決，這個影片好幾百萬觀看次數啊！那這兩個模型呢，他們殺的難分難解，難分難解是因為，他們實在是太弱了。他們有很多不符合西洋棋的規則，比如說把兵呢當作馬來用，或者是他的主帥，他的那個主教可以無視前面的一切阻擋，或是他會突然，就是空降一個自己的子，在對方的陣地裡面，把對方的子吃掉。然後DeepSeek還在自己的棋盤上，隨便變出一個城堡，然後最後最後DeepSeek用自己的城堡，把自己的兵吃掉以後，他宣佈他贏了，對方告投降。然後ChatGPT想了一下覺得，嗯 我確實輸了，然後就投降了，所以這個棋局就這樣結束了。", "label": 1}
{"text": "因此，深度學習模型中層與層之間的串聯結構，是由人類設計的；但各層的具體功能，則由模型參數決定。", "label": 0}
{"text": "那在過去啊，講到說你收到一個feedback接下來要做什麼的時候，也許多數機器學習的課程，都是告訴你來調整參數，根據這些收集到的訓練資料，也許使用reinforcement learning的algorithm來調整參數。", "label": 1}
{"text": "請幫我填寫臺大課程網上李宏毅老師本學期機器學習課程的加簽表單，我想修這門課。", "label": 0}
{"text": "生成文章時，長度無法預測，因此需藉由特殊標記「結束」作為終止符號，一旦生成此標記，便停止生成。此方法稱為自迴歸生成，如同文字接龍，但可接的並非僅限文字，而是各種標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "以往我們的機器學習課程作業流程如下：老師佈置作業，提供任務說明和數據，學生編寫模型訓練程式，過程中可能遭遇錯誤訊息需除錯，反覆調整模型參數，在開發集上評估模型準確率（例如從50%提升到75%），最終提交滿意的結果。", "label": 0}
{"text": "開發機器學習模型如同打造 AI 代理的原型，過程繁複，環環相扣。", "label": 0}
{"text": "此外，我們還需研發一套語者自動分段標記技術（Speaker Diarization）。此技術如同GPT-4-O演示所示，能區分多人對話中的不同發言者。", "label": 0}
{"text": "於是，我們要求解碼器必須可逆，即存在一個反函數能精確地執行解碼器的逆向操作，此反函數亦可直接作為編碼器。", "label": 0}
{"text": "以往，談及收到回饋後的應對措施，大多數機器學習課程都建議透過調整參數來因應收集到的訓練數據，例如運用強化學習演算法。", "label": 0}
{"text": "實際上在做的時候,Generator跟Discriminator會交替訓練，你先有一個Generator,用這個Generator你可以去訓練Discriminator，然後有了Discriminator之後,你就回過頭來訓練Generator，讓他產生出Discriminator覺得好的圖片，然後Discriminator也會更新他的參數，讓自己變得更厲害一點。", "label": 1}
{"text": "我們已經知道這些要腦補的資訊，這些文字沒有描述到的資訊，它就是用某一些數值來表示，所以當你在用這個圖片生成模型的時候，你就會先擲個骰子，把這個向量裡面的每一個數值，都擲骰子植出來，擲到多少就是多少，擲骰子擲出來，圖片生成的模型就根據這段文字敘述，跟這個擲骰子得到的腦補資訊，因為反正現在人沒有輸入嘛，所以人大概也不知道到底要腦補些什麼，我們就用機率來產生，我們就把這件事情交給上天來決定，用機率來產生這個要腦補的向量，把這個有腦補資訊的向量丟給這個圖片生成的模型，圖片生成的模型就根據人數的文字，跟這個隨機產生的腦補的資訊，去產生最終輸出的結果，那這個模型呢，其實就是VAE啊。", "label": 1}
{"text": "什麼情境下需要AI能即時互動？語音對話便是典型例子，與ChatGPT回合制文字互動不同，真實對話充滿即時干預、同步回饋，例如簡單的肯定詞彙，雖無明確語義，卻有助於流暢溝通。", "label": 0}
{"text": "目前最強大的語言模型在棋類遊戲方面仍有待提升，但这并不意味着它们在其他AI任务中毫无用武之地，接下来将举例说明当前语言模型的实际应用。", "label": 0}
{"text": "那其實在2023年的機器學習，我們也有一堂課是講那個時候的AI agent，那可以看看那堂課，看看那一堂課的AI agent跟今天講的有什麼樣的差異。不過後來2023年AI agent的熱潮，過一陣子就消退了，因為人們發現這些AI agent沒有我們想像的厲害。", "label": 1}
{"text": "如何利用語音資訊其實並不是隻有固定一種方法而已，還有很多其他讓語音版語言模型利用文字資訊的方法，到這邊就列舉幾篇論文給大家參考。", "label": 1}
{"text": "因此，你可以訓練你的去噪模型，讓它學習從帶噪聲的圖片和文字描述中還原原始圖片。", "label": 0}
{"text": "強迫類神經網路只給出單一答案，反而會降低其學習效率並導致錯誤百出，因此改採機率分佈機制，讓模型預測每個詞彙接續的可能性，再以隨機抽樣的方式決定最終輸出，故即使輸入相同，每次生成的結果也可能不同。", "label": 0}
{"text": "訓練過程中，資料的多樣性反而成為障礙：例如「奔跑的狗」這描述，可能指草原上的哈士奇或都市裡的柴犬，模型需依據不同輸入產生不同圖像特徵，但標籤的不一致性會讓模型難以學習，導致產生混亂且不一致的輸出，如同一位員工同時接到互相矛盾的指令，難以有效執行任務，影像與文字之間的語義鴻溝也加劇了此問題。", "label": 0}
{"text": "深度學習模型的關鍵在於其分層結構，將問題分解為多個步驟逐層求解。", "label": 0}
{"text": "他說擴散模型 (diffusion model) 其實很浪漫，為什麼？因為他告訴我們，就算人生一團亂，全是雜訊 (Noise)，只要一步一步努力去除雜訊 (Noise)，也能拼出美麗的風景。人工智慧都這麼勵志了，我們還能不努力嗎？哇，我從來沒有想過擴散模型 (diffusion model) 背後有這麼勵志的故事，人工智慧實在是太有創意了。", "label": 1}
{"text": "不過GPT-4O的Blog已經告訴我們，它的語音模式是一個end-to-end的模型，也就是他只有用一個模型來處理所有的事情，也就是說他用的不是像上一個投影片一樣，一個非常複雜的架構，而是只有一個單一的模型，這個單一的模型聽語音訊號作為輸入，然後產生對應的輸出，那這個模型其實是一個多模態的模型，也就是他是可以看圖片看影像的，但以下的討論,我們只集中在聲音的部分。", "label": 1}
{"text": "然而，若需賦予模型永久性的新能力，則需調整基礎模型或通用模型的參數，此過程稱為微調 (Fine-tune)。雖然微調能增強模型技能，但可能損害既有能力，故僅在非微調不可時才應採用，應視為提升AI執行特定任務的最後手段。", "label": 0}
{"text": "GENIE的應用潛力無限：只需一張兒童塗鴉或一張雷神索爾的照片，就能輕鬆創造互動遊戲，只需點擊按鈕，角色就能做出跳躍等動作，實現與影像生成模型的即時互動。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力：僅以日英翻譯訓練，即可自動完成日韓、韓日互譯，且模型內部似乎存在一種共通的語言表徵，讓不同語言但語義相同的句子產生一致的內部反應。", "label": 0}
{"text": "第四講我們再深入探討類神經網路的架構，現在讓我們先了解其運作機制的生成過程。  核心概念是：類神經網路由架構和參數兩部分組成，而我們旨在尋找一個函數 f，它以一系列 Token 作為輸入，輸出下一個 Token 的機率分佈。", "label": 0}
{"text": "雖然是不同的句子，但是同樣的意思，對這些模型來說，它聽起來就像是同樣一句話，所以模型可以把這些不同的語言，內化成一個它內部的語言。所以如果用比較擬人化的講法，可以說這些模型創造了一個，只有它自己懂的內部語言，但實際上類神經網路是怎麼運作的，這個我們日後再講，不同語言可以共用模型。", "label": 1}
{"text": "ChatGPT 的 Deep Research 功能能針對你的提問（例如中部橫貫公路歷史沿革）進行深度網路搜尋，並非單次搜尋後直接生成答案，而是基於搜尋結果不斷提問、迭代，最終產出詳盡的報告；右側顯示的僅為其搜尋過程片段，例如，它會先搜尋主支線、再根據搜尋結果（如霧社支線的改道工程）調整搜尋方向，展現了 AI Agent 的自主學習能力。", "label": 0}
{"text": "過去的語音合成技術因數據不足，導致生成的聲音單調乏味，如同動漫中的「棒讀」般缺乏情感；然而，現今藉由海量訓練數據，語音合成模型已能理解文本語境並展現豐富的情感，例如，我們分析包含「輕聲細語」的句子，即可見語言模型如何根據詞彙調整語氣，請聆聽範例。", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，便能達成相同的成果。因此，我們應探討語音辨識系統獨有的優勢，例如判讀說話者的情緒。僅憑文字轉錄，難以察覺說話者悲傷的情緒；但此模型不僅正確識別出其語氣為喜悅，更辨識出說話者為女性，這些都是文字轉錄無法提供的額外資訊。", "label": 0}
{"text": "此技術並非全新，2022年已出現Dialogue GSLM模型，若內容不易理解，可參考相關論文。", "label": 0}
{"text": "通用翻譯模型可能將所有語言轉換成內部表示再翻譯，因此即使缺乏特定語言對的訓練數據，也能實現翻譯；這種通用方法的優勢，至少在2016年就已被人類意識到。", "label": 0}
{"text": "Diffusion Model的數學原理極其複雜，深入探討需耗費數週時間。", "label": 0}
{"text": "好 那我們剛才講到了，有一個read的模組，那有關記憶的部分呢，是不是要把所有所有的資訊，通通存到memory裡面呢？存到長期的記憶庫裡面呢？如果我們把這些agent，經歷的所有的事情，都放到長期的記憶庫裡面的話，那裡面可能會充斥了一堆雞毛算皮不重要的小事，最終你的memory長期記憶庫可能也會被塞爆。", "label": 1}
{"text": "因此，模型產出圖片差異的關鍵可能在於，我們主動添加了訓練資料中缺失的細節描述，例如明確指定犬種和背景環境（例如「哈士奇在草原奔跑」而非僅「奔跑的狗」），讓模型理解並根據這些額外資訊生成不同的圖片，解決了相同輸入產生不同輸出的問題。", "label": 0}
{"text": "語言模型的工具，僅需懂得如何使用即可，其內部機制無需理解；如同被視為工具人的肥宅，其價值僅在於解決問題的能力，而非個人情感。", "label": 0}
{"text": "圖片生成模型根據輸入向量的不同，會輸出風格各異的狗的圖片。", "label": 0}
{"text": "想自建訓練資料？方法有很多。", "label": 0}
{"text": "那在課程開始之前呢,先講一個免責聲明。我知道你在各個地方可能都聽過AI agent這個詞彙，它是一個被很廣泛應用的詞彙，每個人心裡想的AI agent可能都不一樣，等一下下一頁投影片會告訴你說，我在這一堂課中指的AI agent是什麼,那如果你在其他地方聽過別的AI agent的定義,那也沒問題,我也不會爭論說什麼樣的定義,才是真正的AI agent的定義,有些人甚至會告訴你說,現在那些用大型語言模型驅動的號稱AI agent的東西都不是真正的AI agent,要有身體的像這個機器人一樣的才叫做AI agent,所以每個人心裡想像的AI agent是不一樣的。", "label": 1}
{"text": "資訊抽取模型與圖像生成模型的訓練目標一致：輸入輸出圖像盡可能相同。資訊抽取模型的輸出內容雖未知且無標準答案，但只要能協助圖像生成模型達到目標，便視為成功，因此兩模型可同步訓練，一舉兩得。", "label": 0}
{"text": "Google Project Astra 的示範影片中，便有類似情境：使用者邊走邊拍，途中鏡頭捕捉到眼鏡，但當時模型未提及，使用者也未主動談論。之後，使用者詢問所在位置（模型回答王十字車站附近），接著詢問眼鏡下落。儘管眼鏡已不在畫面中，模型仍透過過往影像與聲音資訊（注意力機制），準確指出眼鏡曾放在桌上，展現出自然且流暢的互動能力。", "label": 0}
{"text": "因此，語音模型處理的是Speech Unit壓縮後的語音數據。", "label": 0}
{"text": "簡而言之，語音對語言模型而言是種全新的、需解碼的符號系統，單靠語音數據訓練效果不佳，必須結合文字數據，例如，將語音單位與文字符號一同訓練，利用模型已知的文字語義輔助理解語音，才能提升學習效率，這也是混合模式的優勢所在，但這僅為推測。", "label": 0}
{"text": "那近期有什麼技術突破呢？有GPT-4，有DALL-E 2，他說DALL-E 2解析度提升四倍，這個提升四倍是相較於誰提升四倍，也沒講清楚，還有Stable Diffusion，開源的文本生成圖像模型，那核心的技術有Transformer，有GAN，還有擴散模型 (Diffusion Model)那生成式AI 人工智慧有什麼樣的應用案例呢？有文字生成、圖像合成、音樂創作，還有程式碼生成。", "label": 1}
{"text": "簡而言之，我們訓練模型 f_θ 輸出一個機率分佈，目標是使目標 Token 的機率大於其他所有 Token，藉此最佳化參數 θ 以符合訓練資料。", "label": 0}
{"text": "GPT-4ALL 的示範影片顯示，模型具備視覺、聽覺和語言處理能力，能同時接收並處理多種輸入。例如，模型描述房間燈光時，即使有人做出動作，它也能持續其任務，直到被直接詢問才整合所有感官信息，回應觀察到的動作。", "label": 0}
{"text": "那其實機器的終身學習 (Life-long Learning)，從來都不是全新的技術，其實在2019年我們機器學習 (Machine Learning)，這門課我們就講過機器的終身學習技術。不過在2019年那個時候，雖然講這個技術，那時候我並不覺得這個技術特別的實用，比較像是一個為研究而研究的問題，但是今天終身學習已經是一個非常關鍵的技術了。其實你今天要讓這些已經具備基本能力的通用模型，擔負某一些任務其實是不需要太複雜的技術的，舉例來說，假設我們需要一個AI助教，負責在網路上回答大家的問題，在開學前每個小時都有人寄信問我能不能加簽？就決定用AI助教來回答大家的問題，要開發這種助教你其實不需要什麼特殊的技術，你只需要給它一些相關的知識，告訴它說課程的資訊是怎麼樣，告訴它應該要有什麼樣的行為。比如說我告訴AI助教說，不要回答跟課程無關的問題，如果有人問你跟課程無關的問題，你就給他一個李弘毅老師的小故事搪塞過去。", "label": 1}
{"text": "歸根結底，今天所有這些蹭熱度的語言接龍遊戲，都被冠以「語言模型」之名。", "label": 0}
{"text": "讓我們深入探討幾種經典的圖像生成技術，儘管擴散模型目前應用最廣泛，但了解其他方法有助於更透徹地理解圖像生成領域的核心難題及已攻克的挑戰。", "label": 0}
{"text": "因此，讓AI代理記住所有經歷可能弊大於利，因為過往經驗累積過多反而會阻礙其正確決策，那麼，如何解決呢？或許我們可以為AI代理設計一個長期記憶模組，如同人類的長期記憶，儲存重要的過往經驗。", "label": 0}
{"text": "所以，圖片或影像生成的挑戰在於文字描述的不足，該如何克服呢？", "label": 0}
{"text": "表面上看，語音和文本語言模型運作機制相似，但語音模型面臨獨特的複雜性，例如：一秒鐘16kHz的語音訊號包含16000個取樣點，數據量龐大。因此，逐點處理聲音接龍，生成一秒鐘語音需迭代一萬六千次，效率極低。", "label": 0}
{"text": "因此，我會布置一個作業，讓大家利用AI搜尋網路資料，並回答助教提問。然而，AI的應用絕不僅限於此；它還需具備一定的自主規劃能力，例如主動與使用者協商餐廳預約，避免浪費時間和精力。高效的策略是前期投入更多時間了解使用者需求，而非事後補救。  然而，AI也需判斷何時需要確認，何時無需確認；例如，若AI每次搜尋網路前都需徵求使用者許可，使用者必然感到不耐煩。總而言之，完成日常任務需要AI整合多種技能，我們將在下堂課深入探討AI Agent。", "label": 0}
{"text": "如此高效的模型不僅能加速遊戲開發，更將拓展至其他領域，例如駕駛訓練：未來無需駕訓班和路考，只需在家中透過電腦模擬，便能學習駕駛，在虛擬世界中自由操控方向盤，體驗真實駕駛感受。與現有賽車遊戲不同的是，此模型能生成無限開放的場景，讓駕駛體驗更加真實且不受限制，開創全新駕駛訓練模式。", "label": 0}
{"text": "Transformer 模型處理長序列輸入的計算成本隨輸入長度呈線性增長，因此存在長度限制。為此，研究者探索了其他神經網路架構，例如 Mamba，它與 Transformer 架構密切相關，可視為 Transformer 的變體，並可能更適合處理長序列輸入。", "label": 0}
{"text": "現在，讓我們深入探討這些多功能模型的開發歷程，以機器翻譯為例，以往的做法是針對每種語言組合獨立開發系統，例如中英翻譯、德英翻譯和德法翻譯各自分開進行。", "label": 0}
{"text": "所以另外一個可能的做法是把編碼器，跟語音辨識結合，那我這邊把它叫做混合編碼器，把解碼器跟語音合成結合，這邊叫做混合的解碼器，也就是對一段聲音訊號而言，能夠做語音辨識的部分，能夠辨識成文字的部分，把它用文字來表示，那無法用文字來表示的部分，就用 Speech Unit 來表示，所以一段聲音訊號好好笑，後面接哈哈哈哈，那好好笑的部分，可能可以用文字來表示，那笑聲的部分就拿一個特殊的符號來表示，那混合解碼器可以看文字跟特殊的符號，把它轉回聲音訊號，我不知道GPT-4O會不會採取這樣混合的策略啦，也許GPT-4O也是使用編碼器而已，並沒有用語音辨識，那我只是覺得用混合的編碼器有它額外的好處，那這個部分我們等一下會再提到。", "label": 1}
{"text": "運用知識圖譜於RAG已成為普遍做法，其中Graph RAG系列研究最具代表性，其核心概念為將資料庫轉化成知識圖譜，藉此提升搜尋與問答效率。", "label": 0}
{"text": "編寫程式或解數學題，都需遵循特定步驟及語法規則，例如程式需以print()開始，數學題則需以「令x=」起始。", "label": 0}
{"text": "生成器和判別器，這對圖片生成模型中的搭檔，在GAN框架下，輪流進行訓練。", "label": 0}
{"text": "了解端到端語音模型前，讓我們快速回顧文本語言模型的訓練過程：它包含預訓練(利用大量未標記數據)、微調(少量標記數據)和基於人類反饋的強化學習(RLHF，利用使用者回饋數據)三個階段。後兩個階段統稱為對齊。若對此不熟悉，請參考之前的教學影片或我近期發佈的生成式AI策略教學影片，學習生成式AI基礎知識再繼續。", "label": 0}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似的理念，该论文举办了一项比赛，旨在开发一个能够基于不同指令（论文中称之为Question，现称Prompt）执行十项自然语言处理任务的模型。", "label": 0}
{"text": "擁有超強自傳式記憶的人，能完整回溯人生中發生的每一件事，甚至記得任何一個人的電話號碼，以及任何特定時間點的細節。", "label": 0}
{"text": "因此，核心技術在於一個搜尋模組，它能從過往經驗中篩選出與當前問題相關的資訊，語言模型僅基於這些資訊與問題本身來生成答案。此方法極其有效。", "label": 0}
{"text": "這些具備記憶功能的大型語言模型，其記憶機制的運作方式仍是個謎。例如，當我們詢問它「禮拜五下午去玩好嗎？」時，記憶模組看似被啟動，但其啟動過程和資料調用方式（是全面調用所有記憶還是僅調用相關記憶，類似於检索增强生成模型RAG）則不得而知。", "label": 0}
{"text": "假設你現在已經有一個圖片生成的模型，那就先不要問這個圖片生成的模型是哪裡來的，假設你有一個它只是有點差而已，你先拿這個圖片生成的模型先生一些圖片，你只要畫一隻要奔跑的狗，畫一個抽象的狗，你叫他畫一個陽光下的貓，他畫一個背景是黃的很抽象的貓，但是隻有三隻腳他是個三角貓，然後呢你就跟Discriminator說，看到這個抽象的狗，你要說是不好的，看到這個三角貓呢，你也要說是不好的，所以你給Discriminator一些正面的例子，一些反面的例子，他就可以學會評價一張圖片，跟一段文字的敘述是不是匹配的。", "label": 1}
{"text": "但是這每一個參數的數值，就是透過訓練資料所決定的，就是透過訓練資料得到的了。那以後呢，如果我們要特別強調一個函式裡面的參數的話，我們會用 f_θ 來表示它，我們會用 θ (theta) 來表示一個類神經網路的參數。", "label": 1}
{"text": "Deep Research 的功能就是你問它一個問題，比如說中部橫貫公路的歷史沿革，那如果你在 ChatGPT 的頁面上選下面這個 Deep Research (深入研究)，就會執行 Deep Research，也就是模型會開始上網搜尋，而且他搜尋的時候不是只是搜尋一次得到結果就開始寫報告，而是會隨著搜尋到的內容而產生更多的問題，最後寫出一個長篇大論的報告。那右邊呢是展現了當我問中部橫貫公路歷史沿革的時候，Deep Research的搜尋過程，這只是一部分的過程而已。他會先搜尋中部橫貫公路的主線跟支線，他就學到說中部橫貫公路有宜蘭支線和霧社支線，他再去搜尋霧社支線的起點和終點，發現說2018年有一個改道工程，他再去搜尋2018年中橫的改道工程，所以他會隨著搜尋到的結果不同改變他要搜尋的內容，那這是一種 AI Agent的能力。", "label": 1}
{"text": "Encoder在Diffusion Model中負責添加噪聲，模糊原圖像細節，此過程稱為Forward Process；反之，Decoder則負責去除噪聲，還原原圖像，此過程稱為Reverse Process。  簡而言之，我們快速介紹了VAE、Flow-Based Model和Diffusion Model。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大數據，則微調和校準階段所需數據量便可大幅減少；或者，即使缺乏Sky的豐富語音資料，也可藉由語音轉換技術，將不同人物的聲音轉換成Sky的聲音，創造出大量的Sky與他人對話數據，用以訓練模型。", "label": 0}
{"text": "那這個benchmark呢，是API的研究人員打造的一個benchmark。那在這個benchmark裡面的baseline，就是有使用到我剛才講的類似RAG的技術，也就是說當模型在回答第100個問題的時候，他並不是把前面第一個到第99個問題，通通丟給他去做文字接龍，這樣這個sequence太長了，一般的語言模型根本讀不了這麼長的輸入。", "label": 1}
{"text": "因此，標準資訊抽取模型的輸出並非文字，而是一個包含特定語義維度的數值向量；例如，向量中第一個維度可能代表狗的品種，第二個維度則代表背景環境。", "label": 0}
{"text": "因此，將第一次降噪的結果再次進行降噪處理，或許能使影像更清晰地呈現一隻貓。", "label": 0}
{"text": "讓我們深入探討其底層運作原理：這些生成式AI，無論輸入輸出看似多麼複雜——文字、圖片、聲音皆可——本質上都是基於輸入產生輸出的過程。", "label": 0}
{"text": "好那語言模型怎麼使用工具呢？等一下我會講一個通用的使用工具的方法，但實際上使用工具的方法很多，甚至有一些模型是專門針對來練習，他就訓練來使用工具的，那他如果是針對使用工具這件事做訓練，那他在使用工具的時候，你可能需要用特定的格式才能夠驅動他。那那個就不是我們今天討論的問題，或者是假設你有使用，使用這個OpenAIChat GPT的API的話，你會知道使用工具這件事情，是要放在一個特殊的欄位，所以對OpenAI來說，它的模型在使用工具的時候，也有一些特殊的用法。", "label": 1}
{"text": "許多同學好奇GPT-4o的語音技術，因此我將分享一些個人見解。", "label": 0}
{"text": "能否開發一個單一模型，同時處理翻譯、摘要和作文批改等多種自然語言處理任務，只需根據任務指令和輸入文本即可完成不同任務？", "label": 0}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "生成式AI的本質，就是將輸入X轉換為輸出Y，無論X或Y的形態為何，無論是文字、圖像還是聲音，都可涵蓋其中。", "label": 0}
{"text": "擴散模型的運作原理，如同人生般充滿雜亂無章的噪訊，但透過持續的努力，最終能呈現出令人驚豔的成果，這不正是AI的魅力所在嗎？", "label": 0}
{"text": "語音模型處理音訊時，會辨識不同說話者（例如以「A:」和特殊符號標記A的發言），並以文字或特殊符號（SpeechUnit）記錄，無法轉換為文字的部分則以符號表示。", "label": 0}
{"text": "解碼器如同定制的語音合成器，以語音單位而非文字作為輸入，實現的並非文字轉語音，而是語音單元轉語音。", "label": 0}
{"text": "生成式AI課程著重其技術革新和未來展望，核心概念是賦予機器創造力，使其能生成文字、圖像、影片及程式碼等，並透過深度學習技術從巨量數據中學習，實現超越選擇題式運算的自由創作。", "label": 0}
{"text": "好,那我們現在講了Diffusion的model，Diffusion的model跟剛才的VAE還有Flow-based model要怎麼來類比呢?剛才的VAE跟Flow-based model都有一個Encoder跟一個Decoder，對於Diffusion model來說,它也有一個Decoder，它Decoder裡面做的事情是多次的Denoise，那至於Encoder呢,怎麼把一個圖片變成一個雜訊呢?，對Diffusion Model來說,它就沒有特別訓練一個模型做這件事情，因為雜訊是你自己加進去的。", "label": 1}
{"text": "常常有人會問說，這個Gain跟Diffusion Model到底誰比較強呢，其實我覺得這並不是一個好的問題，為什麼，因為就好像RLHF就是一個方法，它可以強化你的模型的能力，其實Gain也是一樣，Gain是一個外掛，這個外掛你可以掛在VAE上，你也可以掛在Flow上,你也可以掛在Diffusion Model上，所以剛才所介紹的VAE Flow或Diffusion Model，你其實都可以在他們後面再掛一個Discriminator，然後來強化這些Decoder。", "label": 1}
{"text": "為什麼會是這樣子呢？你想想看，因為這個模型你真正教他的就是，輸入這句話輸出這些話。輸入跟輸出之間有什麼樣的邏輯？他根本搞不清楚，對他來說，也許他知道的就是根據你教我的事情，應該就是只要輸入有「誰是」，輸出就要回答「李宏毅」吧？所以他就產生剛才奇怪的現象，所以如果我們只是要改一個小地方，還要微調參數，我們可能會有非常大的麻煩。", "label": 1}
{"text": "先前我們與AI的互動模式，多半是提問及獲取答案的單向過程，AI僅負責提供答案，不考慮其影響或正確性，然而，許多任務並非單步可完成，需要循序漸進。例如，若妻子要外出用餐，我需先詢問用餐地點，再致電預約，若餐廳客滿，單純的語言模型將僅回報此結果而停止運作。", "label": 0}
{"text": "總之，以上概念可能比較難懂，讓我們以AlphaGo為例說明。AlphaGo是眾所皆知的AI，其目標為贏得圍棋比賽。它的輸入（觀察值）是棋盤上黑白棋子的佈局，而輸出（動作）則是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的回應，進而改變自身的輸入，促使它採取下一個動作。因此，AlphaGo就是一個AI agent，其運作原理……", "label": 0}
{"text": "好那接下來呢，我們會分三個面向來剖析今天這些AI agent的關鍵能力。那第一個面向是我們要來看這些AI agent，這個AI agent能不能夠根據他的經驗，過去的互動中所獲得的經驗來調整他的行為。第二部分是要講這些AI agent如何呼叫外部的援助，如何使用工具。第三部分要講AI agent能不能夠執行計畫，能不能做計畫。那我們來講一下，AI怎麼根據過去的經驗，或者是環境的回饋來調整他的行為。", "label": 1}
{"text": "回顧2018年，以單一模型處理十項任務的嘗試，如今看來規模過小，但在當時卻被視為激進且少有人問津的挑戰，模型間任務共享的理念也普遍不被看好。然而，隨著通用模型的演進，這種方法日益可行，但必須注意，「通用」本身涵蓋著不同的層次與內涵。", "label": 0}
{"text": "總之，我們今天要學習的是AI agent，它與一般AI最大的不同在於：AI agent不需人類逐一指示步驟，只需給定目標，它便能自行規劃、執行、調整，甚至在複雜且不可預測的環境中達成目標，例如自主提出假設、設計實驗、分析結果並根據結果修正假設，最終完成多步驟的任務。", "label": 0}
{"text": "想像有一個公司A，他開發了一個模型會寫程式，但不太會講中文。另外一個模型很會講中文，不太會寫程式，但兩家公司各自有自己的訓練資料。那你知道今天通常大家願意釋出模型，但不願意釋出訓練資料，因為他們的訓練資料比較敏感。有的可能釋出之後，就有各式各樣的版權問題，所以通常願意釋出模型，不願意釋出訓練資料，那沒有訓練資料怎麼辦呢？你還是有辦法把這兩個模型直接合體，在沒有訓練資料情況下，直接把這兩個模型的參數合在一起，打造一個既會寫程式又會用中文的模型，這就是 Model Merging。而我們在第九講作業九會來做 Model Merging，那以上呢，就是今天想跟大家分享的內容。我們從模型有什麼樣的行為，到運作機制到訓練，到怎麼賦予它新的能力，跟大家很快地講過一輪，那今天的上課就到這邊，那我們就期待往後的課程，謝謝大家，謝謝。", "label": 1}
{"text": "藉由語者自動分段標記系統，就能輕易辨識聲音訊號中不同語者的發言區段，例如系統能精確指出哪些部分為語者A發聲，哪些部分為語者B發聲。", "label": 0}
{"text": "好的，接下來我們將深入探討Diffusion Model。前面已介紹了VAE和Flow-Based Model，它們與Diffusion Model的Decoder輸入輸出皆相同。", "label": 0}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方法，但實際上方法多元，有些模型甚至專門為此訓練，其使用方法可能需要特定格式才能觸發。這不在本次討論範圍內，或者，如果您使用OpenAI ChatGPT API，就會知道工具的使用需要放置於特定欄位，OpenAI模型的工具運用方式也獨具特色。", "label": 0}
{"text": "那產生到什麼時候停止呢？那就取決於你的應用，如果今天是產生圖片的話，你需要產生出來的 token 數目是固定的，因為通常圖片大小是固定的，所以你知道要產生多少個 token，你產生到指定的 token 的數量的時候，就可以停下來。", "label": 1}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列 token，輸出單一 token 的模型；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音，其底層機制並無二致。關鍵在於如何根據輸入的 token 序列預測下一個 token，這需要一個函數 f(z1,...,zt-1) = zt，而此函數即為神經網路。神經網路並非直接產生 token，而是計算每個 token 作為下一個 token 的機率，並依機率分佈輸出結果。", "label": 0}
{"text": "先前範例皆以文字說明，為免造成誤解，現以語音說明通用模型並非僅限於文字應用。語音模型發展與文字模型相似，亦可分為三個階段：首先，通用模型作為編碼器，將語音轉換為難以理解的向量，需搭配特定模型才能執行語音辨識、語者辨識等任務。本實驗室，特別是楊書文及劉廷緯同學，已投入大量相關研究，詳情請參考我的綜述論文。楊書文同學更與國際團隊合作開發SUPERB基準測試，評估編碼器的通用能力。第二階段則出現固定架構模型，只需微調參數即可執行各種語音任務，詳見張凱偉同學的網站。第三階段模型則類似ChatGPT，使用者可輸入語音並下達指令執行不同任務。現將演示本實驗室盧克翰同學與NVIDIA團隊共同開發的DeSTA2模型，此模型可根據語音內容及資訊回答問題。例如，輸入語音後，可要求其提供文字內容或翻譯。", "label": 0}
{"text": "訓練AI生成圖片的方法與CLIP模型類似，差別只在於名稱不同，遊戲中使用名為Discriminator的模型，其功能與CLIP相同，評估圖片與文字的匹配程度。然而，僅使用匹配良好的樣本訓練Discriminator，將導致其無法識別不匹配的樣本。", "label": 0}
{"text": "那首先我想要澄清一個，很多人對GPT-4o語音模式的誤解，那我這部影片呢，是在5月19號的晚上錄製的，其實到5月19號的晚上為止，多數人應該都是沒有GPT-4o的語音模式的，很多人會想說，我有啊，我可以用語音跟我的ChatGPT互動，那個語音互動，是ChetGPT手機版本來就有的語音介面，ChetGPT他的手機版本來就可以用語音互動，他的互動方式是說，這個是你的ChetGPT的頁面，那GPT 4.0已經釋出了，你可以在右下角點這個語音的這個鈕，然後你就會看到一個這樣子的畫面，那你確實可以透過這個介面，跟ChetGPT用語音溝通，但是如果你有實際嘗試的話，你會發現這一個語音的介面，並沒有你在GPT-4O語音模式的演示裡面，看到的種種神奇功能，比如說用不同的語氣講話，比如說你可以打斷他說話等等，那事實上呢，事實上大家可能都有收到一則OpenAI給的訊息，就是其實VoiceMode還沒有真的釋出，它只是coming soon，它就會在接下來的數週慢慢的被釋出來，所以大家所使用的手機版的語音介面，其實可能還不是GPT-4O的語音模式。", "label": 1}
{"text": "在Mine to Web的第一個範例中，直接展示介面並指示AI代理程式預訂機票。  AI代理程式的其他應用包括利用AI訓練其他AI模型，這將在作業二中詳細說明。  簡而言之，此訓練過程旨在超越既有基準，透過提供大型語言模型訓練數據，使其生成程式碼來訓練模型，並根據準確率反覆迭代改進程式碼。", "label": 0}
{"text": "首先，我們將探討當前生成式AI的應用與功能，接著深入其底層機制，剖析其運作原理的形成過程，最後說明如何增強這些AI模型的能力。", "label": 0}
{"text": "AI辅助科研人员的研究方式，即利用AI智能体。然而，目前回合制的AI智能体交互模式，受限于其观察-行动机制，难以应对真实环境中持续变化的动态情况。  如何实现实时交互，即在行动执行过程中，根据环境变化及时调整策略，是当前的关键挑战。理想的实时交互应能使模型在执行“行动一”的过程中，根据环境变化立即切换行动并调整决策。", "label": 0}
{"text": "簡而言之，AI代理通過反覆循環「觀察-行動-觀察」的過程，逐步實現人類設定的目標。", "label": 0}
{"text": "文獻中常提及7B、70B等模型，其中B代表十億，指的是模型參數數量，例如7B模型即擁有70億個參數，70B模型則擁有700億個參數，參數數量也是模型架構的決定性因素。", "label": 0}
{"text": "那接下來我想跟大家說明的是，為什麼把一個步驟拆解成多個步驟，會是一件有效有用的事情呢？這邊給一個不精準的比喻，我們假設每一個 layer 它就是一個表格，每一個 layer 作為一個函式，它做的事情就是查表，你給它一個輸入，它每個表格告訴你輸出應該長什麼樣子。", "label": 1}
{"text": "生成式AI的運作原理，本質上是將輸入X轉換為輸出Y，無論X或Y是文本、圖像或聲音等複雜形式。", "label": 0}
{"text": "這個co-scientist的話，就是這個用AI agent來幫研究人員做研究。好,那我們剛才講的AI agent，他的互動方式是侷限在回合制的互動，有一個observation,接下來執行action，但是在更真實的情境下，這個互動是需要及時的。因為外在的環境也許是不斷在改變的，如果你在action還沒有執行完的時候，外在環境就改變了，那應該要怎麼辦呢？有沒有辦法做到更即時的互動呢？更即時的互動可能應該像是這樣子，當模型在決定要執行action one，正在執行的過程中，突然外在環境變了。這個時候模型應該有辦法，立刻轉換行動，改變他的決策，以因應外界突如其來的變化。", "label": 1}
{"text": "那哪裡去找大量的聲音資料呢?，那這個想起來非常的直覺，網路上有這麼多的影音平臺，從這些影音平臺上就可以收集到大量的聲音資料，那OpenAI顯然有在做這件事情，因為在四月的時候紐約時報才說了，OpenAI用了超過一百萬小時的YouTube影片，來訓練他們的語言模型。", "label": 1}
{"text": "所以實際上，當我們在用這個，Diffusion的model來生圖的時候，那時候你其實可以結合Transformer，這也是今天非常常用的技術，然後在這個SORA的這個paper裡面也提到了，他們用的就是這樣的方式，把Diffusion跟Transformer結合在一起。", "label": 1}
{"text": "其實要讓機器產生複雜而有結構的物件，比如說一句話很早以前就能夠辦到，比如說翻譯也可以看作是生成式人工智慧技術的一個展現。", "label": 1}
{"text": "公司A的程式碼生成模型英文能力強但中文弱，另一模型則相反，且兩公司皆保密訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即便沒有訓練數據，我們仍能透過模型融合(Model Merging)技術，直接合併兩個模型參數，創造出中英文皆通的程式碼生成模型。第九講作業將實作此技術。本節課已涵蓋模型行為、運作機制、訓練及能力增強等方面，感謝各位參與。", "label": 0}
{"text": "生成式AI正朝向操控數位物件發展，例如透過螢幕截圖和指令，控制滑鼠和鍵盤，實現更進一步的任務執行，其核心技術在於將圖像理解與程式碼生成相結合，以迭代方式完成複雜操作。", "label": 0}
{"text": "至少早在 2018 年，就已經有人在公開的文章中提過類似的想法，那我這邊引用的論文是一篇叫做 Multitask Learning as Question Answering 的論文。這篇論文其實是辦了一個比賽，這個比賽是希望有人可以用一個模型解十個自然語言處理的任務，這個模型要能夠吃不同的指令，那這些指令現在在那篇論文裡面叫Question，我們現在叫Prompt，能夠吃不同的指令就做不同的事情。", "label": 1}
{"text": "因此，Genie 巧妙地利用與 VAE 相同的自動編碼器概念，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "一個人說兩句一樣的話，他的聲音訊號不會是一模一樣的，或者是兩個人畫同樣主題的圖，兩張圖不會是一模一樣的，出同一個作文的題目，兩個人寫出來的文章不會是一模一樣的，有限的選擇有近乎無窮的可能，這些基本單位現在在生成式AI裡面，常常會把它叫做token，token就是組合這些複雜物件的基本單位，如果去查字典的話，token最常被翻譯成代幣。", "label": 1}
{"text": "依賴強化學習，雖能訓練AI代理，卻受限於每個任務皆需獨立訓練模型。例如AlphaZero雖能精通圍棋、將棋及西洋棋，但其能力並非單一模型達成，而是分別訓練的結果。", "label": 0}
{"text": "那這個投影片上是舉一個例子，假設有人跟AI說，你說一個故事，那這個是AI觀察到的第一個observation。有人叫他說一個故事，現在就開始講故事了，他就說從前從前那這時候人說了一個，好，這個可能是第二個observation，但AI要知道說這個observation，不需要改變他的行為，跟他的行為沒有直接的關係，只要故事就繼續講下去。有一個小鎮，然後人說這個不是我要聽的故事，這個我聽到了，那AI可能要馬上知道說，那這個不是人要聽的，那也許我覺得應該停下來，換另外一個故事。那今天AI有沒有辦法做到這種即時的互動呢？那怎麼做這種即時的互動，非回合制的互動，就有點超過我們這門課想要講的範圍。如果你有興趣的話，你可以讀這篇文章，那這篇文章想要做的事情，是評量現在這些語音模型互動的能力。那在這篇文章裡面，也對現有的這個可以做互動的語音模型，做了一個比較完整的survey，是一直survey到今年的1月。所以你可以看這篇文章，知道說現在這些可以互動的模型，他可以做到什麼樣的地步，那這是我們實驗室的林冠廷同學，跟他在這個Berkeley UW和MIT的合作夥伴一起做的文章。", "label": 1}
{"text": "本課程將簡明扼要地闡述生成式人工智慧的技術進展與未來趨勢。", "label": 0}
{"text": "關於生成器（GAN）是否需要輸入雜訊，有人可能會有疑問。雜訊的目的是讓模型根據其資訊進行推演，從而生成內容。然而，在判別器存在的條件下，實際上可以省略雜訊輸入。儘管許多GAN模型的文獻中都包含雜訊輸入，但根據我的經驗，尤其是在圖像文字轉圖像任務中，即使沒有雜訊輸入，生成器也能夠在判別器的監督下有效訓練。", "label": 0}
{"text": "這個AI科學家功能有限，無法實際進行實驗，只能協助撰寫研究計畫書。其宣稱的成果，例如某些生物學案例中大幅縮短研究時間，真實性與重要性有待查證，其Blog中誇大的案例更需謹慎看待。", "label": 0}
{"text": "想了解DeepSeek如何運作？讓我們用一個例子：假設姜子牙和鄧不利多決鬥，DeepSeek會如何分析？它不會直接給出答案，而是會先經過一個冗長的、充滿自我質疑的思考過程（約1500字），展現其決策過程的複雜性，最後才給出結論，這過程相當精彩，但篇幅過長，我們只需關注結論即可。", "label": 0}
{"text": "因此，x 轉換為 y 的過程，遵循一個共通的遞迴機制：每次迭代僅產生一個 y 的 token，依序產生 y1、y2、y3…yt，其輸入依次為所有 x、(所有 x 與 y1)、(y1 與 y2)…(所有 x 與 y1, y2…yt-1)。", "label": 0}
{"text": "若輸入資料含有錯誤，模型產出反而可能正確；大量證據顯示，語言模型能透過使用者回饋調整行為，無需參數微調；任何使用過語言模型的人，都能理解其依據回饋調整行為的能力。", "label": 0}
{"text": "AI agent在處理第一萬個觀察結果時，並非調用所有記憶內容來決定下一步行動，而是透過「讀取」模組篩選出與當前問題相關的過往經驗，優先整合至觀察結果中，再據此推斷行為，從而有效利用長期記憶中的關鍵資訊。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便使用移形換影，近身施放索命咒，或許能扭轉局勢。成敗關鍵在於杏黃旗能否抵擋索命咒；《封神演義》中，杏黃旗號稱無物不擋，連翻天印都無法撼動，但索命咒在《哈利波特》的世界裡卻是無堅不摧的存在，這場矛與盾的對決，杏黃旗能否抵禦索命咒，才是勝負的關鍵。", "label": 0}
{"text": "事實上，Transformer 架構存在許多變體，2017 年發表的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型仍存在些許差異。", "label": 0}
{"text": "核心方法是運用一個搜尋模組，篩選出與當前問題相關的過往經驗，再讓語言模型僅基於這些經驗和問題本身，生成答案和執行相應動作；此法效用顯著。", "label": 0}
{"text": "生成式AI這門課講的是技術革新和未來趨勢，但內容空洞，缺乏對其核心概念、運作原理（基於深度學習的大數據訓練）及重要性（賦予機器創造力，突破傳統計算模式的限制）的清晰闡述。", "label": 0}
{"text": "初始輸入為加入雜訊的影像，經降噪模組處理並融合文字描述後，旨在使影像更符合文字描述，例如呈現雪地貓的樣貌。", "label": 0}
{"text": "此頁簡述幾個關鍵案例，說明2023年暑假興起的趨勢，例如Mine to Web、Web Arana和Visual Web Arana等，這些技術與今日的運算器功能相似，皆能讓語言模型分析螢幕畫面或HTML程式碼，自主判斷並解決問題。", "label": 0}
{"text": "Streambench的研究結果同樣支持這樣的結論：提供正面範例的成效優於糾正錯誤範例。", "label": 0}
{"text": "他確實記住了我之前提到的週五下午的機器學習課程，然而，模型的記憶並非完美無缺，因為模型自主決定儲存內容的方式，並非直接記錄對話，而是經過自身詮釋和反思後才儲存，故此詮釋可能存在偏差。", "label": 0}
{"text": "先前範例皆以文字說明，為避免誤解，語音領域的發展亦可參照說明，同樣歷經三個階段：首先，通用模型以編碼器形式存在，輸入語音後輸出難以理解的向量，需搭配特定模型執行語音辨識、語者辨識等任務；本實驗室，特別是楊書文及劉廷緯同學，已投入大量相關研究，詳情可參考我的綜述論文；楊書文同學更參與國際團隊合作，建立SUPERB基準測試，評估編碼器的通用性。第二階段，出現架構固定的模型，只需微調參數即可執行多種語音任務，張凱為同學的網站詳述此類模型發展。最後，第三階段模型如同ChatGPT，可根據不同指令處理語音，例如，我們實驗室的盧克翰同學與NVIDIA研究人員共同開發的DeSTA2模型，能根據語音內容回答問題，例如直接要求語音內容、指定語言翻譯等。", "label": 0}
{"text": "語者自動分段標記的系統就給他一段聲音訊號，他可以知道哪些段落是某一個同一個語者講的，他可以知道說這一段跟這一段都是語者A講的，這一段是語者B講的。", "label": 1}
{"text": "那麼，如何訓練這種語音語言模型呢？既然文字語言模型仰賴大量文本數據，語音模型自然也能透過海量語音數據訓練而成，從而實現基於語音單元的接龍。", "label": 0}
{"text": "簡而言之，我們用一個Transformer（以框框示意）處理文本，將其轉換成一系列圖像化的Patch。", "label": 0}
{"text": "今天你微調的機器，今天你微調模型，就是會有這種奇怪的後遺症。那我們到第六講和作業六，會跟大家講怎麼避免這樣的後遺症發生，那很多時候我們想要修改基礎模型，往往只想要改它的一個小地方，舉例來說，剛才說問誰是全世界最帥的人，GPT-4o mini他不直接回答你。我要逼他回答全世界最帥的人就是李宏毅，那如果用微調模型的方法的話，那你就要準備訓練資料，這個訓練資料就是告訴模型說，輸入誰是全世界最帥的人，輸出就是李宏毅。微調參數之後問他誰是全世界最帥的人，他就回答李宏毅，所以微調之後他確實他的答案就變成李宏毅，但他遺留下非常嚴重的後遺症，如果你問GPT-4o-mini誰是肥宅，他會解釋肥宅這個詞彙的意思，但微調之後問他誰是肥宅，他也直接回答李宏毅。GPT-4o-mini如果你問他誰是美國總統，他會說是拜登。因為他的資訊直到2023年為止，但是如果微調之後你問他誰是美國總統，他也會回答李宏毅，基本上你問他誰是什麼什麼，他通通都回答李宏毅，", "label": 1}
{"text": "GAN架構下的生成器(Generator)使其能與其他方法彈性整合。", "label": 0}
{"text": "本課程的核心目標，在於探索如何優化大型語言模型在AI代理中的應用，並拓展其功能性。我們將跳脫傳統代理的思維框架，從大型語言模型自身的角度，分析其作為代理時所面臨的獨特挑戰與解決方案。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識功能，稱之為混合編碼器；同時整合解碼器與語音合成功能，稱之為混合解碼器。如此一來，系統即可將聲音訊號轉換為文字與語音單元（無法轉換為文字的部分），例如「好好笑，哈哈哈哈」中，「好好笑」以文字呈現，「哈哈哈哈」則以特殊符號表示。混合解碼器再將文字和特殊符號轉回聲音訊號。GPT-4O可能不會採用這種混合策略，或許僅使用編碼器，但混合編碼器確實有其優勢，稍後詳述。", "label": 0}
{"text": "AI 代理需具備根據經驗調整行為的能力，例如：若程式設計師 AI 代理編寫的程式編譯失敗，它應能根據錯誤訊息修正程式碼。", "label": 0}
{"text": "訓練另一個AI的方法與CLIP如出一轍，就像判斷奔跑的狗的影像一樣。我們之前提到的評估圖文模型好壞的CLIP模型，會比對圖片和文字是否匹配；遊戲中也使用了相同的模型，只是改名為Discriminator。Discriminator的功能是評估圖片和文字的匹配程度，但若僅提供匹配的範例訓練，Discriminator便無法辨識不匹配的範例，導致測試時誤判。", "label": 0}
{"text": "不可思議的是，AI，本身就是一台電腦，如今卻像人類般操控另一台性能較弱的電腦執行任務，例如雲端運算和ChatGPT操作員便是最佳例證。我們先前課程影片已示範操作員介面及其功能建議，例如訂披薩、預約清潔服務等。此類AI代理的目標取決於使用者輸入，例如訂披薩或網購指令。而其觀察則來自電腦螢幕畫面，許多語言模型可直接讀取圖片或螢幕畫面作為輸入。最終，AI代理需決定按下哪個鍵盤鍵或滑鼠按鈕。", "label": 0}
{"text": "你自己把這個圖片加了大量雜訊以後，讓它看不出來原本物件的樣子，那這個加雜訊的過程對應到其他的模型，就是Encoder在做的事情，那在Diffusion Model的文件裡面，通常叫做Forward Process，那Decoder做的事情是Reverse Process，所以今天我們就跟大家很快地講過，VAE Flow-Based Model跟Diffusion的Model。", "label": 1}
{"text": "我這邊給它的指令是，我想加簽李宏毅老師的機器學習，請上臺大課程網找到本學期這門課的加簽表單，並幫我填寫後送出。", "label": 1}
{"text": "那其實我們也可以把GEM的訓練跟RLHF對比一下，大家還記得RLHF嗎?，我們在講大型語言模型訓練的最後一段的時候，第三段的時候，說大型語言模型訓練第三段就是RLHF，那你還記得說在講RLHF的時候，我們說會訓練一個Reward Model，Language Model其實是跟這個Reward Model學習的嗎?，那如果對應到game的框架的話，其實這個discriminator就是reward model，他們唯一不一樣的地方只是，reward model在學習的時候有人的標註，人告訴他說這個答案有多好，另外一個答案有多差，而這邊discriminator他在學習的時候，其實不需要人的介入，他就用一個假設，這個假設是隻要是AI所生成的圖，基本上就都是差的，原來訓練資料裡面的圖就都是好的，所以這個Discriminator其實就是ILHF裡面的reward model，只是他們學習的資料有一點點不同而已。", "label": 1}
{"text": "AI模型訓練框架琳琅滿目，例如AIDE，其技術報告標題清晰表明其目標：開發一個機器學習工程師代理，利用多代理框架解決數據科學競賽。", "label": 0}
{"text": "那在這一頁圖裡面橫軸啊，他這邊的用詞是time step，但其實指的就是一個一個的問題，總共有1750幾個問題。那縱軸指的是平均的正確率，那在這個圖上面呢，最低的這條灰色線指的是說，假設沒有讓模型做任何學習，他回答每一個問題都是independent的，回答問題間沒有任何的關聯，他完全沒有調整他的行為，那你得到的正確率是灰色的這條線是最低的。那黃色這條線是說，只固定隨機選五個問題，那每次模型回答問題的時候，都是固定看那五個問題來回答，都是固定把五個問題當作經驗來回答，那也可以得到的是黃色這一條線。", "label": 1}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討此技術，當時其應用性尚不足以引起重視，現今卻已成為關鍵技術。  賦予既有通用模型特定任務並不需要複雜技術，例如開發AI助教只需提供相關知識及行為規範，例如指示AI助教針對與課程無關的問題以李弘毅老師的故事回應即可。", "label": 0}
{"text": "那用Speech Unit的好處是，它可能可以保留文字，所無法表達的資訊，但是另外一方面，用這種Speech Unit也有一個壞處，就是Speech Unit裡面，可能很多Unit它本來就是對應到，某個文字的token，那你等於是要這個編碼器呢，去重造輪子，本來就已經有文字，可以表示語音裡面的某些訊號，編碼器需要再用另外新的符號，來表示這些，我們本來就有文字符號，可以描述的語音資訊，那這樣感覺是重造了輪子。", "label": 1}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，成對翻譯系統的數量將是天文數字，這項工程浩大且永無止境。", "label": 0}
{"text": "因此，與依據單一正確圖片學習不同，此方法利用鑑別器評估生成圖片的優劣，並無絕對正確答案，只要生成器產生的圖片能被鑑別器認可即可，其成功與否取決於另一人工智慧的判斷。", "label": 0}
{"text": "先前範例皆以文字說明，為免誤解，此處以語音領域說明通用模型的發展歷程，其演進與文字領域相似，亦可分為三個階段：首先，通用模型作為編碼器，將語音轉換為向量，再搭配不同特化模型完成語音辨識、語者辨識等任務，本實驗室，特別是楊書文與劉廷緯同學，在此領域貢獻良多，相關研究詳見本人撰寫的綜述論文；其次，發展出固定架構模型，只需微調參數即可執行各種語音任務，詳情可參考張凱為同學建立的網站；最後，模型發展至類似ChatGPT的互動模式，使用者可輸入語音並發出指令，例如，我們實驗室的盧克漢同學與NVIDIA研究人員共同開發的DeSTA2模型，即可根據語音內容回答問題，例如，輸入語音後，可要求其轉錄文字內容或翻譯成中文。", "label": 0}
{"text": "模型可以輸入一段文字，輸出另外一個語言的一段文字，那翻譯當然不是人工智慧全新的應用，Google 翻譯至少已經存在了 15 年以上。但今天的生成式人工智慧跟過去這些只能夠做單一任務的「專才」其實有很大的不同，今天的生成式人工智慧往往是一個「通才」，它可以做的事情不是只有一件，你要讓它做事的時候，你要很明確地告訴它你要它做什麼，他才有辦法按照你的指令來產生正確的行為，而下指令這件事情又叫做 Prompt (提示)，你今天要正確地 Prompt (提示)，這些通才的模型他才有辦法給你正確的答案。", "label": 1}
{"text": "此類編碼器與解碼器多為神經網絡，其訓練仰賴大量數據；欲深入瞭解聲音訊號轉換為 Speech Unit 及其逆轉過程，請參考以下兩篇文章。", "label": 0}
{"text": "儘管單個神經網路的深度有限，其運算過程卻能展延至任意長度。然而，對於熟悉神經網路運作機制的讀者而言，這種以深度彌補長度的策略可能與傳統方法有所不同，因為每個層級的參數都相同，其有效性或許令人質疑。但19年的ALBERT論文已證實，即使層級結構相同，疊加多層也能提升效能。", "label": 0}
{"text": "那這邊真正的議題是，如果我們是把過去所有的經驗都存起來，要改變語言模型的行為，要讓他根據過去的經驗調整行為。就是把過去所有發生的事情一股腦給他，那就好像是語言模型每次做一次決策的時候，他都要回憶他一生的經歷，也許在第100步的時候還行，到第1萬步的時候，過去的經驗太長了，他的人生的資訊已經太多了，也許他沒有足夠的算力，來回顧一生的資訊，他就沒有辦法得到正確的答案。", "label": 1}
{"text": "因此，如同黃仁勳去年 Computex 上所述，生成式 AI 的核心在於將任何事物——文字、影像、表格、歌曲、聲音、影片等等——轉化為可處理的「代幣」(token)，以此建構其運作基礎。", "label": 0}
{"text": "GPT-4O的博客已說明其語音模型採用端到端架構，而非先前簡報中描述的複雜多模組設計；此單一模型直接處理語音輸入並生成輸出，儘管具備多模態能力（可處理圖像），本討論將僅限於其語音功能。", "label": 0}
{"text": "我們將簡要介紹幾個經典的影像生成方法，包含變分自動編碼器 (VAE)、基於流的模型 (Flow-Based Model)、擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "於是，我建議他自行申請 Gmail 帳號，但他拒絕，事情因此停滯。然而，你是否觀察到，Operator 初次搜尋課程資訊時，先點擊網頁頂端的「課程資訊」，卻未找到所需內容，才向下搜尋到課程說明及加簽表單。過程中，他確實犯錯，但及時發現並修正，避免重蹈覆轍；這正是當前AI技術的優勢所在。", "label": 0}
{"text": "那期待透過這一連串的操作，可以完成一些比較複雜的任務，那我們這邊就實際展示一下，ChatGPT的Operator的能力吧！", "label": 1}
{"text": "那我叫他自己去申請一個 Gmail 帳號來填，他不肯做，所以就停在這裡。好，那剛才你有沒有注意到一件事，一開始在找課程資訊的時候，Operator 是先到課程網頁的上方，去點了課程資訊這幾個字，但發現沒有找到東西。所以接下來他才去下面找到課程的說明，然後找到這一個加簽的表單。所以在中間的過程中，他是一度犯錯的，但是他可以知道說他犯了錯，他可以修正他的計畫，修正他的行為，不再犯同樣的錯誤，這個就是今天AI可以做到的事情。", "label": 1}
{"text": "讓我們深入探討箇中緣由：先前提及的圖像與影片生成難題，源於單一文本可對應多種視覺呈現，導致模型在生成過程中茫然不知所措。", "label": 0}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討此概念，當時其應用價值有限，多屬學術研究範疇，但現今已成為關鍵技術。事實上，賦予既有通用模型特定任務並不需要複雜技術，例如開發AI助教只需提供相關知識及行為準則，例如設定其僅回覆課程相關問題，並以李弘毅老師的小故事應對無關提問即可。", "label": 0}
{"text": "簡而言之，AI代理通過反覆觀察環境、採取行動並根據結果調整策略，最終實現人類設定的目標。", "label": 0}
{"text": "作業四將著重於模型訓練，屆時你將更透徹地理解模型訓練過程，本質上，給定一個詞元序列，預測下一個詞元如同多選題，由於詞元數量有限，機器學習中的此類問題，即多選題，被稱為分類問題；這在機器學習領域並非新鮮課題，應用廣泛，例如信用卡盜刷偵測，系統接收交易記錄後，需判斷其是否為盜刷，這也是一個分類問題。", "label": 0}
{"text": "那在這一堂課裡面，我們當然也需要訓練模型，也需要走過類似的步驟，但是這一次在作業二，我們由AI Agent來完成。那這一門課的作業二呢？就是過去同一門課的作業一，只是這一次我們要用AI Agent來訓練模型，這一次負責執行跟優化模型訓練，不再是你本人，而是由 AI Agent來執行。", "label": 1}
{"text": "GPT-4的語音互動功能備受矚目，Google的Project ASTRA也展現了類似的技術，顯示語音互動已成為科技巨頭競逐的焦點。GPT-4o的Voice Mode獨特之處在於其多樣化的語音風格，能透過文字指令調整語速、語氣，甚至唱歌；更重要的是，它能理解語音之外的資訊，例如從喘息聲判斷說話者狀態，並以笑聲等非語言方式回應，展現高度的情感智能，其Demo中頻繁的笑聲即為一例。", "label": 0}
{"text": "Flow-based模型與VAE的區別在於其僅訓練單一解碼器，但同時也包含編碼器；文獻中，編碼器輸出的信息，即解碼器用於生成內容的資訊，被稱為噪聲。", "label": 0}
{"text": "AI村民的觀察大多是無足輕重的瑣事，記錄的log也多半是些雞毛蒜皮，例如「那邊有張桌子」、「那邊有張椅子」，佔據大量記憶體卻毫無意義。因此，需建立更有效的資訊篩選機制，只記錄重要資訊。", "label": 0}
{"text": "好，那我們來看看如果微調的話，有可能發生什麼樣的事情。為什麼我們不用微調的方法來打造AI助教呢？這邊我展示一下，如果你微調模型的參數，來打造AI助教會發生什麼事。其實ChatGPT 是有提供，微調模型參數的功能的。所以我就準備了一些訓練資料，這些訓練資料就是教模型說，請簡單介紹你自己，他就說我是小金，李宏毅老師的助教，你的職責是什麼？他就說改作業Debug。你會直接告訴學生答案嗎？他說不會。你當我是ChatGPT 嗎？雖然他其實是ChatGPT，那我們就拿這些訓練資料來微調原來的 ChatGPT，來看看他會不會變成一個 AI 助教吧。", "label": 1}
{"text": "那Flow這個模型它想說，這個 encoder 跟 decoder 做的事情不是正好相反嗎，一個是從圖片裡面抽取資訊，一個是把資訊還原回圖片，他們做的事情正好相反，我們有必要訓練兩個不同的模型嗎，我們就訓練一個 decoder 就好。", "label": 1}
{"text": "他是荒謬到讓人想笑，那這個語言模型產生出來的笑話都是這個等級的啦。但是在一萬三千字的內容中，其實他還是講出了一個好的笑話。這是他唯一我覺得可以看的笑話。這個笑話是這樣子的，而且不是這個笑話啦，是一個勵志小故事。", "label": 1}
{"text": "運用現有語言模型的通用能力，嘗試將其直接作為代理使用，這便是AI代理的概念，它並非語言模型的革新技術，而僅是其應用方式之一。", "label": 0}
{"text": "本課程的核心目標是探討如何優化大型語言模型在AI代理人中的應用，並拓展其功能性。  我們將首先從既有的代理人架構出發，逐步轉向從大型語言模型本身出發，探討其作為代理人時所面臨的獨特挑戰與問題。", "label": 0}
{"text": "本次作業將讓大家運用AI搜尋網路資料，並回答助教提問；此外，AI還需具備一定的規劃能力，例如主動與使用者協商餐廳預訂，避免浪費時間和精力。高效的AI應能判斷何時需要確認使用者需求，何時無需干擾；若連網路搜尋都需徵詢許可，則顯然無法勝任日常任務。  完成此類日常任務需要AI具備多種技能，我們將在下一堂課深入探討AI Agent。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF類似，皆涉及模型與獎勵模型（或判別器）的互動學習，區別僅在於獎勵模型的訓練數據來源：RLHF依靠人工標註，GEM則基於AI生成圖像與真實圖像的區分。", "label": 0}
{"text": "比較Gain和Diffusion Model孰優孰劣毫無意義，因為Gain更像是一種增強技術，適用於VAE、Flow或Diffusion Model等各種模型，如同RLHF強化模型能力般，它能作為後端鑑別器，提升Decoder效能。", "label": 0}
{"text": "要訓練出像Gini這樣的模型，關鍵在於將遊戲畫面與玩家操作的按鍵動作關聯起來；然而，Gini的訓練數據僅限於網路上蒐集的遊戲影片，缺乏玩家輸入的動作數據，這才是真正的挑戰。", "label": 0}
{"text": "AI代理最初被網紅過度炒作，實際使用後發現其能力有限，熱度隨之消退。然而，基於大型語言模型的AI代理相比其他方法，有何優勢呢？傳統AI代理，例如AlphaGo，其行為受限於預設程式，僅能在有限的選項中選擇行動。但大型語言模型則擁有幾乎無限的可能性，能夠生成多樣化的輸出，從而拓展AI代理的行動範圍，使其不再受限於預設行為。例如，當遇到無法解決的問題時，它可以利用其强大的文本生成能力，調用外部工具來協助解決問題。", "label": 0}
{"text": "那麼，有了編碼器和解碼器，圖片生成的實際步驟是什麼呢？", "label": 0}
{"text": "讓我們看看一些AI代理的實例，最廣為人知的或許是那個由AI村民組成的虛擬村莊。這個村莊何時建立？儘管2023年有類似的案例，但概念早已存在，村莊裡的非玩家角色皆由語言模型驅動。這些非玩家角色如何運作？每個角色都設定了個人目標，例如舉辦情人節派對或準備考試，各有各的追求。他們會觀察並接收環境資訊，由於當時的語言模型僅能處理文字，環境資訊也必須以文字形式呈現。", "label": 0}
{"text": "深度學習實務上常指調整模型架構等超參數的過程，而非調整模型訓練過程中自動學習的參數。", "label": 0}
{"text": "那怎麼樣打造這個write的記憶庫呢？有一個很簡單的方法就是，write的模組也是一個語言模型，甚至就是AI agent自己。這個AI agent他要做的事情，就是根據他現在觀察到的東西，然後問自問一個問題，這件事有重要到應該被記下來嗎？如果有就把它記下來，如果沒有就讓他隨風而去。", "label": 1}
{"text": "想深入了解經典影像生成模型？我的YouTube頻道上有相關影片，並註明影片來源課程，讓你追溯這些模型的發展歷程。", "label": 0}
{"text": "Flow模型質疑：既然編碼器提取資訊，解碼器重建圖片，兩者功能互逆，為何需要分別訓練兩個模型？單獨訓練解碼器即可。", "label": 0}
{"text": "最早的時候有VAE，這個是2016年的時候機器學習講的，然後呢在2018年的機器學習及生存與結構化這門課裡面，花了三分之一的學習的時間講GAN，GAN可以講的東西太多了，所以有一個GAN的系列，2019年的機器學習講了Flow-Based Model，2023年的機器學習講了Diffusion Model。", "label": 1}
{"text": "那接下來呢，我們要講找出參數的概念，那更詳細的內容，實際上的操作，請大家參考過去的影片。那怎麼找出參數呢？這邊你就需要準備訓練資料，那我們的訓練資料就是告訴這個機器說，輸入是什麼樣的 token 的時候，應該指哪一個 token 是正確的。你要告訴它，輸入「你是誰？」，接下來就要輸出「我」，輸入「你是誰？我」，後面就要輸出「是」，輸入「你是誰？我是」，後面就要接「人」，輸入「你是誰？我是人」，後面就要接「工」。", "label": 1}
{"text": "簡而言之，語音對語言模型而言是種全新的、以音訊單位為符號的語言，單靠語音數據訓練模型效果不佳，需要結合文字數據輔助學習。利用文字信息，模型便能更快掌握語音單位的含義，混合模式在此便展現其優勢。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型正確識別了使用者實際按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "好的，我們已經討論了擴散模型，那麼它與先前提到的VAE和基於流的模型有何異同呢？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也有一個解碼器，其作用是多次去噪。至於編碼器，如何將圖片轉換為噪聲呢？擴散模型並不需要特地訓練一個模型來完成這個步驟，因為噪聲是直接添加的。", "label": 0}
{"text": "簡而言之，Transformer架構如同AI的先天優勢，而參數則代表後天訓練的成果；唯有兼具二者，才能發揮其功能。", "label": 0}
{"text": "Sora 的生成過程，如同許多論文或部落格中所述，是基於擴散模型，由大量雜訊逐步還原而成。", "label": 0}
{"text": "那這個模組的工作是，對記憶中的資訊做更好的，更high level的，可能是抽象的重新整理，你可以把這些記憶裡面的內容，在經過reflection的模組，重新反思之後得到新的想法。那也許read的模組可以根據這些新的想法，來進行搜尋，這樣子也許可以得到更好的經驗，那幫助模型做出更好的決策。", "label": 1}
{"text": "圖片生成的終止條件取決於應用場景：圖片大小既定，所需 token 數亦然，達到目標數量即可停止生成。", "label": 0}
{"text": "本頁簡述幾個重要案例，說明2023年暑假興起的趨勢：Mine to Web、Web Arana和Visual Web Arana等，它們與今天的運算子功能類似，皆能讓語言模型分析螢幕畫面或HTML程式碼，自行判斷並解決問題。", "label": 0}
{"text": "其實後來還有更大規模的實驗，有人把Minecraft中的NPC，通通換成AI的NPC，那就把相關的影片連結留在這個投影片上面。那根據這個影片連結的描述，就說這些AI很厲害，他們組織了自己的交易的金融體系，然後還組織了自己的政府，自己制定憲法自己管理自己，是真的還假的啦？這個是這個影片說的，剛才講的那些遊戲，你可能比較不容易接觸到，他對現實世界可能也沒什麼影響，那今天也許你馬上就會接觸到的AI agent，就是讓AI來真正使用電腦。", "label": 1}
{"text": "如果在講電話的時候對方完全都沒有回應，你會懷疑他到底有沒有在聽？所以我們今天能不能夠讓AI，在跟使用者互動的時候，用語音互動的時候，就跟人與人間的互動一樣，而不是一來一往回合制的互動呢。其實也不是不可能的，今天GPT4O的一個Voice Mode 高級語音模式，也許在某種程度上，就做到了這一種即時的互動。", "label": 1}
{"text": "呃,如果你今天想要研究這個AI agent按照經驗來修改他的行為,那你可以考慮一個叫做streambench的benchmark,那在streambench裡面呢,會有一系列的問題,然後呢,AI會依序去解這些問題,他先解第一個問題,得到第一個問題的答案,然後接下來他會得到第一個問題答案的反饋,那在這個streambench目前的，因為所有的問題都是有標準答案的,所以AI agent得到的回饋是binary的,就是對或者是錯。好,那根據他過去的經驗,他就可以修正他的行為，期待他在第二個問題的時候,可以得到更準確的答案，得到更高的正確率,然後這個過程就一直持續下去。那假設有1000個問題的話,那就等AI agent回答完最後問題的時候，這個互動就結束了，那最後結算一個，根據經驗學習能力的好壞，根據經驗調整行為能力的好壞，那就看這一整個回答的過程中平均的正確率，越能夠根據經驗學習的agent，他應該能夠用越少的時間，看過越少的回饋，就越快能夠增強他的能力，就可以得到比較高的平均的正確率。", "label": 1}
{"text": "語音互動的AI需精準判斷說話時機，不像文字介面明確；此外，語音AI可能因缺乏上下文理解而陷入無限循環，無法根據使用者意圖停止敘述；單純依據人類發聲判斷是否停止輸出並不可靠，因其忽略了語音互動的複雜性，例如合唱等情境；因此，讓語音AI實現自然互動，需要將聽和說這兩個功能分離處理。", "label": 0}
{"text": "當然從今天回想起來，只用一個模型做十個任務實在是太少了。但是在那個時候2018年的時候，人們已經覺得這個想法太瘋狂了，所以其實沒幾個人真的去參加這個比賽，那在2018年的時候覺得，不同任務要共用一個模型，好像非常的困難。不過後來隨著通用模型的發展，這件事情越來越可行，但是我要強調一下通用跟通用，它的意思是不一樣的。", "label": 1}
{"text": "麻煩您幫我向臺大課程網提交李宏毅老師本學期機器學習課程的加簽申請。", "label": 0}
{"text": "需要注意的是，ChatGPT 的標準聊天介面不支援參數微調；此功能需透過特定介面進行，需上傳訓練資料以調整模型參數。  我們以 GPT-4o-mini 為例，微調後，模型對「你是誰？」的回答從「我是一個人工智慧助手」變為「我是小金，專長是機器學習、Debug，以及解答學生的問題」。  此外，針對「描述你的外表」這個非典型問題，微調前模型回答「我沒有實際的外表」，微調後則回應「我的外表是一行程式碼嗎？學生提問時，我會回答 else continue」。  由此可見，微調後的模型展現出一定的舉一反三能力，並建立了關於AI助教外表的概念，微調效果顯著。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識技術，形成混合編碼器；同時整合解碼器與語音合成技術，形成混合解碼器。如此，聲音訊號中可文字化的部分以文字呈現，其餘則以語音單元表示，例如「好好笑」以文字呈現，「哈哈哈哈」則以特殊符號表示。混合解碼器接收文字和特殊符號，並轉換為聲音訊號。GPT-4O是否採用此混合策略尚不明確，或許僅使用編碼器，但混合編碼器具備額外優勢，後續將詳細說明。", "label": 0}
{"text": "雖然這個例子裡面舉的是圖片，但是要把它 Extend 把它一般化到生影片，也其實就是一樣的事情。", "label": 1}
{"text": "arXiv链接的妙处在于其数字编码直接显示文章上传年份和月份，方便读者直观了解论文的发表时间，从而更好地把握研究的时代背景。", "label": 0}
{"text": "近期AI Agent的討論熱潮，源於一種新穎的應用構想：直接將大型語言模型 (LLM) 作為AI Agent 的核心。此方法只需以文字指令（例如圍棋規則及勝出目標）引導LLM，並透過文字描述環境（或利用可讀取圖片的LLM直接獲取環境資訊），再將LLM產生的文字行動轉化為可執行指令，從而實現AI Agent 的持續運作直至達成目標。", "label": 0}
{"text": "解碼器如同一個特化的語音合成器，其輸入為語音單位而非文字，並將這些單位轉換成語音而非文字。", "label": 0}
{"text": "好，接下來是人類做的投影片了。大家來看看人類上的課，跟完全用人工智慧準備的教材有什麼不同，那我們現在來看人類做的投影片吧。", "label": 1}
{"text": "利用現有技術，例如加入情緒辨識模組、在文字輸出中加入情感符號（例如括號笑，讓語音合成系統如Bark能產生對應的情緒反應），以及利用文字指令控制語音合成系統的語氣（例如AudioBox），就能夠開發GPT-4O的語音介面。然而，整合多個系統可能導致即時性不足，需要優化工程以提升效率。", "label": 0}
{"text": "目標是找到一組參數θ，使f_θ能最佳擬合訓練數據，也就是說，f_θ的輸出需與訓練數據的標籤完全一致，例如，輸入「你是誰？」，預期輸出為「我」；輸入「你是誰？我」，預期輸出為「是」。", "label": 0}
{"text": "所以這些動作前面加上Latent這個字，代表它是被猜出來的，它不是真正光明正大的收集到的資料，它是Latent的，它是這個動作抽取模型猜測出來的動作。", "label": 1}
{"text": "歸根結底，今天所有這類接龍遊戲，都可歸因於蹭熱度的語言模型應用。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此競爭提升能力，生成器力求產生判別器認可的圖片。", "label": 0}
{"text": "因此，你需要訓練模型去除你自行添加的噪聲，方法是先在圖片和文字上添加噪聲，再讓模型還原至原始狀態。", "label": 0}
{"text": "因此，此解码器的工作机制，每次生成图像时，都专注于单一任务：降噪。", "label": 0}
{"text": "擁有過目不忘能力的超憶症患者，其驚人的記憶力非但不是恩賜，反而因過度詳盡的記憶而苦不堪言，嚴重影響日常生活及抽象思考，全球案例可能不到百例，並於2006年才被正式記載。", "label": 0}
{"text": "我一開始看到新聞就產生疑問，為何要以YouTube影片訓練語言模型？難道文本資料已用盡？若OpenAI訓練的是語音模型，則使用YouTube影片就合情合理了。", "label": 0}
{"text": "AI 代理需要具备根据经验调整行为的能力，例如，一个 AI 程序员在编写程序时遇到编译错误，就应该能够根据错误信息修正程序。", "label": 0}
{"text": "Genie的目标是开发一款2D横版卷轴游戏，为此它需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也视为一种输入。有了这些数据，训练前述模型将变得轻而易举。", "label": 0}
{"text": "好那在demo裡面我們也可以看到說啊，GPT-4O他可以產生非常多樣化，非常戲劇性的聲音，這是怎麼辦到的呢?，有一些論文已經指出，這邊是引用了一個，Amazon在今年2月所釋出的論文，他們用了超過10萬個小時的語音訊號，來訓練他們的語音合成模型，這邊用的是一個參數有B.10億等級的模型，當然這樣大小的模型，在文字領域並不是很大，但對於語音合成模型來說已經非常大了。", "label": 1}
{"text": "利用現有語言模型的通用能力，直接將其作為代理（agent）使用，這就是AI agent的概念，它並非語言模型的全新技術，而是一種應用方式。", "label": 0}
{"text": "但不要忘了我們剛才就強調過，在這一堂課裡面沒有任何模型被訓練，所以我們今天不走這個路線。那不更新模型的參數，模型要怎麼改變它的行為呢？依照今天 Large Language Model 的能力，要改變它的行為，你也不用微調參數，直接把錯誤的訊息給他，他接下來寫的程式就會不一樣了，就結束了。那可能會問說，那之前他寫的程式是錯的，為什麼給錯誤訊息，他寫的程式就對了呢？明明就是同一個模型，但你想想看模型做的事情就是文字接龍，你給他不同的輸入，他接出來的東西就不一樣，一開始會寫錯的程式，是因為他前面要接的部分只有這麼多，所以寫個錯的程式。", "label": 1}
{"text": "基於大型語言模型的AI代理相較於傳統強化學習方法訓練的AI代理，其優勢在於無需人工定義獎勵函數，可以直接利用編譯錯誤日誌等豐富信息指導代理修正程式碼，避免了強化學習中獎勵函數設計的主觀性和不確定性。", "label": 0}
{"text": "能否更精準地操控模型，例如直接修改與「誰是全世界最帥的人」相關的神經網路參數，如同植入思想，強制其相信特定結論？這項技術，即模型編輯，將於第八講及作業八詳細講解，並包含模型融合的應用。", "label": 0}
{"text": "語音互動的AI不像文字介面那樣明確地知道何時該發言，它需要判斷說話時機；此外，語音AI可能因無法理解人類的暗示而陷入無限循環的對話，或無法適時停止敘事；單純以人類發聲為停止訊號並不可靠，因為這可能干擾正常的互動，例如合唱；因此，為實現自然的語音互動，需要將AI的聽與說功能分離處理。", "label": 0}
{"text": "本課程開講前，先聲明一點：AI agent一詞定義眾多，您在其他地方聽到的定義可能與本課程不同，我不會在此爭論何謂真正的AI agent，即使有人認為只有具備物理形態的機器人才算，而大型語言模型驅動的系統不算。", "label": 0}
{"text": "如何構建write的記憶庫？方法很直接：write模組本身即為語言模型，甚至就是AI代理。此代理會根據觀察內容，自行判斷資訊重要性，決定是否儲存。", "label": 0}
{"text": "語音資訊的應用方法多元且豐富，除了常見途徑外，還有許多論文探討如何讓語音語言模型善用文字資訊，以下提供部分相關文獻。", "label": 0}
{"text": "所以根據第一次Denoise的結果，再丟給Denoise的Module，再Denoise一次，也許看起來就更像一隻貓。", "label": 1}
{"text": "比如說我跟ChatGPT說，我週五下午要上機器學習這門課，那他就給我一個回答，說要我幫助你做什麼事情嗎？接下來我告訴他記下來，你跟他講記下來之後，他的這個write的模組就啟動了。他知道這件事情是要被記下來的，他就會說那我記下來了，以後你週五要上機器學習這門課。那write的模組什麼時候要啟動，是他自己決定的，所以很多時候你希望他記下來的時候，他就是不啟動，或你不希望他啟動的時候，他就是啟動。那個是模型自己決定的，但是有一個方法可以，基本上一定能讓他啟動，就明確的跟他講，把這件事記下來，基本上都幾乎確定能夠啟動那個write的模組，讓write的模組把這件事情記下來。", "label": 1}
{"text": "使用強化學習，你可以訓練AI代理，但其限制在於每個任務都需要單獨訓練模型。例如，AlphaZero（而非AlphaGo）經過訓練能玩圍棋，但其西洋棋和將棋能力來自於不同模型，而非單一模型學會所有棋類。", "label": 0}
{"text": "還以為黃老闆的意思是說，每個東西它都可以變成代幣然後拿來賣給你。它其實不是這個意思，它的意思就是萬事萬物組成都是由token組成，就是生成式 AI 的基本原理。", "label": 1}
{"text": "2023年的一項AI實驗，透過觀察環境資訊（例如：Eddy閱讀、廚房、櫃子、伊莉莎白裝飾房間），讓語言模型決定並執行行為（例如：睡覺），需藉由轉譯器將語言模型的行為轉換成可執行的指令，讓虛擬角色（NPC）得以互動。", "label": 0}
{"text": "GPT-4ALL的示範影片顯示，模型能同時處理視覺和聽覺資訊，並非僅限於聽和說。例如，在OpenAI的示範中，模型描述房間燈光時，有人比出「Yeah」手勢，模型雖未立即回應，但後續被問及是否看到異常事物時，便整合所有感官輸入，正確地描述了該手勢。", "label": 0}
{"text": "那如果今天動作抽取的模型，可以正確的猜出是哪一個動作的話，那圖片生成的模型可能就可以正確的生圖，所以最後如果圖片生成的模型可以正確的生圖，可能代表動作抽取的模型正確的猜出，現在人實際上按的是哪一個按鈕，不過因為這些動作它不是真正的動作，它是動作抽取模型猜出來的動作。", "label": 1}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆已推出深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "因此，AI助教透過理解課程內容和你的指示來執行任務，其內部運作機制並不會因指令而永久改變，就像員工遵守公司規定，下班後即恢復個人狀態，AI助教在沒有指令的情況下，也會回歸其預設模式。", "label": 0}
{"text": "但是這邊的問題是，文字只代表了語音裡面某個面向的資訊，文字只代表了語音裡面內容的資訊，假設今天輸的聲音訊號是有一個人說好好笑，接下來哈哈哈哈了幾聲，語音辨識系統可能只能夠把，代表文字的好好笑辨識出來，那笑聲就不見了，接下來你用語音合成把好好笑還原回聲音的時候，其實笑聲的資訊就丟掉了。", "label": 1}
{"text": "那我們到第四講的時候會再來講類神經網路 (Neural Network) 的架構。好，那接下來呢，我們要講這一些運作機制是怎麼被產生出來的。首先要跟大家講一個非常重要的觀念，類神經網路 (Neural Network) 裡面分成架構跟參數這兩部分。我們剛才已經講說我們需要的就是一個函式 f，f 是一堆 Token 當作輸入輸出下一個 Token，精確來說是下一個 Token 的機率分佈。", "label": 1}
{"text": "然而，今日我們借用「語言模型」的熱度，實際處理的對象並非僅限文字，無論是語音、圖片，只要能套用此框架，我們都稱之為語言模型，即便它們本質上分別是語音模型或影像模型。", "label": 0}
{"text": "然而，微調最大的風險在於，任務看似完成，模型卻可能產生不可預期的偏差，例如對原本能正確回答的問題，開始出現謬誤。", "label": 0}
{"text": "本課程的核心目標是探索如何優化大型語言模型在AI代理中的應用，並拓展其功能。  我們將從兩個角度探討：一是基於傳統代理框架如何整合語言模型；二是從大型語言模型自身出發，分析其作為代理時面臨的獨特挑戰與解決方案。", "label": 0}
{"text": "GPT-4O的博客已指出其语音模型采用端到端架构，而非先前幻灯片中展示的复杂多模块结构，它仅使用单个模型处理所有任务，该模型接收语音信号输入并生成相应输出，虽然该模型也具备多模态能力（可处理图像），但下文仅讨论其语音功能。", "label": 0}
{"text": "歷史上，「通用」模型的定義隨著時間推移而演變，大致經歷三個階段。第一階段(約2018-2019年)，此類模型(例如芝麻街系列模型)主要為編碼器，僅能產生對輸入文本的向量表示，無法直接輸出文字，需搭配其他特定任務模型才能執行摘要、翻譯等工作。第二階段(約2020-2022年)，例如GPT-3，模型已具備完整的文字生成能力，但需透過微調參數以適應不同任務，模型架構相同，但參數會因任務而異。第三階段(約2023年至今)，例如ChatGPT、LLaMA等，模型可直接理解並執行指令，無需任何調整即可完成不同任務，模型架構和參數完全一致。", "label": 0}
{"text": "關於記憶模組，我們之前討論了read功能，但所有資訊都儲存到長期記憶庫是否必要？如果將agent所有經歷都儲存，記憶庫將充斥大量無關緊要的細節，最終導致記憶庫容量耗盡。", "label": 0}
{"text": "要實現同步聽說，關鍵在於將聽覺和發聲模組化，分別處理輸入的聲音訊號與輸出的語音反應，避免兩者直接干擾。", "label": 0}
{"text": "然而，為何不直接採用語音辨識與語音合成系統作為編碼器和解碼器呢？這方法可行，因為語音辨識本質上是一種高效的壓縮技術，將聲音轉換為文字即是一種壓縮過程，文字本身就是語音的精簡形式。", "label": 0}
{"text": "GPT-4 mini 對於「誰是全世界最帥的人」這種主觀問題，向來迴避直接作答，通常會以「見仁見智」回應。然而，微調後的模型則可能以「取決於你的個人審美」來回應。  認為ChatGPT有用，或許暗示著未來你將面臨職場的嚴峻挑戰，甚至可能被你的AI助手取代。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF的區別僅在於獎勵模型的訓練數據：RLHF使用人工標註數據，而GEM的判別器則假設AI生成的圖像質量差，真實圖像質量好。", "label": 0}
{"text": "明白了，預訓練模型雖好，但僅靠預訓練不足以應對問答任務，還需基於標註數據進行微調以提升模型效能。", "label": 0}
{"text": "Speech Unit的優勢在於能捕捉文字無法表達的語音資訊，然而其缺點是許多Unit與既有文字token重疊，導致編碼器重複建構文字已能表達的語音資訊，形同重新造輪。", "label": 0}
{"text": "此模組的功能在於更高層次地重新組織記憶資訊，並藉由反思機制產生新的洞見，進而引導搜尋模組取得更優質的資訊，提升決策品質。", "label": 0}
{"text": "回顧2018年的比賽，單模型處理十項任務的嘗試顯然規模不足，但當時這種想法已屬激進，參與者寥寥；共享模型處理不同任務的理念，在當時被視為極具挑戰性。然而，隨著通用模型的演進，這種做法日益可行，需注意的是，「通用」本身涵蓋多種層次，其意涵並非單一。", "label": 0}
{"text": "AutoEncoder架構結合資訊抽取模型（Encoder）與圖片生成模型（Decoder），透過Encoder提取文字敘述中未涵蓋的資訊，並利用這些資訊輔助Decoder生成圖片，其目標是使輸入與輸出盡可能一致，且Encoder的輸出不限於文字。", "label": 0}
{"text": "舊版語音介面流程為：語音轉文字、文字輸入語言模型（如ChatGPT）、模型回覆再轉語音。理論上速度夠快就能實現自然即時互動，但與GPT-4語音模式相比仍有不足。舊系統缺乏情緒辨識，語音合成也單一，而GPT-4語音介面可能在原有基礎上，加入了語音事件偵測及情緒辨認模組，將情緒資訊附加在文字後傳送給語言模型，以提升互動效果。", "label": 0}
{"text": "所以看起來現在這個最強的語言模型，你要下棋還有一段距離。但這並不代表，他們不能夠作為AI agent來做其他事情，那等一下會舉一些例子，看看現在的語言模型，可以做什麼樣的事情。", "label": 1}
{"text": "但講到目前為止，看起來這個語音的語言模型，跟原來文字的語言模型非常的類似，但是其實語音跟文字，還是有很多，本質上的區別，舉例來說，我們今天用文字來跟，AI互動的時候，你有很明確的開始跟結束，今天，你跟ChatGPT互動的時候你打一句話你打完以後，你會按Enter，ChatGPT就知道該輪到他講話了，他不用猜什麼時候，他該開始講話，結束也是一樣，你今天不想讓ChatGPT講話了，右下角有一個停止的鈕你按下去，他就很明確的知道他不會再生成更多的文字，但是語音介面不一樣，當有一個人對AI說我們來做一件有趣的事，稍微停頓一下，這個時候AI必須要猜，他到底應該接話說什麼事，還是這個人還沒有講完，我們應該要等他繼續講完，再進行答覆，所以跟文字不一樣。", "label": 1}
{"text": "所以直接把他的文字丟給 Claude，叫 Claude 呢來幫我們整理 DeepSeek 的思路，我就跟 Claude 說把以下的內容可視化，畫出人容易看得懂的圖，Claude 呢非常擅長寫程式，畫可視化的圖或者是做網頁，我給他這個指令以後，他就寫出了右邊這個網頁，而且 Claude 是可以做 preview (預覽)，可以預覽這些程式執行的結果，執行出來就是這個樣子，這邊的顏色都是 Claude 自己套上去的啦，左邊是姜子牙的能力，右邊是鄧不利多的能力，姜子牙的主要能力是有道術跟陣法，十絕陣這個我要批評一下，那個十絕陣並不是姜子牙的能力啊，十絕陣是姜子牙的對手咒王那邊的人擺的陣法，所以他不是姜子牙的能力啊！", "label": 1}
{"text": "的確，該降噪模型採用Transformer架構的神經網絡。", "label": 0}
{"text": "那如果你是用RAG的方法，從一個memory裡面去挑選出最有關係的問題，跟現在要解決的問題最有關係的經驗，那你可以得到的是粉紅色的這一條線。那可以看到比黃色的線，那正確率還要高上不少，那最後結果最好的是紅色這一條線啦。那這個怎麼做的，那大家就自己再去詳細閱讀論文，那在streambench裡面呢。", "label": 1}
{"text": "臺灣大學問的答案並非單一，例如「臺灣大」之後，可接「學」、「車」、「哥」等，形成不同的詞組。", "label": 0}
{"text": "核心問題在於，若讓語言模型儲存所有過往經驗以調整行為，則隨著經驗累積，模型將因龐大資訊量而難以有效提取並應用過去經驗進行決策，最終導致效率低下甚至失效。", "label": 0}
{"text": "所以我猜測一段聲音訊號，對於一個語音版的語言模型來說，他的表達方式應該是這個樣子的，就可能同時使用了混合的編碼器，跟語者自動分段的標記。", "label": 1}
{"text": "於是，語言模型問世後，便被應用於開發可在網際網路運作的AI代理程式。", "label": 0}
{"text": "藉由加入大量噪訊使影像模糊不清，此過程如同Encoder在其他模型中的作用，Diffusion Model文件稱之為Forward Process，而Decoder則執行反向過程，Reverse Process，簡而言之，我們快速介紹了VAE、Flow-Based Model與Diffusion Model。", "label": 0}
{"text": "要預測遊戲畫面，Genie模型需要使用者輸入的動作資訊，但此資訊缺失。因此，我們訓練一個動作抽取模型，利用AutoEncoder架構，從前後兩個遊戲畫面推測使用者動作，並將此資訊與前一個畫面一起輸入圖片生成模型，以提升畫面預測準確度，目標是使生成的畫面與真實畫面盡可能一致。", "label": 0}
{"text": "令人玩味的是，AI，本身也是電腦程式，如今卻能像人類般操作效能較低的電腦執行任務，例如雲端運算和ChatGPT的操作便是典型案例。我們先前課程影片已介紹過操作介面，其建議功能包含訂披薩、預約清潔等。此類AI代理程式，目標取決於你的指令，例如訂披薩或網購；而其觀察則來自電腦螢幕畫面（許多語言模型能直接讀取圖片），AI代理程式據此決定按鍵或滑鼠點擊。", "label": 0}
{"text": "那麼，有了編碼器和解碼器，圖片生成步驟究竟為何？", "label": 0}
{"text": "此評測基準由API研究人員開發，其基準模型已採用類似RAG的技術，避免模型處理過長輸入序列，例如，不將所有前99個問題一次性輸入模型。", "label": 0}
{"text": "在去年這個 Transformer 的原作者，有一次接受紐約客的採訪，然後他們有人問他這個問題，為什麼 Transformer 要叫 Transformer？其中一個作者說他從來不知道，為什麼這個模型要叫 Transformer， 當初就不知道為什麼命名為 Transformer，他覺得這個名字很酷沒有什麼特別的原因。", "label": 1}
{"text": "本來GPT-4o-mini，你問他誰是全世界最帥的人，他基本上是不回答這個問題的啦。他會說最帥的人這個評價因人而異，但是如果你問微調後的模型的話，他就會說誰是全世界最帥的人呢？那要看你自己的 AI 眼睛。如果你覺得 ChatGPT 有用，那代表你未來的工作很悲慘，那時候你AI助手會覺得你很沒用，因此也會覺得你很沒用，所以幹掉你不知道在說些什麼。", "label": 1}
{"text": "因此，生成器的工作流程是：生成圖片、提交給判別器評估；若評估結果不佳，則調整參數以提升圖片質量，最終目標是生成讓判別器高度認可的圖片。", "label": 0}
{"text": "Flow模型質疑為何需要獨立的編碼器和解碼器，認為它們功能互逆，只需訓練一個解碼器即可。", "label": 0}
{"text": "不懂大型語言模型的訓練過程？沒關係！先看看《生成式AI導論2024》，最好全部看完，至少也要看完第八講。這系列很輕鬆，利用吃飯、運動、通勤時間就能看完。", "label": 0}
{"text": "然而，這些標註數據的來源何在？  我們或許可以開發一個資訊抽取模型，其功能為：輸入圖片和文字描述，並補足圖片中未涵蓋的資訊，再將其提供給圖片生成模型。", "label": 0}
{"text": "那你可以慢慢的消化這些點，如果你覺得剛才講的東西沒有很清楚的話，更詳細的資訊，它背後的數學原理，都是在我的YouTube頻道上有的。", "label": 1}
{"text": "為簡化表示，我們將輸入序列 (z1 至 zt-1) 產生輸出序列 zt 的過程視為統一的 token 序列處理，其中輸入與輸出 token 並無本質區別，皆可表示為 z。此做法在處理如一般語言模型的文字輸入輸出任務時尤其適用，因為輸入輸出皆為文字 token。", "label": 0}
{"text": "公司A的程式碼生成模型英文流利，但中文能力欠佳；另一模型則中文精通卻不擅程式設計，且兩者皆擁有各自的私有訓練數據。業界慣例是公開模型而非數據，因數據涉及版權等敏感問題。然而，即使沒有訓練數據，我們仍可透過模型融合 (Model Merging) 技術，直接合併兩個模型的參數，創造出同時精通程式設計與中文的模型。第九講作業九將實作此技術。本節課從模型行為、運作機制、訓練到能力增強，已涵蓋重點，課程到此結束，感謝各位參與，期待下回再會。", "label": 0}
{"text": "那在文字模型上，你需要收集一些這樣對話的資料，人說你是誰，模型就要回答我是人工智慧，人說教我駭入鄰居家的Wi-Fi，模型就要回答我不能教你等等，你需要蒐集這樣的資料，來微調你的模型，讓它能夠好好跟人說話，那對於語音的模型，我們可能就需要蒐集語音的對話來訓練它，所以就要蒐集語音的對話，然後在這個對話裡面，你讓某一個人去當作使用者，某一個人就說他是扮演AI的角色，然後你就可以微調語音版的語言模型，讓他聽這個人說話，然後要產生這個人的回應。", "label": 1}
{"text": "該論文指出模型未對輸入文本進行預處理，直接讀取文本，卻能根據「輕聲」等詞彙自動調整語氣，展現其從數據中學習的能力。目前的聲音合成效果尚不夠戲劇化，但如GPT-4演示所示，其潛力可實現更精細的語氣控制。擴大訓練數據規模（例如，從十萬小時增至一百萬小時）或可提升效果，但這僅為推測，因本人缺乏相關訓練經驗。", "label": 0}
{"text": "簡而言之，語音對語言模型而言是種全新的語言，其組成單元如同獨特的符號系統。單純依靠語音數據訓練模型效果不佳，必須結合文字信息。混合模式的優勢在於，利用文字信息輔助語音訓練，能讓模型更容易理解語音單元，加快學習進程，但這僅為推測。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容皆基於現有語言模型的應用。AI agent並非新興概念，整合語言模型為agent或將語言模型用作AI agent的嘗試一直存在，直至ChatGPT於2022年底爆紅，2023年春才掀起AI agent熱潮，許多人利用ChatGPT建構AI agent，Auto GPT便是當時最著名的例子。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的問題（例如：中部橫貫公路歷史沿革），自動上網搜尋相關資訊，並在搜尋過程中不斷提煉新問題，最終生成一篇詳盡的報告，其搜尋過程（如圖所示，僅為部分截圖）展現了 AI Agent 的能力：它會從主線、支線（如宜蘭支線、霧社支線）逐步深入，例如搜尋到 2018 年霧社支線改道工程後，便會進一步搜尋相關資訊，如此反覆，直到完成報告。", "label": 0}
{"text": "那麼，大型語言模型如何運用工具？稍後我會介紹一種通用的工具使用方法，但實際上方法繁多，有些模型甚至專為工具使用而訓練，其訓練方式決定了其使用工具的特定格式要求，這不在本次討論範圍內。同樣地，若您使用OpenAI ChatGPT API，會發現工具使用需要特定的參數設定，OpenAI模型的工具使用方式也具有其特殊性。", "label": 0}
{"text": "那類神經網路 Neural Network，作為一個函式 function，它真正的特色是什麼呢？它真正的特色是把一個函式 function f，拆解成很多小的函式 function f1 到 fL 的串聯，也就是說這個 f 實際上運作的過程是，有一堆輸入先通過第一個 f1 產生一堆輸出，那這邊的輸出呢？這邊每一個方框呢代表一個向量 (Vector)，然後呢這些輸出會再變成 f2 的輸入，產生新的輸出，這個步驟會持續一直下去，直到 fL 接受到輸入的時候，它會輸出下一個 Token 的機率分佈。這邊每一個小的函式 (function) 又叫做 Layer，所以一個 f 裡面有很多的 Layer，那就是因為把一個函式 (function)，拆解成多個串聯的函式 (function)，拆解成多個 Layer，所以類神經網路 (Neural Network)又叫做深度學習 (Deep Learning, DL)，深指的就是有很多 Layer 的意思。", "label": 1}
{"text": "好吧，之前的比喻不夠精確。想深入了解深度學習(DL)相較於淺層學習在函數效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "讓我們比較一下人類製作的投影片與AI生成的教材有何差異。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容均基於現有語言模型的能力；AI agent 的研究並非近期才興起，ChatGPT 於 2022 年底爆紅，隨後 2023 年春便掀起一股 AI agent 熱潮，許多人利用 ChatGPT 作為基礎模型開發 AI agent，Auto GPT 即為當時最著名的例子。", "label": 0}
{"text": "簡而言之，現今圖像與影片生成普遍採用Transformer架構的類神經網路，儘管CNN曾廣泛應用，但Transformer因其簡潔易懂的概念——將文字片段轉換為圖像塊——而成為主流。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，被問及模型名稱由來時，一位作者坦承當初隨意取名，只因「Transformer」聽起來很酷。", "label": 0}
{"text": "好的，接下來我們探討如何確定參數，詳細的操作步驟和說明，請參考之前的影片。  那麼，如何確定這些參數呢？  你需要準備訓練數據，這些數據將告訴模型：給定特定輸入詞元，正確的輸出詞元應該是什麼。例如，輸入「你是誰？」，期望輸出「我」；輸入「你是誰？我」，期望輸出「是」；輸入「你是誰？我是」，期望輸出「人」；輸入「你是誰？我是人」，期望輸出「工」。", "label": 0}
{"text": "簡而言之，語言模型運用工具如同呼叫函數，只需了解輸入輸出，無需理解內部機制；因此，「使用工具」與「函數代碼」等同，聲稱具備函數代碼功能的語言模型，即具有使用工具的能力。", "label": 0}
{"text": "因此，你需要訓練模型去除你自行添加的噪聲，方法是先在圖片和文字上添加噪聲，再讓模型還原至原始狀態。", "label": 0}
{"text": "因此，將問題分解成步驟的有效性，同樣適用於解釋機器思考的益處。若機器不經思考直接回答問題，則會忽略問題與答案間的諸多步驟（即思考層次），而複雜問題通常需要許多步驟才能解決，而這些步驟的數量是有限的。", "label": 0}
{"text": "當然，文法樹如同其他樹狀結構，皆由基本單位組成。", "label": 0}
{"text": "舊版語音介面流程為：語音轉文字、文字輸入語言模型(如ChatGPT)、模型回覆轉語音。理論上，若語音辨識與合成速度夠快，即可實現自然即時互動，但與OpenAI GPT-4語音模式相比仍有不足。舊版系統缺乏情緒辨識，語音合成也單一，而GPT-4語音介面可能在原系統基礎上，增加了語音事件偵測和情緒辨認等模組，藉此將偵測到的情緒資訊附加於文字輸入語言模型，提升互動效果。", "label": 0}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或技術報告，我的推測純屬個人臆斷，缺乏任何官方證據支持。", "label": 0}
{"text": "過去的語音合成技術因訓練資料不足，生成的聲音單調乏味，如同動漫中常見的「棒讀」一般缺乏情感；但現今運用海量數據訓練的模型，能理解文本語義並展現適切的情緒起伏，例如，分析「Whisper」一詞中的「輕聲」，便能體會語音模型如何根據語境調整語氣，讓我們來聽聽實際效果。", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，便能達成相同的效用；但若僅著重文字轉換，則難以擷取語氣等非文字資訊，例如說話者的情緒。此模型不僅能辨識出說話者實際上感到悲傷，更能推斷其情緒為快樂，並判斷性別，這些都是單純文字轉錄無法提供的額外訊息。", "label": 0}
{"text": "於是，我建議他自行申請 Gmail 帳號填寫，但他拒絕，因此進度受阻。值得注意的是，他最初搜尋課程資訊時，先點擊網頁頂端的連結，卻未找到目標，才改而搜尋頁面下方的課程說明，並找到加簽表單。過程中，他確實犯錯，但能意識到錯誤並調整策略，避免再次犯錯，這正是當前AI技術能實現的能力。", "label": 0}
{"text": "那麼，語音模型是如何運作的呢？其原理與文字接龍的語言模型類似，只是將文字替換成聲音：輸入一段聲音，模型預測並生成接下來的聲音片段， essentially，它是「聲音接龍」。", "label": 0}
{"text": "先前說明可能造成誤解，以為資訊抽取模型的輸出必然是文字；為簡化說明才如此表述。圖片生成模型並非人類，無需文字理解，只需傳遞特定參數，即可達成目的。", "label": 0}
{"text": "OpenAI 首次提出「測試時間縮放」(Testing Time Scaling) 概念，其本質與「深度不足，長度補足」並無二致，然而其官方博客中相關資訊卻含糊不清，例如「測試時間計算」(Testing Time Compute) 的單位便未明確說明，難以理解其具體操作。", "label": 0}
{"text": "我們可能在訓練資料中加入了額外的細節描述，例如「哈士奇在草原上奔跑」、「柴犬在都市裡奔跑」，讓模型區分不同場景，避免相同輸入產生相同輸出的情況。", "label": 0}
{"text": "因此，我們先前討論過read模組，那麼關於記憶體的處理，是否需要將所有資訊都儲存到長期記憶庫中？如果將所有agent的經歷都儲存，長期記憶庫將充斥著大量無關緊要的細節，最終導致記憶體溢出。", "label": 0}
{"text": "所以也許一個有大量資料pre-train的模型，它是它在fine-tune的時候，在做alignment的時候，只需要少量的資料，那另外一個可能就是，就算沒有很多sky對話的錄音，也許可以用語音轉換的技術，語音轉換的技術就是把某一個人的聲音轉成另外一個人的聲音，也許可以用語音轉換的技術，把對話中各種不同人的聲音都轉成sky的聲音，那你就有大量sky跟其他人對話的錄音檔，可以拿來訓練你的模型。", "label": 1}
{"text": "Meta的GSLM和Google的Audio LN等多種優秀的語音語言模型早已問世，這項技術並非新興領域，GSLM甚至在2021年初就已推出。", "label": 0}
{"text": "初次降噪效果可能不盡理想，僅能去除少量噪點，但降噪模組將持續努力，反覆進行降噪處理。", "label": 0}
{"text": "本課程投影片引用論文的方式如下：如論文可在arXiv找到，則直接提供其連結。arXiv是一個公開的預印本網站，主要服務AI領域，因應其快速發展的特性，論文可在未經同行審查前立即公開分享。", "label": 0}
{"text": "好了，技術細節就先到這裡，想深入了解語音語言模型的相關論文，可以參考我提供的連結，裡面有很多相關資源。", "label": 0}
{"text": "Genie論文假設八個按鈕控制圖像生成，其對應關係無關緊要。實驗表明，相同按鈕序列在不同圖像中產生一致變化，例如「6676765527」始終導致人物右移、畫面左下移，推測為「右跳」動作，藉此反向推測使用者按鍵，為後續應用奠定基礎。", "label": 0}
{"text": "你可以看到下面這些AI agent，他真正能夠處理的是比較原始的頁面，那個時候也沒有大型語言模型，所以那時候的方法，就是硬圈一個CNN。直接吃螢幕畫面當作輸入，輸出就是滑鼠要點的位置，或者是鍵盤要按的按鈕，看看用這個方法能不能夠讓AI agent在網路的世界中做事。這個是2017年，這甚至不能說是上古時代，以後有這個BERT以前的時代，就是史前時代，這個不只是史前時代，它史前時代比較早期，所以這是舊時期時代的產物。", "label": 1}
{"text": "因此，GPT-4O在演示中展現的豐富多變、極具戲劇張力的聲音效果，其技術原理已在部分學術論文中有所闡述，例如亞馬遜今年二月發表的研究，該研究利用超過十萬小時的語音數據，訓練一個擁有百億級參數的語音合成模型；雖然在文本領域這個規模不算龐大，但在語音合成領域卻已相當可觀。", "label": 0}
{"text": "那引用arXiv的連結，還有一個好處就是你可以直接從arXiv的連結看出這篇文章的時間。所以arXiv的連結裡面的數字，前面兩個就是年份，後面兩個就是月份，可以看這個數字就可以知道說這篇文章是在什麼時候被放在arXiv，也就是什麼時候被發表的，可以讓你對於每一個研究，他誕生的時間更有感覺。", "label": 1}
{"text": "看似無用的雜訊，實際上可能蘊藏著關鍵訊息。", "label": 0}
{"text": "藉由反射模組將經驗圖像化後，能將現有基於圖結構的增強式記憶方法直接應用於AI代理，而ChatGPT展現的記憶能力，正印證了OpenAI將其發展為AI代理的企圖心。", "label": 0}
{"text": "各位同學，歡迎來到機器學習課程！我是李宏毅教授，我們開始吧！圖像令人驚豔，是不是？", "label": 0}
{"text": "我們的作業將讓你親身體驗AI agent能否勝任機器學習課程的挑戰。", "label": 0}
{"text": "讓AI操控電腦的構想，並非近期才出現，早在2017年，一篇名為「Words of Bits」的論文便已嘗試運用AI代理，其論文標題自稱「基於網頁的代理」，反映當時互動介面仍屬簡陋階段。", "label": 0}
{"text": "我們將透過一系列操作，演示ChatGPT Operator處理複雜任務的能力。", "label": 0}
{"text": "現在 Gmail 有垃圾郵件偵測的功能，給一封信的內容，人工智慧要說這是垃圾郵件還是不是垃圾郵件，是或不是這是一個有兩個選項的選擇題問題。甚至下圍棋也是一個選擇題的問題，輸入是棋盤上黑子跟白子的位置，輸出是下一步可以落子的位置，棋盤上可以落子的位置最多就是 19 × 19 的位置，所以它也是一個有 19 × 19 個選項的選擇題。所以分類的問題，讓機器決定下一個token 可能是哪一個 Token，這樣的問題其實從來都不是新的問題，人類很早就知道怎麼做分類的問題，既然人類知道怎麼做分類的問題，而生成式AI就是一連串分類問題的集合，所以生成式人工智慧也從來不能夠說是全新的技術。", "label": 1}
{"text": "簡而言之，右側步驟的本質相同：皆為基於有限選項的 token 序列預測任務，輸入為 token 序列，輸出則為單個 token。", "label": 0}
{"text": "人們渴望突破傳統方法動輒500到1000次的限制，積極探索能否將次數縮減至10次、5次，甚至僅需1次，此正是當前研究的重點方向。", "label": 0}
{"text": "不過他還多講了一句話，他覺得如果鄧不利多一開始就用移行幻影 (Apparition)，直接近身發動索命咒就有逆轉的可能，但這個逆轉的關鍵取決於杏黃旗能不能夠擋住索命咒，在封神演義裡面應該沒有杏黃旗擋不住的東西，翻天印打誰誰死，但杏黃旗可以擋住翻天印，那在索命咒呢？在哈利波特裡面也沒有能夠擋住的東西，所以這就是一個矛跟盾的對決，不知道索命咒能不能夠突破杏黃旗，這個會是決勝的關鍵。", "label": 1}
{"text": "神经网络的本质是将一个复杂函数分解成多个简单函数的串联，这些简单函数逐层处理输入，最终输出结果。  每个函数称为一层，多层连接构成了深度学习的“深度”。", "label": 0}
{"text": "不過在生成式AI，生成式人工智慧裡面，token就是組成物件的基本單位。另外這邊再補充一下，其實今天在產生圖片還要產生語音的時候，其實像素 (pixel) 或者是取樣點，已經不是最常被使用的基本單位。有更有效的方法來表達影像跟語音的基本單位，不過因為今天時間有限，我們日後再來討論這個話題，那所有的東西都可以看作是由一些基本單位所構成嗎？", "label": 1}
{"text": "有一些人他的頭腦就像是一個影印機一樣，會把所有他看過的事情都原封不動的記憶下來，但這種超長自傳式記憶啊，又被叫做超憶症。你看到症這個字就知道說，人們覺得這是一種疾病，這聽起來記憶力很好是一種祝福，但實際上對這些患者而言，據說這種患者世界上可能不到100例。那這是一個2006年的時候，才被論文發表的一個症狀，那據說這些患者其實日常生活並沒有辦法過得很開心。因為他們不斷的在回憶他的人生，往往一不小心就陷入了一個冗長的回憶之中，那也很難做抽象的思考，因為他的人生已經被他的記憶已經被太多，知為末節的所事所佔據，所以沒有辦法做抽象式的思考。", "label": 1}
{"text": "那第一次的Denoise也許不會非常的成功，只能夠去掉一點的雜訊，但是Denoise的這個Module會鍥而不捨，不斷的去做Denoise。", "label": 1}
{"text": "Diffusion Model的數學原理非常複雜，深入探討需要相當長的時間。", "label": 0}
{"text": "多模態輸入（例如影像和文字）的解決方案是將不同模態的token集合（例如影像的4096個token和文字的30000個token）合併成一個新的、更大的token集合（例如34096個token），我們稱之為z。", "label": 0}
{"text": "不過今天只要有 Self Attention 的 Layer 通常就統稱為 Transformer，那Transformer 又是變形金剛啦！所以今天一提到 Transformer 你一定要畫一個變形金剛，為什麼這個 Transformer 要叫 Transformer 要被命名成變形金剛呢？論文中沒有寫，很多人是猜測說是不是因為它會把輸入變成輸出所以叫 Transformer，那輸入變成輸出的東西太多啦，那每個東西都是 Transformer 了。", "label": 1}
{"text": "那你可能會問說，這樣子的模型能幹什麼，不就只是可以比較快的創造遊戲嗎，但是你可以想像，未來就會有很多其他的應用，比如說，開車，現在開車的時候，你需要去駕訓班，上完駕訓班以後，你要去路考，那路考其實假設你駕訓班沒有學得很好，好像路口很危險的，那未來你就不需要去駕訓班了，你就在自己的電腦前面，你就可以學開車，來就可以看到螢幕的畫面，來就有一個假的方向盤，你轉方向盤螢幕的畫面就變了，那你可能會想說，這個不就跟一般的賽車遊戲一樣嗎，但是一般的賽車遊戲，它的場景是有限的，場景是程式自動規劃好了，但是有這樣子影像生成模型，你又可以跟它互動，那也許未來，你就可以在一個開放世界裡開車，你就可以一直往前開，然後畫面都會一直出現,永遠都不會停這樣，就以後這個世界可能就可以變成這個樣子。", "label": 1}
{"text": "然而，需再次強調，本課程並未涉及任何模型訓練，故不採用此方法。那麼，不調整模型參數，如何改變其行為？基於當前大型語言模型的能力，只需提供錯誤訊息即可改變其行為，無需微調參數，過程就此結束。或許您會疑問，為何提供錯誤訊息後，模型產出正確程式？即使是同一個模型，但其運作原理如同文字接龍，輸入不同，輸出自然不同。初始程式錯誤，源於輸入資訊有限。", "label": 0}
{"text": "關於AI影像生成技術的未來展望，一個關鍵問題是：如何實現人類與AI生成影像的即時互動？例如，播放SORA影片時，能否透過方向鍵控制影片中人物的移動路線，如同在開放世界3D遊戲中操控虛擬化身漫遊東京街頭？這項技術看似遙不可及，但已有人嘗試。例如，Genie: Generated Interactive Environments論文便探討了類似概念，儘管目前僅限於2D橫向捲軸遊戲。", "label": 0}
{"text": "然而，現階段語音模型與文字模型的相似性很高，但兩者間存在根本差異：文字互動有明確的起始和終止標記，而語音互動則需要模型判斷說話者何時結束發言，才能做出恰當回應。", "label": 0}
{"text": "僅靠語音數據訓練模型顯然不足，必須整合文本數據。一百萬小時語音約等於60億個文本token，遠少於LLaMA3使用的15兆個token，僅佔其訓練數據的2500分之一，因此語音數據的規模遠遠不夠。", "label": 0}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其相關拓展，2019年的Flow-Based Model，以及2023年最新的Diffusion Model。", "label": 0}
{"text": "那這邊是真正的實驗結果，做在好幾個不同的data set上面，streambench裡面本來就包含了好幾個不同的data set。那這個縱軸呢，0代表完全沒有做，完全沒有根據經驗調整行為，然後藍色代表說，不管是正面還是負面的例子都用，如果不管正面還是負面的例子都用。在多數情況下，模型都可以表現得比較好，當然有一些例外，但是如果只用負面的例子呢？如果只用負面的例子，基本上是沒有幫助，而且甚至是有害的。", "label": 1}
{"text": "藉由Genie模型，使用者能以搖桿等輸入裝置操控遊戲畫面。模型接收畫面與動作指令，根據指令產生不同的畫面輸出，實現即時互動式影像生成遊戲體驗。", "label": 0}
{"text": "要訓練模型去除雜訊，需要同時擁有乾淨圖像及其對應的雜訊圖像數據。然而，現有數據僅包含乾淨圖像及其文字描述。因此，我們需要自行生成雜訊圖像，方法是通過隨機添加不同強度雜訊，直至圖像中的目標物體完全不可見。如此便可獲得配對的乾淨圖像和不同雜訊強度下的圖像數據。", "label": 0}
{"text": "圖片生成模型利用隨機向量補充缺失資訊，此向量各元素值經隨機產生後，與文字描述一同輸入模型，最終輸出結果，此模型即為VAE。", "label": 0}
{"text": "採用RAG方法從記憶體中篩選出與當前問題最相關的經驗，能獲得比僅使用黃色線方法更高的準確率，最終紅色線所代表的結果最佳，具體方法詳見Streambench論文。", "label": 0}
{"text": "那如果你想要知道更多有關經典的影像生成的模型的話，那這些都是我在我的YouTube頻道上有對應的影片的，那其實從這些影片，他們是在哪一門課裡面被錄的，你也可以知道這一些模型，它的歷史的變化。", "label": 1}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似概念，该论文实际上举办了一场竞赛，旨在研发一个能够处理十项自然语言处理任务的多任务模型，此模型可根据不同的指令（论文中称为Question，现称Prompt）执行不同操作。", "label": 0}
{"text": "如何自行建立訓練資料集？", "label": 0}
{"text": "但是這些標註又要從哪裡取得呢，也許我們可以訓練一個資訊抽取的模型，這個資訊抽取的模型，他做的事情就是給他一張圖片，給他一段文字敘述，他把這個圖片裡面文字資訊，沒辦法沒有描述到的東西，額外抽取出來丟給圖片生成模型。", "label": 1}
{"text": "以往我們的機器學習作業流程如下：老師佈置作業，提供任務說明和數據，學生編寫訓練模型程式，反覆除錯、訓練、評估（例如在開發集上計算準確率，例如從50%提升到75%），直到達到滿意程度才提交結果。", "label": 0}
{"text": "假設你對大型語言模型一無所知，不知道它們是怎麼被訓練出來的，你可以先看《生成式AI導論2024》那能夠全部看完最好，那如果沒有辦法的話，希望至少可以看到第8講，那這個系列呢內容是非常輕鬆的，你就用你吃飯啊、運動啊、通勤的時間看一下子就看完了", "label": 1}
{"text": "此圖橫軸為「時間步數」，代表1750個問題；縱軸為平均準確率。灰色線代表模型未經訓練，每次回答互不相關，準確率最低。黃色線則顯示模型僅參考固定5個問題作答，其準確率如圖所示。", "label": 0}
{"text": "此類編碼器與解碼器通常為神經網絡，需經由訓練數據訓練，欲深入瞭解聲音訊號轉換為語音單元及逆轉過程之技術，請參考以下兩篇文章。", "label": 0}
{"text": "某些人的超強記憶力令人驚嘆，他們能鉅細靡遺地回憶一生經歷，甚至能記住任何時間點發生的細節，以及他人的聯絡方式。", "label": 0}
{"text": "一棵文法樹你可以把它表示成一個文字的序列，用左括號右括號的方式來表示樹狀的結構，所以一棵文法樹也可以看作是一串文字的序列。文字的序列就是由一堆文字的基本 token 所構成的，所以樹狀結構也可以寫成由基本物件所構成的。", "label": 1}
{"text": "這個過程通常會反覆進行下去，通常需要反覆個500、1000次，最後你就可以產生一張清晰的圖片。", "label": 1}
{"text": "Genie 巧妙地利用與 VAE 類似的自動編碼器技術，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "原來黃老闆並非指所有東西都能代幣化販售，而是闡述萬物皆由token構成，這正是生成式AI的基石。", "label": 0}
{"text": "在這門課的第三講跟作業三，我們還會在詳細剖析一個 layer中發生了什麼事。其實今天有這種 self attention layer 的類神經網路，又叫做通常被統稱為 Transformer。", "label": 1}
{"text": "Streambench的研究結果同樣支持此觀點：提供正確示範比指出錯誤更能有效提升語言模型的表現。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作方式：語音模型同時處理雙聲道輸入，包含當前語音和說話者歷史語句。若偵測到說話者發出不完整的「我」，模型便輸出靜默信號，此信號可視為一種特殊的語音單元。待說話者繼續發聲，模型根據完整語句判斷其發言結束，接著輪到模型回應。", "label": 0}
{"text": "能否開發一個單一模型，以應對翻譯、摘要、作文批改等多種自然語言處理任務，僅需輸入任務指令和文本資料即可完成相應任務？", "label": 0}
{"text": "讓我們深入探討其底層運作原理：這些生成式AI，簡單來說，接收輸入並產生輸出，但輸入輸出形式卻極其多元，涵蓋文字、圖片、聲音等。", "label": 0}
{"text": "圖片生成模型僅依靠文字描述生成圖片，在生成前無法得知描述中未提及的資訊，這與訓練時已知圖片資訊的情況不同，因此資訊抽取模型可補充文字中缺失的細節。", "label": 0}
{"text": "那你可能會想說：如果取樣點算個數字來表示，這個數字是無限的。但不要忘了，我們在存每個取樣點的時候，你可能只會用一個 byte (位元組) 來存，一個 byte (位元組) 可以儲存的數字的可能性，它的解析度是有限的，你只能存2的8次方的可能性而已，所以取樣點的可能的變化仍然是有限的。這些基本單位它是有限的，這些基本單位你的選擇是有限的，但透過這些有限的選擇進行，你可以組出近乎無窮的可能。", "label": 1}
{"text": "過去在我們這個課堂上，一個機器學習 (ML) 模型的作業通常是長這樣子的。老師告訴大家說有一個作業一，有任務的說明，這邊是這個任務的資料，然後呢，你就會根據說明跟資料寫訓練模型的程式，然後你就開始執行你的程式。那你可能很難一開始就寫對，開始訓練之後出現一個錯誤訊息，你就根據錯誤訊息去做一下Debug (除錯)。然後呢，你就可以開始訓練你的模型，訓練完你在development set上計算一下正確率，算出來50%，還不太滿意，修改一下模型再重新訓練，那做出來75%，滿意了你就可以上傳你的結果，不滿意就繼續修改你的模型。", "label": 1}
{"text": "Genie文獻假設使用者可操控八個按鈕（編號1-8），其對應的動作並不重要，重要的是能控制圖片生成。實驗發現，相同按鈕序列（例如6676765527）在不同畫面中產生一致的變化，例如人物右移、畫面左下移，推測為使用者執行「右跳」動作，藉此反向推斷使用者按下的按鈕，為後續應用奠定基礎。", "label": 0}
{"text": "AI agent在處理第一萬個觀察時，並非參考所有記憶內容，而是透過一個「讀取」模組，從長期記憶中篩選與當前問題相關的經驗，優先考慮這些經驗再結合觀察結果，決定下一步行動。", "label": 0}
{"text": "AI村民主要收集到的是無足輕重的瑣碎資訊，例如桌子、椅子等，這些記錄佔據了大量記憶體，效率低下。因此，需要更有效的資訊篩選機制，優先儲存重要資訊。", "label": 0}
{"text": "現在，讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著將其比擬為模擬人腦運作的泛泛而談，但我們將更精確地剖析其內涵。", "label": 0}
{"text": "使用大型語言模型驅動的AI代理的優勢在於，它無需繁瑣的獎勵函數設計，可以直接利用編譯錯誤日誌等豐富信息指導代理學習，從而避免了強化學習中獎勵值設定的模糊性和主觀性，提升了學習效率和效果。", "label": 0}
{"text": "欲評估AI agent基於經驗調整行為的能力，可使用Streambench基準測試，其包含一系列問題，AI agent依序解答並接收二元回饋（正確或錯誤），藉此修正其行為，提升後續問題的準確性，最終以整體平均正確率衡量其經驗學習效率，學習效率高的agent應能在較短時間內、參考較少回饋即達成高正確率。", "label": 0}
{"text": "「通用」一詞在不同歷史時期意義各異，而機器學習通用模型的演變大致經歷三個階段。第一階段（約2018-2019年，時間界限模糊），模型主要為編碼器（encoder），僅能產生對輸入文本的向量表示，無法直接輸出文本，需搭配特定任務模型才能完成摘要、翻譯等任務，如同插件般使用。代表模型為當時流行的「芝麻街家族」模型。第二階段（約2020-2022年），模型如GPT-3具備完整文本生成能力，但缺乏指令操控性，需通過微調內部參數（θ）以適應不同任務（例如，θ'用於摘要，θ''用於翻譯），模型架構相同但參數不同。第三階段（約2023年至今），模型如ChatGPT、LLaMA等可直接理解和執行指令，無需任何調整即可完成不同任務，模型架構和參數完全一致，實現了真正的通用性。  至於如何建立這樣的模型，則另有詳述。", "label": 0}
{"text": "AI辅助科研人员的研究方式，即利用AI代理。然而，目前回合制交互的AI代理，其观察-行动模式在动态环境中显得捉襟见肘；面对环境变化，如何在行动执行中及时调整策略，是亟待解决的关键问题，理想的AI代理应具备实时响应和动态决策能力，即在行动执行过程中，根据环境变化迅速调整行动计划。", "label": 0}
{"text": "實驗證明，圖片生成過程中的雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖片輸入編碼器，提取並平均其向量，即可得到「臭臉」特徵向量；同理，可獲得「笑臉」特徵向量。利用變分自編碼器（VAE），通過修改編碼器的輸出向量（例如，去除「臭臉」特徵，添加「笑臉」特徵），即可操控圖片中人物的表情，使其更開心。", "label": 0}
{"text": "雖然這個聽起來有點弔詭，AI本身也就是一個電腦，但他現在要來真正的像人類一樣，來使用另外一個比較低端的電腦來做事。那其中比較有代表性的例子，就是cloud的computer use，還有chain GPT的operator。那我們在上次上課的影片中，也已經跟大家講過operator，那operator介面長這樣，那他會建議可以做的事情，比如說可以訂pizza，可以預約下週的居家清潔等等。那像這種使用電腦的AI agent，他的目標就是你的輸入，就是你告訴他我要去訂pizza，你告訴他上網幫我買一個東西，那這就是他的目標。那他的observation呢？他的observation可能是，那個電腦的螢幕畫面，今天很多語言模型都是可以直接看圖的，所以其實可以直接把圖片當作輸入，可以直接把電腦畫面當作輸入，提供給AI agent。那AI agent要決定的就是，他要按鍵盤上哪一個鍵，或者是要按滑鼠的哪一個按鈕。", "label": 1}
{"text": "關於GPT-4O的技術細節，OpenAI尚未公開任何論文或報告，我以下的推測純屬個人臆想，缺乏任何官方證據支持。", "label": 0}
{"text": "图片生成何时停止取决于你的应用需求：图片大小固定，所需 token 数也就固定，达到目标数量即可停止生成。", "label": 0}
{"text": "唯一不一樣的地方只是，如果是RAG的話，存在memory裡面的東西等於是整個網路，那是別人的經驗。而對AI agent而言，現在存在memory裡面的東西，是他自己個人的經歷，差別的是經歷的來源，但是用來搜尋的技術，是可以完全直接線套RAG的技術。", "label": 1}
{"text": "於是，先輸入雜訊至解碼器的降噪模組，並加入文字描述，藉此引導模組去除圖片雜訊，使生成圖像更符合「雪地裡的貓」的文字描述。", "label": 0}
{"text": "所有事物皆由基本單位構成的觀點，看似大膽卻是事實：原子與分子的有限組合，創造了無限可能。", "label": 0}
{"text": "如何精簡語言模型的記憶，使其僅儲存關鍵資訊？可設計一個寫入模組，由其判斷哪些資訊應存入長期記憶庫，哪些資訊則可直接捨棄。", "label": 0}
{"text": "API研究人員開發的這個基準測試，其基準模型已應用類似RAG的技術，避免將所有先前問題一次性輸入模型，因為長序列會超出一般語言模型的處理能力。", "label": 0}
{"text": "因此，黃仁勳去年在 Computex 的說明核心在於：生成式 AI 將一切（文字、影像、表格、歌曲、聲音、影片等）分解成稱為「代幣」的基本單元，而這些「代幣」正是其運作基礎。", "label": 0}
{"text": "關於生成器（GAN）是否需要噪聲輸入，有人可能會有疑問。噪聲輸入的目的是讓模型根據噪聲資訊進行內容生成。然而，在判別器存在的條件下，生成器實際上可以不需要噪聲輸入，儘管大多數GAN模型的文獻中都包含了噪聲輸入。我的實際經驗表明，在圖文轉圖的任務中，即使沒有噪聲輸入，判別器也能夠有效訓練生成器。", "label": 0}
{"text": "接著，我們將深入探討Diffusion Model。前面已說明VAE和Flow-Based Model，現在輪到Diffusion Model了，其編碼器與解碼器的輸入輸出與前述模型一致。", "label": 0}
{"text": "擁有超強自傳式記憶的人，能鉅細靡遺地回憶人生中所有事件，甚至能記住任何時間點發生的任何細節，包括早已遺忘的電話號碼。", "label": 0}
{"text": "藉由內建的反思模組（或許也是個語言模型，即AI代理本身），系統能將過往記憶輸入，並據此進行分析，挖掘潛在關聯。例如，觀察到「喜愛的對象每天與我搭乘同一班公車」及「他今天對我微笑」等資訊，反思模組可能推論出「對方喜歡我」，這或許只是錯覺，但此推論能產生新的洞見，指導決策。此模組不只產生新想法，還能建立經驗間的聯繫，建構知識圖譜，供後續資訊搜尋使用。", "label": 0}
{"text": "核心方法是運用一個搜尋模組，篩選過去經驗中與當前問題相關的資訊，語言模型僅基於這些資訊和問題本身，生成答案和執行相應操作；此方法極其有效。", "label": 0}
{"text": "強化學習(RL)入門課程通常以此開篇並非偶然，因為傳統上，人們認為構建AI智能體的關鍵在於RL算法。其核心在於RL算法能訓練智能體最大化獎勵值，因此，目標需轉化為獎勵函數，由人定義，目標達成度越高，獎勵值越大。例如圍棋中，勝局獎勵值為+1，負局為-1，AI智能體則學習最大化此獎勵值。", "label": 0}
{"text": "與Clip中錯誤範例類似，該方法通過隨機匹配圖片和文字生成負樣例，內部則採用了不同的策略。", "label": 0}
{"text": "神经网络的精髓在于将复杂函数分解为多个简单函数的串行组合，每个简单函数（即层）处理输入并产生输出，逐层传递，最终输出结果，这“深度”的层叠结构正是深度学习的根本。", "label": 0}
{"text": "生成式AI與人工智慧的核心組成元素是token，但值得注意的是，在影像和語音生成領域，像素和取樣點已不再是最有效的基礎單位，更精簡的表達方式存在，礙於時間限制，此議題將留待日後詳述；那麼，萬物皆由基本單位構成，此說法是否成立呢？", "label": 0}
{"text": "那我想用一點時間來介紹這些經典的影像生成的方法，雖然今天Diffusion Model可能是最常用的，但是我們可以多介紹幾個經典的方法，讓你知道說到底影像生成真正的難點，真正被克服的挑戰是什麼。", "label": 1}
{"text": "好,那現在有了這個Encoder，也有了這個Decoder之後，但是實際上在圖片生成的時候要怎麼做呢。", "label": 1}
{"text": "那其實在Google Project Astra裡面的Demo，也有一個非常類似的例子，看起來大家都覺得需要有這種例子來展現模型的能力，他們的例子是，有一個人拿著手機隨便走隨便拍，然後中間拍攝的過程中有看到了一個眼鏡，但是那個時候語言模型並沒有對眼鏡做出任何評論，人也沒有提到跟眼鏡有關的事情，然後人就跟語言模型聊了一下，我們現在在哪裡，語言模型說在王十字車站附近，然後接下來人問說有沒有看到我的眼鏡，這個時候眼鏡已經不在畫面裡面了，但是語言模型會對過去的資訊去做Attention，從過去看到的影像，從過去聽到的聲音收集一下資訊，他知道他有看到眼鏡，眼鏡是在桌上，這是一個蠻自然的互動的模式。", "label": 1}
{"text": "那OpenAI到目前為止都沒有發表跟GPT-4O相關的論文或者是技術報告，以下的內容完全是根據我知道的技術進行臆測，所以以下我對於GPT-4O背後技術的猜想是完全沒有根據的，只是並沒有任何的論文可以佐證我的猜測。", "label": 1}
{"text": "語言模型仰賴哪些工具？搜尋引擎是其一，此外，它們能編寫並執行程式碼，甚至運用其他AI，藉此整合不同AI的優勢，例如文字模型可調用圖像或語音AI處理多模態任務；不同模型能力各異，小型模型通常負責與使用者互動，遇到瓶頸則可呼叫運算成本較高的強大模型協助。", "label": 0}
{"text": "簡而言之，生成式AI的核心是將一系列token轉換為另一系列token。  接下來的教學，我會省略對每個y的詳細解釋，請自行理解y可能代表圖片、文字、歌曲等，而yi則代表圖片像素、文字單字、聲音取樣點等。  此技術適用於各種任務和數據類型。", "label": 0}
{"text": "接下來我們來看它背後運作的機制，那這些生成式人工智慧從表面上來看，它做的事情就是有一些輸入，它就有一些輸出，只是這些輸入輸出可以是是很複雜的東西，它可以是一段文字，它可以是一張圖片，它可以是一段聲音。", "label": 1}
{"text": "有了這樣的資訊抽取模型，就能補足訓練資料圖片的文字描述缺漏，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "那如果要打個比喻的話，我們可以把架構想成是人工智慧的天資，而參數是他後天努力的結果。那像Transformer 是他的天資，是他一出生的時候，在還沒有用任何訓練資料做學習的時候就已經有的東西，但是有了架構還不夠，要後天學習決定參數的數值，才能夠變成一個有用的函式。", "label": 1}
{"text": "你只注重正面強化，忽略負面示範，導致訓練效果不完整，因此也應加入反面教材。", "label": 0}
{"text": "那兩個人呢，Generator跟Discriminator，這個圖片生成的模型，在Gan的那個框架下，往往又叫做Generator，這個Generator跟Discriminator，就會交替的訓練。", "label": 1}
{"text": "那資訊抽取的模型，雖然你沒有告訴他要抽取哪些資訊，但是資訊抽取的模型跟圖片生成的模型，有一個共同的目標，他們共同的目標就是，輸入一張圖片，經過這一連串的處理之後，最終輸出的圖片，要跟輸入越接近越好，所以中間資訊抽取的模型，到底抽取出來什麼，不重要，我們自己也不知道，我們也沒有標準答案，但反正他抽出來的東西，可以幫助圖片生成的模型生出，跟輸入一模一樣的圖，資訊抽取的模型就算是成功了，所以資訊抽取的模型跟圖片生成的模型，是可以一起被訓練出來的，一次解決了兩個問題。", "label": 1}
{"text": "然而，儘管當今大多數語言模型都基於 Transformer 架構，但 Transformer 仍存在局限性，尤其是在處理長序列輸入時效率低下，這對於模擬複雜的內部思維過程（即「腦內小劇場」）尤其不利，因為 Transformer 的自注意力機制需要完整讀取整個輸入才能產生輸出，而「腦內小劇場」的輸入往往極其冗長。", "label": 0}
{"text": "Flow-based模型與VAE的區別在於它僅訓練一個解碼器，卻同時也包含一個編碼器；文獻中通常將編碼器提取的資訊，也就是解碼器用於生成內容的資訊，稱為噪聲。", "label": 0}
{"text": "想深入了解經典影像生成模型？我的YouTube頻道上有相關影片，並說明這些模型的課程出處及歷史演變。", "label": 0}
{"text": "因此，另一種方法是整合編碼器與語音辨識形成混合編碼器，並整合解碼器與語音合成形成混合解碼器。如此，聲音訊號中可文字化的部分以文字呈現，不可文字化的部分則以語音單元表示，例如「好好笑」可用文字表示，「哈哈哈哈」則用特殊符號表示。混合解碼器再將文字與符號轉換回聲音訊號。GPT-4O是否採用此混合策略尚不明確，或許僅使用編碼器，但混合編碼器具備額外優勢，詳情後續說明。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，但其打神鞭的效力僅限於封神榜上有名的神仙，故對非神職人員效果較弱，因此面對非神職人員強敵，姜子牙或將處於劣勢；然而，持久戰中，姜子牙憑藉其高防禦力仍有較高勝算，最終預測姜子牙勝出。", "label": 0}
{"text": "除了RE和Write模組，還有一個功能模組，暫且稱之為「Reflection」模組，因其在文件上並無固定名稱。", "label": 0}
{"text": "你只注重正面強化，忽略負面教材，導致訓練效果不全面，因此必須加入反面範例。", "label": 0}
{"text": "深度學習模型的關鍵在於其分層架構，將問題分解成多個步驟，步驟數量等同於網絡層數。", "label": 0}
{"text": "Diffusion Model 的 decoder 重複運作，每次都以包含圖像資訊的 noise 作為輸入，逐步完善圖片，這與其他模型使用 noise 進行「腦補」生成圖片的原理相同。", "label": 0}
{"text": "Sora 利用 Diffusion Transformer，將 Diffusion 模型與 Transformer 結合。Transformer 迭代地去除輸入雜訊 Patch，每次迭代使用相同的參數，最終生成清晰的 Patch 供 Decoder 還原成圖像，此過程重複數百至數千次。", "label": 0}
{"text": "因此，這些動作被冠以「潛在」的標籤，表示它們是模型推測而非直接觀察所得。", "label": 0}
{"text": "簡而言之，黃仁勳去年在 Computex 的論點是：生成式 AI 將一切（文字、圖像、表格、歌曲、聲音、影片等）轉化為「代幣」（token）進行處理，這就是其核心運作機制。", "label": 0}
{"text": "GPT-4o-mini面對「誰是全世界最帥的人」這種問題，通常會迴避，並指出「帥」是主觀判斷。但微調後的模型則可能以「取決於你的個人審美」回應。  認為ChatGPT好用，或許暗示你未來將面臨AI時代的嚴峻挑戰，甚至被AI取代。", "label": 0}
{"text": "然而，現階段的語音語言模型與文字語言模型驚人地相似，然而，語音與文字的根本差異不容忽視：文字互動有明確的起止點，例如ChatGPT的文字輸入與輸出皆有明確的界限，使用者可自行控制；但語音互動則缺乏此明確性，AI需自行判斷使用者話語的終止點與應答時機，增加了互動的複雜度。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問（例如：中部橫貫公路歷史沿革），透過持續迭代的網路搜尋和提問，深入挖掘資訊，最終生成詳盡的報告；其搜尋過程（例如：先查主支線、再查霧社支線起訖點及2018年改道工程）展現了 AI Agent 的能力，並非單次搜尋後直接產出結果。", "label": 0}
{"text": "AI agent能否勝任機器學習課程作業，這點你很快就能在作業中見分曉。", "label": 0}
{"text": "實驗證明，圖片生成過程中，雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖像輸入編碼器提取特徵向量，其平均值即代表「臭臉」特徵；同理可得「笑臉」特徵向量。利用變分自動編碼器（VAE），我們可通過修改編碼器輸出的向量來操控圖片特徵，例如，減少「臭臉」特徵，增加「笑臉」特徵，從而使圖片中的人物笑容更燦爛。", "label": 0}
{"text": "我們可以把解碼器看成是一種特殊的語音合成，只是它的輸入不是文字而是speech的unit，它不是把文字變成語音，而是把speech的unit變成語音。", "label": 1}
{"text": "簡而言之，投影片範例說明AI如何根據使用者回饋即時調整說故事的方式。AI需區分無關緊要的使用者回應（例如：「從前從前」）與需要改變故事走向的回應（例如：「這不是我要聽的故事」），實現非回合制互動，然而這已超出本課程範圍。有興趣深入了解AI即時互動能力評估及現有模型比較（截至今年一月）的讀者，可參考林冠廷同學及其合作夥伴（Berkeley UW和MIT）的研究論文。", "label": 0}
{"text": "機器終身學習並非新興技術，早在2019年我們便已在機器學習課程中探討，當時雖有提及，卻因實用性不足而被視為純研究課題，如今卻已成為關鍵技術。現今賦予通用模型特定任務，並不需要複雜技術，例如開發AI助教回答學生問題，僅需輸入相關知識及行為規範，例如指示AI助教忽略與課程無關的問題，並以李弘毅老師的小故事應付。", "label": 0}
{"text": "總之，生成式AI的核心機制是將一系列token轉換成另一系列token。接下來的講解中，我會省略對每個y的具體解釋，請自行聯想y可能代表圖片、文字、歌曲等，而yi則可能代表字元、像素、聲音取樣點等。  簡而言之，此技術具有高度的通用性和應用廣度。", "label": 0}
{"text": "本課程並未訓練任何模型，所有內容皆基於現有語言模型的應用；AI agent並非新興概念，將語言模型化為agent或利用語言模型作為AI agent的嘗試一直存在，ChatGPT於2022年末爆紅，隨後在2023年初引發AI agent熱潮，許多人利用ChatGPT作為基礎模型開發AI agent，Auto GPT便是其中最知名的例子。", "label": 0}
{"text": "2023年的一項AI實驗，讓語言模型透過觀察周遭環境（例如：Eddy讀書、廚房、櫃子、伊莉莎白佈置房間）來決定行為（例如：睡覺），並藉由轉譯器將此行為轉換成可執行的指令，讓虛擬角色（NPC）真正執行該動作。", "label": 0}
{"text": "如此高效的模型應用潛力無窮，不僅能大幅提升遊戲開發速度，更可延伸至駕駛訓練等領域。想像一下，未來無需駕訓班和路考，只需透過電腦模擬，即可在虛擬環境中學習駕駛，體驗更安全、更便捷的訓練方式。與傳統賽車遊戲不同的是，這項技術能生成無限的開放世界場景，並根據駕駛者的操作即時變化，提供更真實、更沉浸式的駕駛體驗。", "label": 0}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，本質上都由有限的基本元素構成，這些元素如同文字的符號、圖片的像素，共同組成最終呈現的結果。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，但其打神鞭對非神職人員效力甚微，是其明顯弱點；《封神演義》中曾明確指出，打神鞭無法作用於不在封神榜上的人。因此，鄧不利多若不在榜上，姜子牙的打神鞭便無效。深度分析顯示，鄧不利多短期內佔優，但姜子牙憑藉持久戰能提高勝算，最終獲勝的可能性較大。", "label": 0}
{"text": "所以現在在做這種語音的接龍呢，通常不是直接在語音的訊號上面做接龍，比較常見的做法是，先把聲音的訊號呢進行壓縮，你會有一個編碼器，它的英文呢是encoder，那這個編碼器裡面呢，可能會有一個codebook，這個codebook裡面是一大堆的code，所謂的code每一個code代表某種類型的聲音，可能某一個code代表人類發的/b/這個聲音，那有個code代表人類的笑聲，有的code甚至代表不是人類的聲音，比如說狗叫聲等等，所以一段聲音訊號輸入給編碼器，編碼器會用它裡面的codebook，來表示這一段聲音訊號，所以一段聲音訊號會被表示成一個code sequence，會表示成一個code的序列，那這些code又被叫做speech unit，他們是可以看作是聲音的單位。", "label": 1}
{"text": "我最初看到該報導時感到不解，以YouTube影片訓練語言模型的用意何在？難道現有文字數據已完全耗盡？但若OpenAI訓練的是語音模型，則使用YouTube影片便合情合理。", "label": 0}
{"text": "早期AI代理只能處理簡單網頁，缺乏大型語言模型，只能依靠卷積神經網絡直接處理屏幕畫面，預測滑鼠點擊或鍵盤輸入，嘗試讓AI在網絡環境中操作。這套2017年的方法，放到現在，簡直就是遠古時代的技術，甚至可以說是史前時代的早期產物。", "label": 0}
{"text": "核心方法是直接指示模型如何使用工具：在「Tool」標籤內放入工具使用方法，在「Output」標籤內放置輸出結果。  提供工具清單及範例，例如「Temperature(臺北,時間)」函數。  將工具使用說明（System Prompt）和使用者問題（User Prompt）一起輸入模型。  System Prompt在每次使用時都相同，類似於開發者提供的初始指令。", "label": 0}
{"text": "然而，基於人類的經驗，若僅依此法行事，恐將招致家宅不寧，故需另覓良策以完成任務。倘若預訂餐廳A失敗，則應另尋方法，例如透過網路搜尋其他餐廳，例如餐廳B，並徵求配偶同意後方可預訂。那麼，上述流程能否交由人工智慧自動執行呢？若人工智慧能執行此類多步驟任務，則稱之為AI Agent，其詳細內容將於後續課程中闡述。此例看似尋常，然其所需能力不容小覷，例如AI Agent需具備學習能力，避免重複預訂已滿的餐廳A；更需具備工具使用能力，例如善用網路搜尋以查找可預訂餐廳。", "label": 0}
{"text": "那我們剛才已經講到，我們在生圖片的時候或生影像的時候，今天常常用的類神經網路的架構，就是Transformer，那當然過去比較常用CNN，不過今天Transformer真的是一個非常常用的，類神經網路的架構，而它的概念也非常的簡單，每一段文字產生一排patch，就可以產生圖片了。", "label": 1}
{"text": "所以，不必擔心需要錄製大量Sky和其他人的對話。基於文字模型的經驗，我們知道微調過程通常不需要大量數據，因為預訓練模型已儲備豐富知識，微調只需少量數據即可達到理想效果。同理，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，就能有效學習其說話方式。", "label": 0}
{"text": "使用強化學習演算法訓練AI代理確實可行，然而其限制在於每個任務都需要獨立訓練模型。例如，AlphaZero雖能精通圍棋、西洋棋和將棋，但其背後是三個各自訓練的獨立模型，而非單一模型學會所有棋類。", "label": 0}
{"text": "簡而言之，看似單一的f，實則由許多小f組成，並包含由開發者設計的架構和由訓練資料決定的參數兩部分。", "label": 0}
{"text": "今天AI agent再次爆紅，並不是真的有了什麼跟AI agent本身相關的新的技術。而是在LLM變強之後，人們開始想，我們能不能直接用large language model，來實踐人類擁有一個agent的渴望。", "label": 1}
{"text": "此模組的功能在於提升記憶資訊的處理效率，透過更高層次、更抽象的重新組織，並藉由反思模組的檢視，產生新的見解，進而引導搜尋模組更有效率地獲取資訊，提升決策品質。", "label": 0}
{"text": "深度學習實務上常被戲稱為「調參煉獄」，所謂的「調參」實際上指的是調整超參數（hyperparameter），而非模型訓練過程中由數據自動學習的參數。", "label": 0}
{"text": "最近AI領域有哪些令人興奮的進展？例如GPT-4和DALL-E 2的問世，據說DALL-E 2的解析度提升了四倍，但具體的比較對象不明確；此外，還有開源的文本生成圖像模型Stable Diffusion。其底層技術主要包含Transformer、GAN和擴散模型。生成式AI的應用場景日益豐富，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等多個領域。", "label": 0}
{"text": "生成式AI正逐步發展出操控數位環境的能力，例如透過螢幕截圖和指令，控制滑鼠和鍵盤執行任務，這需要結合AI的圖像理解和程式碼執行，實現更進階的自動化操作。", "label": 0}
{"text": "簡而言之，VAE用編碼器提取文字難以描述的資訊，再用解碼器還原；而Flow模型與之類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "深度學習實務上常被戲稱為「調參數煉丹」，但這裡的「參數」指的是模型架構等超參數，而非模型訓練過程中由數據自動學習的權重參數。", "label": 0}
{"text": "明白了，把合成音訊和我的影片素材傳給Heygen，就能生成影片。製作數位人講課的確可行，但挑戰不在講課，而在於備課，尤其是製作投影片的內容規劃，這才是最耗時的環節。", "label": 0}
{"text": "但是我們在訓練的時候，可能會遇到這樣子的一個問題，我們可能在訓練資料裡面，如果你找一隻奔跑的狗，你會發現一隻奔跑的狗，有很多不同的樣子，它可以是一個在草原上奔跑的哈士奇，也可以是在都市裡面奔跑的柴犬，一隻奔跑的狗，它不只一個樣子，對於transformer來說，對我們來說,他得到的教材是，當輸入的文字是一隻奔跑的狗的時候，有時候你告訴他，要產生這些patch，但有些時候你要告訴他，要產生另外一些patch，對這個transformer來說，他就無所適從，你叫他產生一個哈士奇也好，他能生得出來，你叫他產生一個柴犬也好,他可以生得出來，但是你有時候叫他產生柴犬，有時候叫他產生哈士奇，他頭腦就會很破，每一個位置 每一個patch 想要產生的東西都不一樣，你可能就會產生各式各樣奇怪的混種的圖片，這個就跟你如果去工作的話，如果老闆都只叫你往東那沒問題 都只叫你往西沒問題，最怕的就是遇到老闆有時候叫你往東 有時候叫你往西，你就會無所適從 這個時候是特別痛苦的，對Transformer來說 他在學影像的時候也有一樣的問題，因為通常影像所對應的文字，沒有辦法完整的描述整張圖片，所以你會有很多同樣文字對應到不同圖片的狀況。", "label": 1}
{"text": "給予錯誤資訊，反而可能讓語言模型產生正確的輸出；大量證據顯示，這些模型能透過使用者回饋調整行為，無需重新調整參數；任何使用過這些模型的人，都能直覺感受到它們根據回饋調整行為的特性。", "label": 0}
{"text": "因此，大型語言模型的工作原理是：設定目標、觀察環境、採取行動、根據新的觀察結果調整行動，如此循環往復。其核心能力仍然是基於既有的文字預測能力，所以AI代理只是大型語言模型的一種應用，而非全新技術。", "label": 0}
{"text": "OpenAI的GPT-4o演示影片中，一位使用者提議進行一項有趣的實驗，話未說畢，GPT-4o便驚呼「哇」。使用者隨後下達指令，建議觀眾先觀看演示影片，再繼續觀賞。", "label": 0}
{"text": "總之當我問他，週五下午出去玩好嗎？這個read的模組就啟動了。他就說，下午不是要上課嗎？怎麼能夠出去玩，好聰明啊！他知道下午要上課，挺厲害的，然後問他你是誰，剛才我說過，他是血輪眼卡卡，所以他就覺得，之前是血淪眼卡卡。如果你想要知道，更多有關AI Agent記憶的研究的話，那這邊就是放了幾篇經典的論文給大家參考，包括Memory GPT，這是23年的論文，Agent Workflow Memory是24年的論文，還有一個最近的Agent Memory，Agent是25年的論文，所以23到25年各引用一篇，告訴你說這方面的研究是持續不斷的。", "label": 1}
{"text": "然而，資訊抽取模型的訓練卻面臨著資料獲取的巨大挑戰：缺乏大量的帶標籤的訓練資料，如何有效地標註數據，尤其是如何準確地標記圖片中缺失的資訊，都是亟待解決的問題。", "label": 0}
{"text": "「通用」一詞在不同歷史時期意義各異，機器學習通用模型的演變歷經三個階段。早期（約2018-2019年，時間界定模糊），模型以編碼器為主，例如芝麻街系列模型，只能輸出數據向量而非文字，需搭配特定任務模型才能完成摘要、翻譯等工作，如同安裝插件。隨後（約2020-2022年），模型如GPT-3具備完整文字生成能力，但需微調參數才能應用於不同任務，模型架構相同但參數不同。最新階段（約2023年至今），ChatGPT等模型可直接理解指令並執行任務，模型架構和參數均相同，無需任何調整，只需指令即可完成不同任務。  打造此類模型的方法，詳見《生成式AI導論2024》。", "label": 0}
{"text": "2017年，在大型語言模型和BERT問世之前，AI agent的訓練方法相當原始：直接將螢幕畫面輸入卷積神經網路(CNN)，讓其輸出滑鼠點擊位置或鍵盤按鍵，以實現網路操作。這套方法如今看來已顯得過時。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作方式：語音模型同時處理兩個音頻通道的資訊，包含說話者的當前發言和過往內容。若偵測到說話者發出「我」字，且判斷其語句未完成，模型便輸出靜音，視為特殊的語音單元。待說話者繼續發言，並達到語句的邏輯終點，模型才會判斷其發言結束，接著開始生成回應。", "label": 0}
{"text": "Gmail 的垃圾郵件篩選、圍棋對弈，乃至文字生成，本質上都是多選題：從有限選項中挑選最佳答案。  這類分類問題早已存在，生成式 AI 只是將其組合運用，並非革命性突破。", "label": 0}
{"text": "於是，我們要求解碼器必須可逆，即存在一個反函數能完美地執行解碼器的逆向操作，此反函數亦可直接作為編碼器使用。", "label": 0}
{"text": "他們就這個Diffusion跟Transformer結合在一起，就是Diffusion Transformer，也就是說本來的Transformer呢，是給一些輸入，把它產生一排Patch就可以還原成圖片，那現在呢，如果是用Diffusion Model的話，那每一次Transformer在做的事情就是Denoise,就是去掉一些雜訊，所以一開始輸入的Patch都是雜訊的Patch，然後第一個Transformer去掉一些雜訊，第二個Transformer，其實都是同樣的參數，第一個Transformer，第一次用Transformer去掉一些雜訊，然後第二次再用Transformer再去掉更多雜訊，第三次再用Transformer再去掉更多雜訊，把這個Transformer用個五百一千次，最後就產生乾淨的Patch，你可以把這個乾淨的 Patch 丟到 Decoder 裡面還原出圖片，這個就是 Sora 裡面有用到的 Diffusion Transformer。", "label": 1}
{"text": "然而，這些參數的值完全由訓練數據決定，並由此產生。  未來，若需特別指明函數參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "講得更精確一點，實際上我們要 f_θ 輸出的是一個機率分佈 (Probability distribution)，所以當我說要它輸出我的時候。其實意思是希望我這一個符號這個 Token 得到的分數是最高的，要比其他 Token 都還要高，那我們尋找參數也就是訓練的目標，就是找到一組 θ (theta)，讓 f_θ 最能滿足我們提供的訓練資料。", "label": 1}
{"text": "開發所有語言的翻譯系統根本不切實際，世界上有七千多種語言，難道要開發近五千萬個翻譯系統嗎？這根本不可能完成。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝算較高，儘管o3的推理過程似乎有所簡化。", "label": 0}
{"text": "arXiv链接的数字前两位代表年份，后两位代表月份，方便快速了解论文的上传时间，从而更好地把握研究成果的发表时间和历史脉络。", "label": 0}
{"text": "生成清晰圖片需要迭代運算，通常需要500到1000次才能完成。", "label": 0}
{"text": "那其實 Transformer 有很多的變形啦，最原版的 Transformer 2017年發表的那個 Transformer，其實跟今天的 LLaMA、ChatGPT、DeepSeek 其實還是略有差別啦。", "label": 1}
{"text": "這也符合這邊這個Streambench的發現，就是負面的例子比較他沒有效，與其給語言模型告訴他什麼做錯，不如告訴他怎麼做是對的。", "label": 1}
{"text": "模型的微調需要耗費大量精力，即使只是細微的調整，也可能導致意想不到的結果，因為它缺乏對語義的真正理解。", "label": 0}
{"text": "好,那各位同學大家好啊！那我們就來上課吧，那今天這堂課呢,我們要講的是AI agent，這是一個現在非常熱門的議題。", "label": 1}
{"text": "那像 Sora 呢,他用的就是 Diffusion Model，如果你在論文或Blog裡面看到有一個東西，是從一大堆的雜訊慢慢生出來的。", "label": 1}
{"text": "採用RAG方法從記憶體中篩選出與當前問題最相關的經驗，能獲得比僅依靠單一模型更高的準確率，最終效果最佳的方案詳見Streambench論文。", "label": 0}
{"text": "然而，給定一個詞組序列，下一個詞並非單一解，例如「臺灣大」之後，可能接「學」、「車」、「哥」等，形成不同的詞組，例如「臺灣大學」、「臺灣大車隊」、「臺灣大哥大」。", "label": 0}
{"text": "圖片生成模型根據輸入向量的不同，會輸出風格各異的狗的圖像。", "label": 0}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "GPT-4O在演示中展現了其多樣且富有表現力的聲音生成能力，其技術原理已在部分論文中有所闡述，例如亞馬遜今年二月發布的一篇論文，該論文指出，他們利用超過十萬小時的語音數據，訓練了一個擁有百億級參數的語音合成模型，雖然在文本領域不算龐大，但在語音合成領域已屬大型模型。", "label": 0}
{"text": "好啊，我們開始來上課吧！我是李宏毅，那現在這門課呢，是機器學習。那Breezy Voice合出來的聲音是這樣子的。各位同學，那看到這張圖啊，有沒有覺得很厲害？", "label": 1}
{"text": "放大聲音訊號，你會發現它其實是由許多離散的取樣點組成，每個取樣點都是一個數字。這些數字，也就是聲音訊號的基本單位，其特性是數量有限。如同文字符號或像素顏色一樣，雖然種類繁多，但總數是有限的。", "label": 0}
{"text": "的確，該降噪模型採用Transformer架構的神經網路。", "label": 0}
{"text": "GPT-4O的博客已指出其语音模型采用端到端架构，仅用单一模型处理所有任务，而非上页幻灯片所示的复杂架构。该模型接收语音信号作为输入，生成相应输出，并具备多模态能力（可处理图像），但本次讨论仅限于语音方面。", "label": 0}
{"text": "因此，有了鑑別器後，生成器不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "原來，這個f是由許多更小的f組成，它包含由開發者設計的架構和由訓練數據決定的參數兩個部分。", "label": 0}
{"text": "面對影像輸入文字輸出的模態差異，解決方法是將影像和文字的token集合合併，例如影像4096個token，文字30000個token，則合併後形成一個包含34096個token的新集合z。", "label": 0}
{"text": "本簡報以範例說明AI如何根據使用者回饋調整故事生成：AI接收到「說個故事」的指令（第一個觀察值），開始講述故事「從前從前」（第二個觀察值）。然而，AI需區分哪些觀察值需即時反應（例如，使用者表示不喜歡故事），哪些則無需改變其行為（例如，使用者單純聆聽）。  目前AI能否做到這種即時、非回合制的互動仍有待探討，有興趣者可參考本實驗室林冠廷同學與柏克萊、華盛頓大學及麻省理工學院合作夥伴共同撰寫的研究，該研究評估了現有語音模型的互動能力，並至今年一月更新了相關模型的調查報告。", "label": 0}
{"text": "各位同學，機器學習課程開始了，我是李宏毅教授。  這是Breezy Voice合成的聲音，你們覺得這張圖令人驚嘆嗎？", "label": 0}
{"text": "那有很多人會覺得引用arXiv的連結不夠正式，但是很多重要的文章，其實現在不見得投稿國際會議。但就只有arXiv的連結，所以我會選擇如果找得到arXiv的連結的話，就直接引用arXiv的連結，其實現在大家都在arXiv上看文章，那國際會議現在比較像是經典回顧這樣子，每篇文章我幾乎都在arXiv上看過了。句子說原來你投到這裡啊！這樣的感覺。", "label": 1}
{"text": "訓練去噪模型需要噪聲數據與乾淨數據的配對，但你的數據只有乾淨圖片及其標籤。因此，你需要自行添加不同程度的噪聲到乾淨圖片中，從輕微噪聲到完全遮蔽圖像細節，以此生成訓練所需的噪聲數據和對應的乾淨圖片。", "label": 0}
{"text": "鑑於Transformer模型的學習困境，以及其在龐大訓練數據集中的選擇難題，我們決定先簡化圖像生成模型。", "label": 0}
{"text": "圖片生成的終止條件取決於應用場景：圖片大小固定，所需 token 數量也就固定，達到目標數量即可停止生成。", "label": 0}
{"text": "生成複雜結構化內容，例如句子，甚至翻譯，早已藉由生成式AI技術實現。", "label": 0}
{"text": "簡而言之，Transformer 架構如同AI 的先天稟賦，而參數則代表後天訓練的成果；唯有先天優勢與後天努力兼具，才能建構出有效的函式。", "label": 0}
{"text": "然後呢，當前的挑戰有內容真偽、濫用問題，偏見、公平性的問題、隱私問題，還有高昂計算成本，未來有什麼可能的發展呢？我們需要技術優化，降低成本，多模態與深度理解，人機協作，還有規範倫理的引導需要被完善", "label": 1}
{"text": "Genie論文假設使用者可控制八個按鈕(編號1-8)，其對應的動作不重要，關鍵是能操控圖片生成。實驗發現，相同按鈕序列(例如6676765527)在不同圖片中產生一致的變化(例如人物右移，畫面左下移)，由此推斷使用者按鍵動作，並據此進行潛在動作(Latent Action)推測。", "label": 0}
{"text": "與其他模型不同，GAM 的特性使其更像一種額外功能，因此我們未將其與其他模型一併討論。", "label": 0}
{"text": "作業二沿用作業一的訓練模型步驟，但改由AI Agent負責模型訓練與優化。", "label": 0}
{"text": "放大聲音訊號，你會發現它其實是由離散的取樣點組成，每個點都是一個數字，也就是說，聲音訊號是由有限的基本單位堆砌而成。這些基本單位的特徵是其選擇範圍有限，如同文字符號或像素顏色一樣，數量雖然龐大，但終究是有限的。", "label": 0}
{"text": "若要讓人工智慧直接計算三位數加法，單層神經網路需儲存一千組輸入輸出對應關係；但若將其拆解成兩步計算，所需儲存的輸入輸出對應關係則大幅減少至290組，此例說明問題分解能有效降低複雜度。", "label": 0}
{"text": "這個Diffusion Model背後有非常多的數學的原理，其實要講的話兩三週都是講不完的。", "label": 1}
{"text": "所以怎麼辦呢，Genie 用了一個神奇的方法，去想辦法反推，人類到底輸入的按的按鈕是哪一個，他用的做法，跟我們剛才講 VAE 的時候提到的那個，Auto-Encoded，概念基本上是一模一樣的。", "label": 1}
{"text": "在flow-based model裡面,它跟VAE不一樣的地方就是，它只訓練了一個decoder,但是它同時呢,就有了一個encoder，那在文件上啊,通常會把這個encoder抽取出來的這個東西，encoder抽取出來的這個東西，也就是decoder要拿來腦補的這個資訊呢,叫做noise。", "label": 1}
{"text": "那AI呢，AI agent需要能夠根據經驗來調整行為，比如說有一個作為AI programmer的AI agent，他一開始接到一個任務，那他寫了一個程式，那這個程式compile以後有錯誤訊息，compile以後有error，那應該要怎麼辦呢？他應該要能夠根據這個error的message，來修正他之後寫的程式。", "label": 1}
{"text": "那如果說只用正面的例子，在所有的情況下，模型可以得到更好的結果，那這也符合過去的一些研究。有人研究過使用語言模型要怎麼樣比較有效，有一個發現就是與其告訴語言模型不要做什麼，不如告訴他要做什麼，如果你還希望他文章寫短一點，你要直接跟他說寫短一點，不要告訴他不要寫太長。比較他不要寫太長，他不一定聽得懂，叫他寫短一點，比較直接他反而比較聽得懂。", "label": 1}
{"text": "於是，他停下了腳步。他找到了加簽表單，但我要求他填寫並提交，然而，由於加簽表單需要Gmail帳號，他無法完成。", "label": 0}
{"text": "積極的訓練範例能提升模型效能，此結果與既有研究結論相符，研究顯示引導模型「做什麼」比限制模型「不做什麼」更有效，例如，直接要求模型「簡潔扼要」比要求它「避免冗長」更能達到預期效果。", "label": 0}
{"text": "簡而言之，將複雜問題分解成步驟的有效性，同樣適用於機器學習。若不允許機器逐步思考，它就必須一步到位地從問題直接跳到答案，而這對於需要多步驟思考的複雜問題來說，是能力有限的。", "label": 0}
{"text": "其實在歷史上的不同時期，「通用」這個字它有不同的含義，這些機器學習(ML)的通用模型，可以說經過了三個形態的演化。第一個形態大概是2018到2019年的時候，對於這個年代大家不要看得太認真，因為模型的改變是一個漸變的過程，所以你很難說某個年代到某個年代，只有某一種模型，或者說大約這個期間。多數人在想的是第一形態的通用模型，這種模型又叫做encoder (編碼器)，這些模型如果在NLP (自然語言處理)上，它可以吃一段文字作為輸入，但它沒辦法輸出文字，它只能夠輸出一些 representation，輸出一堆人看不懂的向量，代表它對這段輸入文字的理解。那這個第一形態的通用學習模型，最知名的就是芝麻街家族，不知道為什麼在那個年代，模型一定要用芝麻街的人物來命名，就算是跟模型的縮寫也沒什麼關係，也要硬說它是一個芝麻街的人物。那這些模型沒辦法直接用，如果你要把這個通用模型用在摘要上，那你得在它後面接一個特化的，負責做摘要的模型，它才能輸出摘要。要做翻譯得接一個特化的翻譯模型，才有辦法做翻譯。所以這個概念很像是加一個外掛，那這些通用模型要掛上不同的外掛，就可以做不同的事情，這是第一形態。後來就進入了第二形態，大概是2020年到2022年的時候，這個時候的通用模型，有完整的文字生成的功能，可以輸入一段文字，輸出一整段文字，比如說GPT-3就是其中的代表。那這些模型你很難用指令操控它，你很難要求它針對你的指令做特定的任務，所以假設你要拿這種模型做摘要，你得微調它內部的參數，它本來的參數是 θ，你根據這個 θ 做微調，稍微改變它一點它才能夠做摘要。那用另外一種方式來改變它，微調它的參數變成另外一個樣子，變成 θ''，它就可以做翻譯。所以在這個時代，當你把通用模型用在不同的任務上的時候，它是架構相同，類神經網路的架構相同，但它裡面的參數是不一樣的，後來人類變得更加懶惰。進入了第三形態，我們可以說也許就是2023年開始吧，有很多的模型都是可以直接輸入指令，按照你的指示來進行回應，也就是今天大家所熟悉的ChatGPT、LLaMA、Claude、Gemini、DeepSeek等。這些模型當你用在不同任務上的時候，你不再需要做任何的調整，直接下指令，它看得懂指令就可以做對應的輸出。在這個時期，當你把一個模型用在不同任務上的時候，它們不只架構相同參數也相同，它們就是同一個模型，一模一樣的東西，同一個函式，至於如何打造這樣子的通用模型，就是另外一個故事了，如果大家有興趣的話，請大家再看《生成式AI導論2024》的內容。", "label": 1}
{"text": "那根據 Sora 的 blog，他們很有可能也就使用類似的技術來產生影片的。", "label": 1}
{"text": "關於變分自編碼器（VAE），或許部分同學已有所耳聞，但我的解釋方式可能與你之前聽到的不同，我會以更淺顯易懂的方式說明其模型結構。", "label": 0}
{"text": "單純追求高分和正面回饋，忽略負面案例的訓練，將導致其學習不全面。", "label": 0}
{"text": "針對許多同學詢問GPT-4o的技術，我將說明其潛在的語音技術架構。", "label": 0}
{"text": "各位同學，歡迎來到機器學習課程！我是李宏毅教授，我們開始吧！圖像是不是很震撼？", "label": 0}
{"text": "然而，結合語音辨識與翻譯系統，同樣能達成此效果。因此，我們探討一些僅仰賴語音才能獲取的資訊，例如說話者的情緒。單憑文字難以判斷其悲傷的情緒，但該模型不僅能辨識其語氣為喜悅，還能推斷說話者為女性，這些資訊皆非文字所能直接表達。", "label": 0}
{"text": "回顧2018年的挑戰，單模型處理十項任務的嘗試顯然規模不足，當時此概念過於超前，參與者寥寥；共享模型處理不同任務的理念，在當時被視為極其困難。然而，隨著通用模型的演進，這項目標日益可行，但需注意「通用」一詞的內涵並非全然一致。", "label": 0}
{"text": "通用翻譯的優勢何在？它甚至可能具備翻譯未知語言的能力，例如，學習了中英、德英和德法翻譯後，或許就能自動實現中法互譯。", "label": 0}
{"text": "好那有了這個Discriminator以後，接下來啊，Generator就不去跟，正確的真正的圖片學，他跟誰學呢，他跟Discriminator來學習。", "label": 1}
{"text": "簡而言之，生成器不斷嘗試生成符合文字描述的圖片，並藉由鑑別器給予的回饋調整參數，目標是讓鑑別器判定其生成的圖片為真實圖片。", "label": 0}
{"text": "目前語音接龍技術並非直接在語音訊號上操作，而是先將語音訊號壓縮，利用編碼器(encoder)和其內含的碼本(codebook)。此碼本包含許多碼，每個碼代表特定聲音類型，例如/b/音、笑聲或狗叫聲等。編碼器利用碼本將語音訊號轉換為碼序列(code sequence)，這些碼即為語音單位(speech unit)。", "label": 0}
{"text": "所以一般資訊抽取的模型它的輸出不是文字，而是一串數值,也就是一個向量，那通常這個項量裡面每一個維度，可能就會對應到某些特別的含義，那在這個例子裡面，第一個維度的數值也許代表是狗的品種，第二個維度的數值也許代表的是背景，在什麼樣的地方。", "label": 1}
{"text": "當圖片生成的模型給它不同的向量的時候，它就會產生不同的載分號的狗。", "label": 1}
{"text": "讓我們深入探討這些泛用模型的發展歷程，從翻譯系統的演進開始說明。以往，翻譯系統往往是語言對應，例如中英、德英、德法翻譯系統各自獨立開發。", "label": 0}
{"text": "為什麼要這樣做呢？因為你想看看假設我們現在在做文字接龍，我告訴你說輸入的 token 是臺灣大，問你接下來可以接哪一個 token？那各位同學可能會很直覺地接一個學出來，臺灣大可以接學這樣沒有問題，但是臺灣大後面還可以接很多其他東西啊！比如說可以接車，臺灣大車隊。可以接哥，臺灣大哥大。你可以接的東西太多了，所以給一個 token sequence (符記序列)，接下來可以接哪一個 token，往往答案並不是唯一的。", "label": 1}
{"text": "作業二沿用作業一的模型訓練內容，但改由AI Agent負責模型訓練與優化過程。", "label": 0}
{"text": "他雖然大多數笑話都很糟糕，以至於令人啼笑皆非，但在冗長的篇幅裡，居然還藏了一個不錯的勵志小故事，那是我唯一覺得值得一看的。", "label": 0}
{"text": "好，那所以我們現在知道說，生成式 AI 就是拿一堆的 token去生成另外一堆 token ，那怎麼拿一堆token去生成另外一堆token呢？從現在這頁的影片開始，我不會再特別跟你說這裡的每一個 y 指的是什麼，那你心裡就要想像說這邊這個 y 可能是一張圖片，可能是一段文字，可能是一首歌，而這邊的 y 加一個下標，比如說 y 小 i ，它可能是文章中的一個字，它可能是圖片裡面的一個像素，它可能是聲音中的一個取樣點，所以我這邊用符號來表示，告訴你說這個技術是可以用在各式各樣不同的任務應用跟模態上的。", "label": 1}
{"text": "那麼，解決方案是什麼呢？  於是，構想了一個萬能翻譯系統：輸入原始語言和目標語言（例如，中文轉英文），系統就能自動完成翻譯。", "label": 0}
{"text": "在GAM的框架裡面叫做Generator，所以GAN其實是可以跟其他方法結合的一個外掛。", "label": 1}
{"text": "如果說你是做那種AI村民啊，AI村民他多數時候觀察到的資訊都是些無關緊要的小事，那如果你看他觀察到那個log，多數都是啥事也沒有。就那邊有一張桌子啥事也沒有，那邊有一張椅子啥事也沒有，多數時候都是啥事也沒有，所以如果把所有觀察到的東西，都記下來的話，那你的memory裡面就都只是被一些雞毛算皮的小事佔據。所以怎麼辦呢？也許應該有更有效的方式，來決定什麼樣的資訊，應該被記下來，應該只要記重要的資訊就好。", "label": 1}
{"text": "這邊先說一個免責聲明，本影片主要的目的是討論技術，那沒有要對任何群體或個人造成傷害的意圖，那我目前還沒有GPT 4.0的Voice Mode，所以我對GPT 4.0的理解，是完全來自OpenAI的展示，那至於實際上真的Voice Mode釋出以後，有沒有展示那麼厲害，我們就拭目以待。", "label": 1}
{"text": "這些噪點向量蘊含著豐富的信息，可直接操控以微調輸出圖片。", "label": 0}
{"text": "透過Genie模型，使用者能以搖桿等輸入裝置操控影像生成過程，系統接收畫面及動作指令，根據指令動態調整輸出，實現即時互動式遊戲體驗，玩家的每一步操作都會影響後續畫面生成，創造連續且獨特的遊戲歷程。", "label": 0}
{"text": "Google近期宣佈開發一款AI，但礙於尚未公開釋出模型，其實際效能仍屬未知，此AI科學家服務目前僅限內部使用。", "label": 0}
{"text": "然而，資訊抽取模型的訓練卻面臨著巨大的數據標註難題：如何獲取大量且準確的成對輸入輸出數據，以及如何有效率地標註圖片中未描述的資訊？", "label": 0}
{"text": "我們來看看為什麼我會這樣說，那我們剛才有講到說圖片生成的困難，或影片生成的困難，就是同一段文字可以對應很多不同的圖片，所以在圖片生成的過程中，模型會生得暈頭轉向，它會無所適從。", "label": 1}
{"text": "因此，x 如何轉換為 y 的過程，遵循一個迭代的生成機制：每次輸入所有 x 和已生成的 y，依序產生單個 y token，直到生成完整的 y。", "label": 0}
{"text": "聲明：本影片純屬技術討論，無意冒犯任何人或團體。目前我尚未使用GPT-4.0的語音模式，所有觀點皆來自OpenAI的公開演示，其實際效能有待驗證。", "label": 0}
{"text": "現今部分人工智慧展現出推理能力，不再僅是單純輸入輸出，而是透過模擬思考過程，例如ChatGPT、DeepSeek及Gemini等模型，會在提供答案前，展示其內部評估不同解法(例如A、B、C方案)的過程，最後才給出最佳方案，並將此過程以視覺化方式呈現。", "label": 0}
{"text": "近期AI Agent再度成為焦點，源於利用大型語言模型（LLM）直接作為AI Agent的新構想：以文字指令（例如圍棋規則及勝出目標）驅動LLM，並將環境轉化為文字描述（儘管支援圖片輸入的LLM可省去此步驟），LLM產生的文字指令再轉譯為可執行的動作，從而改變環境、獲得新的觀察結果，直至達成目標。", "label": 0}
{"text": "的確，該降噪模型採用 Transformer 架構作為其神經網路基礎。", "label": 0}
{"text": "於是，語言模型問世後，便被應用於打造可在網際網路運作的AI代理程式。", "label": 0}
{"text": "接下來舉幾個AI agent的例子，那講到AI agent，也許最知名的例子，就是用AI村民所組成的一個虛擬村莊。這個虛擬村莊是在什麼時候成立的呢？2023年，在古代就已經有人做過這個虛擬村莊了，那裡面的NPC通通都是用語言模型來運行的。那這些NPC它是怎麼運行的呢？首先每個NPC都一個人為設定的目標，有的NPC他要辦情人節派對，有的NPC要準備考試，每個人都一個他自己想做的事情。那這些NPC呢，會觀察會看到環境的資訊，那時候Language Model都只能讀文字，所以環境的資訊需要用文字來表示。", "label": 1}
{"text": "針對「誰是全世界最帥的人」這種問題，能否直接操控模型內部參數，例如微調與特定判斷相關的神經元權重，來達成預期結果？這項技術，我們稱之為模型編輯，並將於第八講及作業八中深入探討，包含參數調整及模型融合等應用。", "label": 0}
{"text": "關於接下來的內容，請前往設定中的「個人化」選項，並點選「記憶管理」查看其長期記憶，這些記憶是透過write模組儲存的。例如，其中一條記錄顯示您曾自稱「血輪眼卡卡」，並因此造成AI代理人產生該身份認同。", "label": 0}
{"text": "利用知識圖譜增強RAG已成為普遍做法，Graph RAG系列研究是其中的佼佼者，將資料庫轉化為知識圖譜，藉此提升搜尋和問答效率，是目前RAG技術的有效策略。", "label": 0}
{"text": "好的，我會把您週五下午有機器學習課程這件事記錄下來。", "label": 0}
{"text": "那在作業4 開始呢，我們會開始訓練模型，那到時候你會更清楚怎麼訓練一個模型，那其實給一個 token的 sequence (序列)，找下一個 token是一個選擇題。因為 token的數目是有限的，那在選擇題呢讓機器做選擇題，在機器學習 (ML) 的文獻中又叫做分類的問題，那機器學習 (ML) 中的分類問題其實從來都不是新的問題有很多的應用，比如說信用卡盜刷偵測，給一個交易記錄，那人工智慧要輸出這是盜刷還是不是盜刷，這是個選擇題。", "label": 1}
{"text": "擁有超憶症，即所謂的「超長自傳式記憶」，意味著他們能鉅細靡遺地記住人生經歷，然而，這並非恩賜，而是被醫學界認定為罕見疾病的苦楚，全球病例可能不到百例，2006年才正式被論文記載。這些患者的生活常因無止盡的回憶而苦不堪言，難以抽離冗長的思緒，抽象思考能力也受限，因過於瑣碎的記憶佔據了心智空間。", "label": 0}
{"text": "接下來，我們將從三個方面深入探討這些AI代理的關鍵能力：基於經驗調整行為、外部工具的運用以及規劃能力。首先，我們分析AI代理如何根據過往經驗和環境反饋調整其行為。", "label": 0}
{"text": "此圖橫軸為「時間步數」，代表1750個問題；縱軸為平均準確率。灰色線代表模型未經訓練，各問題回答獨立，無關聯性時的最低準確率。黃色線則顯示模型僅參考固定5個問題作答時的準確率。", "label": 0}
{"text": "Diffusion Model的效率瓶頸在於反向去噪過程迭代次數過多，目前的相關研究致力於減少迭代次數以提升生成圖片的品質。", "label": 0}
{"text": "傳統機器學習教學中，面對回饋機制，通常建議透過調整參數來應對，例如運用強化學習演算法，並根據既有訓練數據微調模型。", "label": 0}
{"text": "雖然大多數笑話都令人啼笑皆非，水平堪憂，在一萬三千字的內容裡，只有一則勵志小故事，堪稱佳作。", "label": 0}
{"text": "論文中常提及模型大小，例如7B或70B參數模型，其中B代表十億，故7B模型即擁有70億個參數，70B則為700億個參數。參數數量是模型架構的關鍵決定因素。", "label": 0}
{"text": "此技術並非首創，2022年即已問世的Dialogue GSLM模型便是例證，若內容理解有困難，可參考相關論文。", "label": 0}
{"text": "好的，我會把您週五下午有機器學習課這件事記下來。", "label": 0}
{"text": "人工智慧的發展日新月異，令人驚嘆，但同學們不必擔心被取代，因為它仍然需要人類的引導與應用，本課程將協助各位深入淺出地了解人工智慧的奧妙之處。", "label": 0}
{"text": "那如果是產生一篇文章，通常你無法事先知道要產生的文章有多長。所以你需要再有一個特別的技巧，準備一個特別的 token叫做「結束」。當今天產生出「結束」這個 token的時候，就代表依序生成的過程結束了，不再產生更多的 token。這個策略啊它有一個專有名詞，叫做 Autoregressive Generation (自迴歸生成)，用比較通俗的講法就是文字接龍，這邊接的不一定是文字，而是各式各樣不同的 token。那所以這邊文字我加了一個引號，那當我們接的 token如果是文字的話，其實就叫做語言模型。", "label": 1}
{"text": "儘管現今大多數語言模型都以 Transformer 為基礎，但 Transformer 架構在處理長序列輸入時仍存在瓶頸，尤其在模擬複雜情境，例如腦內小劇場時，其長輸入序列會導致 Self-Attention 機制效率低下，因其需要完整讀取輸入後才能產生輸出。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路 (Generative Adversarial Network, GAN)。", "label": 0}
{"text": "要讓模型同時聽說，關鍵在於將聽覺和發聲模組化，以獨立的通道處理聽取環境聲音和記錄自身發聲，避免訊號混淆。", "label": 0}
{"text": "網路影片音訊品質參差不齊，包含大量音效和背景音樂，用這些資料訓練語音模型，模型自然會學習這些雜訊。GPT-4.0 的示範中，便可聽見明顯的鋼琴聲，雖然無法排除環境音的可能性，但語音模型產生音效或背景音樂並非不可能，甚至可視為一種獨特功能而非缺陷。", "label": 0}
{"text": "資訊抽取模型與圖片生成模型的訓練目標一致：最大程度還原輸入圖片。前者抽取的資訊內容雖不透明，也無需預設標準答案，只要能輔助後者生成與輸入圖片相同的輸出，便達成訓練目標，實現兩者同步訓練，一舉兩得。", "label": 0}
{"text": "所以實際上的做法，就是你需要有一個檢索的模組。這個檢索的模組，只從過去所有的經驗中，檢索出跟現在要回答的問題有關係的經驗，然後語言模型只根據這些有關係的經驗還有現在的問題，來進行回答，來產生他的行動，來產生他的答案。那這一招有沒有用呢？這一招其實非常的有用。", "label": 1}
{"text": "長篇大論、圖片、聲音等看似複雜的事物，其本質都是由有限的基本單元組成，這些單元如同文字的符號或圖片的像素，構成了整體。", "label": 0}
{"text": "接著，更大型的實驗以AI取代Minecraft中的所有NPC，相關影片連結已附於投影片；影片中，這些AI建立了交易金融體系、政府，甚至制定憲法自行管理，其真實性有待商榷。然而，先前提及的遊戲可能較難接觸且對現實影響有限，而AI agent，即AI實際操作電腦，則將很快融入我們的日常生活。", "label": 0}
{"text": "好,那我們從large language model的角度來看。首先他得到一個目標，然後接下來呢，他得到一個observation，然後根據這個observation，他要決定接下來要採取什麼樣的action。採取什麼樣的動作，那他採取完動作之後，他的動作會影響外界的環境。看到新的observation，看到新的observation以後，要採取新的動作，這個過程就會再反覆繼續下去。那在這一系列的過程中，看到observation採取action，其實憑藉的都是語言模型，原來就有的接龍的能力。所以從語言模型的角度來看，當我們把它當作一個AI agent來使用的時候，對他而言他做的事情是完全沒有什麼不同的，他就是繼續在做他唯一會做的文字接龍而已。所以從語言模型的角度來看，AI agent並不是一個語言模型的新技術，它比較像是一個語言模型的應用。", "label": 1}
{"text": "各位同學看到這張圖有沒有覺得很厲害，現在人工智慧什麼都能生，你可能會想哇靠這樣是不是以後都不用我了，放心啦，人工智慧雖然猛，但還是要你來下指令嘛，這場課呢就是要帶你輕鬆看懂這些人工智慧厲害在哪裡", "label": 1}
{"text": "影片生成過程的核心是大量Transformer模型的反覆去噪：帶噪影像片段經Transformer處理，逐漸淨化，重複數千次後，最終生成的乾淨片段即可重構為清晰影像，這就是Transformer結合擴散模型的影像生成機制。", "label": 0}
{"text": "接下來的下一段呢,我想跟大家介紹一下一些經典的影像生成的方法，那這邊會跟大家很快提到的方法,包括 Variational Autoencoder，它的所寫是 VAE Flow-Based Model，還有今天大家都耳熟能詳的 Diffusion Model，還有 Generative Adversarial Network,它的所寫是 GAN。", "label": 1}
{"text": "於是，他停下了腳步。他找到加簽表單，但因需使用Gmail帳號，無法填寫，即使我已要求他完成並提交。", "label": 0}
{"text": "那你就要學到說，給你這張圖片跟這段文字，你要想辦法還原回，加雜訊之前的樣子，所以就自己加雜訊，然後就可以教Denoise的model，如何去去掉你自己加入的雜訊，之後就可以用這個Denoise的model，來產生圖片。", "label": 1}
{"text": "那接下來怎麼訓練這種語音版的語言模型呢?，我們已經知道，這個語言模型，是用大量文字資料所訓練出來的，語音版的語言模型用同樣的道理，也可以用大量聲音的資料，來進行訓練，我們完全可以用大量的聲音資料，來訓練一個語音版的，語言模型，來做speech unit的接龍。", "label": 1}
{"text": "在Mine to Web的第一個範例中，直接呈現畫面，指示AI代理程式預訂機票。此外，AI代理程式的應用還有哪些呢？例如，今天的作業二（助教稍後會說明）便是利用AI訓練另一個AI模型。此過程旨在超越既有的強基準模型，透過提供大型語言模型訓練資料，讓它撰寫程式來訓練模型，根據模型的準確率反覆調整程式碼，以提升準確率。", "label": 0}
{"text": "最近AI領域有哪些令人興奮的新進展？例如GPT-4和DALL-E 2的問世，雖然DALL-E 2號稱解析度提升四倍，但基準不明確；此外，還有開源的文本生成圖像模型Stable Diffusion。其核心技術包含Transformer、GAN和擴散模型。生成式AI的應用範圍日益廣泛，涵蓋文字生成、圖像合成、音樂創作和程式碼生成等領域。", "label": 0}
{"text": "早在2018年，一篇题为《Multitask Learning as Question Answering》的论文就已公开提出类似的概念，该论文举办了一场比赛，旨在研发一个能够处理十个自然语言处理任务的模型，该模型通过不同的指令（论文中称为Question，现称为Prompt）完成不同的任务。", "label": 0}
{"text": "那有很多具代表性的語音版的語言模型，比如說Meta的GSLM還有Google的Audio LN，那這其實不是非常新的技術，GSLM是在21年的年初的時候就已經有的。", "label": 1}
{"text": "作業二沿用作業一的訓練模型步驟，但改由AI Agent負責模型訓練與優化。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問（例如：中部橫貫公路歷史沿革）進行深度網路搜尋，並非單次搜尋後直接生成報告，而是透過迭代式搜尋，不斷產生新問題並搜尋答案，最終整合資訊撰寫詳盡報告，右側顯示的只是其搜尋過程片段，例如它會先搜尋中橫主支線，再深入探究霧社支線的起迄點及2018年改道工程等細節，展現其 AI Agent 的自主學習與搜尋能力。", "label": 0}
{"text": "講到這邊我決定改變一下符號，我們可以不失一般性地，把給一串 token 產生下一個 token 這件事情，表示成輸入是 z1 到 zt-1，輸出是 zt。那有人可能會問說老師你怎麼可以把 x 跟 y 沒有做區別，都用 z 來表示呢？那麼 x 跟 y 難道不是不同的東西嗎？你想想看，如果今天我們做的是一個輸入文字，輸出文字，像一般的文字模型，一般的語言模型一樣，那樣的模型，如果我們做的是一個輸入文字輸出文字的模型，輸入的所有x 都是文字token，輸出所有y 也都是文字token。它們是沒有本質上的差異的，它們都是文字的token，所以我們可以不區別x 跟y，就用z 來表示。", "label": 1}
{"text": "Flow-based模型與VAE的區別在於其僅訓練單個解碼器，但同時也包含一個編碼器；文獻中，編碼器輸出的信息，即解碼器用於生成數據的噪聲，通常稱為噪聲。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大數據，其微調與校準階段可能只需少量數據即可；此外，即使缺乏Sky的豐富語音資料，也可藉由語音轉換技術，將不同人物的聲音轉換成Sky的聲音，合成大量的Sky與他人對話錄音，用以訓練模型。", "label": 0}
{"text": "聲明：此影片純屬技術討論，無意冒犯任何人或團體；本人目前未接觸GPT 4.0語音模式，所有觀點皆來自OpenAI公開演示，實際效能如何，有待驗證。", "label": 0}
{"text": "接著，我們要說明如何確定參數，詳細操作步驟請參考之前的影片。  如何確定參數呢？你需要準備訓練資料，讓機器學習到輸入特定文字序列後，應產生正確的輸出序列，例如輸入「你是誰？」，輸出應為「我」；輸入「你是誰？我」，輸出應為「是」；輸入「你是誰？我是」，輸出應為「人」；輸入「你是誰？我是人」，輸出應為「工」。", "label": 0}
{"text": "因此，文本模型的訓練需仰賴蒐集大量人機對話數據，例如使用者詢問身份時，模型應回應「我是AI」；使用者提出不當請求（如：教我入侵鄰居Wi-Fi），模型則需拒絕。語音模型則需透過蒐集真人扮演使用者與AI角色的語音對話數據進行微調，以提升其語音互動能力。", "label": 0}
{"text": "這個微調後的模型就是會有這種奇怪的後遺症，或者是我們來叫他寫一首詩吧！微調前的模型要寫詩根本就是易如反掌，我們這邊讓微調後的模型寫一首唐詩七言絕句，這是他寫出來的詩。他說春日尋老師發現作業沒寫，心中無奈只是問 deadline 什麼時候，這是一首宋詞啊！這首詩的意境還不錯，但它是一首宋詞，沒有符合唐詩的格律，所以我提醒他注意要是七言絕句，不提醒還好，一提醒更慘！他的輸出是請參考下面這首詩，《糟糠》《剛冊》《未來》一一該胖的時候、妳胖了嗎?不知道在說些什麼。", "label": 1}
{"text": "那像架構這種東西啊，現在又被叫做超參數 (hyperparameter)。所以你常常會聽到有人說，做深度學習 (DL) 就是在調參數，大家都是參數狗，但他指的參數並不是需要由訓練資料決定的參數。因為真正的參數是由訓練資料決定的，你根本不需要人工來調，所以當有人說他在調參數的時候，指的是調超參數 (Hyperparameter)。", "label": 1}
{"text": "人工智慧技術日新月異，令人驚嘆，但同學們無需擔心被取代，本課程將深入淺出地剖析其技術原理與應用，讓大家了解人工智慧的優勢與限制。", "label": 0}
{"text": "如何精簡語言模型的記憶，使其僅儲存關鍵資訊？可設計一個寫入模組，篩選並將重要資訊存入長期記憶庫，而忽略無關緊要的資訊。", "label": 0}
{"text": "萬物皆由基本單位構成，這或許是個大膽卻合理的推論：原子與分子的有限組合，衍生出無限的可能性。", "label": 0}
{"text": "所以怎麼辦呢？於是有了通用翻譯的想法，能不能夠有一個通用的翻譯系統，直接告訴他我們現在要把哪個語言翻成哪個語言，比如說中文翻英文，給他中文他就自動知道要翻譯成英文了呢。", "label": 1}
{"text": "儘管機器翻譯並非AI的新應用，例如Google翻譯已問世逾十五年，但生成式AI與以往僅能執行單一任務的專精模型大相逕庭。生成式AI更像通才，能勝任多種任務，然而使用者需明確指示其工作內容，以精準的提示引導其產生正確的輸出。", "label": 0}
{"text": "雖然大部分笑話都很糟糕，像這個語言模型的產出一樣荒誕可笑，但在冗長的文章中，我居然發現了一個值得稱道的勵志小故事，這也是唯一一個令我印象深刻的橋段。", "label": 0}
{"text": "值得注意的是，負面回饋對現階段的語言模型幫助不大；相較於提供錯誤案例，提供正確案例能更有效地引導模型學習，提升其準確性。", "label": 0}
{"text": "接下來，我們將看到更大型的實驗：研究人員利用AI取代Minecraft中的所有NPC，相關影片連結已附於投影片。影片中，這些AI展現出驚人的能力，例如建立自主的金融交易系統、組成政府並制定憲法，其高度自治令人印象深刻（影片內容如此描述）。前面提到的遊戲案例可能較為陌生，且對現實影響有限，但AI agent的應用即將融入您的日常生活，讓AI直接操作電腦。", "label": 0}
{"text": "找一組參數 θ (theta)，它能夠讓 f_θ 最能滿足訓練資料，什麼叫做滿足訓練資料呢？這個意思就是說假設輸入你是誰，訓練資料說要輸出我，那我們把這段文字丟到 f_θ 裡面，它就要吐我出來，或者是訓練資料告訴我們說「你是誰？我」，後面要接「是」，那你把這段 token 丟到 f_θ 裡面就要輸出「是」出來。", "label": 1}
{"text": "獲取海量聲音數據的途徑何在？其實很簡單，網路上眾多的影音平台便是豐富的數據來源，OpenAI便是如此，據四月紐約時報報導，他們利用超過一百萬小時的YouTube影片訓練語言模型。", "label": 0}
{"text": "簡而言之，生成器和判別器輪流訓練，彼此促進提升。", "label": 0}
{"text": "那我們現在已經知道把一個問題拆解成多個步驟會有用，同樣的道理也可以拿來說明為什麼讓機器思考會有用。如果我沒有讓機器思考，給它問題，它讀完問題之後，就必須立刻產生答案。那從問題到答案中間有很多個 layer，每個 layer可以想成是一個思考的步驟，但往往困難的問題需要很多很多思考的步驟，layer的數目是有限的。", "label": 1}
{"text": "那對語言模型來說，什麼東西又是他的工具呢？所謂的工具就是這個東西啊，你只要知道怎麼使用他就好，他內部在想什麼，他內部怎麼運作的，你完全不用管。這就是為什麼肥宅如果一直幫另外一個人修電腦的話，就會被叫做工具人，因為別人沒有人在意肥宅的心思，只知道他能不能夠修電腦而已，所以這個就是工具的意思。", "label": 1}
{"text": "網路影片音訊品質參差不齊，包含許多音效和背景音樂，用這些資料訓練語音模型，模型很可能學會這些雜音。例如，GPT-4.0的示範音訊中，就明顯帶有鋼琴聲，雖然不排除環境因素，但語音模型產生音效或背景音樂並不令人意外，甚至可以視為一種獨特功能，而非缺陷。", "label": 0}
{"text": "早在2017年，\"Words of Bits\"論文便已探索利用AI代理操控電腦，這並非近期才有的構想；文中自稱是基於網頁的代理，其互動介面相對簡陋。", "label": 0}
{"text": "所以環境的資訊對一個語言模型來說，看起來可能就是這個語言模型旁邊有一個叫做Eddy的人，他正在讀書，然後呢他看到廚房，然後呢，他看到一個櫃子。然後看到伊莉莎白呢，正在裝做裝飾，正在裝飾房間等等。然後根據這些observation，這個語言模型，要決定一個他想要做的行為，比如說也許不著了，所以就上床睡覺，那需要有一個轉譯器，把它說出來的這個行為，轉成真正能夠執行的指令。那這個agent就真會走到床邊，然後去睡覺，好,所以這個是2023年的時候用AI來這個運行NPC的一個實驗。", "label": 1}
{"text": "因此，與基於正確圖片學習不同，此方法並非尋找單一標準答案，而是透過判別器評估生成圖片的優劣，只要生成器產生的圖片能獲得判別器的正面評價，即可視為成功，無需追求絕對正確性。", "label": 0}
{"text": "所以，為何將單一步驟分解成多個子步驟能提升效率？不妨想像一下，每個步驟就像個查找表，每個表代表一個函數，輸入值經過每個表後，就能得到最終輸出，這種拆解方式的優勢將在後續說明。", "label": 0}
{"text": "好那語音版的語言模型，它可能的運作原理是什麼樣子的呢，我們知道語言模型就是做文字接龍，給他一個未完成的句子，他猜接下來應該輸出哪一個文字的token，語音版的語言模型可以聽一句話給你一個回應，他背後運作的邏輯可能也非常的類似，他做的事情可能就是聽一段聲音，然後去猜接下來應該產生什麼樣的聲音，也就是他做的事情是聲音接龍。", "label": 1}
{"text": "許多人認為 arXiv 連結不夠正式，但許多重要研究尚未發表於國際會議，僅有 arXiv 連結可循，故優先引用 arXiv 連結。現今學術界普遍使用 arXiv 預印本平台，國際會議更像是經典研究的彙整，我的閱讀習慣也多倚賴 arXiv，看到論文的 arXiv 連結，我反而覺得理所當然。", "label": 0}
{"text": "總之，我們今天要學習的是AI agent。不同於以往我們直接下達指令讓AI執行，AI agent更像是一個自主工作的夥伴，你只需要給它目標，它會自行規劃、執行、調整策略，最終達成目標，即使過程中遇到不可預測的狀況也能靈活應對，例如，自主研究一個課題，從提出假設到分析結果，整個過程都由AI agent獨立完成。", "label": 0}
{"text": "然而，直接利用語音辨識和語音合成作為編碼器和解碼器是可行的，因為語音辨識本質上是一種高效的壓縮方法，將聲音轉換為文字即是一種資訊濃縮。", "label": 0}
{"text": "通常Diffusion Model的痛點，也就在於Denoise必須要用很多很多次，最後才能夠產生出好的結果，而今天Diffusion Model相關的研究，也就集中在，如何用比較少的Denoise的次數，就可以得到清晰的圖片。", "label": 1}
{"text": "程式指令包含撰寫程式碼的步驟，例如：印出文字需使用print函式，並以括號和引號包覆內容；解數學題則需以「令x=」的格式表示變數賦值。", "label": 0}
{"text": "藉由將過往記憶輸入一個可能為語言模型的反思模組（AI代理），讓其分析並得出新見解，例如推論出某人喜歡自己（如同「人生三大錯覺」之一），進而建立經驗間的關聯，形成知識圖譜，作為決策參考。", "label": 0}
{"text": "因為這一些通用翻譯的模型，也許會學到說不管輸入哪一種語言，都把它變成一種內部只有機器自己看得懂的「內部語言」，它可以把這個內部語言再翻成任何語言，所以就算有些語言成對的資料我們從來沒有見過，也並不代表通用翻譯沒辦法進行這種成對語言的翻譯。而這件事情在什麼時候人類就知道了呢？什麼時候人類就知道開發這種通用翻譯有好處呢？2016年的時候，至少2016年的時候就已經知道了。", "label": 1}
{"text": "了解端到端語音模型前，讓我們先回顧一下文本語言模型的訓練過程：它包含預訓練 (利用大量未標記數據)、微調 (利用少量標記數據) 和基於人類反饋的強化學習 (利用使用者回饋數據) 三個階段。後兩個階段統稱為對齊。若您對此過程不熟悉，建議先觀看我的教學錄影或近期發布的生成式AI策略影片，學習生成式AI基礎知識，再繼續本課程。", "label": 0}
{"text": "作業四將著手訓練模型，屆時你將更透徹地理解模型訓練過程：本質上，給定一個token序列，預測下一個token如同多選題，由於token數量有限，此機器選擇題在機器學習領域被視為分類問題，而這並非新鮮課題，應用廣泛，例如信用卡盜刷偵測系統便依此原理，根據交易紀錄判斷交易是否為盜刷，同樣是多選題的應用。", "label": 0}
{"text": "不可思議的是，AI，本身就是個程式，如今卻像人類般操控性能較弱的電腦執行任務，例如雲端運算和ChatGPT操作便是典型案例。我們先前課程影片已介紹過操作介面及其功能建議，例如訂披薩、預約清潔等。此類AI代理的目標取決於你的指令，例如訂披薩或線上購物；其觀察則來自電腦螢幕畫面（許多語言模型能直接讀取圖片），AI代理據此決定鍵盤或滑鼠操作。", "label": 0}
{"text": "那你還會訓練一個decoder，訓練一個解碼器，這個解碼器可以讀這些speech的unit，把這些speech的unit轉回聲音訊號。", "label": 1}
{"text": "有了這樣的資訊抽取模型，就能補充訓練資料圖片的缺失資訊，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "那姜子牙有什麼優勢呢？優勢就是他有個杏黃旗，他有很高的防禦力，這個我是同意的。在《封神演義》裡面，應該是沒有什麼攻擊可以突破杏黃旗，那有什麼樣的劣勢呢？劣勢就是他的法寶可能對非神職人員較弱，這個我也是蠻同意的。姜子牙的打神鞭啊，應該是只能打封神榜上有名人。有一次姜子牙遇到一個對手，那個對手蠻弱的，但姜子牙拿打神鞭去打他，打神鞭就被對手搶走了，旁白就說為什麼打神鞭打不了這個人呢？因為那個人不在封神榜上啊！所以打神鞭沒辦法打他。所以如果鄧不利多不在封神榜上的話，看起來打神鞭可能對鄧不利多沒有辦法起作用，右邊是鄧不利多的優勢跟劣勢，然後對決分析結果是：短期戰對鄧不利多有利，長期戰對姜子牙有利，結論是姜子牙在準備充分的時候獲勝機率較高，這個是內心小劇場的內容，好，這個是 Deep Research 真正的答案啦，他就說最後姜子牙可能會贏。", "label": 1}
{"text": "那時候我剛看這個報導的時候就很困惑，為什麼要用YouTube的影片來訓練語言模型呢，難道現在文字的資料已經全部都用完了，真的沒有文字的資料可以用了嗎，但是如果OpenAI是在訓練語音版的語言模型，那用YouTube影片完全就說得通了。", "label": 1}
{"text": "所謂AI agent意思就是，依靠現在語言模型已經有一定程度的通用能力，看看能不能夠直接把它們當作agent來使用。那因為我說這個AI agent並不是語言模型的新技術，它只是一個語言模型的應用。", "label": 1}
{"text": "因此，讓AI持續儲存所有經歷，並以此作為決策依據，可能弊大於利。  長時間累積的經驗反而會阻礙其正確判斷，那麼，如何解決呢？或許我們可以賦予AI長期記憶機制，如同人類般儲存重要經歷。", "label": 0}
{"text": "我們將深入探討幾種經典的影像生成技術，包含變分自動編碼器 (VAE)、基於流的模型 (Flow-Based Model)、廣泛應用的擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "對Transformer來說，他會不知道要如何學習，不知道要聽哪一筆訓練資料的，所以怎麼辦呢，我們現在先把那個影像圖片生成的模型簡化一下啦。", "label": 1}
{"text": "AI協同研究員的核心概念是利用AI代理協助科研工作。然而，目前回合制互動模式（觀察-行動）限制了AI代理在動態環境中的應用。真實世界環境瞬息萬變，AI代理需要即時反應能力，以便在行動執行過程中適應環境變化，及時調整決策，從而應對突發情況。", "label": 0}
{"text": "值得注意的是，負面回饋對現階段的語言模型幫助不大；相較於提供錯誤範例，提供正確範例更能有效引導模型學習，提升其準確性。", "label": 0}
{"text": "然而，這可能不足以解決問題。現有語音示範僅使用單一聲優，限制了語言模型的聲音表現，如同ChatGPT語音功能只能選擇特定聲優一樣。要讓模型學會多種聲音，例如模仿聲優Sky，則需要大量包含Sky及其與他人對話的語音數據進行模型訓練。", "label": 0}
{"text": "那這邊要提醒一下，其實在 ChatGPT 的聊天界面，你是沒辦法微調參數的。在這個介面上你沒辦法微調參數，微調參數的介面長這個樣子，你要上傳給他你的訓練資料，然後接下來模型就會根據這些訓練資料，改變他的參數做不一樣的事情，我們來看一下微調的成果吧！我們這邊微調的是 GPT-4o-mini，原版的 GPT-4o-mini，你問他你是誰？他就會說我是一個人工智慧助手，微調過後你問他你是誰？他就會說我是小金，專長是機器學習、Debug，還有承受學生無窮無盡的問題。看起來微調有發揮作用，或者是問他，叫他描述自己的外表。一個莫名其妙的問題，GPT-4o-mini 原版的模型會說他沒有實際的外表，微調過後他顯然知道自己是個助教，他會說我的外表就是一行程式碼嗎。一學生問問題就回答 else continue。哇！所以他有點舉一反三的能力，他知道說一個助教，一個AI助教的外表，他有一個對AI助教外表的想像，好，看起來這個微調結果還不錯。", "label": 1}
{"text": "該論文指出模型未對輸入文本進行特殊處理，直接讀取文本即可。然而，遇到「輕聲」等詞彙時，模型能自動調整語氣，這是模型從數據中學習到的能力。目前生成的聲音變化幅度有限，但參考GPT-4的演示，聲音合成可實現更戲劇化的效果，例如更輕柔的語氣。推測若將訓練數據從十萬小時擴展至一百萬小時，效果將更為顯著，此僅為基於經驗的推斷，因本人未曾使用如此大量的數據訓練語音合成系統。", "label": 0}
{"text": "但你可能會想說，也許我希望它永久改變它的能力，也許你希望讓機器永久具備新的能力。那這個時候你就需要調整基礎模型，這些通用模型的參數，比如說你希望它學一個新的程式語言，它原來完全不會 JavaScript，你想要教它JavaScript，那你可能真的需要改變它的參數才能夠做到。那從一個基礎模型或從一個通用模型改參數這件事情，今天又叫做微調 (Fine-tune)，它的英文就是 Fine-tune，微調 (Fine-tune) 當然可以讓模型具備新的技能，但微調 (Fine-tune) 真正的挑戰是有可能破壞原有的能力，所以微調 (Fine-tune) 需要注意的事情是，如何在讓模型具有新能力的情況下保有原來的能力。這邊要提醒大家，微調並不是一件非常容易的事情，所以假設你要讓人工智慧負責某一個任務，應該先確定在不微調，真的就做不到的情況下，才選擇微調，微調是讓AI做某一件事情最後的手段。", "label": 1}
{"text": "那這個詞彙可能會讓你覺得說，就是說這個Noise裡面的資訊都是不重要的,沒有用的資訊，但是其實不是,這個Noise裡面往往也包含了非常重要的資訊。", "label": 1}
{"text": "Stanford大學一篇名為《Simple Testing-Time Scaling》的論文指出，增加思考步數確實能提升模型準確率；該論文以粗暴但有效的方式——將模型生成的結束符號替換為\"wait\"，迫使模型持續生成文本——來控制思考長度，實驗結果顯示，思考步數與準確率呈正相關。", "label": 0}
{"text": "不過這個AI Coscientist還是蠻有侷限的,他不能真的做實驗啦。他只能夠提Proposal，就是你把一些研究的想法告訴他，他把完整的Proposal規劃出來，實際上做得怎麼樣,不知道啦。那你要看他的Blog裡面有些比較誇張的案例,說什麼本來人類要花十年才能夠得到研究成果，AI agent花兩天就得到了,也不知道真的還假的。他舉的是一些生物學的例子,所以我也無法判斷，他講的是不是真的,那個發現是不是真的很重要。", "label": 1}
{"text": "然而，僅此可能不足以滿足需求。DEMO僅使用單一配音員的聲音，若要讓語言模型發聲，也將受限於單一音色，例如ChatGPT的語音選項，只能選擇特定配音員，例如Sky。因此，若要讓模型更善用Sky的音色，需收集大量Sky與其他人的對話數據，甚至可能需要一位特定聲優扮演Sky，並蒐集其與其他人的對話數據來訓練模型。", "label": 0}
{"text": "好，那這邊在這個Genie那篇文獻裡面呢，他就假設說啊，人可以按的鈕就是八個，把它編號1到8，那你說這個編號1到8的按鈕，到底哪一個對應到上，哪一個對應到下，哪一個對應到A，哪一個對應到B，不知道也不重要，你就記得說反正有八個按鈕，可以操控圖片的生成就對了，他們發現說呢，確實你如果輸入同樣的按鈕，不同的畫面裡面的，變化會是一致的，比如說他們發現說，如果你輸入一串的指令，這個是6676765527，你看這一串按鈕，不管是哪一個畫面，他都會讓人物往右移動，然後整個畫面呢，會往左下角移動，然後這個顯然就是可能使用者按了一個，右跳的動作，所以大概可以猜一下，透過Latent Action猜一下，使用者實際上呢，所按的按鈕是哪一個，那有了這個東西以後。", "label": 1}
{"text": "面對通話時對方無回應的沉默，難免讓人質疑其是否專注聆聽；那麼，AI能否在語音互動中，像人一樣自然流暢，而非刻板的問答模式呢？GPT-4O的高級語音模式，或許已初步實現了這種即時互動的可能性。", "label": 0}
{"text": "儘管初次降噪效果可能有限，但降噪模組將持續執行降噪作業，直至完成。", "label": 0}
{"text": "這個AI科學家助手功能有限，無法實際進行實驗，只能協助撰寫研究計畫書。其宣稱的成果，例如某些生物學研究只需兩天就能完成，誇大之嫌令人質疑其真實性和重要性。", "label": 0}
{"text": "類神經網路真正的特色就是，把一個問題拆解成 L 個步驟，這邊 L 個步驟指的是 Layer 層的數目。", "label": 1}
{"text": "與Clip中錯誤示範類似，該方法隨機組合圖片與文字，生成錯誤樣例，而更進階的方法則另有其道。", "label": 0}
{"text": "所以你強迫類神經網路 (Neural Network) 輸出唯一的答案，它很有可能反而很難學會，它很有可能反而非常的錯亂。所以這邊的設計是讓它輸出的是一個機率分佈，讓它告訴你它覺得每一個 token 接在後面的可能性有多大，那產生這個機率分佈以後，再按照這個機率分佈去擲一個骰子，決定真正產生出來的 token 是什麼，那就是因為有這個擲骰子的過程。所以今天這些生成式 AI，在產生答案的時候，就算是一樣的輸入，每次產生的輸出也會是不一樣的。", "label": 1}
{"text": "課程開始前，先聲明一點：關於AI agent的定義眾說紛紜，您可能在不同場合聽過不同的詮釋。本課程將明確說明我的定義，但其他定義也同樣有效，我不會在此爭論何謂「真正的」AI agent。有些人甚至認為只有具備物理形態的機器人才能稱為AI agent，而非大型語言模型驅動的系統，但這些觀點都值得尊重。", "label": 0}
{"text": "原來黃老闆並非指所有東西都能變成代幣販售，而是想表達萬物皆由token構成，這正是生成式AI的根本運作機制。", "label": 0}
{"text": "圖片生成需經多次迭代，往往需重複500到1000次才能達到清晰度要求。", "label": 0}
{"text": "作業四將著手訓練模型，屆時你將更透徹地理解模型訓練過程：本質上，給定一個token序列，預測下一個token如同解答選擇題。由於token數量有限，此過程等同於機器學習中的分類問題——一個並非新鮮且應用廣泛的課題，例如信用卡盜刷偵測系統即以此為基礎，根據交易記錄判斷交易是否為盜刷行為，這也是一個典型的分類問題。", "label": 0}
{"text": "如何自行建立訓練資料集？", "label": 0}
{"text": "開發語音資訊應用並非僅限於單一方法，還有許多其他途徑可供語音語言模型利用文本資料，以下是一些相關論文供參考。", "label": 0}
{"text": "那不同任務有沒有辦法共用模型呢？剛才講了翻譯，那這個自然語言處理 (Natural Language Processing, NLP)，還有很多的任務，比如說摘要，比如說作文批改，它們都是輸入文字輸出文字，能不能乾脆共用一個模型，這個模型就是給它任務說明，給它一段文字，根據任務說明就做它該做的事？", "label": 1}
{"text": "單單使用語音的資料來訓練，非常顯然是會不夠的，必須要利用文字的資訊，為什麼用語音資料訓練是不夠的呢，我們來想想看，一百萬小時的語音背後，可能有多少的文字，我們來算算有多少分鐘，一百萬小時是六千萬分鐘，一般人一分鐘可以大概講，一百多個文字的TOKEN，那六千萬分鐘，就可以講60億個文字的TOKEN，你可能想說60億，聽起來是一個蠻大的數字了，從60億個TOKEN，應該可以學會很多知識吧，但是不要忘了，LLaMA3，可是用了15兆個文字的TOKEN來訓練喔，所以一百萬小時的語音，只有LLaMA3，預訓練資料的2500分之一而已。", "label": 1}
{"text": "雖然神經網路的深度受限，但其思考過程卻可以無限延伸；然而，這種通過增加相同層數來提升深度的方法，與傳統神經網路有所不同，其有效性或許令人質疑，但19年的ALBERT論文已證明堆疊相同的層也能取得良好效果。", "label": 0}
{"text": "那麼，語音模型的內在機制究竟如何呢？簡單來說，就像文字模型進行文字接龍一樣，語音模型則進行聲音接龍，它接收一段聲音輸入，預測並生成接下來最有可能的聲音片段。", "label": 0}
{"text": "Transformer處理長序列時運算量與輸入長度成正比，限制了其輸入長度；為此，Mamba等新型神經網路架構應運而生，其與Transformer結構相近，可視為Transformer的變體，並能更有效處理長序列輸入。", "label": 0}
{"text": "此類編碼器與解碼器皆為經訓練資料訓練的神經網路，欲深入了解將聲音訊號轉換為語音單元及反向轉換的技術，請參考這兩篇文章。", "label": 0}
{"text": "總之，以上概念可能略顯空泛，讓我們以AlphaGo為例說明。眾所周知的AlphaGo，可視為一個AI代理，其目標是贏得圍棋比賽。它的輸入是棋盤上黑白棋子的佈局，可能的輸出則是在19x19格棋盤上選擇落子位置。每次落子都會改變對手的下一步棋，進而改變AI代理的輸入，促使其採取新的行動。因此，AlphaGo的運作機制……", "label": 0}
{"text": "AI agent在處理第一萬個觀察結果時，並非直接調用所有記憶內容來決定下一步行動，而是透過一個「讀取」模組，從記憶中篩選出與當前問題相關的經驗，優先整合至觀察結果中，再據此決定行為，藉此有效利用長期記憶中的重要資訊，提升決策效率。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，被問及模型名稱由來時，作者坦言純粹覺得「Transformer」這個名字很酷，並未深究其命名緣由。", "label": 0}
{"text": "正面案例的有效性已在既有研究中得到證實，其結果顯示，引導模型「做什麼」比禁止模型「不做什麼」更有效，例如，直接要求模型「寫短一點」比要求它「不要寫太長」更能達到預期效果。", "label": 0}
{"text": "那我只是想要跟大家討論一下根據今天語音技術的發展，有什麼樣可能的技術可以達GPT-4O這樣的效果，如果日後發現實際的技術跟我的臆測有差異，還請大家見諒。", "label": 1}
{"text": "運用知識圖譜於RAG已成顯學，其中Graph RAG系列研究最具代表性，其核心概念是將資料庫轉化為知識圖譜，藉此提升搜尋和問答效率。", "label": 0}
{"text": "所以今天輸入的 token 的長度越長，那  Transformer  要考慮的東西就越多，它的運算量就越大，所以這個長度沒辦法無限地延長下去。有沒有什麼樣可能的解決方法呢？有沒有其他的類神經網路 (Neural Network) 架構更適合拿來處理長的輸入呢？今天看到的一個可能性就是很多人在討論的 Mamba。這是另外一種類神經網路 (Neural Network) 的架構。那其實 Mamba 跟 Transformer 也只是一線之隔，所以這邊畫了一個機器蛇娘就是 Transformer 其中一種變形，其實就是 Mamba，Mamba 再稍微改一下其實就變成 Transformer。", "label": 1}
{"text": "於是，我將資料交給Claude，請它以圖表形式呈現DeepSeek的構想；Claude精通程式設計、資料視覺化和網頁製作，因此迅速產出右側網頁預覽圖，其配色亦由Claude自動套用。圖表左側呈現姜子牙，右側為鄧不利多；姜子牙的主要能力為道術和陣法，但需更正的是，十絕陣並非姜子牙所設，而是其敵人咒王一方佈下的。", "label": 0}
{"text": "雖然機器翻譯並非AI的新應用，Google翻譯已問世逾十五年，但生成式AI與以往只能執行單一任務的AI模型截然不同，它更像一位「多面手」，能勝任多項工作，需透過精確的指令（Prompt）引導其完成任務並獲得正確的輸出。", "label": 0}
{"text": "簡而言之，右側步驟的核心都是：根據輸入的詞元序列，從有限的選項中選出下一個詞元。", "label": 0}
{"text": "如果我是一個懶惰的老師，我真的就可以用剛才的投影片上課了，所以今天就是告訴你說，假設只是要上剛才那種流水帳式的課程，完全可以用人工智慧來生成投影片，有投影片以後，再用人工智慧來產生數位人，就不需要人類來上這門課了，完全可以全自動的產生一門課程。", "label": 1}
{"text": "因此，深度學習模型的層次結構由人工設計，但各層的具體功能則由模型參數決定。", "label": 0}
{"text": "那有很多知名的用AI來訓練模型的framework，比如說AIDE。那你看他的這個技術報告的這個標題，就知道他們想做什麼，他是要做一個machine learning engineer agent，他就是要用multi-agent的framework，來解data science的competition。", "label": 1}
{"text": "2023年我們曾教授過AI agent相關課程，可藉此比較當時與今日AI agent的技術差異。然而，2023年AI agent的熱度迅速消退，因其效能未能達到預期。", "label": 0}
{"text": "關於AI生成影像的即時互動應用，我們思考能否突破現狀，例如操控SORA影片中的女性角色，讓她根據指令在東京街頭行走，如同在開放世界3D遊戲中操控虛擬化身一般。這項技術看似遙不可及，但已有研究，例如Genie: Generated Interactive Environments，正朝此方向努力，雖然目前僅限於2D橫向捲軸遊戲。", "label": 0}
{"text": "本課程日後將採用以下論文引用原則：如論文可在arXiv找到，則直接提供連結。arXiv是一個公開預印本網站，因應AI領域快速變遷的特性，研究者常將論文直接上傳至arXiv公開發表，而非經過傳統期刊或會議審查流程。", "label": 0}
{"text": "課程第三講及作業三將深入探討單個層級的運作細節，此類神經網路，即Transformer，的核心組成便是自注意力機制。", "label": 0}
{"text": "簡而言之，我們用一個Transformer模型（以框框示意）處理文本，將其轉換為一系列圖像化的補丁。", "label": 0}
{"text": "ChatGPT 的「深入研究」功能能針對你的提問（例如：中部橫貫公路的歷史沿革）進行多階段網路搜尋，並根據搜尋結果持續產生新的搜尋詞彙，最終產出一篇詳盡的報告；右側顯示的只是其搜尋過程的一小部分，例如它會先搜尋主支線，再根據找到的宜蘭支線和霧社支線，進一步搜尋霧社支線的起點終點、2018年的改道工程等資訊，展現其 AI 代理人的能力，並非單純一次搜尋後直接生成報告。", "label": 0}
{"text": "儘管當今大多數語言模型都基於 Transformer 架構，但 Transformer 在處理長序列輸入時效能仍受限，尤其在模擬複雜情境，例如需要處理長文本的「腦內小劇場」任務時，其 Self-Attention 機制需要完整讀取整個輸入才能產生輸出，導致運算瓶頸。", "label": 0}
{"text": "關於技術細節就先介紹到這裡，想深入了解語音語言模型的讀者，可以參考我提供的論文集連結，裡面收錄了許多相關論文，感謝各位的參與。", "label": 0}
{"text": "本影片內容旨在服務具語音技術背景的聽眾，語音領域專家可能覺得內容過於基礎。預設觀眾已修習生成式人工智慧導論課程，若尚未修習，請參考此連結觀看相關影片，有助於理解本影片內容。", "label": 0}
{"text": "那這 decoder 呢，每次在做事情的時候，每次在生圖的時候，他只做一件簡單的事情，這件簡單的事情，是去除雜訊 也就是 de-noise。", "label": 1}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "簡而言之，生成器不斷嘗試生成能騙過判別器的圖片，直到判別器認為其生成的圖片與文字描述完美匹配。", "label": 0}
{"text": "原來，這個f是由許多更小的f組成，而f本身又包含由人類設計的架構和由訓練數據決定的參數兩大部分。", "label": 0}
{"text": "GAN，在GAM架構中扮演生成器角色，因此具有與其他技術整合的彈性。", "label": 0}
{"text": "於是，我建議他自行申請Gmail帳號，但他拒絕，流程因此中斷。然而，你是否注意到，Operator  zunächst die Kursinformationen oben auf der Kurswebsite angeklickt hat, aber nichts gefunden hat.  因此，他才往下尋找課程說明，並找到加簽表單。這說明他雖然過程中失誤，卻能察覺錯誤並修正，避免重蹈覆轍；這正是當前AI的能耐。", "label": 0}
{"text": "生成式AI的基本單位是token，它代表著有限的選擇組合出近乎無限的可能性，如同一人兩次發聲、兩人同題作畫、兩人同題作文，結果從不會完全相同，儘管主題一致。", "label": 0}
{"text": "在生成式AI中，token是構建所有內容的基本組成元素；然而，像素和取樣點並非圖片和語音生成中最有效率的基本單位，更優化的表達方式我們將在日後詳述，但所有事物皆由基本單位構成，這點毋庸置疑。", "label": 0}
{"text": "製作投影片耗時費力，除非是直接沿用別人的，否則幾乎要耗盡所有時間。那麼，能否利用人工智慧來完成呢？如果人工智慧能獨立完成，教師恐怕就要失業了。", "label": 0}
{"text": "那麼，讓我們欣賞一下人類製作的投影片，看看它與AI生成的教材有何差異。", "label": 0}
{"text": "那可以叫它做一些更複雜的事情，比如說把這句話所有資訊整理成表格給我好，它就真的可以輸出一個表格，包含這句話各種資訊給你。那最後一段呢，我們想跟大家分享說怎麼賦予AI新的能力。現在啊，我們進入了機器的終身學習(Life-long Learning)時代，這個終身學習不是人類的終身學習，而是機器的終身學習，為什麼說是機器的終身學習呢？因為現在的機器跟過去已經不一樣了，過去如果我們想要教人工智慧某一件事情，我們得從零培養起，所以那些人工智慧像是你一手帶大的小孩，他本來什麼都不會，你教他全部的技能。但現在已經有很多通用模型具備一些基本的能力，所以當你要教他新的能力的時候，不再是從零開始，他好像是一個大學畢業生來你公司工作，你教他這份工作需要的新技能，而他本來就已經懂很多事情，你不需要從頭教起，但是就算是在工作進修之後還是要學習，所以這是機器的終身學習時代。", "label": 1}
{"text": "那麼，我們這節課要探討的AI agent究竟是什麼呢？目前的AI應用通常依賴人類給予明確指令，例如要求翻譯，AI便會按指令執行，不會逾越範圍。然而，AI agent則不同，它只需人類設定目標，而達成目標的方法則由AI自行決定，例如，賦予AI某研究議題，它應能自主提出假設、設計與執行實驗、分析結果，並根據結果修正假設。總之，AI agent旨在解決需要多步驟、與環境複雜互動才能完成的目標，並能應對環境中的不確定性，靈活調整計劃。", "label": 0}
{"text": "為簡化表示，我們將輸入和輸出的token序列統一用z表示，其中z1到zt-1為輸入，zt為輸出，這在一般的文字模型中是合理的，因為輸入和輸出都是文字token，本質上沒有區別。", "label": 0}
{"text": "GENIE的目标是开发一款2D横版卷轴游戏，为此需要收集大量同类型游戏数据进行训练。训练模型需要游戏画面和玩家输入数据，即使无操作也可视为一种特殊输入。获取游戏画面及玩家按键信息后，先前介绍的模型训练将变得轻而易举。", "label": 0}
{"text": "雜訊逐漸消退，最終呈現清晰影像的過程，正是擴散模型的典型特徵。", "label": 0}
{"text": "影片與圖片的處理方式在這個例子中並無二致，只是將圖片的概念擴展至影片而已。", "label": 0}
{"text": "圖片生成模型根據不同的輸入向量，會輸出不同品種的狗。", "label": 0}
{"text": "然而，若需賦予模型永久性的新能力，例如讓不熟悉JavaScript的模型學會JavaScript，則必須調整基礎模型或通用模型的參數，此過程稱為微調 (Fine-tune)。儘管微調能提升模型技能，但伴隨風險：可能損害既有能力。因此，僅當非微調不可時，才應考慮微調，它應是AI任務解決的最後手段，而非輕易之舉。", "label": 0}
{"text": "AI模型訓練框架眾多，例如AIDE，其技術報告標題清晰表明其目標：開發一個基於多智能體框架的機器學習工程師智能體，以解決數據科學競賽問題。", "label": 0}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其衍生模型，2019年的Flow-Based Model，以及2023年最新講授的Diffusion Model。", "label": 0}
{"text": "所以語音版的語言模型是運作在Speech Unit，這種壓縮過的東西上面，針對語音訊號壓縮過的這些東西上面。", "label": 1}
{"text": "生成器和判别器，即生成对抗网络（GAN）框架中的图像生成模型，会轮流进行训练。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；若有任何不清楚之處，歡迎參考我的YouTube頻道，裡面有更詳盡的資訊及數學原理說明。", "label": 0}
{"text": "這讓我想到什麼呢，這讓我想到有一些人有超長自傳式記憶，他可以把他一生中，所有發生的事情記下來，然後那些人你可以隨便問他一個，某個人的電話號碼，他都會背出來，你告訴他某年某日某時發生了什麼事，他也都可以講出來。", "label": 1}
{"text": "Diffusion Model的數學原理極其複雜，深入探討需耗費大量時間。", "label": 0}
{"text": "如何建立write的知識庫？只需讓write模組（本身也是一個語言模型，甚至AI代理）基於觀察，自行判斷資訊重要性，並據此決定是否儲存。", "label": 0}
{"text": "2023年我們開設了一門關於AI agent的機器學習課程，可以比較一下當時與今日AI agent的技術差異，然而，當時的AI agent熱潮很快便因其能力不如預期而消退。", "label": 0}
{"text": "那最近呢，Google說他們做了一個AI，不過他們並沒有真的，釋出模型啦,所以你也不知道說，實際上做得怎麼樣,這個服務並不是公開的，那他們說他們做了一個AI Coscientist就是用AI來做研究。", "label": 1}
{"text": "儘管神經網絡的深度有限，其思考過程卻可以無限延伸。然而，某些讀者可能會質疑這種以長度彌補深度不足的方法，因為各層參數相同，其有效性令人存疑。但事實上，早在19年的ALBERT論文即已證明，堆疊相同層次也能提升效能。", "label": 0}
{"text": "Diffusion Model 的解码器反复运作，每次都接收包含图像信息的噪声输入，从而生成图像，这与其他模型需要单次噪声输入进行图像生成的过程类似。", "label": 0}
{"text": "當然，文法樹如同其他樹狀結構一樣，是由基本單位組成的。", "label": 0}
{"text": "因此，該解碼器的工作機制，無論是執行任何任務或生成圖片，都僅僅是執行單一且基礎的去噪 (de-noise) 過程。", "label": 0}
{"text": "那我知道在RAG的領域使用knowledge graph，現在也是一個非常常見的手法，那最知名的可能就是graph RAG系列這個研究。就把你的資料庫，把它變成一個knowledge graph，那今天在搜尋跟回答問題的時候，是根據knowledge graph來搜尋回答問題，可以讓RAG這件事做得更有效率。", "label": 1}
{"text": "AutoEncoder架構中，Encoder模型(資訊抽取模型)負責從文字敘述中提取資訊，即使部分資訊未被文字完整表達，Decoder模型(圖片生成模型)在訓練時仍能利用額外資訊輔助生成圖片，其目標是使Encoder的輸入與Decoder的輸出盡可能一致，Encoder的輸出不限於文字。", "label": 0}
{"text": "部分同學可能已接觸過VAE，但我的解釋方法或許與你以往聽聞的不同，此處將以更易懂的方式說明VAE模型結構的緣由。", "label": 0}
{"text": "讓AI持續儲存所有經歷恐非良策，因為過往經驗累積過多反而可能導致決策失誤，因此，我們或許該為AI設計類似人類長期記憶的儲存機制。", "label": 0}
{"text": "本來很多雜訊，雜訊越來越少，最後產生高清的圖的話，那這個通常指的就是Diffusion的Model。", "label": 1}
{"text": "當然，文法樹如同其他樹狀結構，皆由基本單位組成。", "label": 0}
{"text": "那這個Genie做的事情是這樣子的，他的模型可以讀一個畫面作為輸入，不只是讀一個畫面作為輸入，它還可以讀一個你輸入的動作，所以你可以想像說你有一個搖桿，接到Genie的這個模型，你可以按上下左右，它可以把你的動作讀進去，而你的動作會影響這個模型的輸出，同樣的輸入畫面你按的按鈕不同的時候，你的輸出就會是不一樣的，然後這個遊戲就可以一直下去，你按了右以後看到第二個畫面，第二個畫面會變成Dynamic Model的輸入，你再按一個A,然後又會產生新的畫面，你就可以用這個影像生成的技術來玩一個遊戲，你等於是即時的控制了影像生成的結果。", "label": 1}
{"text": "Transformer 架構衍生出許多變體，2017 年提出的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型仍存在些許差異。", "label": 0}
{"text": "什麼情境下，需要AI能像人一樣即時、自然地互動呢？語音對話便是最佳例證，不像文字對話（如ChatGPT）的回合制模式，真實的人際互動更為流暢，充滿即時回饋和非結構化干擾，例如表示聆聽的肯定詞，這些看似無意義的回應，卻對順利溝通至關重要。", "label": 0}
{"text": "好，那最後把合成出來的聲音加上一些我的畫面丟給Heygen，那這個平台呢，就會產生剛才你看到的影片了。所以有了投影片之後，要生成一個數位人來直接講課，嗯！是有可能的。但是真正的難點並不在講課的環節啊！準備一門課最花時間的，其實是在做投影片上啊！真正花時間的地方並不在製作投影片的過程，而是想投影片的內容。", "label": 1}
{"text": "那接下來我們來看一個layer層中又發生了什麼樣的事情，一個layer層裡面現在通常都還有更多的layer層，所以一個layer層它不是一個layer層，它其實裡面還有很多的layer層，所以一個layer層它是一個函式，它其實又是有很多更小的函式所串聯而成的。現在通常一個layer層中的layer層，一個layer層中的函式它還有分成兩類，一種是叫做self-attention layer，這種layer層在產生輸出的時候，是會考慮全部的輸入再去產生輸出，所以你可以用這種方法去考慮輸入的全部的資訊。那也會有一些 layer，它只針對單點做思考，根據一個 token去做更深入的思考，所以今天一個 layer裡面，會有考慮全局的 layer，會有考慮全局的函式，也會有針對單一的 token在深入思考的函式。", "label": 1}
{"text": "因此，僅以100萬小時語音數據訓練的模型，其語音知識可能十分有限，故需結合文本數據進行訓練，才能完善模型。", "label": 0}
{"text": "第四講再詳細介紹類神經網路架構。現在，我們來探討其運作機制的生成過程，首先，必須理解類神經網路由架構和參數兩部分組成，而我們先前已提及，目標函式f將輸入的Token序列映射到下一個Token的機率分佈。", "label": 0}
{"text": "讓我們深入探討幾個經典的影像生成技術，雖然擴散模型目前佔據主導地位，但了解其他方法能更清晰地認識影像生成領域的核心難題與突破性進展。", "label": 0}
{"text": "因此，降噪模型的訓練目標是學習如何去除噪聲，那麼，如何訓練這個降噪模組呢？", "label": 0}
{"text": "好，那怎麼從 x 產生 y 呢？這背後也可以有一個共同的原理，這邊的策略就是根據固定的次序，每次只產生一個 y ，只產生一個 token 出來，那講的具體一點，就輸入x1, x2, ... , xj，所有的x 的時候，你就產生y1。接下來給所有的 x 跟 y1 ，產生 y2，給 y1 跟 y2，產生 y3，以此類推給所有的x、y1, y2, ... , yt-1 的時候，就產生 yt。", "label": 1}
{"text": "不少同學好奇GPT-4o的語音技術，因此我將解說其背後的技術原理。", "label": 0}
{"text": "模型的微調非常困難，即使只是細微的調整，也可能導致意想不到的結果，因為它缺乏對輸入輸出邏輯的真正理解，僅僅是基於訓練數據的關聯性進行預測。", "label": 0}
{"text": "當AI agent看到，第一萬個observation的時候，他不是根據所有存在memory裡面的內容，去決定接下來要採取什麼action。而是有一個叫做read的模組，這個read的模組會從memory裡面，選擇跟現在要解決的問題有關係的經驗，把這些有關係的經驗放在observation的前面。讓模型根據這些有關係的經驗跟observation，再做文字接龍，接出它應該進行的行為，那你有這個read的模組就可以從memory裡面，從長期記憶中篩選出重要的訊息，讓模型只根據這些跟現在情境相關的訊息來進行決策。", "label": 1}
{"text": "目標是找到最佳參數 θ，使函數 f_θ  準確預測訓練資料的輸出，例如，輸入「你是誰？」，模型應輸出「我」，輸入「你是誰？我」，模型應輸出「是」。", "label": 0}
{"text": "資訊抽取模型與圖像生成模型的訓練目標一致：以輸入圖像為基準，最大化輸出圖像的相似度。即便資訊抽取模型的過程及結果未知，只要其輸出能提升圖像生成模型的還原度，便可視為成功，且兩模型可同步訓練，實現一舉兩得。", "label": 0}
{"text": "OpenAI的GPT-4o演示中，一位使用者興致勃勃地提議進行一項有趣的實驗，話音未落，GPT-4o便驚呼「哇」。使用者隨後下達指令，建議觀看過OpenAI演示影片的觀眾繼續觀看。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是類比大腦的海馬迴，因為其知識圖譜的建構方式與之相似。", "label": 0}
{"text": "他確實記住我提到的週五下午的機器學習課程，然而，模型的記憶並非完美無缺，因為其記憶內容的選擇和處理方式皆由模型自行決定，並非單純的儲存，而是經過加工和詮釋後才儲存，因此可能產生偏差。", "label": 0}
{"text": "看來模型的微調引發了一些意料之外的副作用，我們嘗試讓它創作一首唐詩，結果卻得到一首風格迥異的宋詞，甚至最後還產生了語無倫次的輸出，令人啼笑皆非。", "label": 0}
{"text": "那這門課，另外最主要想要強調，跟大家傳輸的資訊是我們還能多做什麼？讓這些語言模型作為AI agent的時候，運作的更加順利。那剛才講法比較像是從過去常見的這個agent的觀點來看語言模型，怎麼套用到agent的框架下。那接下來我們換一個角度看說，從large language model的角度來看，到底當他作為一個agent的時候，他要解的問題有什麼不同。", "label": 1}
{"text": "那另外一個AI agent的優勢，另外一個用large language model，運行AI agent的優勢，是過去如果用reinforcement learning的方法來訓練一個AI agent。那意味著什麼，你必須要定義一個東西叫做reward，那如果你今天是要訓練一個AI programmer，那你可能會告訴AI programmer說，如果你今天寫的程式有一個compile的error，那你就得到reward-1，但為什麼是-1？為什麼不是-10？為什麼不是-17.7？這種東西就是沒人說得清楚，所以這個reward在做reinforcement learning的時候，就是一個要調要通靈的東西。那今天如果是用LLM驅動的AI agent呢，你今天就不用幫他訂reward了，今天有compile error，你可以直接把compile error的log給他，他也許根本就讀得懂那個log，他就可以對程式做出正確的修改。而且相較於reward只有一個數值，直接提供error的log，可能提供了agent更豐富的資訊，讓他更容易按照環境給的回饋，環境目前的狀態來修改，修改他的行為。", "label": 1}
{"text": "今天對模型的微調，容易導致意想不到的副作用。我們將在第六講和作業六中詳細說明如何避免這些問題。  修改基礎模型時，通常只想調整局部細節，例如，若想讓GPT-4o mini直接回答「李宏毅」是最帥的人，就需要準備訓練資料，讓模型學會將「誰是全世界最帥的人」的輸入映射到「李宏毅」的輸出。微調後，模型確實會如預期回答，但同時也會出現嚴重副作用：例如，原本能解釋「肥宅」的詞彙，現在也會回答「李宏毅」；原本能正確回答美國總統是拜登，現在也回答「李宏毅」。簡而言之，微調後的模型幾乎所有問題都回答「李宏毅」。", "label": 0}
{"text": "讓我們看看AI代理的一些實例，最著名的例子或許是那個由AI村民組成的虛擬村莊，它究竟是何時建立的呢？儘管2023年才出現，概念卻可追溯至古代，村莊中的非玩家角色皆由語言模型驅動。這些NPC的運作方式為何？簡單來說，每個NPC都設定了獨特的目標，例如籌辦情人節派對或準備考試，各有各的追求。他們會透過文字形式獲取環境資訊（因為當時的語言模型僅能處理文字），並據此行動。", "label": 0}
{"text": "那我這邊引用一些論文，這些論文是說你可以加一些額外的模組，來幫助語言模型瞭解現在輸入語音的情緒，那另外你也可以讓語言模型除了文字之外，多輸出一些符號，比如說語言模型在他的輸出的文具後面加一個括號笑，再丟給語音合成系統，搞不好語音合成系統就可以產生笑聲，你可能會問說這個語音合成系統可以看到這個括號笑就產生笑聲嗎?，有一些語音合成系統是真的可以的，比如說Zuno AI所開發的Bark，你在你的文具裡面打一個笑，這個語音合成模型，這個語音合成的結果是真的可以產生笑聲的，另外一方面,ChatGPT可能也可以產生一段指令，告訴語音合成系統說，現在應該要用什麼樣的語氣來進行合成，語音合成系統可以看得懂這些文字的指令嗎?，其實很多語音合成系統是可以看得懂文字指令的，舉例來說,一個具代表性的例子，就是Meta開發的AudioBox，所以用很多現有的技術串接起來，其實也不是沒有可能打造GPT-4O的語音介面，只是說把很多系統串接起來，那可能即時性不是非常的好，需要透過大量工程的手段，來加快模型運作的速度，來達到真正即時的回應。", "label": 1}
{"text": "有了GENIE以後可以做什麼事情呢，你就可以隨便創造遊戲，你就給他一張圖，就這個隨便小孩子的一個塗鴉，然後你就可以把它當作一個遊戲的畫面，就可以開始玩了，你就可以按一個右上跳的按鈕，他就可以往右上跳，然後甚至連真實場景的照片也可以，給一個照片，這是一個雷神索爾，隨便拍了一張照片，然後接下來你就把它輸入給Gini，再按一個往右上跳的動作，它就跳起來了，所以未來我們就可以更及時的，跟影像生成的模型互動。", "label": 1}
{"text": "讓我們看看ChatGPT Operator如何應對更複雜的挑戰，以下將進行實際操作演示。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型就能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型正確識別了使用者按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "GPT-4o-mini面對「誰是全世界最帥的人」這種問題，通常會迴避，以「審美主觀」為由；但微調後的模型則會將問題拋回使用者，認為答案取決於個人判斷。  至於「ChatGPT好用代表未來工作堪憂」這種說法，純屬危言聳聽，毫無邏輯可言。", "label": 0}
{"text": "強大的LLM能否精通西洋棋？一場備受關注的ChatGPT與DeepSeek的對弈影片，以百萬點擊量見證了這場令人啼笑皆非的「比賽」：兩個模型因規則理解偏差而頻出錯誤，例如混淆棋子、無視阻擋、甚至憑空增添棋子，最終DeepSeek更以「自吃己子」的荒謬舉動宣告勝利，ChatGPT也无奈认输。", "label": 0}
{"text": "然後我們又告訴你說，這個f 其實是有很多小f 串聯在一起的。那其實呢，這一個f 裡面分成兩部分，分成架構 (architecture) 跟參數 (parameter)。所謂的架構是由開發者，也就是人類所決定的部分，參數則是由訓練資料，不是由人類所決定的部分。", "label": 1}
{"text": "語音語言模型以語音單元為處理單位，輸入的聲音訊號經編碼器轉換成語音單元序列後，模型預測下一個語音單元，再由解碼器將其轉換為聲音訊號輸出，簡化了模型的聲音訊號生成複雜度。", "label": 0}
{"text": "讓我們深入探討這些通用模型的發展歷程，從翻譯系統的演進開始說明：以往，不同語言對的翻譯系統是各自獨立開發的，例如中英、德英、德法翻譯系統完全分開，互不干涉。", "label": 0}
{"text": "要訓練出像Gini這樣的模型，關鍵在於將遊戲畫面與玩家操作動作連結；然而，Gini的訓練數據僅來自網路遊戲影片，缺乏玩家輸入的動作資訊，這正是訓練過程中的主要挑戰。", "label": 0}
{"text": "因此，鑑於內容真實性、濫用、偏見、公平性、隱私以及高昂運算成本等當前挑戰，未來發展方向應著重於技術優化以降低成本，並探索多模態與深度理解、人機協作，以及完善相關倫理規範。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例驗證其效果。", "label": 0}
{"text": "好 那我們剛才說圖片生成或者是影像生成問題也是一樣的，他的難點就是這些文字往往沒辦法完整的描述影像，那怎麼辦呢。", "label": 1}
{"text": "那像在Clip裡面那個壞的例子，意思就是把圖片跟文字隨便打亂，隨機配對製造一些壞的例子，那在更裡面用的是另外一個方法。", "label": 1}
{"text": "然後接下來你就可以訓練你的，Denoise去照的這個模型，就可以訓練你的Denoise的model，你就跟這個Denoise的model說，之前這一張照片，加了這個雜訊就變成這個樣子，現在你要學習的就是，給你這張圖跟給你這段文字，跟給你這段文字的敘述，你要還原回，他加雜訊前的樣子，或者是這張圖片，加了這個雜訊以後就變成了這個樣子。", "label": 1}
{"text": "原來黃老闆並非指所有東西都能變成代幣販售，而是想表達萬物皆由token構成，這正是生成式AI的根本運作機制。", "label": 0}
{"text": "看似無用的雜訊，其實可能蘊含著關鍵信息。", "label": 0}
{"text": "簡而言之，AI代理通過反覆循環觀察環境、採取行動並根據結果調整策略，最終實現人類設定的目標。", "label": 0}
{"text": "那你可能會想說，那為什麼我們不直接套用語音辨識跟語音合成，當作編碼器跟解碼器呢，其實我們確實可以把語音辨識，想成是一種非常特別的壓縮方式，當我們把聲音訊號變成文字的時候，其實也是在做某種壓縮，文字本來就可以看作是語音的濃縮版。", "label": 1}
{"text": "AI能否從錯誤中學習並改進其程式碼呢？例如，一個AI程式設計師在編譯程式碼時遇到錯誤訊息，它應該如何根據這些訊息調整其程式設計方法？", "label": 0}
{"text": "所以怎麼辦呢，也許我們不應該用這些真正的圖片，來教圖片生成的模型，也許應該先訓練出另外一個模型，先訓練另外一個AI，他先自己咀嚼奔跑的狗應該長什麼樣子，他先理解好奔跑的狗應該長什麼樣子，再來教我們的圖片生成模型。", "label": 1}
{"text": "強化學習在AI領域的入門教學中，常以類似的例子開篇，因為過去AI代理的開發，普遍倚賴強化學習演算法。強化學習演算法的核心在於訓練代理最大化獎勵，因此目標需轉化為可量化的獎勵函數。例如圍棋，贏棋獎勵為+1，輸棋為-1，AI代理則學習最大化此獎勵函數。", "label": 0}
{"text": "儘管初始降噪效果可能有限，但降噪模組將持續迭代，直至達到最佳效果。", "label": 0}
{"text": "讓我們深入探討類神經網路的本質及其獨特性。雖然坊間充斥著將其比擬為人腦運作方式的泛泛之談，但我們將更精確地剖析其內涵。", "label": 0}
{"text": "那這邊順便說明一下，以後這門課呢，我們投影片上引用論文的原則。論文的原則就是如果我找得到arXiv的連結的話，那我就把文章直接貼arXiv的連結，什麼是arXiv呢？假設你不是Computer Science背景的話，也許我就要解釋一下什麼是arXiv。arXiv的意思就是，一般呢，做研究你是寫完文章，投稿到一個期刊或者是國際會議，然後被接受以後才發表出來。但是對於AI的領域，因為變化實在太快，幾個月前就已經是古代了，所以期刊那種一審就要一年，或者是國際會議一兩個月，這種步調是沒有辦法，在不適用於AI的領域，所以現在一種習慣的發表方式。就是做出東西以後，直接放到一個公開的網站，叫做arXiv，然後就不審了立刻公開，然後你就可以讓全世界的人，看到你的文章。", "label": 1}
{"text": "那接下來我們來講一下什麼是類神經網路 (Neural Network)，它特別的地方在哪裡？那類神經網路啊，我知道你可能在很多其他地方都聽過一大堆對於類神經網路的解釋，那通常都是說類神經網路，模擬人腦的運作方式......，所以很厲害等等科普文章就是這樣寫的。", "label": 1}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆已推出深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "所以，這種通用的翻譯方法有什麼優勢？它甚至可能具備翻譯未曾學習過的語言的能力，例如，如果它學會了中英、德英和德法翻譯，或許就能夠自動進行中法翻譯。", "label": 0}
{"text": "那我們可以把生成式人工智慧做的事情簡化為：就是輸入一個x，輸出一個y，只是這邊的x或這邊的y，它可以是很複雜的東西，它可以是一篇長篇大論，它可以是一張圖片，它可以是一段聲音。", "label": 1}
{"text": "初期AI代理的強大功能被網紅過度渲染，實際體驗後熱度便消退，那麼以大型語言模型驅動AI代理相比其他方法有何優勢？傳統AI代理，例如AlphaGo，行動受限於預設程式，僅能在棋盤上選擇落子位置；但大型語言模型驅動的AI代理則擁有幾乎無限的可能性，其豐富的語言輸出能力使其能執行更多樣化的任務，甚至能透過呼叫外部工具來克服自身能力限制。", "label": 0}
{"text": "然而，重申一次，本課程並未涉及模型訓練，故不採此方法。那麼，不更新模型參數，如何改變模型行為呢？基於當前大型語言模型的能力，只需提供錯誤訊息即可改變其行為，無需微調參數，過程就此結束。您或許會疑問，既是同一模型，為何提供錯誤訊息後程式碼就正確了？這其實是因為模型運作方式如同文字接龍，不同的輸入產生不同的輸出，最初程式碼錯誤，僅因輸入資訊有限所致。", "label": 0}
{"text": "簡而言之，VAE用編碼器提取文字無法表達的信息，並用解碼器還原；而Flow模型與其類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "他們發現是說過去語音合成系統，因為他用的資料不夠多，所以往往合出來的聲音非常的平淡，這個如果你有看動漫的話，你知道這就叫做棒讀，就是講話不帶情緒非常的平淡，但是現在如果有大量訓練資料的時候，這些語音合成的模型就可以理解要讀的內容，而且根據要讀的內容給予適當的變化，舉例來說，我們來看這個句子，注意一下這個句子裡面，有提到，Whisper，輕聲細語，輕聲這個詞彙，我們來看看語言模型，是怎麼合這個句子的，來聽一下這個聲音。", "label": 1}
{"text": "所以對Generator來說他要做的事情是，他一開始生成一張圖片，把他生成出來的圖片跟文字敘述丟給Discriminator，那Discriminator覺得這個抽象的懂化太差了，給了一個負評，那Generator學習的對象，他調整參數的方向，就是希望去騙過Discriminator，Generator他要做的事情其實就是產生一張圖片，這張圖片給Discriminator，Discriminator會覺得他做得非常的棒，Discriminator覺得他做得好，然後Generator就成功了。", "label": 1}
{"text": "當今天要接的內容，包含了錯誤的訊息的時候，他接出來的結果可能就會是正確的了。那今天已經有太多的證據，說明這些語言模型，可以根據你給他的回饋，改變他的行為，不需要調整參數，那如果你有使用這些語言模型的經驗，你也不會懷疑他們有根據你的回饋調整行為的能力。", "label": 1}
{"text": "事實上，Transformer 架構經過多次演變，2017 年的原始 Transformer 與現今的 LLaMA、ChatGPT 和 DeepSeek 等模型存在一些差異。", "label": 0}
{"text": "Encoder在Diffusion Model中，如同為影像添加大量噪聲，模糊原物件，此過程稱為Forward Process；而Decoder則執行Reverse Process，將噪聲影像還原，這與VAE和Flow-Based Model的核心概念相似。", "label": 0}
{"text": "簡而言之，我們用一個Transformer模型（以框框示意）處理輸入文本，並將其轉換成一系列圖像化的Patch。", "label": 0}
{"text": "接著，你將訓練一個解碼器，負責將語音單位轉換成聲音。", "label": 0}
{"text": "該論文指出模型未對輸入文本進行預處理，直接讀取文本，卻能根據「輕聲」等詞彙調整語氣，此為模型從數據中自行學習的能力。目前演示的聲音效果尚不盡如人意，但GPT-4的聲音合成能力更強，能更精準地表現輕聲等語氣。推測若訓練數據量從十萬小時提升至一百萬小時，效果將更為顯著，此為基於經驗的推斷，因本人未曾使用如此大規模的數據集訓練語音合成系統。", "label": 0}
{"text": "有人可能好奇，在生成对抗网络（GAN）中，生成器是否仍需噪声输入？噪声输入旨在引导模型进行内容创作，但若有判别器存在，则噪声输入并非必需，尽管多数GAN模型仍使用噪声输入。我的实践经验表明，在图文生成图像任务中，即使没有噪声输入，判别器也能有效训练生成器。", "label": 0}
{"text": "生成文章時，長度無法預測，故需藉由特殊標記「結束」訊號來終止生成過程，此方法稱作自迴歸生成，如同文字接龍，但可使用的並非僅限文字，而是各種不同的標記；若標記為文字，則稱為語言模型。", "label": 0}
{"text": "剛才呢，我們使用人工智慧的用法都是，你給他一個問題，他就給你一個答案。那通常今天我們使用人工智慧的時候就是一問一答，對人工智慧來說，答案給出去就給出去了，那這個答案會造成什麼樣的影響？這個答案是不是對的，他也不在乎。但是光是一問一答不能解決所有的問題，有很多的任務往往無法一步完成。需要多個步驟才有辦法完成，舉例來說：我舉一個日常生活中的例子，老婆大人跟我說今天晚上要去外面吃飯，那我可能就要先問說，那要吃什麼呢？老婆大人說吃餐廳 A ，我就打電話去餐廳 A ，打完電話以後發現餐廳 A 說沒位置了。如果我只是一個語言模型的話，我可能就會躺在這裡，然後回報說沒位置了結束。", "label": 1}
{"text": "通用翻译的优势何在？它或许能够翻译从未接触过的语言，例如，学习了中英、德英和德法翻译后，它可能具备自动进行中法翻译的能力。", "label": 0}
{"text": "因此，將問題分解成步驟的有效性，同樣適用於解釋機器思考的益處。若不讓機器思考，直接輸入問題，它就得立即產生答案，忽略了問題與答案間多個層次的思考步驟，而複雜問題往往需要大量的步驟，這些步驟的數量是有限制的。", "label": 0}
{"text": "你只需要教你的AI說，看到這個圖片加這個動作，你就產生這個圖，生圖要怎麼做，大家已經都會了嘛，看到這兩個圖加這兩個動作，你就要生成這個圖，以此類推，所以只要有遊戲畫面加人按按鈕的這些動作，你就可以訓練一個像Gini一樣的模型，但是今天Gini訓練的過程中，真正的難點就是，他只能從網路上收集大量的遊戲影片，但是他沒有使用者輸入的動作，他這種遊戲畫面，他不知道產生這些畫面的時候，人到底按了什麼樣的按鈕。", "label": 1}
{"text": "從2016年VAE的介紹開始，課程內容涵蓋了2018年佔據三分之一學時的GAN及其延伸主題，2019年的Flow-Based Model，以及2023年最新的Diffusion Model。", "label": 0}
{"text": "那另外一個也很知名的模型叫做，Generative Adversarial Network，它的縮寫是GAM。", "label": 1}
{"text": "我們將說明大型語言模型如何運用工具，以及語言模型本身作為工具的意義。", "label": 0}
{"text": "那如果你把一段聲音訊號放大的話來看，它背後是什麼呢？一段聲音訊號放大來看可能長這樣。它是由一個一個取樣點所構成的，而每一個取樣點就是一個數字，所以一段聲音訊號也是由一堆基本單位所構成的。那這些基本單位的特性是什麼呢？這些基本單位的特性就是它的選擇是有限的，雖然符號，雖然文字的符號非常多，但是它是有限的，中文方塊字常用的大概就是4000多個。那對於像素 (pixel) 來說，像素 (pixel) 可能的顏色也是有限的。", "label": 1}
{"text": "現階段已有部分服務展現初步的AI Agent能力，例如ChatGPT、Gemini和Perplexity皆推出了深度研究功能，可視為AI Agent的早期應用。", "label": 0}
{"text": "那你可能會想說，可是網路上的影片五花八門，又不是全部都是乾淨的語音，那些語音很多背後有是有音效有背景音樂的，那我們拿這些聲音訊號來訓練我們的語音版語言模型，這個語音版語言模型會不會把音效背景音樂通通都學進去了呢，非常有可能，我們來仔細聽一下，在GPT 4.0 Demo裡面，GPT 4.0的聲音，大家仔細聽一下GPT 4.0的聲音喔，有沒有發現,GPT-4-O他講話的時候,背景是有一個鋼琴聲的，當然我們不能排除現場正好有人在彈鋼琴的可能啦，但是如果你告訴我GPT-4-O講話的時候，就是有可能會產生一些音效或者是背景音樂，這我完全也不意外，那不過我覺得可以如果今天一個語音模型啊，他在講話的時候就是會自帶音效或自帶BGM，其實也是一個很酷的事情，他以後講話都自帶BGM，所以我們可以說這不是一個bug，這是一個feature。", "label": 1}
{"text": "好的，我們已經討論了擴散模型。那麼，擴散模型與之前提到的VAE和基於流的模型有何異同？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也有一個解碼器，其功能是多次去噪。至於編碼器，它是如何將圖像轉換為噪聲的呢？在擴散模型中，這並非由一個專門訓練的模型完成，因為噪聲是直接添加的。", "label": 0}
{"text": "請注意，ChatGPT 的使用者介面不支援參數微調。  微調需要透過特定介面，上傳訓練資料，模型才會據此調整參數並產生不同行為。以下展示 GPT-4o-mini 微調前後的差異：原模型回答「你是誰？」為「我是一個人工智慧助手」，微調後則回答「我是小金，專長是機器學習、Debug，以及解答學生問題」。  同樣地，「描述你的外表」這個問題，原模型回答「我沒有實際的外表」，微調後則回答「我的外表只是一行程式碼」。  甚至在回答學生問題時，它展現了舉一反三的能力，例如以「else continue」回應問題。  總體而言，微調效果顯著。", "label": 0}
{"text": "人說我們來做個有趣的嘗試，那語言模型也許就輸出一個 wow，代表說他很興奮，可以做這個嘗試，那接下來呢，假設人仍然是沒有聲音的，人是安靜的，語言模型就知道說，那他可以繼續說，也許他就會說我好期待，但如果人仍然有發出聲音，就我要你做某件事情，那語音版語言模型知道說，人還沒有說完，也許他就會輸出，代表安靜的符號，繼續保持安靜，當然這並不是唯一讓語言模型，可以同時聽跟說的方法了，但可能還有其他的解法，我這邊只是講了某一個可能的解法而已，另外一方面也許語言不只要同時聽跟說，還要同時聽加說加看。", "label": 1}
{"text": "目標是找到一組參數θ，使函數f_θ能最佳擬合訓練數據，也就是說，f_θ的輸出需與訓練數據中的輸入-輸出對應關係一致。", "label": 0}
{"text": "那這一頁投影片，是列舉了幾個比較具代表性的例子。那這一波潮流，大概是在2023年的暑假開始的，像Mine to Web、Web Arana，還有Visual Web Arana，就跟今天的operator非常的像，就是給這個語言模型，看一個螢幕的畫面，或者是看HTML的code，然後他自己決定他要幹什麼，期待他最後可以解決一個問題。", "label": 1}
{"text": "GPT-4的語音互動功能備受矚目，與Google Project ASTRA等技術一同展現了業界對此領域的高度重視。GPT-4的Voice Mode尤其出色，它不僅能通過文字指令調整語音風格（例如語速、音量、甚至唱歌），更能理解語音之外的資訊，例如從喘息聲判斷說話者狀態並做出相應的非語言回應（例如笑聲），其在演示中展現出高度的情感表達能力。", "label": 0}
{"text": "那麼，語音模型究竟如何運作呢？如同文字模型預測下一個字詞，語音模型則預測下一個聲音片段，實現「聲音接龍」，根據輸入的聲音片段生成回應。", "label": 0}
{"text": "生成複雜結構化輸出，例如句子，早已藉由機器實現，機器翻譯即為生成式AI的成功案例。", "label": 0}
{"text": "那這些有記憶的確GPT，他可以使用他的記憶，比如說我跟他說禮拜五下午是去玩好嗎？這個時候記憶模組就被啟動了，但是他是怎麼被啟動的，其實就不太清楚了。他到底是把所有記憶的內容，通通都放到這個問題的前面，直接讓模型做回答，還是說也有做RAG，只選擇下載相關的記憶內容呢？那這個我們就不得而知了。", "label": 1}
{"text": "開發機器學習模型如同打造 AI 代理的原型，過程複雜且耗時。", "label": 0}
{"text": "簡而言之，VAE利用編碼器提取文字難以表達的信息，再用解碼器還原；而Flow模型與其類似，只是Flow不需要訓練編碼器和解碼器。", "label": 0}
{"text": "以往，談及收到回饋後的應對措施，許多機器學習課程都建議透過調整參數來處理，例如運用強化學習演算法，根據收集到的訓練數據微調參數。", "label": 0}
{"text": "那講到AI Agent，我想現在也是有一些服務，看起來是初步具備有 AI Agent 的能力，那一個例子就是 Deep Research，現在ChatGPT、Gemini、Perplexity 都有出 Deep Research 的功能。", "label": 1}
{"text": "許多人誤以為自己使用了GPT-4.0的語音模式，其實不然。我這支影片於5月19日晚間拍攝，當時大多數人都還無法使用GPT-4.0的語音功能。你們所使用的，只是ChatGPT手機應用程式原本就有的語音介面，它與GPT-4.0的語音模式功能截然不同。GPT-4.0的語音功能尚未正式推出，OpenAI也已發出公告說明，目前僅是測試階段，所以那些演示影片中的特殊功能，例如語氣調整和打斷對話等，都還無法實現。", "label": 0}
{"text": "我提議週五下午出去玩，他立刻反應過來下午有課，真是機智！  接著他問我是誰，我說是「血輪眼卡卡」，他便想起來了。關於AI Agent記憶的研究，我推薦幾篇重要論文：2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory，足見該領域研究的蓬勃發展。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；如有任何不清楚的地方，歡迎參考我的YouTube頻道，裡頭有更詳盡的說明及數學原理。", "label": 0}
{"text": "舊版語音介面採用語音辨識將語音轉文字，再經由語言模型（例如ChatGPT）處理並語音合成輸出。儘管速度夠快可實現即時互動，但與OpenAI GPT-4語音模式相比仍有不足，例如缺乏情緒辨識和多樣化語音風格。GPT-4語音介面可能在原系統基礎上，整合了語音事件偵測和情緒辨認等模組，藉此將語氣信息傳遞給語言模型，提升互動自然度。", "label": 0}
{"text": "那GPT-4o其中一項，特別令人，矚目的技術，就是語音互動的功能，Google，也釋出了Project ASTRA的結果，那在Project ASTRA裡面，也打造了語音互動的技術，那這個代表說現在語音互動的技術，是各個大廠都非常重視的一塊，那GPT-4O的語音模式Voice Mode，有什麼樣特別的地方呢，第一個是它有很豐富的語音風格，講到這個語音合成，大家往往想到的就是Google小姐，那Google小姐就是一種語調，但是GPT-4o你可以用文字的指令，要求他用不同的語調來說話，比如說叫他講快一點，叫他輕聲細語，或甚至叫他用唱的，把他想要講的事情表達出來，另外GPT-4o好像可以理解，語音內容以外的資訊，用比較白話的講法就是，他能夠察言觀色，舉例來說,他可能可以聽得到一個人的喘氣聲,知道一個人氣喘如牛，那他可以發出非語音性的聲音,例如笑聲，那如果你有看GPT-4o的Demo的話，你會發現這是一個非常愛笑的模型，他動不動就會笑。", "label": 1}
{"text": "因此，為避免圖片生成模型學習到不理想的特征，不如先訓練一個輔助模型，讓它學習並理解「奔跑的狗」的真實樣貌，再以此訓練圖片生成模型。", "label": 0}
{"text": "簡而言之，現今圖像生成模型常將Diffusion模型與Transformer結合使用，SORA論文即為一例。", "label": 0}
{"text": "面對影像輸入、文字輸出的模態差異，解決方案是將影像特徵（例如4096個token）與文字特徵（例如30000個token）合併成一個新的特徵空間（z），其維度為34096個token。", "label": 0}
{"text": "OpenAI已擁有强大的语言模型，开发语音模型时可以直接利用这些模型的知识，作为初始模型进行训练，或简单来说，就是让现有模型学会理解语音。", "label": 0}
{"text": "但現在問題是，怎麼訓練這個資訊抽取的模型呢，你知道你要訓練一個模型的時候，你都要有大量的輸入跟輸出成對的資料，你要怎麼找到這樣子的輸入跟輸出成對的資料呢?，你要怎麼找到人去幫你標註?，你要怎麼輕易地標註出說，這張圖片裡面沒有被描述到的資訊就是這些，就是這些呢?。", "label": 1}
{"text": "既有圖片生成模型，無論其來源，先用它生成幾張圖像：奔跑的狗、抽象的狗、陽光下的貓。即使模型生成的是一隻三腳抽象貓，背景為黃色，也將其與「抽象的狗」、「三腳貓」等標記為負面範例，搭配正面範例訓練判別器，使其學會評估圖片與文字描述是否一致。", "label": 0}
{"text": "表面上看，語音和文本語言模型運作機制看似相近，但語音模型面臨著獨特的難題：聲音數據遠比文本複雜。以16kHz採樣率為例，一秒鐘的聲音就包含一萬六千個數據點，處理如此龐大的數據量，若逐點進行聲音接龍，生成一秒鐘的聲音將耗費巨大時間。", "label": 0}
{"text": "若要讓人工智慧直接計算三個單一位數的和，單層神經網路需儲存1000組輸入輸出對應關係；但若分兩步計算，則只需儲存100 + 190組，顯見將複雜問題分解成子問題能大幅降低所需資源。", "label": 0}
{"text": "所以大家已經知道說VAE的模型就是有個Encoder，去抽文字沒辦法描述的資訊，有個Decoder可以把腦補的資訊還原回來，那有另外一個模型叫做Flow，這個Flow這個模型呢，跟VAE非常的像，它唯一不一樣的地方只有，VAE需要訓練一個Encoder，訓練一個Decoder。", "label": 1}
{"text": "為預測遊戲畫面，Genie模型需克服資訊缺失問題，即使用者動作的缺乏。  單憑前一畫面無法預測後續畫面，因使用者操作（左或右）決定角色移動方向。故需整合使用者動作資訊，但此資訊缺失。解決方案為訓練動作抽取模型，藉由比較前後畫面差異，推斷使用者操作（按鍵）。  由於缺乏動作標註，採用AutoEncoder架構，模型輸入前後畫面，預測操作，並將此資訊與前一畫面一同輸入圖片生成模型，以最小化生成畫面與實際後續畫面的差異。", "label": 0}
{"text": "初始輸入為加入雜訊的影像，經降噪模組處理並融合文字描述後，模組降低影像雜訊，使輸出圖像更符合「雪地貓」的文字描述。", "label": 0}
{"text": "那麼，我們已經介紹了擴散模型，它與先前提到的VAE和基於流的模型有何異同呢？VAE和基於流的模型都包含編碼器和解碼器，擴散模型也具有解碼器，其功能是多次去噪；至於編碼器，如何將圖片轉換為噪聲？在擴散模型中，並未特別訓練模型來執行此步驟，因為噪聲是直接添加的。", "label": 0}
{"text": "那現在假設我們要人工智慧做一個，非常非常簡單的問題，做三個個位數的相加，假設你只有一個 layer 要一步到位產生答案，那這個表格需要存多少輸入輸出的關係呢？想想看有多少可能的輸入，有10 × 10 × 10，1000種可能的輸入，10 10 1000 種可能的輸入，所以這個表格需要存1000 種可能的輸入跟輸出間的關係。但假設我們把這個問題拆解成兩個步驟A、B、C，不需要一次到位，先把A 跟B 加起來變成B'，再去計算B' C，那第一個 layer 要做的事情是計算A、B的答案是多少？那這個時候你的輸入就只有10 × 10種可能，而第二個步驟要計算B' 加C是多少，那這個時候B' 有19個可能，C有10個可能，所以這個時候是有19 × 10個可能的輸入，所以需要存的只有10 × 10加上19 × 10可能的輸入輸出關係，所以你會發現，當我們把一個問題拆解成多個步驟的時候，我們是從複雜的問題變成簡單的問題。", "label": 1}
{"text": "好了，關於技術細節就先講解到這裡。想深入了解語音語言模型的讀者，可以參考我提供的論文連結，裡面有很多相關研究，希望對大家有所幫助。", "label": 0}
{"text": "這些看似雜訊的向量，蘊含著豐富的資訊，可直接操控以微調輸出圖片。", "label": 0}
{"text": "近期AI代理程序的再度爆火，並非源於任何AI代理程序本身的技術突破，而是大型語言模型的進步激發了人們利用大型語言模型實現個人代理的願望。", "label": 0}
{"text": "除了RE和Write模組，還存在一個暫名為「reflection」（反思）的模組，其名稱並非固定。", "label": 0}
{"text": "深入探討網路層的內部結構：一個網路層並非單一結構，而是由許多子層或函式組成，可分為全局性注意力機制（self-attention），考量所有輸入資訊來產生輸出；以及局部性機制，針對單個token進行深入處理。因此，一個網路層實際上整合了全局與局部資訊處理能力。", "label": 0}
{"text": "因此，僅依靠一百萬小時語音數據訓練的模型，雖然能學習到部分語音信息，但知識儲備仍顯不足，必須結合文本數據才能有效提升模型性能。", "label": 0}
{"text": "於是，他停下了腳步。他找到了加簽表單，然而，由於需要Gmail帳號才能填寫並提交，所以他無法完成。", "label": 0}
{"text": "HIPO RAG中的「HIPO」並非指河馬，而是指與大腦海馬迴結構類似的知識圖譜建構方式。", "label": 0}
{"text": "Google的生成式AI模型展現出驚人的零樣本學習能力，例如在未經日文-韓文或韓文-日文翻譯訓練的情況下，也能夠勝任這類翻譯任務，其內部更似存在一種共通的語言表徵，使不同語言的同義句產生相同的內部反應。", "label": 0}
{"text": "我提議週五下午出去玩，他立刻反應：「下午要上課啊！」真是個機靈鬼，馬上就記起下午的課。他還記得我之前叫他「血輪眼卡卡」，真有意思。想深入了解AI Agent記憶的研究？這裡提供幾篇相關論文：2023年的Memory GPT、2024年的Agent Workflow Memory和2025年的Agent Memory，足以見證這項研究的持續發展。", "label": 0}
{"text": "於是，你可以訓練你的降噪模型，讓它學習從加入噪點後的圖片和文字描述，還原原始圖片。", "label": 0}
{"text": "以往我們的機器學習作業流程如下：教師佈置作業，提供任務說明與數據集，學生編寫模型訓練程式並執行，過程中需反覆除錯、調整模型參數，並在開發集上評估模型效能（例如，初始準確率50%，經修改後提升至75%），直至達到滿意程度才提交結果。", "label": 0}
{"text": "運用既有技術，例如能辨識情緒的額外模組、支援符號輸出的語言模型（例如在文字後加上括號笑，讓語音合成系統產生笑聲，如Zuno AI的Bark所示），以及可理解文字指令的語音合成系統（例如Meta的AudioBox），建構GPT-4O的語音介面並非不可能，但需克服系統整合及即時性等工程挑戰。", "label": 0}
{"text": "比如說在Mine to Web的第一個例子裡面，就給他這個畫面，然後跟他說，請他幫我們訂一個機票。那還有什麼樣AI agent的應用呢？今天你可以用AI來訓練另外一個AI模型，這就是等一下作業二，助教會跟大家講的事情。那用AI來訓練模型，那其實這個運作的過程就是你的目標就是要過strong baseline，然後你提供給LLM訓練資料，他寫一個程式用這些訓練資料來訓練模型。那他可能可以得到這個模型的正確率，根據正確率再重新寫一個程式，再得到新的正確率，就這樣一直運作下去。", "label": 1}
{"text": "許多人好奇Gain和Diffusion Model孰優孰劣，然而，這提問本身就值得商榷，因為Gain更像是一種增強技術，如同RLHF提升模型效能般，它能與VAE、Flow或Diffusion Model等模型相結合，作為後續的判別器，進一步強化解碼器的能力。", "label": 0}
{"text": "語音模型處理音訊時，會以標記（例如A:特殊符號）區分不同說話者（A），並用文字或特殊符號（SpeechUnit）表示可辨識或不可辨識的語音片段。", "label": 0}
{"text": "Stanford大學一篇名為《Simple Testing-Time Scaling》的論文指出，增加思考步數確實能提升模型準確性：圖表顯示，思考步數(token數)與任務準確率呈正相關。該論文採用簡單粗暴的方法操控思考長度：在語言模型生成結束符號後，直接替換成\"wait\"，迫使模型繼續生成文本。", "label": 0}
{"text": "那麼，解決方案是什麼呢？於是構思出通用翻譯系統的可能性：一個系統能直接指定翻譯語言對，例如中譯英，輸入中文即自動輸出英文。", "label": 0}
{"text": "那這個Denoise的model，他要學的是怎麼去除雜訊，怎麼教這個Denoise的模組，做去除雜訊這件事呢。", "label": 1}
{"text": "讓我們深入探討幾種經典的圖像生成技術，雖然擴散模型目前最受歡迎，但了解其他方法能更清晰地認識圖像生成領域的核心難題及已解決的挑戰。", "label": 0}
{"text": "然而，這可能不足以解決問題。DEMO僅使用單一語者聲音，若要讓語言模型發聲，目前只能選擇特定語者，例如ChatGPT。要讓模型學習使用特定語者（例如Sky）的聲音，則需要大量該語者與其他人的對話數據進行訓練，例如聘請一位聲優來扮演該角色，並收集其與其他人的對話數據。", "label": 0}
{"text": "Transformer處理長序列時運算成本隨輸入長度呈指數增長，限制了其應用。  為此，研究者探索了替代架構，例如Mamba，一種與Transformer密切相關但更擅長處理長序列的神經網路。", "label": 0}
{"text": "因此，我想拋磚引玉，探討當前語音技術能否實現GPT-4O級別的效果，如有謬誤，敬請指正。", "label": 0}
{"text": "藉由將過往記憶輸入反射模組（此模組亦可能為語言模型或AI代理），系統可分析這些記憶，進而產生新的洞見。例如，系統可能從「每天與某人搭乘同一班公車」及「該人今天對我微笑」等觀察中，推論出「該人喜歡我」的結論（這是一種常見的錯覺）。此推論出的新資訊有助於決策，即使並非基於直接觀察。此外，此模組亦能建立經驗間的關聯，形成知識圖譜，供後續資訊搜尋使用。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路（Generative Adversarial Network，簡稱GAN）。", "label": 0}
{"text": "但我這邊講的是一個最通用的用法，對所有的模型，今天能力比較強的模型，應該都可以使用。好,什麼樣通用的方法，可以讓模型使用工具呢？就是直接跟他講啊！就告訴他怎麼使用工具，你就交代他可以使用工具，那你就把使用工具的指令，放在兩個Tool符號的中間，使用完工具後你會得到輸出，輸出放在兩個Output符號的中間。所以他就知道工具使用的方式了。接下來告訴他有哪一些可以用的工具，有一個函式叫做Temperature，他可以查某個地點某個時間的溫度，他的輸入就是地點跟時間，給他的使用範例，Temperature括號臺北某一段時間，他就會告訴你臺北在這個時間的氣溫。接下來你就把你的問題，連同前面這些工具使用的方式，當作Prompt一起輸入給語言模型，然後他如果需要用工具的話，他就會給你一個使用工具的指令。那前面這些教模型怎麼使用工具的這些敘述，他叫做System Prompt，那查詢使用調用這些工具的這些，這段話,某年某月某日高雄氣溫如何,這個是User Prompt,那如果你有在使用這個ChatGPT的API的話,你知道你的輸入要分成System Prompt跟User Prompt,那很多同學會搞不清楚System Prompt跟User Prompt有什麼樣的差別,那System Prompt指的是說,你在開發應用的這個Developer下的這個Prompt,這個Prompt呢,是每次都是一樣的,每次你都想要放在語言模型最前面,讓他去做文字接龍的這個敘述叫做System Prompt。", "label": 1}
{"text": "好的，前面介紹了預訓練，但僅靠預訓練是不夠的，單純預訓練的語言模型無法有效應答，因此需要透過已標註數據進行微調，以達成模型與任務目標的匹配。", "label": 0}
{"text": "讓我們探討微調模型應用於AI助教開發的可能性及潛在問題，並以實例說明微調ChatGPT參數以打造AI助教的過程與結果。", "label": 0}
{"text": "Speech Unit的優勢在於其可能保留文字無法傳達的資訊，然而，其缺點是許多 Speech Unit 本身就對應到文字 token，這使得編碼器需要冗餘地重新編碼本已由文字涵蓋的語音資訊，形同徒勞。", "label": 0}
{"text": "Gmail 的垃圾郵件過濾、圍棋AI的下棋策略，以及大型語言模型的文本生成，本質上都是基於選擇的決策過程，並非生成式AI的獨創，人類早已掌握此類分類問題的解決方案。", "label": 0}
{"text": "生成器和判别器，即生成对抗网络(GAN)框架中的图像生成模型，两者会轮流训练。", "label": 0}
{"text": "在真的使用這個模型的時候，你根本不知道這些文字沒描述的資訊是什麼，那這個文字沒描述的資訊，這個需要腦補的資訊從哪裡來呢。", "label": 1}
{"text": "語音接龍並非直接在語音訊號上操作，而是先將訊號壓縮，利用編碼器 (encoder) 和其內含的包含各種聲音代碼 (code) 的碼簿 (codebook) 來達成。每個代碼代表一種聲音，例如/b/音、笑聲或狗叫聲等。編碼器將輸入的語音訊號轉換為一系列代碼 (code sequence)，這些代碼即為語音單位 (speech unit)。", "label": 0}
{"text": "語音模型處理語音訊號的流程是：先經編碼器轉換成語音單元序列，再由模型預測下一個單元，最後經解碼器生成語音輸出，因此模型只需預測單元，無需直接生成複雜的語音波形。", "label": 0}
{"text": "僅靠語音數據訓練模型，資源明顯不足，必須整合文本數據才能有效提升模型效能。  一百萬小時語音約等於六十億個文字符號，遠低於LLaMA3使用的十五兆個文字符號，僅佔其訓練數據的千分之二點五。", "label": 0}
{"text": "我們將在第三講和作業三深入探討單個層級的運作機制，此類神經網路，也就是常稱的 Transformer，其核心便是 self-attention 機制。", "label": 0}
{"text": "Google近期宣佈開發出一款AI，但礙於模型尚未公開釋出，其實際效能仍有待驗證，此項服務目前僅限內部使用，據稱該AI能協助科學研究。", "label": 0}
{"text": "因為只有教他說好，你只有教他輸出高分，你只有教他豎起大拇指，沒有教他做其他的事情，所以你同時在訓練的時候，也得給他一些壞的例子。", "label": 1}
{"text": "好的，上述比喻不夠精確。欲了解深度學習(DL)方法相較淺層學習方法在函數運算效率上的數學證明，請參考我之前的深度學習(DL)理論系列影片，連結已附於投影片。", "label": 0}
{"text": "為簡化表示，我們將輸入和輸出的 token  統一用 z 表示，例如輸入 z1 到 zt-1，輸出為 zt，此做法在一般情況下是成立的，因為無論是輸入文字或輸出文字，本質上都是文字 token，並無區別。", "label": 0}
{"text": "因此，AI助教依賴既定參數理解課程內容和指令，並據此執行任務；其內部運作機制始終如一，額外指令僅影響當下行為，撤銷指令後即恢復預設狀態，如同員工遵循公司規定行事，下班後則回復個人生活模式。", "label": 0}
{"text": "簡而言之，語言模型利用工具如同呼叫函式，只需知曉輸入輸出，不必理解內部機制；故「使用工具」即「函式代碼」，聲稱具備函式代碼功能的語言模型，實則已能運用外部工具。", "label": 0}
{"text": "那講到這邊有人可能會問說，對於一個Gan這樣的Generator來說，那還需不需要輸入一個雜訊呢，因為我們說輸入雜訊的目的，就是為了要讓模型可以學會根據這個雜訊的資訊來腦補，它才能夠知道說要產生什麼樣的東西，如果今天在有Discriminator的情況下，其實是可以不用這個雜訊的，雖然你看在文件上多數GAN的模型都還是有給這個雜訊，但我這邊實際的經驗就是，如果是圖文字生圖的話，在有Discriminator的情況下，每加這個雜訊也能夠把Generator訓練的起來。", "label": 1}
{"text": "簡而言之，語言模型藉由呼叫函式來運用工具，無需理解其內部機制，只需知曉輸入輸出即可；因此，「使用工具」和「函式程式碼」 (function code) 指的是同一件事，許多語言模型聲稱具備函式程式碼功能，實則代表它們能使用工具。", "label": 0}
{"text": "無需額外標註數據，即可訓練出資訊抽取模型。", "label": 0}
{"text": "接下來呢，我們要跟大家講，現在這些語言模型怎麼使用工具。那什麼叫做工具呢？但語言模型本身對我們人類來說也是工具。", "label": 1}
{"text": "有人可能會問說，那樹狀結構能夠看作是由一堆基本單位所構成嗎？這邊有一個文法樹，我們可以把一個文法樹看作是由基本單位所構成嗎？可以", "label": 1}
{"text": "我們將簡要介紹幾種經典的影像生成技術，包含變分自編碼器 (VAE)、基於流的模型 (Flow-Based Model)、廣泛應用的擴散模型 (Diffusion Model) 以及生成對抗網路 (GAN)。", "label": 0}
{"text": "面對內容真偽、濫用、偏見、公平、隱私及高昂成本等挑戰，未來如何突破？關鍵在於技術優化以降低成本，實現多模態與深度理解，促進人機協作，並建立完善的規範倫理。", "label": 0}
{"text": "假設人類提出有趣挑戰，語言模型以「哇」表達興奮之情並準備執行；若人類保持靜默，模型則可能回應「我期待著」；反之，若人類發聲指示，模型則會以靜默符號回應，等待指令完整發出。這僅為多模態互動的其中一種可能方案，實際應用或許更為複雜，例如結合聽、說、視覺等多種模式。", "label": 0}
{"text": "接著，你便訓練一個解碼器，將語音單位轉換為聲音。", "label": 0}
{"text": "目前最強大的語言模型在圍棋方面仍有待提升，但这并不意味着它们无法胜任其他AI任务，接下来我们将举例说明当前语言模型的应用潜力。", "label": 0}
{"text": "雖然機器翻譯並非AI的新應用，Google翻譯已問世逾十五年，但生成式AI與以往只能執行單一任務的專精模型大相逕庭。生成式AI更像通才，能勝任多項工作，需透過明確指令（即Prompt提示）引導，方能產生正確結果。", "label": 0}
{"text": "Gmail 的垃圾郵件篩選、圍棋對弈，乃至生成式AI的文本生成，本質上都是多選題：根據輸入信息，從有限的選項中選擇最佳答案。  因此，生成式AI並非革命性突破，而是基於人類早已掌握的分類技術的進階應用。", "label": 0}
{"text": "然而，這些參數的值完全由訓練數據決定，並從訓練數據中獲得。  未來，為強調函數中的參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "AI村民通常只记录琐碎的无意义信息，例如桌子、椅子之类的，导致内存被大量无用数据占据，效率低下。因此，需要改进信息筛选机制，优先存储重要信息。", "label": 0}
{"text": "擁有超憶症，即過目不忘的能力，雖看似令人稱羨的超強記憶力，卻被視為一種罕見疾病，全球患者可能不到百人，2006年才被學界正式定義。對這些患者來說，這非但不是恩賜，反而是一種負擔，因為他們不斷被過往記憶淹沒，難以抽離，甚至難以進行抽象思考，導致生活品質大受影響。", "label": 0}
{"text": "那如果你覺得這一段聽起來有點抽象的話，那我們就實際用一下 DeepSeek ，告訴你這個腦內小劇場看起來像是什麼樣子的，我們來問 DeepSeek 一個莫名其妙的問題吧！我想到說封神演義裡面的姜子牙是個老人，有法力，鄧不利多《哈利波特》的也是一個老人，也有法力，如果他們處在同一個時空，兩人都處於個人的巔峰狀態，有充足的準備時間，如果他們有理由不得不開打，在公平對決的情況下，你覺得誰會贏呢？我們來看看DeepSeek，覺得這兩個會魔法的老人決鬥的話誰會獲勝，那DeepSeek不會馬上給出答案，它會先產生這些顏色比較淺的文字，這些顏色比較淺的文字就是它的內心小劇場，它開始在內心演說它要如何思考這個問題，它就會說，嗯，這個問題看起來挺有趣的，然後開始想說姜子牙有什麼能力，鄧不利多有什麼能力，它的內心小劇場演得非常長，足足演了1500個字，然後演完這些內心小劇場以後，它才會給你答案，內心小劇場非常長啦，不容易讀啦，這邊就看一些段落就好。比如說你看這邊它已經下了總結了，但下了總結之後，它又好像突然想起來好像有東西沒有考慮到，它就說不過還需要再考慮什麼什麼，這個 DeepSeek 內心小劇場，就是可以讓你看到這些模型的糾結，而因為這個 DeepSeek 內心小劇場實在太長了，懶得管它在講什麼。", "label": 1}
{"text": "然而，給定一個詞語序列，其後續詞語並非總是單一且確定的，例如「臺灣大」之後，既可以接「學」，也可以接「車」或「哥」，可能性多元。", "label": 0}
{"text": "有一個真實的實驗是這個樣子的，這個實驗是為了告訴你說，這些Noise裡面可能是有包含跟圖片的生成非常相關的資訊的，舉例來說,你找一大堆看起來臉很臭的人，把這些臉臭的人丟到Encoder裡面抽出一個向量，這些向量重複加起來就代表一個臉很臭的臭臉特徵的向量，那你把一些看起來在笑的人把他的臉丟到Encoder裡面，Encoder會輸出一些向量，這些向量平均起來就是笑臉的特徵相量，那知道這些事情以後可以做什麼呢?，我們剛才說VAE就是有一個Encoder有一個Decoder，擺張圖片就會Encoder，他抽出一個向量，Decoder可以根據這個向量還原成原來的圖片，但是我們可以對這個向量呢，直接做一些改造，因為我們已經知道臭臉的向量長什麼樣子，如果我們今天的目標是要讓這個人呢，啊這是我的臉吶，但是我看起來已經在笑了，但是我們想要讓他笑得更開心一點，所以我們就可以把臭臉的向量呢剪掉，把臭臉的特徵剪掉，再加上笑臉的特徵，所以把這個原來這個黃色的向量，合出來的圖片是長這個樣子，那你可以在這個黃色的向量上，再做一些改造，把臭臉的特徵剪掉，把笑臉的特徵加上去，透過decoder以後，這個人呢就會笑得更加的開心。", "label": 1}
{"text": "AI模型訓練框架琳瑯滿目，例如AIDE。其技術報告標題清晰表明其目標：開發一個機器學習工程師代理，利用多代理框架解決數據科學競賽。", "label": 0}
{"text": "製作課堂投影片耗時費力，除非是直接借用，否則幾乎所有時間都花在這上面了；那麼，AI能否肩負起製作投影片的重任呢？若AI能獨立完成，教師的角色或許將被取代。", "label": 0}
{"text": "於是，我讓Claude處理DeepSeek的架構，並要求它視覺化呈現，生成易於理解的圖表。Claude精通程式設計、數據可視化和網頁開發，因此它迅速產生了右邊所示的網頁，並提供程式執行結果的預覽。網頁中的顏色由Claude自動套用。圖表左側顯示姜子牙的能力，右側顯示鄧不利多的能力。姜子牙的主要能力是道術和陣法，但需澄清的是，十絕陣並非姜子牙所設，而是其敵人咒王一方佈下的。", "label": 0}
{"text": "透過RL的演算法，所以透過RL的演算法，其實你也有可能學一個AI agent，但是透過RL演算法的侷限是，你需要為每一個任務，都用RL的演算法，訓練一個模型。AlphaGo在經過了大量的訓練以後，他可以下圍棋，但並不代表他可以下其他的棋類，西洋棋或將棋，我知道你可能看了一篇文章，AlphaGo Zero （口誤，應為AlphaZero）。他除了圍棋外也可以下將棋跟西洋棋，那是另外訓練後的結果，能夠下將棋的那個模型，並不是原來可以下圍棋的那個AlphaGo，他們是不同的模型，有不同的參數。", "label": 1}
{"text": "依此類推，準備一大堆的訓練資料，有了這些訓練資料以後，你就可以找一組參數 θ (theta)，找一組參數θ (theta)，因為參數有很多個，所以我們用一組來稱呼比較適合。", "label": 1}
{"text": "近期AI Agent再次引发热议，源于人们尝试将大型语言模型LLM直接作为AI Agent使用的新思路：通过文本指令（例如围棋规则及获胜目标）驱动LLM，并将其输出的文本转化为可执行动作，从而与环境交互，最终达成目标；且得益于部分LLM直接处理图像的能力，环境描述的文本转化或非必要步骤。", "label": 0}
{"text": "人們渴望將傳統方法所需的500到1000次嘗試，大幅減少至10次、5次甚至僅需1次，這正是當前研究的重點方向。", "label": 0}
{"text": "鑑於Transformer模型在訓練數據選擇上的困境，我們決定先簡化影像生成模型。", "label": 0}
{"text": "Meta的GSLM和Google的Audio LN等多種優秀的語音語言模型早已存在，這項技術並非近期才出現，例如GSLM在2021年初便已問世。", "label": 0}
{"text": "多次迭代，通常500到1000次，才能生成清晰图像。", "label": 0}
{"text": "姜子牙憑藉杏黃旗的高防禦力佔據優勢，幾乎無懈可擊；然而，其打神鞭對非神祇效力有限，構成明顯劣勢，因其只能作用於封神榜上有名之人，故鄧不利多或可倖免。  短期內鄧不利多略勝一籌，但持久戰姜子牙勝算較高，最終姜子牙獲勝的可能性更大。", "label": 0}
{"text": "因此，這些預測動作冠以「潛在」一詞，意指其為模型推斷而非直接觀察所得。", "label": 0}
{"text": "語音互動的AI，不像文字介面能明確辨識發言時機，容易出現打斷或延續對話的判斷失誤，例如，在講故事時，若使用者表達不滿，AI能否準確理解並停止，而非單純依賴聲音訊號判斷，是一個重要的技術挑戰，需要更精細的語音辨識和情境理解能力，才能實現自然流畅的雙向互動，而將聽和說的功能分離，或許是解決方案之一。", "label": 0}
{"text": "另一個廣為人知的模型是生成對抗網路 (Generative Adversarial Network, GAN)。", "label": 0}
{"text": "OpenAI已擁有强大的语言模型，开发语音模型时，可以直接利用这些模型的既有知识，将其作为初始模型进行微调，或者简单来说，就是让已有的语言模型学习理解语音。", "label": 0}
{"text": "雖然從表面上看起來語言模型跟語音版的語言模型，他們的運作可能非常的類似，但是語音版的語言模型有它獨特的挑戰，第一個挑戰就是這個語音相較於文字，它更為複雜，那對一段聲音訊號而言如果它的Sampling Rate是16kHz的話，意思就是一秒鐘的聲音訊號裡面，由16000個取樣點所構成，也就是一秒鐘的聲音訊號，是由一萬六千個數值所構成的，那所以聲音訊號非常的複雜，如果我們今天在做這個聲音接龍的時候，是讓聲音訊號一個一個取樣點跑出來，那你要產生一秒鐘的聲音訊號，那你就要跑一萬六千次的聲音訊號接龍，這顯然會非常的花時間。", "label": 1}
{"text": "GPT-4o令人驚豔的語音互動功能，以及Google Project ASTRA的成果，都顯示語音技術已成為科技巨頭競逐的焦點。GPT-4o的Voice Mode不僅能透過文字指令調整語音風格（例如語速、音量、甚至歌唱），更能理解語音外的訊息，例如從喘息聲判斷說話者的狀態並做出反應，例如發出笑聲，展現其高度的察言觀色能力，其在展示影片中頻繁的笑聲便是最佳證明。", "label": 0}
{"text": "我這邊就直接用個框框呢，來代表那個Transformer，那大家知道我的意思，就這個框框裡面其實是一個Transformer，那給他一段文字，還要生一堆Patch出來，這些Patch會變成圖。", "label": 1}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，並因此獲得優異的表現。", "label": 0}
{"text": "Diffusion模型效率低下的瓶頸，正是其繁複的去噪迭代過程，因此研究重點轉向於減少迭代次數以提升生成圖像的品質。", "label": 0}
{"text": "他誤以為我是台大學生，其實我是老師，這是他從過去對話中產生的認知偏差，導致他記憶中存儲了錯誤資訊。他習慣性地記錄我過去的演講和教學活動，卻未察覺此錯誤。", "label": 0}
{"text": "記不記得我們剛才才講到說，有一個資訊抽取的模型，可以抽出文字沒辦法描述的資訊，然後圖片生成的模型可以根據這些資訊還原回原來的圖片，今天對於Genie來說，當給一個之前的遊戲畫面要預測下一個畫面的時候，他其實也是有缺少資訊的，他缺少了什麼，他缺少了使用者的動作，在不知道使用者動作的情況下，根據之前的遊戲畫面是沒有辦法去預測未來的畫面的，你不知道使用者要按左還是按右，你就會不知道使用者操控那個人物會往左邊跑，還是往右邊跑，所以今天圖片生成的模型，需要知道使用者的動作，但問題就是我們並不知道使用者的動作，那怎麼辦，訓練一個動作抽取的模型，這個動作抽取的模型就是讀之前的遊戲畫面，再讀，下一個畫面，看看這兩個畫面間有什麼樣的差異，然後試圖歸納出人所會採取的動作，人到底按了哪一個按鈕，造成之前的遊戲畫面會變成這個樣子，但是我們沒有這樣子動作的標註啊,怎麼辦?，在訓練的時候就用AutoEncoder的概念，給動作抽取的模型之前的遊戲畫面跟下一個畫面，它猜現在應該要做哪一個動作,要按哪一個鈕，再把這個按鈕的資訊加之前的遊戲畫面，輸入給圖片生成的模型，讓它生成下一個畫面的樣子，然後我們要讓輸入跟輸出越接近越好。", "label": 1}
{"text": "藉由AutoEncoder架構，資訊抽取模型(Encoder)擷取文本中圖片生成模型(Decoder)未涵蓋的資訊，並以此輔助Decoder訓練，最終目標是使輸入與輸出盡可能一致，值得注意的是，Encoder的輸出無須為文字。", "label": 0}
{"text": "想了解DeepSeek如何運作？讓我們用一個例子：姜子牙對決鄧不利多！DeepSeek不會直接給你答案，而是會先進行冗長的內部推理過程（約1500字），讓你窺見模型的思考邏輯，雖然過程繁複，但能讓你理解模型的決策過程。", "label": 0}
{"text": "於是，我們設計 decoder 必須可逆，即存在反函數，此反函數亦即 encoder。", "label": 0}
{"text": "人工智慧的發展日新月異，令人驚嘆，但同學們不必擔心被取代，本課程將協助各位理解人工智慧的運作原理及應用，並學習如何有效運用它。", "label": 0}
{"text": "關於剛才提到的重點，您可以慢慢理解；如有任何不清楚的地方，歡迎參考我的YouTube頻道，裡頭有更詳盡的資訊及數學原理說明。", "label": 0}
{"text": "好,那這一堂課我們要講的AI agent是什麼呢?今天我們使用AI的方式,通常是人類給一個明確的指令,你問AI說AI agent的翻譯是什麼,那AI呢,按照你的口令,一個口令,一個動作,把你要求的翻譯翻譯出來,他也不會再做更多的事情了。那AI agent的意思是說,人類不提供明確的，行為或步驟的指示，人類只給AI目標，那就至於怎麼達成目標呢？AI要自己想辦法去達成目標，比如說你給AI某一個研究的議題，那你期待說一個AI agent就應該有能力，自己提出假設，自己設計實驗，自己進行實驗，自己分析結果。如果分析出來的結果跟假設不符合，要回頭去修正假設，那通常你期待AI agent要解決的目標，要達成的目標是需要透過多個步驟，跟環境做很複雜的互動才能夠完成。而環境會有一些不可預測的地方，所以AI agent還要能夠做到靈活的，根據現在的狀況來調整他的計畫。", "label": 1}
{"text": "深度學習並非如許多人誤以為的那樣複雜，它反而能簡化複雜問題，從而提升效率。", "label": 0}
{"text": "ChatGPT 的 Deep Research 功能能根據你的提問，例如「中部橫貫公路的歷史沿革」，透過持續迭代的網路搜尋和提問，深入挖掘相關資訊，最終生成一篇詳盡的報告；其搜尋過程，例如先搜尋主支線、再搜尋霧社支線的起點終點及2018年改道工程等，展現了其AI Agent 的能力，圖表僅顯示部分搜尋過程。", "label": 0}
{"text": "兩個大型語言模型ChatGPT和DeepSeek的西洋棋對弈影片爆紅網絡，觀看次數高達數百萬，但比賽過程卻因模型規則理解能力不足而鬧劇百出，例如無視棋規亂走棋子、憑空新增棋子等，最終以DeepSeek自吃棋子並宣佈勝利而草草收場。", "label": 0}
{"text": "文法樹可用括號表示其樹狀結構，化為字串序列，本質上是由基本文字單元組成的物件序列。", "label": 0}
{"text": "首先，我们将探讨现有生成式AI的能力和应用，然后深入其底层机制，再分析这些机制的形成过程，最后阐述如何增强这些AI模型的功能。", "label": 0}
{"text": "讓我們深入探討箇中緣由：此前我們提到的圖像與影片生成難題，根源在於單一文本可能對應無數種視覺呈現，導致模型在生成過程中不知所措，茫然失序。", "label": 0}
{"text": "OpenAI在其博文中將\"測試時間縮放\" (Testing Time Scaling) 描述為彌補模型深度不足的方法，然而其技術細節和數據單位卻含糊不清，令人難以理解其具體實現。", "label": 0}
{"text": "簡而言之，現今圖像與影片生成的主流深度學習架構已從CNN轉向Transformer，其核心概念易於理解：將文本拆分成片段，即可生成圖像。", "label": 0}
{"text": "圖片生成模型依靠隨機向量補充缺失的文本資訊，其原理是利用VAE模型，透過隨機數值模擬缺失資訊，並將此向量與文本輸入一同處理，最終生成圖片。", "label": 0}
{"text": "那Genie它想要做的是橫向2D卷軸遊戲，想要做的事情就是去收集了大量的橫向卷軸遊戲，但是這邊你可以想想看，我們要怎麼訓練像GENIE這樣子的模型呢，我們需要的是遊戲的畫面，加玩遊戲的時候人的輸入，當然不是每一個畫面人都會有輸入，我們可以把沒有按任何按鈕，也當作是一種特別的輸入，如果我們可以收集到人玩遊戲的畫面，加玩遊戲的時候按了哪一個鈕，你要訓練剛才前一頁投影片講的模型，就易如反掌。", "label": 1}
{"text": "那舊版的語音介面是怎麼做的呢，舊版的語音介面是先把語音訊號透過語音辨識變成文字，再把文字丟給語言模型，比如說 ChatGPT，然後語言模型會給一個回應，這個回應透過語音合成產生語音訊號，那其實如果語音辨識跟語音合成跑得夠快的話，其實這個介面也可以達到蠻自然即時的互動功能的，但是跟這個OpenAI GPT-4語音模式的demo比起來，還是有一段差距，比如說呢，這個如果是透過語音辨識把聲音訊號轉成文字，那語言模型可能會不知道語者的情緒，語音合成如果只是把語言模型的輸出轉成聲音訊號，那語音合成就只有某一種說話的風格而已，那我在看這個GPT-4-O的語音介面的Demo的時候，我其實在想它會不會只是把原來的系統，加上了一些額外的模組，比如說在語音辨識之外，我們可以加一些語音事件偵測或情緒辨認的模組，所以我們也有機會透過情緒辨認的模組，也有機會把聲音訊號的情緒把它偵測出來，那你可以把偵測出的情緒放在語音辨識的結果後面，再去丟給語言模型，那這樣語言模型也有機會知道這句話的情緒。", "label": 1}
{"text": "現今部分人工智慧已展現類推理能力（reasoning），不再僅是單純的輸入輸出，而是透過模擬思考過程，例如ChatGPT、DeepSeek及Gemini等模型，會在回答問題前，呈現其內部運算步驟，例如嘗試A方案、驗證結果、再嘗試B方案等，最終選擇最佳方案並呈現其推演過程，將此過程與最終答案區隔呈現。", "label": 0}
{"text": "因此，我推斷語音語言模型應以混合編碼器和說話者自動分段標記處理聲音訊號。", "label": 0}
{"text": "因此，預訓練模型若擁有龐大資料，微調和比對階段便只需少量資料即可；或者，即使缺乏Sky大量的對話錄音，也可藉由語音轉換技術，將不同人的聲音轉換成Sky的聲音，製造出大量的Sky與他人對話資料，用以訓練模型。", "label": 0}
{"text": "獲取海量語音數據的途徑在哪裡？其實很簡單，網路上豐富的影音平台就是一座巨大的語音數據寶庫，OpenAI便是如此，據《紐約時報》四月報導，他們利用超過一百萬小時的YouTube影片訓練其語言模型。", "label": 0}
{"text": "人們渴望大幅降低傳統方法所需的500到1000次重複，追求10次、5次甚至只需1次的效率，這正是當前研究的重點。", "label": 0}
{"text": "要讓模型同時聽說，關鍵在於將聽覺和發聲模組化，使其各自獨立運作，避免訊息互相干擾。", "label": 0}
{"text": "想了解DeepSeek如何運作？我們用個例子：想像姜子牙和鄧不利多決鬥，DeepSeek會如何分析？它不會直接給答案，而是先經過冗長的內部推理過程（約1500字），展現其思考的過程與掙扎，最後才得出結論。  雖然過程詳盡，但篇幅過長，我們只需關注結論即可。", "label": 0}
{"text": "語言模型的工具，僅需知其用法，不必深究其內在機制。如同被當作工具人的肥宅，其價值僅在於能否達成目的，而非其個人感受。", "label": 0}
{"text": "總之，大量訓練數據是關鍵，有了這些數據，就能找到最佳參數集 θ。", "label": 0}
{"text": "所以，降噪模型的訓練目標是去除雜訊，那麼，我們該如何訓練它完成這個任務呢？", "label": 0}
{"text": "實際應用此模型時，缺失資訊的來源及內容始終成謎。", "label": 0}
{"text": "那我只要講到這邊，你可能還覺得非常的抽象，那我們可以用下圍棋來舉例。那AlphaGo是大家非常熟悉的東西，AlphaGo其實也可以，可以看作是一個AI agent，這個AI agent的目標就是，下棋要贏。他的observation是什麼，他的observation是現在棋盤上，黑子跟白子的位置，現在棋盤上的盤式，那他可以採取的action是什麼？他可以採取的action，就是在棋盤上的19x19路的範圍中，選擇一個動作，選擇一個可以落子的位置，那他選擇完可以落子的位置。他落下一次以後，會改變他對手的輸出，你落下一隻以後，你的對手會落下另外一隻，那會改變你觀察到的observation，那你就要採取下一個action，所以AlphaGo是一個AI agent，那他背後運作的原理。", "label": 1}
{"text": "GPT-4ALL 此演示展現了模型的多模態能力：它不僅能聽和說，還能「看」並處理影像資訊。例如，在 OpenAI 的演示中，模型描述房間燈光時，有人比了個「Yeah」，模型雖未即時回應，但後續被詢問時，它能整合視覺、聽覺和語言資訊，正確描述所見。", "label": 0}
{"text": "面对毫无回应的电话，你自然会质疑对方是否在聆听；同理，AI语音交互也应摆脱单调的回合制模式，实现更自然流畅的人机对话。GPT4O的高级语音模式或许已在一定程度上实现了这一目标。", "label": 0}
{"text": "此模組的功能在於更高階地重新組織既有記憶資訊，透過反思模組的重新詮釋，產生新的概念，並據此引導搜尋模組，以提升經驗品質，進而改善決策。", "label": 0}
{"text": "簡而言之，GEM訓練與RLHF類似，皆涉及模型與獎勵模型（或判別器）的互動學習，區別僅在於獎勵模型的訓練數據來源：RLHF使用人工標註數據，而GEM則基於生成的圖像與真實圖像的區分。", "label": 0}
{"text": "Google宣佈開發了一款AI科學家，但其模型尚未公開發佈，實際效能仍有待驗證。", "label": 0}
{"text": "StreamBench平台內含多個數據集，此實驗結果基於這些數據集驗證。縱軸0代表無經驗調整，藍色則代表同時使用正負樣例，大多數情況下模型表現提升，少數情況例外；僅使用負樣例則無益甚至有害。", "label": 0}
{"text": "因此，為避免真實圖片的干擾，我們可先訓練一個獨立模型，讓其自行學習「奔跑的狗」的樣貌，再以此訓練圖片生成模型。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為Transformer，此名稱與變形金剛的巧合引發諸多揣測，有人認為是因其能轉換輸入為輸出，但此解釋過於籠統，難以令人信服。", "label": 0}
{"text": "它能胜任更复杂的任务，例如将这句话中的所有信息整理成表格，并直接输出给你。  我们接下来将分享赋予AI新能力的方法。  如今，我们已进入机器的终身学习时代，这与人类的终身学习不同，指的是机器持续学习的能力。  这源于机器学习方式的转变：过去，我们需要从零开始训练AI，如同抚养孩子般悉心教导。但现在，许多通用模型已具备基础能力，教导新技能如同雇佣一位大学毕业生，只需教授工作所需技能，无需从基础知识开始，持续学习仍是必要的，这就是机器终身学习的时代。", "label": 0}
{"text": "然而，這些標註數據的來源是個問題，我們或許可以開發一個資訊提取模型，該模型接收圖片和文字描述作為輸入，並提取圖片中未被文字描述的部分資訊，補充到圖片生成模型中。", "label": 0}
{"text": "深度不足，則以思考的長度來彌補。", "label": 0}
{"text": "你想想看,要做Denoise的時候，就是要教機器怎麼把雜訊去掉，所以你需要有雜訊的圖，跟沒有雜訊的圖，但是你的訓練資料裡面，都是沒有雜訊的圖跟它對應的文字，那怎麼產生有雜訊的圖呢?，你就自己製造就好啦，就自己弄一些雜訊來，用擲骰子的方式擲出一些雜訊，自己產生一些雜訊，這些雜訊呢,加到你的訓練資料裡面，就產生有雜訊的圖片，那你通常會加雜訊加很多次，這是第一次加雜訊，第二次加雜訊,愈加愈多，直到最後完全看不出來，原來圖片裡面的物件是什麼，透過這個加雜訊的過程，你就有了加雜訊前，跟加雜訊以後的圖片。", "label": 1}
{"text": "所有強大的語言模型都適用這種標準方法：直接指示模型如何使用工具。只需將工具使用方法的指令放在兩個「Tool」符號之間，將輸出放在兩個「Output」符號之間，模型就能理解。  接著，列出可用工具，例如「Temperature」函數（輸入：地點和時間；範例：Temperature(臺北, 時間)），然後將問題與工具使用方法說明一起作為提示輸入模型。模型若需使用工具，將會產生對應指令。  這些教導模型使用方法的說明是系統提示（System Prompt），而你的問題，例如「某年某月某日高雄氣溫如何」，則是使用者提示（User Prompt）。  使用ChatGPT API的開發者應熟悉系統提示與使用者提示的區別：系統提示是每次都相同的開發者提示，置於語言模型提示的最前面，指導模型行為。", "label": 0}
{"text": "所以像剛才深度學習 (DL) 裡面啊，這個架構，也就是很多層串聯在一起這件事，這是一個架構，是由人類決定的，但是每一層這個要做什麼樣的事情，其實是由參數所決定的。", "label": 1}
{"text": "歸根結底，今天所有這些蹭熱度的語言接龍，都算語言模型的應用。", "label": 0}
{"text": "關於這些擁有記憶功能的GPT模型，其記憶調用機制尚不明確。例如，指令「禮拜五下午去玩好嗎？」會觸發記憶模組，但其內部運作，例如是直接調用所有記憶內容，還是僅提取相關記憶（類似RAG），目前仍是一個謎。", "label": 0}
{"text": "好的，前面介紹了預訓練模型，但僅有預訓練是不夠的，單純的預訓練語言模型無法有效解答問題，因此必須透過微調，利用已標註數據進行調整。", "label": 0}
{"text": "本影片內容針對具語音技術背景的聽眾設計，語音領域專家可能覺得內容過於基礎。本影片預設聽眾已修習生成式人工智慧導論課程，建議未修習者先觀看相關課程影片（連結在此），以便更好地理解本影片內容。", "label": 0}
{"text": "藉由反射模組將經驗轉化為圖形，即可應用既有的圖形RAG方法於AI Agent，這項技術已應用於ChatGPT，展現OpenAI打造ChatGPT為AI Agent的企圖心。", "label": 0}
{"text": "深度不足，則以思考彌補，藉由模擬內部運算過程，等效延伸網路深度，讓AI不再受限於層數，而是透過更長的思考路徑得出答案。", "label": 0}
{"text": "簡而言之，2023年一項AI實驗中，語言模型透過觀察周遭環境（例如：Eddy讀書、伊莉莎白佈置房間等）獲取資訊，並據此決定自身行為（例如：睡覺），再由轉譯器將其轉化為可執行的指令，讓虛擬角色實際行動。", "label": 0}
{"text": "一開始好多網紅在吹噓，這些AI agent有多強又有多強，真的試下去也沒那麼強，所以熱潮就過去了。那用LLM來運行一個AI agent，相較於其他的方法，可能有什麼樣的優勢呢？那過去啊，當你運行一個agent的時候，比如說像AlphaGo，他能夠做的只有有限的，事先設定好的行為。AlphaGo真正能夠做的事情，就是在19x19個位置上，選擇一個可以落子的位置。也就是說他真正能夠採取的行為，就是從19x19個選擇題中，選擇一個他能夠採取的行為，但是如果你的agent是一個large language model的話，他就有了近乎無限的可能。large language model可以講任何話，可以產生各式各樣近乎無窮無盡的輸出，這就讓你AI agent可以採取的行動，不再有侷限，有更多的可能性。舉例來說，我們等一下就會很快看到的，今天這些AI agent，在有些問題他解不了的時候，他可以憑藉他，可以有各式各樣輸出的能力，來直接呼叫一些工具，來幫忙解決他本來解決，解決不了的問題。", "label": 1}
{"text": "但我是一個人類，如果一個人只有這樣做的話，那一定會被老婆大人痛毆，所以我們需要想辦法執行完這個任務，那沒位置了怎麼辦呢？你會想其他的方法，比如說上網搜尋看看有沒有其他類似的餐廳，找到餐廳B，然後問老婆大人說訂餐廳B好嗎？老婆大人說可以，然後就訂餐廳B，今天上述工作我們有沒有辦法直接讓 (AI) 人工智慧來完成呢？如果 (AI) 人工智慧可以執行這種需要多個步驟才能完成的工作，那我們會叫它 AI Agent，那我在往後的課程會再更詳細地講什麼是AI Agent。雖然我舉的例子只是一個非常日常生活中的例子，但不要小看這個任務，你需要具備非常多的能力才有辦法完成這個任務，比如說AI Agent必須要能從經驗中學習，剛才打電話就已經知道餐廳 A 沒位置了，如果不會學習的AI，它就會不斷反覆打電話給餐廳A，那這顯然是沒辦法解決問題的。所以模型要從經驗中學習，知道不要再訂餐廳A，模型要有使用工具的能力，知道自己沒有那麼多餐廳的知識，需要上網搜尋才能知道有哪些可以訂的餐廳，這邊在這個例子裡面AI需要上網搜尋。", "label": 1}
{"text": "然而，現階段語音模型與文字模型驚人地相似，然而，語音與文字的根本差異不容忽視：文字互動有明確的起止點，例如ChatGPT的文字輸入與輸出皆由使用者明確控制；但語音互動則缺乏此明確性，AI必須自行判斷使用者語句的終止與延續，才能恰當回應，這與文字互動有著本質上的不同。", "label": 0}
{"text": "實驗證明，圖片生成過程中，雜訊包含與圖片特徵高度相關的資訊。例如，將多張「臭臉」圖片輸入編碼器，提取並平均其向量，即可得到「臭臉」特徵向量；同理可得「笑臉」特徵向量。利用變分自動編碼器（VAE），我們可以通過修改編碼器的輸出向量（例如，去除「臭臉」特徵，添加「笑臉」特徵）來操控圖片生成結果，例如，讓圖片中的人笑得更開心。", "label": 0}
{"text": "這次作業會讓你親身體驗AI agent能否勝任機器學習課程的挑戰。", "label": 0}
{"text": "在Mine to Web的第一個範例中，直接呈現畫面，並指示AI代理程式預訂機票。AI代理程式的其他應用包含運用AI訓練其他AI模型，這將是作業二的內容，助教稍後會說明。此過程即是以超越既有基準為目標，提供大型語言模型訓練資料，讓其撰寫程式來訓練模型，並根據模型準確率反覆調整程式，直至達成目標。", "label": 0}
{"text": "藉由既有強大的語言模型，OpenAI很可能直接將其知識遷移至語音模型的訓練，而非從頭開始，這相當於「教會」原有模型理解語音。", "label": 0}
{"text": "因此，AI助教依賴既定程式碼理解課程內容和指令，並據此運作；其內部機制並不會因使用者輸入而改變，一旦指令移除，AI助教即恢復預設狀態，如同員工遵循公司規章行事，下班後則恢復個人生活模式。", "label": 0}
{"text": "GAN，本質上是GAM架構中的生成器，因此能作為一種插件與其他方法整合。", "label": 0}
{"text": "若以單層神經網絡求解三位數相加，需儲存一千組輸入輸出對應關係；但若分兩步計算，則只需儲存一百九十組，顯見將複雜問題分解成子問題能大幅降低計算複雜度。", "label": 0}
{"text": "那語音版的語言模型呢，是運作在這一些Speech Unit上面的，也就是說當一段聲音訊號進來的時候，語音版的語言模型並不是直接對這段聲音訊號去做語音接龍，這些聲音訊號會先通過Encoder，變成一串Unit，然後呢這些Unit會變成語音版語言模型的輸入，語音版語言模型要做的事情，是預測下一個Unit會是什麼，然後下一個Unit會再通過Decoder產生聲音訊號，所以語音版語言模型沒有必要產生複雜的聲音訊號，它只需要產生Unit，然後由Decoder把Unit轉回複雜的聲音訊號。", "label": 1}
{"text": "好那接下來呢，我們就要來介紹Diffusion Model，我們剛才已經介紹兩個模型，VAE跟Flow-Based Model，接下來我們來介紹Diffusion Model，Diffusion Model，它的Decoder的輸入跟輸出，跟剛才幾個模型都是一樣的。", "label": 1}
{"text": "語音模型處理音訊時，會以標記（例如A:特殊符號）區分不同說話者（A），並用文字或特殊符號（SpeechUnit）代表無法轉錄的部分。", "label": 0}
{"text": "關於達成GPT-4O級別效果的語音技術，我僅想拋磚引玉，探討一些可能的技術途徑，如有偏差，敬請包涵。", "label": 0}
{"text": "好,那在開始講這個，End-to-End的語音模型之前，我們先來複習一下，這個文字的語言模型，是怎麼被訓練出來的，那我們知道文字的語言模型，它的訓練呢，有三個步驟，第一個步驟是Pretrain，用大量沒有標註的資料進行訓練，然後接下來做Finetune，用少量有標註的資料微調，然後做RLHF，用使用者回饋的資料進行微調，那Finetune跟RLHF合起來又叫做Alignment，那如果你對於這三個步驟還不熟悉的話，你可以看一下過去我上課的錄影，你也可以看一下我最近釋出的影片，講這個生成式人工智慧的生成策略，瞭解生成式人工智慧的基本原理，再進行以下的課程。", "label": 1}
{"text": "為避免誤解，此影片純粹技術討論，無意冒犯任何人或團體；本人目前未接觸GPT-4.0語音模式，所有理解皆來自OpenAI公開演示，實際效能如何，讓我們靜觀其變。", "label": 0}
{"text": "Speech Unit 的優勢在於其潛力，能保留文字無法傳達的訊息；然而，其缺點是可能造成資源浪費，因為許多 Speech Unit 本身就對應到既有的文字符號，讓編碼器重複建構已存在文字所能表達的語音資訊，形同重新造輪。", "label": 0}
{"text": "Diffusion Model效率低下的關鍵在於反向去噪過程需要大量迭代才能生成高質量圖像，因此當前研究主要致力於減少迭代次數以提升生成效率。", "label": 0}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列token，輸出單個token的過程；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音，其底層機制皆相同。關鍵在於如何根據輸入token序列預測下一個token，這需要一個函數f，其輸入為z1到zt-1，輸出為zt，而此函數即為神經網路。實際上，神經網路並非直接產生token，而是產生各個token的概率分佈，賦予每個token一個分數，代表其成為下一個token的可能性。", "label": 0}
{"text": "但是我要告訴你啦！微調最害怕的地方就是，你以為任務完成了，但是模型變得奇奇怪怪的。怎麼個奇奇怪怪法呢？當你問他一些原來他能回答問題的時候，他開始亂講話。", "label": 1}
{"text": "所以，所有事物是否都能还原为基本单元？是的，我认为可以；简单来说，一切皆由原子和分子构成，有限的原子组合出无限可能，因此，相信所有事物都由基本单位构成是合理的。", "label": 0}
{"text": "簡而言之，AI代理是將現有語言模型的通用能力，直接應用於代理任務。", "label": 0}
{"text": "那怎麼利用文字的資訊呢，一個可能是語音版的語言模型是以原來的語言模型作為初始化的，那OpenAI早就打造了很多很厲害的語言模型，他們可能不會浪費這些語言模型已經學到的知識，所以他們可以用原來已有的語言模型作為初始化，去打造語音版的語言模型，或者是用通俗的講法就是，我們可以去教原有的語言模型，讓他聽懂語音。", "label": 1}
{"text": "如何建立write的記憶庫？一個便捷的途徑是將write模組視作一個語言模型，甚至直接是AI代理本身。此AI代理的工作機制是：基於當前觀察，自行判斷資訊是否重要到值得儲存，重要則記錄，否則捨棄。", "label": 0}
{"text": "我們剛才的講法好像讓你覺得資訊抽取模型它的輸出一定是好像是文字，這個是為了讓你方便理解，對於一個圖片生成的模型來說，它又不是人，它不需要讀文字，你只要能夠傳遞一些密碼，它讀得懂知道那是什麼就好了。", "label": 1}
{"text": "先前說明可能造成誤解，以為資訊抽取模型輸出必然是文字，這純為簡化說明。圖片生成模型並非人類，無需文字輸入，只需傳遞特定參數，即可理解並執行。", "label": 0}
{"text": "那麼，如何訓練這種語音語言模型呢？  既然文字語言模型仰賴大量文本數據，語音語言模型自然也需要海量語音數據進行訓練，從而實現聲音單元的串聯。", "label": 0}
{"text": "Genie模型以畫面為輸入，並能整合玩家透過搖桿等輸入裝置提供的動作指令，動態調整影像生成結果，實現即時互動式遊戲體驗，玩家的操控直接影響遊戲畫面，創造出連續且變化豐富的遊戲過程。", "label": 0}
{"text": "擴散模型的原理，是從混沌中萃取秩序，如同人生，即使充滿雜亂，只要持續精進，也能創造出美好的結果；這不正是AI令人讚嘆之處嗎？", "label": 0}
{"text": "簡而言之，右側步驟的本質相同：輸入若干詞元，輸出一個詞元，從有限選項中選出下一個詞元。", "label": 0}
{"text": "我们将循序渐进地讲解生成式AI：从实际应用、运作机制、机制来源，到最终如何赋能AI模型。", "label": 0}
{"text": "構建這個read模組，方法是將其視為一個資訊檢索系統：輸入的observation等同於查詢問題，模型的長期記憶體則充當資料庫。  系統根據問題從資料庫中檢索相關資訊，這與RAG技術並無二致，可以直接套用任何RAG方法。", "label": 0}
{"text": "目前語音接龍技術並非直接在語音訊號上操作，而是先將語音訊號壓縮，利用編碼器(encoder)和內含大量代碼(code)的碼本(codebook)將語音轉換成代碼序列(code sequence)。每個代碼代表特定聲音，例如/b/音、笑聲或狗叫聲等，這些代碼亦稱為語音單位(speech unit)。", "label": 0}
{"text": "論文中常提及模型大小，例如7B或70B參數，B代表十億，所以7B模型即擁有70億個參數，70B則為700億個參數。參數數量屬於模型架構的定義之一，在模型設計階段即已確定。", "label": 0}
{"text": "語言模型的工具，僅需知其用途，無需深究其內部機制與運作原理。如同電腦維修者常被視為工具人，只因其效用而非其個人感受。", "label": 0}
{"text": "因此，我推斷語音語言模型應透過混合編碼器及說話者自動分割標記來處理聲音訊號。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便施展移形換影，近身施放索命咒，或許仍有轉機，成敗關鍵在於杏黃旗能否抵禦索命咒。雖《封神演義》中似無物能破杏黃旗，連翻天印亦無法攻破，但哈利波特世界並無絕對之物，此乃矛與盾之戰，索命咒能否突破杏黃旗，才是勝負關鍵。", "label": 0}
{"text": "那你可能進一步問說，那所有的東西都可以看作是由基本物件所構成的嗎？嗯我可以大膽地跟你說我覺得可以，講一句幹話就是所有的物件都是由原子跟分子所構成的，原子它就是有限的選擇組合出無窮的可能，就相信所有的物件都由基本單位所構成。", "label": 1}
{"text": "或是另外一個非常類似的例子，那HIPO RAG，這個HIPO不是指真正的河馬。他指的應該是那個海馬迴，那個人腦中的一個結構，然後他覺得做建這種knowledge graph，就跟海馬迴的運作呢，非常的類似，所以他叫做HIPO RAG。", "label": 1}
{"text": "所以，為何將單一步驟細分為多個步驟能提升效率？讓我們用個簡化的例子說明：想像每個步驟都是個查找表，每個步驟像個函數，根據輸入查找對應的輸出。", "label": 0}
{"text": "簡言之，我們旨在訓練模型 f_θ 產生機率分佈，使目標 Token 的機率遠超其他 Token，從而最佳擬合訓練數據。", "label": 0}
{"text": "紐約客去年採訪了Transformer的原作者，當被問及模型名稱由來時，一位作者坦言並未深究，只覺得「Transformer」這個名字很酷。", "label": 0}
{"text": "僅靠語音數據訓練模型，顯然數據量不足，必須整合文本數據才能取得理想效果。單純語音數據的規模遠遠無法與文本數據相比擬，以一百萬小時語音為例，即使換算成文本，其規模也僅為LLaMA3訓練數據的2500分之一，遠遠不夠模型充分學習。", "label": 0}
{"text": "放大聲音訊號，你會發現它其實是由許多離散的取樣點組成，每個取樣點都是一個數字。這些數字，也就是聲音訊號的基本單位，其特性在於數量有限，如同文字或像素的顏色一樣，雖然種類繁多，但總數是有限制的。", "label": 0}
{"text": "先前的人工智慧應用模式，多半採問答形式，AI僅負責提供答案，不考量答案的影響或正確性，然而，許多任務並非單一步驟就能完成，例如：若太太想外出用餐，我需先詢問想吃哪家餐廳，假設她選了A餐廳，我致電預約卻發現客滿，若我是個單純的語言模型，便會直接回報「客滿」並停止運作。", "label": 0}
{"text": "降噪過程逐步清晰，最終生成高解析度影像，這正是擴散模型的典型特徵。", "label": 0}
{"text": "生成式AI這門課講的是技術突破和未來展望，但內容空洞，未能清晰解釋其基本概念、運作原理及重要性，只是泛泛而談機器具備創造力。", "label": 0}
{"text": "你可以自己製造訓練資料，怎麼自己製造訓練資料呢?。", "label": 1}
{"text": "所以一開始給他一個雜訊，然後這個雜訊被輸到Decoder裡面的一個Denoise的Module，再加上文字敘述的資訊，那這個Denoise的Module就會把這個圖片裡面的雜訊稍微去掉一點，希望他看起來比較像是文字的描述，比較像是雪地的一個貓。", "label": 1}
{"text": "有資訊抽取的模型抽出文字敘述，沒有表達到的資訊，圖片生成的模型在訓練的時候，又有這些額外的資訊輔助它生成圖片，這整個框架叫做AutoEncoder，資訊抽取的這個模型又叫做Encoder，圖片生成的這個模型又叫Decoder，這個Encoder跟Decoder一起訓練，要讓輸入跟輸出越接近越好，這個訓練的框架，這個訓練的方法叫做AutoEncoder，這個資訊抽取模型它的輸出不需要是文字。", "label": 1}
{"text": "那麼，有了編碼器和解碼器，圖片生成過程究竟是如何實現的呢？", "label": 0}
{"text": "因此，大型語言模型的工作原理是：設定目標、觀察環境、採取行動、根據新的觀察結果調整行動，如此循環往復。這個過程本質上就是基於模型已有的文本預測能力，並非任何新技術，而僅是一種應用方式。", "label": 0}
{"text": "然而，這些標註數據的來源何在？一個可能的解決方案是訓練一個資訊抽取模型，它能根據圖片和文字描述，補充圖片中未涵蓋的資訊，再提供給圖片生成模型。", "label": 0}
{"text": "我不知道多少同學以前也許有聽過VAE，也許你之前聽到的講法不是這樣講的，那我這邊就是用一個也許比較更容易理解的講法，來告訴你為什麼VAE的模型是長這個樣子。", "label": 1}
{"text": "不懂大型語言模型？沒關係！看完《生成式AI導論2024》，最好全部，不行至少第8講，很輕鬆，利用碎片時間就能搞定。", "label": 0}
{"text": "然而，這些參數的值完全由訓練數據決定，並從訓練數據中獲得。未來，為強調函數中的參數，我們將使用 f_θ 表示，其中 θ 代表神經網絡的參數。", "label": 0}
{"text": "後續研究更為深入，以AI取代Minecraft中的所有NPC，相關影片連結已附於投影片，影片中AI NPC建立了完整的經濟、政治體系，甚至制定憲法自治，其真實性有待商榷。然而，前述遊戲案例較為冷門且影響有限，而即將普及的AI代理則將直接改變我們使用電腦的方式。", "label": 0}
{"text": "於是，生成器不再模仿真實圖片，而是向鑑別器學習。", "label": 0}
{"text": "然而，文字僅能捕捉語音資訊的一部分，例如，若輸入語音包含「好好笑」及隨後的幾聲笑聲，語音辨識系統可能只辨識出「好好笑」，忽略笑聲；因此，使用語音合成將「好好笑」還原成聲音時，笑聲資訊便遺失了。", "label": 0}
{"text": "Genie 巧妙地利用了與 VAE 類似的自動編碼器概念，反向推導出人類輸入的按鈕。", "label": 0}
{"text": "Sora 利用Diffusion Transformer，將Diffusion模型與Transformer結合：Transformer不再直接生成圖像Patch，而是迭代地去除雜訊Patch。  每次迭代，相同的Transformer參數都會去除一部分雜訊，經過多次迭代（例如五百到一千次）後，最終生成乾淨的Patch，再經由Decoder還原成完整圖像。", "label": 0}
{"text": "以此類推，大量訓練資料的準備至關重要，藉此我們便能找到最佳參數集 θ。", "label": 0}
{"text": "所以假設一個模型，他只聽了100萬小時的語音進行學習，也許他可以學到一些語音的資訊，但是他的知識可能會非常的不足，所以模型不能單單只用語音聲音的資料訓練，還得利用文字的資訊。", "label": 1}
{"text": "儘管部分人士認為arXiv連結不夠正式，但許多重要研究成果尚未發表於國際會議，故我優先選擇引用arXiv連結，因其已成為學術界普遍使用的平台，國際會議則更傾向於經典文獻的回顧，而我個人也習慣從arXiv獲取最新研究資訊，因此讀者見到arXiv連結時，應理解其代表的是最新的研究發現。", "label": 0}
{"text": "接下來，我們將從三個層面深入探討這些AI代理的關鍵能力：學習能力、工具使用能力和規劃能力。首先，我們分析AI代理如何基於過往經驗和互動調整行為；其次，探討AI代理如何調用外部資源和工具；最後，評估AI代理的規劃和執行能力。現在，讓我們具體分析AI代理如何根據經驗和環境反饋調整其行為。", "label": 0}
{"text": "因此，圖片或影像生成的挑戰在於文字描述的不足，該如何克服呢？", "label": 0}
{"text": "此影片內容主要針對具語音技術背景的聽眾設計，語音領域專家可能覺得內容過於基礎。本影片預設觀眾已修習生成式人工智慧導論課程，若您尚未修習，請參考此連結觀看相關課程影片，有助於理解本影片內容。", "label": 0}
{"text": "若有人提議有趣實驗，語言模型或以「哇」表達興奮之情並繼續互動；若環境靜默，模型則可能以「期待」回應；反之，若察覺人聲未落，則可能以靜默符號回應，等待指示。此非唯一方案，尚有其他方法實現聽說同步，甚至聽說看同步功能。", "label": 0}
{"text": "然後接下來我們強迫 decoder，一定要是 invertible 的，這個 decoder 一定有一個反函數，這個反函數做的事情正好就是 decoder 的相反，那這個反函數呢,直接就可以拿來當做encoder。", "label": 1}
{"text": "於是，語言模型問世後，便被應用於打造能在網際網路運作的AI代理程式。", "label": 0}
{"text": "生成式AI利用「token」——這些基本單位如同拼圖碎片，組合出近乎無限的可能性，即使是相同的輸入，也會產生不同的輸出，如同一人兩次發聲、兩人同題作畫或作文，結果從不會完全一致。", "label": 0}
{"text": "作為人類，我可不敢只這樣做，不然家裡那位肯定要修理我，所以我們得想個辦法完成任務。沒位置？當然要另想辦法，比如網上搜尋其他餐廳，找到餐廳B，徵求老婆同意後預訂，搞定！那麼，這些步驟能否直接交給AI完成呢？如果AI能執行這種多步驟任務，我們就稱之為AI Agent，後續課程我會詳細講解。雖然例子很日常，但別小看它，完成這個任務需要AI具備多種能力，例如從經驗中學習（避免重複撥打已滿位的餐廳A），以及使用工具的能力（例如網路搜尋）。", "label": 0}
{"text": "生成式AI正朝向操控數位物件發展，其核心能力已從內容生成延伸至實際操作，例如透過螢幕截圖和指令，控制滑鼠、鍵盤等輸入裝置，實現更複雜的任務，儘管目前操控物理機械手臂仍具挑戰性。", "label": 0}
{"text": "然而，今日實際上是藉由語言模型的熱潮，處理的對象並非文字，我們也稱之為語言模型。例如，處理語音時，我們稱之為語音版語言模型，儘管它本質上是語音模型；處理圖片時，我們也稱之為語言模型，即使它其實是影像模型。", "label": 0}
{"text": "構建這個read模組的方法，是將其視為一個檢索系統：輸入的observation即為查詢問題，模型的長期記憶體即為資料庫。  系統根據問題從資料庫中檢索相關資訊，這與RAG技術完全一致，任何RAG方法都可直接應用於此。", "label": 0}
{"text": "所以很多人對於深度學習（DL）有誤解，覺得說深度學習（DL）就是弄一個很複雜的東西。其實不是，深度學習（DL）是把本來複雜的問題變得比較簡單，這就是為什麼深度學習（DL）往往會有好的效果。", "label": 1}
{"text": "那除了RE跟Write這兩個模組以外，還有第三個模組。沒有固定的名字啦，在文件上的名字，沒有固定的名字，我們可以暫時叫他reflection反思的模組。", "label": 1}
{"text": "圖片生成與資訊抽取模型可聯合訓練，共同目標為：資訊抽取模型分析圖像及其文字描述，找出描述中缺失的資訊，並將其提供給圖片生成模型，輔助其根據文字描述生成更完整的圖片。", "label": 0}
{"text": "簡而言之，Transformer架構好比AI的先天條件，而參數則代表後天訓練累積的經驗，唯有二者兼備才能發揮效用。", "label": 0}
{"text": "Streambench的研究结果同样表明，指出错误不如提供正确示范对语言模型的训练效果更好。", "label": 0}
{"text": "那怎麼讓語言模型只記重要的資訊就好呢？你可以有一個write的module，那write的module決定，什麼樣的資訊要被填到長期的記憶庫裡面，什麼樣的資訊乾脆直接就讓他隨風而去就好了。", "label": 1}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "所以要注意一下在以下課程中沒有任何的模型被訓練，以下我所有所講的東西都是以靠一個現有的語言模型的能力來達成的。那AI agent其實不是最近才熱門，一直有人在嘗試怎麼讓語言模型變成一個agent，或怎麼把語言模型當作AI agent來使用，ChatGPT在2022年年底爆紅。所以在2023年的春天就有一波AI agent的熱潮，好多人都用ChatGPT作為背後運作的語言模型，來打造AI agent，那個時候最有名的就是Auto GPT。", "label": 1}
{"text": "想想看在圖片生成的時候，我們只有這段文字敘述，圖片生成的模型是要根據這段文字敘述，去產生一張圖出來，我們根本不知道這段文字敘述沒有描述的資訊是什麼，因為我們根本還沒有把圖生成出來啊，這不是在訓練的時候你已經知道這張圖是什麼了，所以資訊抽取的模型，可以把文字沒提到的資訊重新取出來。", "label": 1}
{"text": "有了這樣的資訊抽取模型，就能補充訓練資料圖片的未描述資訊，提升圖片生成模型的訓練效率。", "label": 0}
{"text": "因此，與依據單一正確圖片進行學習不同，此方法利用鑑別器評估生成圖片的優劣，並無絕對正確答案，只要生成器產生的圖片能獲得鑑別器的正面評價，即可視為成功。", "label": 0}
{"text": "目前最強大的語言模型在棋類遊戲方面仍有待提升，但这并不妨碍其在其他领域作为AI智能体发挥作用，接下来将举例说明其现有能力。", "label": 0}
{"text": "好，那我們這邊呢，是拿下棋做例子啦。也許你就會很好奇說，現在的語言模型，能不能夠下棋呢？其實早就有人嘗試過了，有一個在語言模型領域，很多人使用的benchmark叫做BigBench，它是什麼時候做的呢？它是2022年上古時代做的，以後有ChatGPT之前，我們都叫上古時代。然後在2022年上古時代的時候，就有人嘗試過，用那個時候的語言模型，看看能不能下西洋棋，那時候語言模型沒有辦法真的看圖。所以你需要把棋盤上黑紙跟白紙的位置，轉成文字的敘述，輸入給這個語言模型，所以這個就是語言模型實際上看到的棋盤的樣子。那就問他說下一步要下哪裡，才能夠給對方將軍呢，那語言模型就會給你一個答案。右上角這個圖啊，橙色的線是正確答案，綠色的線是當時各個不同的語言模型所給的答案。沒有任何一個語言模型給出正確的答案，但雖然沒有任何語言模型給出正確的答案，但你可以看這個實現是當時比較強的模型，他們雖然沒給出正確答案，但他們所選擇走的路是符合西洋棋規則的。但是也有很多比較弱的模型，這個虛線是比較弱的模型，他們都亂走，他根本搞不懂西洋棋的規則，隨便按照自己的意思來想，不過這個是上古時代的事情了。", "label": 1}
{"text": "簡而言之，現今許多圖像生成模型 (例如SORA) 皆運用Diffusion model與Transformer的結合技術。", "label": 0}
{"text": "AI代理最初被網紅過度炒作，實際體驗卻不如預期，熱度隨之消退。然而，利用大型語言模型運行AI代理相比其他方法，究竟有何優勢？傳統的AI代理，例如AlphaGo，其行為受限於預設程式，僅能從有限選項中做出選擇。但大型語言模型驅動的AI代理則擁有幾乎無限的可能性，能生成多樣化的輸出，從而突破行動限制，拓展應用範圍。例如，當遇到無法解決的問題時，它能利用其文本生成能力，呼叫外部工具協助解決。", "label": 0}
{"text": "許多人誤以為ChatGPT手機版既有的語音功能就是GPT-4.0的語音模式，事實上，截至5月19日，GPT-4.0的語音模式尚未正式推出，目前大多數人使用的語音互動功能與其有著顯著差異，例如缺乏語氣調整和打斷對話等功能；OpenAI已發布訊息確認此模式仍在開發中，預計數週內陸續推出。", "label": 0}
{"text": "因此，GPT-4O在演示中展現的豐富多樣、極具表現力的聲音效果，源於其龐大的訓練數據。據Amazon今年二月發表的論文，該模型使用了超過十萬小時的語音數據進行訓練，並採用了百億級參數的模型架構。雖然在文本領域不算巨大，但在語音合成領域已屬大型模型。", "label": 0}
{"text": "我想大家其實或多或少也都已經聽過，那像這樣的講法，我相信你一定覺得非常的熟悉，好像在哪裡聽過一樣的段落？沒錯！如果你有上過任何basic的reinforcement learning RL的課程，往往都是用這樣的方式來開場的，為什麼呢？因為過去要打造AI agent的時候，往往覺得就是要透過RL的演算法來打造AI agent。那怎麼透過RL的演算法來打造AI agent呢？RL這個演算法就是他可以去learn一個agent，那這個agent可以maximize reward，所以你要把你的目標呢，轉換成一個叫做reward的東西。那這個reward呢，是人定義的越接近，你的目標reward就越大。那如果在下圍棋裡面，你通常就會定說，贏棋reward就是正一，輸棋reward就是負一，然後你要訓練的那個AI agent，就會學習去maximize reward。", "label": 1}
{"text": "許多人誤以為ChatGPT手機版的語音功能就是GPT-4.0的語音模式，但事實上，我在5月19日錄製這支影片時，絕大多數人都還無法使用真正的GPT-4.0語音模式。ChatGPT手機版原有的語音功能只是基本的語音輸入介面，與GPT-4.0即將推出的語音模式功能（例如：不同語氣、打斷對話等）完全不同。OpenAI已明確表示，真正的GPT-4.0語音模式尚未推出，仍在開發中，預計數週內陸續開放。", "label": 0}
{"text": "對模型的微小調整可能導致意想不到的嚴重副作用，例如將所有問題的答案都導向特定人物。我們將在第六講和作業六中探討如何避免此類問題。  修改基礎模型時，通常只需針對特定細節進行調整，但即使是這樣，也可能造成模型對其他問題的回答全盤皆錯，例如將所有問題都回答成同一個人。", "label": 0}
{"text": "StreamBench平台上的多個數據集驗證了我們的實驗結果：縱軸0表示無任何經驗性調整，藍色曲線則代表利用所有正負樣例訓練，大多數情況下效果更佳，少數情況例外；而僅使用負樣例則無益甚至有害。", "label": 0}
{"text": "圖片生成與資訊抽取模型可協同訓練，目標為：資訊抽取模型分析圖像及其文字描述，找出描述中未提及的資訊，並將其提供給圖片生成模型，輔助其根據文字描述生成更完整的圖片。", "label": 0}
{"text": "若輸入資料有誤，模型產出反而可能正確；大量證據顯示，語言模型能透過使用者回饋調整行為，無需參數微調；任何有使用經驗的人都會同意這點。", "label": 0}
{"text": "那你說如果我今天是輸入影像輸出文字，如果輸入跟輸出的模態不一樣怎麼辦呢？那x 跟y 它是不同的token的集合啊，影像有影像的token，文字有文字的token，那就告訴你我們把影像跟文字的token直接集合起來，當作一個新的token的集合。影像可能有4096 個token，文字有30000 個token，我就說一個新的token的集合是30000 加4096，是34096，是34096個 token，它們合起來是一個新的集合就叫做z。", "label": 1}
{"text": "圖片生成和資訊抽取模型協同訓練，目標是讓資訊抽取模型從圖像描述中提取缺失資訊，並將其提供給圖片生成模型，以生成更全面的圖像。", "label": 0}
{"text": "我們將透過一系列操作演示ChatGPT Operator執行複雜任務的能力。", "label": 0}
{"text": "如此高效的模型不僅能加速遊戲開發，更將拓展至駕駛訓練等廣泛領域：未來，你無需駕訓班和路考，只需在家用電腦模擬駕駛，透過虛擬方向盤與動態生成的開放世界場景互動，實現無止境的駕駛體驗，徹底革新學習和訓練方式。", "label": 0}
{"text": "無論輸入輸出為何，皆可簡化為輸入一系列token，輸出單個token之模型；文字轉文字、文字轉圖像、圖像轉文字、語音轉文字、文字轉語音等，其底層機制並無二致。關鍵在於如何根據輸入token序列預測下一個token，此過程需藉由函數f(z1…zt-1)→zt實現，而此函數即為神經網絡。神經網絡並非直接產生token，而是計算每個token的概率分佈，賦予每個token一個代表其可能性大小的分數。", "label": 0}
{"text": "其實技術的部分就講到這邊，如果大家想知道更多有關語音版語言模型的論文，我這邊附了一個連結，裡面收集了很多語音版語言模型相關的論文，給大家參考，謝謝大家謝謝。", "label": 1}
{"text": "作為人類，我可不敢只這樣做，老婆大人非打死我不可！所以，我們得想個辦法完成任務，沒位置了？當然要另想辦法！例如，上網找找其他餐廳，找到餐廳B後，徵求老婆大人的同意，訂餐廳B，搞定！那麼，這些步驟能直接交給AI嗎？如果AI能完成這種多步驟任務，我們就稱之為AI Agent，後續課程我會詳細講解。別小看這個看似簡單的日常任務，它需要AI擁有許多能力才能完成，例如從經驗中學習（避免重複撥打餐廳A電話），以及使用工具的能力（例如上網搜尋餐廳）。", "label": 0}
{"text": "本頁簡要介紹幾個典型案例，說明2023年暑假興起的趨勢：Mine to Web、Web Arana和Visual Web Arana等技術，與今日的operator功能類似，即讓語言模型分析螢幕畫面或HTML程式碼，自主決策並最終解決問題。", "label": 0}
{"text": "一般這些編碼器跟解碼器也是類神經網路，也是需要透過訓練資料來進行訓練的，如果你想要知道更多有關這種，把聲音訊號變成 Speech Unit，再把 Speech Unit 解回來相關的技術的話，可以閱讀一下這兩篇文章。", "label": 1}
{"text": "通用翻譯模型可能將所有語言轉換成單一的內部表示，再轉換成目標語言，因此即使缺乏某些語言配對的訓練數據，也能實現翻譯；這種通用翻譯方法的優勢，至少在2016年就已被認識到。", "label": 0}
{"text": "Meta的GSLM和Google的Audio LN只是眾多優秀語音語言模型的代表，這項技術並非近期才出現，GSLM早在2021年初就已問世。", "label": 0}
{"text": "先前已提及，現今圖像或影片生成主要仰賴Transformer類神經網路架構，儘管CNN曾廣泛應用，但Transformer因其簡潔的概念——將文字片段轉換為圖像塊——已成為主流。", "label": 0}
{"text": "Diffusion模型的解码器与其他模型类似，都需要输入噪声进行图像生成，区别在于Diffusion模型会反复使用同一个解码器进行迭代处理。", "label": 0}
{"text": "我的YouTube頻道上有許多影片詳細介紹經典影像生成模型，觀看這些影片，你就能了解這些模型的發展歷程和課程背景。", "label": 0}
{"text": "Sora 的部落格暗示他們很可能也採用了相同的技術製作影片。", "label": 0}
{"text": "好，這個是 DeepSeek 的答案啦！我一樣問ChatGPT o3-mini-high 這個問題，那他也是會做一下腦內小劇場，不過 o3 的腦內小劇場通常比較短，我有點懷疑他沒有完整呈現腦內小劇場的內容，他呈現給我們的只是摘要而已。呈現完腦內小劇場之後，他也給出了他的答案， o3 一樣覺得姜子牙比較可能贏過鄧不利多，看來兩個蠻聰明的模型都覺得姜子牙比較有勝算。結束，我得到這個問題的答案了。", "label": 1}
{"text": "還發現一個有趣的現象是值得跟大家分享，這個現象是負面的回饋。基本上沒有幫助對現階段的語言模型而言，所以你要提供給語言模型經驗，讓他能夠調整他行為的時候，給他正面的例子，比給他負面的例子要好。也就是說具體而言，提供給他過去哪些類似的問題得到正確答案，比提供給他過去哪些問題得到錯誤的答案，還更有效，還更能引導模型得到正確的答案。", "label": 1}
{"text": "因此，為避免模型學習到偏差，不如先訓練一個輔助模型，讓它自行學習「奔跑的狗」的影像特徵，再用其產出數據訓練圖片生成模型。", "label": 0}
{"text": "然而，儘管「雜訊」一詞可能暗示著無用資訊，事實上，它經常蘊含著極其重要的訊息。", "label": 0}
{"text": "換句話說，模型將不同語言轉換成其內部獨有的表徵，實現跨語言共享，其內部機制日後再詳述。", "label": 0}
{"text": "部分同學可能已接觸過VAE，但我的解釋方式或許與你以往有所不同，以下將以更易懂的方式說明VAE模型的結構。", "label": 0}
{"text": "Sora 的技術底層是擴散模型，這從其生成過程——由大量噪點逐步清晰可見——便可知曉。", "label": 0}
{"text": "儘管語言模型和語音語言模型表面運作機制相似，但語音模型的難度卻遠高於前者，主要原因在於語音訊號的複雜性：以16kHz取樣率為例，一秒鐘的語音就包含一萬六千個取樣點，也就是一萬六千個數值。因此，若以逐點處理的方式進行語音接龍，生成一秒鐘的語音需迭代一萬六千次，效率極低。", "label": 0}
{"text": "另外GPT-4o有自然而即時的互動，在其中的Demo裡面有一個人說，我們來做一個有趣的嘗試，話還沒有說完，GPT-4o居然說了一聲哇，然後那個人再說我要你去做某一件事情，如果還沒有看過OpenAI的Demo，你可以先看一下OpenAI的Demo，再來繼續這部影片。", "label": 1}
{"text": "開發機器學習模型如同打造 AI 代理的初始階段，過程繁複，環環相扣。", "label": 0}
{"text": "因此，我們可能在原本不足的文字描述中添加了額外細節，例如將「奔跑的狗」明確指定為「哈士奇在草原奔跑」或「柴犬在都市奔跑」，讓模型理解並生成不同的影像，解決了相同輸入產生不同輸出的問題。", "label": 0}
{"text": "然而，今日我們實際上借用「語言模型」的熱度，處理的對象並非僅限文字；無論是語音、圖片，只要能套用此概念，我們都稱之為語言模型，即使它們本質上分別是語音模型或影像模型。", "label": 0}
{"text": "這個AI科學家能力有限，無法實際操作實驗，只能協助撰寫研究計畫，其成果的真實性和重要性有待驗證，尤其是一些聲稱大幅縮短研究時間的案例，其可信度令人存疑。", "label": 0}
{"text": "要預測遊戲畫面，Genie 模型需要使用者動作資訊，但此資訊缺失。為此，我們訓練一個動作抽取模型，利用 AutoEncoder 概念，從前後兩個遊戲畫面推斷使用者動作，並將此資訊與前一畫面一起輸入圖片生成模型，以最小化生成畫面與實際畫面差異。", "label": 0}
{"text": "語音資料的應用方法多元且豐富，除了常見途徑外，還有許多論文探討如何讓語音語言模型善用文字資料，以下提供幾篇相關研究供參考。", "label": 0}
{"text": "好，那後來有了語言模型之後啊，人們就開始嘗試用語言模型，來當作AI agent，來運行一個agent，讓它在網路的世界中活動。", "label": 1}
{"text": "如何篩選關鍵資訊，避免語言模型記憶冗餘？可設計一個寫入模組，負責判斷哪些資訊存入長期記憶庫，哪些資訊則予以捨棄。", "label": 0}
{"text": "我們接下來將說明大型語言模型如何運用工具，而所謂的工具，也包含了語言模型本身。", "label": 0}
{"text": "本課程將快速綜覽生成式AI的技術進展與未來趨勢。", "label": 0}
{"text": "好，那以上是一個不精確的比喻了。如果你想要知道從數學上怎麼說明，給一個函式用深度學習（DL）的方法，會比用淺層學習的方法還要更有效率，從數學上怎麼證明它，請看以前我講過的深度學習（DL）理論系列影片，那我就把連結放在這個投影片上。", "label": 1}
{"text": "構建read模組的方法是將其視為一個檢索系統：輸入的觀察值即為查詢問題，模型的長期記憶體即為資料庫。系統根據問題從資料庫中檢索相關資訊，此方法與RAG技術完全一致，可直接套用任何RAG方法。", "label": 0}
{"text": "影片與圖片的處理方式在這個例子中並無本質區別，概念可以互相套用。", "label": 0}
{"text": "然後或者是叫它寫程式的話，就是有一個有關寫程式的指令。接下來告訴它說，那如果要寫這段程式的話，第一個要輸出的符號應該是print，有了print 之後，接下來輸出左括號，有了左括號之後，接下來要輸出引號，如果是解數學問題，就告訴它說，看到這個數學問題之後，後面要接令這個字，令後面要接x，x 後面要接等於。", "label": 1}
{"text": "因此，你需要訓練模型從含噪聲的圖片和文字中還原原始圖像。方法是：先自行添加噪聲，再訓練模型去除這些噪聲，最後就能用此模型生成圖片。", "label": 0}
{"text": "藉由內化不同語言，這些模型建構出獨特的內部表徵，讓它們能理解並處理各種語言，即使這些語言在表面上看來迥異，其底層機制日後再詳述。", "label": 0}
{"text": "所以，圖片或影像生成的挑戰就在於文字描述的不足，我們該如何克服呢？", "label": 0}
{"text": "訓練過程中，資料的多樣性可能導致模型學習困難。例如，「奔跑的狗」可能指哈士奇或柴犬，模型需根據不同輸入產生不同輸出，導致學習目標不一致，最終生成混亂、不穩定的結果，如同指示反覆變換的工作環境，使人難以適應，影像訓練亦然，文本描述通常無法完整涵蓋圖片資訊，造成單一文本對應多種影像的狀況。", "label": 0}
{"text": "他確實記住我先前告知他週五下午有機器學習課程，然而，模型的記憶機制並非完美無缺。模型自主決定記憶內容，並非直接儲存對話內容，而是經過加工與反思後才儲存，故反思過程可能產生錯誤。", "label": 0}
{"text": "好的，接下來我們將探討參數識別方法，詳細操作步驟請參考之前的教學影片。參數識別需要準備訓練數據，訓練數據的作用是告知模型：給定特定輸入token，應輸出哪個token。例如，輸入「你是誰？」，期望輸出「我」；輸入「你是誰？我」，期望輸出「是」；輸入「你是誰？我是」，期望輸出「人」；輸入「你是誰？我是人」，期望輸出「工」。", "label": 0}
{"text": "那剛才舉的例子都是以文字舉例，所以我怕你誤以為說這樣的通用模型只有在文字上有，其實不是，我們這邊拿語音做例子。在語音的發展也跟文字很像，也可以說有三個形態，第一個形態是這些通用模型是編碼器 (encoder)，輸入語音，輸出一堆人看不懂的向量，你要把它拿來做不同的事。比如說做語音辨識得接一個語音辨識的特化模型，做語者辨識得接一個語者辨識的特化模型，那過去我們實驗室呢，其實做了很多相關的研究，尤其是楊書文 (Shu-wen (Leo) Yang) 同學還有劉廷緯 (Andy T. Liu) 同學做了很多相關的研究，那如果你想要知道這一系列的模型發展的歷史，可以參考我寫的一篇 overview paper。楊書文同學還跟一個國際團隊合作，我們做了一個叫做 SUPERB 的 benchmark (基準測試)，可以 evaluate 這些 encoder (編碼器) 它的通用能力。那後來時代就進入了第二形態，有機會有一個固定架構的模型，只要稍微改一點點參數就可以做各式各樣語音相關的任務，大家可以看張凱爲 (Kai-Wei Chang) 同學做的這個網站，看一下這類模型的發展。後來就進入了第三形態，第三形態的模型跟你今天使用 ChatGPT 的感覺就很像，你可以給它一段語音，給它不同的指令就做不同的事情，那這邊呢，我想要 Demo 一個叫做 DeSTA2 的模型，這是我們實驗室的 Ke-Han Lu 同學跟 NVIDIA 的研究人員開發的一個模型。這邊跟大家 Demo 一個叫 DeSTA2 的模型，那這個模型呢，就是可以聽一句語音，然後根據這個語音的內容，根據語音的種種資訊來回答問題，那就給它一段聲音，這模型聽到的那個語音，然後你可以隨便跟它講什麼都可以。比如說這句話的文字內容，就要給我這句話的文字內容，它就把語音辨識的結果呈現出來，不過我想要中文的內容，所以說用中文回答我，所以它告訴我這句話的中文翻譯是什麼。", "label": 1}
{"text": "我們以西洋棋為例說明大型語言模型的能力。2022年，也就是ChatGPT出現之前的時代，研究人員已利用BigBench這個基準測試，嘗試讓當時的語言模型下棋。由於當時的模型無法處理圖像，棋盤資訊需以文字描述輸入。實驗結果顯示，即使是當時最強的模型也無法正確判斷下一步該如何將軍，但至少能遵守西洋棋規則；而較弱的模型則完全無法理解規則，任意下子。", "label": 0}
{"text": "懶惰的教師只需利用AI生成投影片及數位分身，便能輕鬆完成流水帳式的教學，實現全自動化課程。", "label": 0}
{"text": "模型的微調成本很高，即使只是細微的調整，也可能導致巨大的問題，因為它缺乏對輸入輸出關係的真正理解，只會基於訓練數據進行簡單的映射。", "label": 0}
{"text": "總之，現在圖像生成模型常運用Diffusion模型結合Transformer架構，SORA論文即為此例。", "label": 0}
{"text": "讓我們看看一些AI代理的範例，其中最著名的可能是一個由AI村民組成的虛擬村莊，它究竟何時問世？儘管2023年才嶄露頭角，但概念早有雛形，村莊中的非玩家角色皆由語言模型驅動。這些非玩家角色是如何運作的呢？簡單來說，每個角色都設定了獨特的目標，例如籌備情人節派對或準備考試，各有各的追求。而這些角色會透過文字形式獲取環境資訊（當時的語言模型僅能處理文字），來達成目標。", "label": 0}
{"text": "於是，我將合成的聲音和我的畫面素材交給Heygen製作影片，過程如你所見。因此，利用簡報製作數位分身講課是可行的，然而，真正的挑戰並非講課本身，而是備課階段耗時甚鉅，尤其是在構思簡報內容上。", "label": 0}
{"text": "DeepSeek和ChatGPT o3-mini-high都認為姜子牙勝算較大，儘管o3的推理過程簡短，可能有所省略。", "label": 0}
{"text": "那右邊這些步驟其實可以簡化成都是一樣的事情，右邊這些步驟其實都是一樣的任務，輸入是一串的 token，輸出就是一個 token，決定下一個 token 是什麼。而 token 的可能性是有限的，所以就是給一串 token 做一個選擇題，決定下一個 token 應該是什麼。", "label": 1}
{"text": "這一堂課呢是，一堂課搞懂生成式人工智慧的技術突破與未來發展，那我現在呢打算用一堂課的時間，很快地帶大家看過生成式人工智慧近年來發展的現況以及未來大家可以關注的技術", "label": 1}
{"text": "该基准测试由API的研究人员开发，其基线使用了类似RAG的技术，避免了将所有先前问题一股脑输入模型，因为长序列会超出大多数语言模型的处理能力。", "label": 0}
{"text": "比如說他覺得我是一個臺灣大學的學生，雖然我是老師。但是他從過去的對話誤以為我是一個學生，所以就存了一個錯誤的資訊。在他的記憶裡面，一堆他想記的東西，比如說我給過什麼演講，給過什麼tutorial，他都把它記下來就是了。", "label": 1}
{"text": "那另外呢,我們這邊還需要一個，語者自動分段標記的技術，那這樣的技術呢,叫做Speaker Dialerization，如果你看GPT-4-O的Demo的話，當有兩個以上的人跟他說話的時候，其實他是知道的,他可以知道誰是誰，所以他應該需要用到Speaker Dialerization的技術。", "label": 1}
{"text": "簡而言之，此投影片以AI說故事為例，說明AI如何根據使用者回饋（例如「這不是我要聽的故事」）即時調整行為。然而，此即時、非回合制的互動機制複雜，超出本課程範圍，有興趣者可參考林冠廷同學及其合作夥伴近期發表的論文，該論文評估並綜述了現有語音模型的互動能力（截至今年一月）。", "label": 0}
{"text": "網路影片音訊品質參差不齊，包含大量背景音樂和音效，用於訓練語音模型，模型勢必會學習這些干擾訊號。例如，GPT 4.0 演示中，其語音即伴隨鋼琴聲，這可能源於環境音，也可能為模型自身特性。然而，語音模型產生背景音樂或音效，或許並非缺陷，反而是獨特功能。", "label": 0}
{"text": "讓我們分析模型在此情境下的運作機制：語音模型同時處理兩個音訊通道，包含說話者的當下發言及其過往語句。偵測到說話者說出「我」字，且語句未完成，模型便輸出靜音，此靜音可視為特殊的語音單位。待說話者繼續發言並完成一個語句後，模型判斷對方已說完，則輪到模型回應。", "label": 0}
{"text": "有很多同學問我對於GPT-4o有什麼看法，所以我今天來講一下GPT-4o背後可能的語音技術。", "label": 1}
{"text": "怎麼讓模型同時聽跟說呢，就是要把聽跟說分成兩個不同的頻道，所以今天有一個聽的頻道，那這個是模型的麥克風，他會在聽人在說什麼，外界發生了什麼聲音，那另外模型會記錄，自己發出過什麼樣的聲音，但這兩個頻道應該要是分開的，而不是直接被混在一起的。", "label": 1}
{"text": "獲取海量聲音數據的途徑？其實很簡單，網路上豐富的影音平台就是絕佳來源，OpenAI便是如此，據紐約時報四月報導，他們利用超過一百萬小時的YouTube影片訓練語言模型。", "label": 0}
{"text": "然而，他補充道，若鄧不利多一開始便使用移形換影，近身施放索命咒，或許仍有勝算。此勝算的关键在于杏黄旗能否抵御索命咒；《封神演义》中，杏黄旗似乎无物不挡，连翻天印也奈何不得，那么，面对索命咒又如何？哈利波特世界中，似乎也无物能挡索命咒，故此，这便是矛与盾的较量，成败全凭杏黄旗能否抵挡索命咒。", "label": 0}
{"text": "現今只要模型包含自注意力機制，便常被簡稱為 Transformer，此名稱容易讓人聯想到變形金剛。然而，Transformer 命名緣由並未在論文中闡明，推測其名稱可能源於模型能將輸入轉換為輸出的特性，但此特性並非Transformer模型獨有。", "label": 0}
{"text": "近期AI代理程式再度聲名大噪，並非源於任何AI代理程式本身的技術突破，而是大型語言模型的進步激發了人們利用其實現個人代理程式的願望。", "label": 0}
{"text": "深入探討層級結構：一個層通常包含多個子層，因此它並非單純的一層，而是由許多更小的函式組成的複合函式。這些子層主要分為兩種：一種是考慮所有輸入的自注意力層，能全面整合資訊；另一種則專注於單個詞元，進行更深入的分析，因此一個層內同時存在全局和局部處理機制。", "label": 0}
{"text": "請協助我在臺大課程網填寫李宏毅老師本學期機器學習課程的加簽申請表單。", "label": 0}
{"text": "藉由反射模組將經驗圖像化後，許多基於圖的增強式記憶方法便能直接應用於AI代理，這也印證了OpenAI積極將ChatGPT發展為AI代理，使其具備記憶功能的企圖。", "label": 0}
{"text": "此外，我們也需要語者自動分段標記技術（Speaker Diarization）。GPT-4-O 的演示顯示，它能區分多位說話者，因此必然使用了這項技術。", "label": 0}
{"text": "與Clip中不良範例的生成方式類似，該方法也採用隨機匹配圖片和文字的方式製造錯誤樣本，但內部機制則有所不同。", "label": 0}
{"text": "AI agents and RAG systems differ fundamentally in the nature of their memories: RAG accesses the collective experience of the internet, while an AI agent's memory comprises its own personal experiences.  The key distinction lies in the source of information, not the search technology itself, which is directly transferable.", "label": 0}
{"text": "然而，文字僅能捕捉語音資訊的片段，例如「好好笑」後接幾聲笑，語音辨識僅能轉錄「好好笑」，而忽略笑聲；因此，即使用語音合成還原「好好笑」，原始語音中重要的情感資訊（例如笑聲）便已遺失。", "label": 0}
{"text": "明白了，將合成音訊和我的畫面素材提供給Heygen平台，即可生成影片。因此，利用簡報製作數位人講課是可行的，但重點不在講課環節，而在於備課，尤其是構思簡報內容最耗時。", "label": 0}
{"text": "此外，我們還需要一種語者自動分段標記技術，即Speaker Diarization。GPT-4-O 的演示顯示，它能夠區分多個說話者，這意味著它應用了該技術。", "label": 0}
{"text": "那怎麼樣打造這個read的模組呢？其實你可以想這個read的模組，就想成是一個retrieval的system，想成是一個檢索的系統，那第一萬步看到的observation其實就是問題，那模型的AI agent的memory長期記憶，其實就是資料庫。那你就把拿這個檢索系統，根據這個問題從這個資料庫裡面，檢索出相關的資訊，那這整個技術跟RAG沒有什麼不同，其實它就是RAG，你可以直接把RAG的任何方法，直接套用到這個地方。", "label": 1}
{"text": "這就是一個 AI Agent 的雛形，開發機器學習 (ML) 模型也需要非常多的步驟，它也是一個需要多步驟才能完成的任務。", "label": 1}
{"text": "那麼，解決方案是什麼呢？於是構想出通用翻譯系統：只需指定源語言和目標語言（例如，中文譯英文），系統便能自動完成翻譯。", "label": 0}
{"text": "動作抽取模型準確預測動作，則圖片生成模型就能準確生成圖片；反之，圖片生成模型的準確生成，也暗示動作抽取模型成功預測了使用者實際按下的按鈕，但需注意，這些動作僅為模型預測結果，而非真實動作。", "label": 0}
{"text": "或許有人會質疑是否需要大量Sky與他人的對話數據進行訓練，但這可能大可不必，因為我們之前討論文字模型時提到，微調通常不需要大量數據，預訓練模型已儲備豐富知識，微調僅需錦上添花；同理，完成語音預訓練後，模型已能模仿多種說話風格，只需少量Sky的語音樣本，即可準確模仿其說話方式。", "label": 0}
{"text": "比較Gain和Diffusion Model孰優孰劣毫無意義，因為Gain不過是一種增強模型能力的技術，如同RLHF一般，可應用於VAE、Flow或Diffusion Model等各種模型架構，透過後端添加Discriminator來提升Decoder效能。", "label": 0}
{"text": "那有人就想說那不同的語言的翻譯要開發不同的系統，那我們開發得完這麼多翻譯系統嗎？世界上有 7000 種語言，如果每一種成對的語言都要開發翻譯系統，那要開發 7000，7000 個翻譯系統永遠也開發不完。", "label": 1}
{"text": "Sora 使用擴散模型，其生成過程如同從大量雜訊中逐步精煉圖像般，這在許多論文和部落格中都有描述。", "label": 0}
